<?xml version="1.0" encoding="ISO-8859-1"?>
<!DOCTYPE proceeding SYSTEM "proceeding.dtd">
<proceeding ver="6.0" ts="04/10/2010">
<conference_rec>
	<conference_date>
		<start_date>11/14/2007</start_date>
		<end_date>11/17/2007</end_date>
	</conference_date>
	<conference_loc>
		<city><![CDATA[Toronto]]></city>
		<state></state>
		<country>Canada</country>
	</conference_loc>
	<conference_url>www.futureplay.org</conference_url>
</conference_rec>
<series_rec>
	<series_name>
		<series_id>SERIES11563</series_id>
		<series_title><![CDATA[Future Play]]></series_title>
		<series_vol></series_vol>
	</series_name>
</series_rec>
<proceeding_rec>
	<proc_id>1328202</proc_id>
	<acronym>Future Play '07</acronym>
	<proc_desc>Proceedings of the 2007 conference</proc_desc>
	<conference_number>2007</conference_number>
	<proc_class>conference</proc_class>
	<proc_title>Future Play</proc_title>
	<proc_subtitle></proc_subtitle>
	<proc_volume_no></proc_volume_no>
	<isbn13>978-1-59593-943-2</isbn13>
	<issn></issn>
	<eissn></eissn>
	<copyright_year>2007</copyright_year>
	<publication_date>11-14-2007</publication_date>
	<pages>279</pages>
	<plus_pages></plus_pages>
	<price><![CDATA[]]></price>
	<other_source></other_source>
	<abstract>
		<par><![CDATA[<p>The Future Play Conference focuses on three main themes. The first theme, future game development, addresses academic research and emerging industry trends in the area of game technology and game design. The second theme, future game impacts and applications, includes academic research and emerging industry trends focused on designing games for learning, for gender, for serious purposes, and to impact society. Finally, the third theme, future game talent, is designed to provide a number of industry and academic perspectives on the knowledge, skills, and attitude it takes to excel in the games industry.</p> <p>Future Play addresses these issues through exciting and thought-provoking keynotes from leaders in academia and industry, peer-reviewed paper sessions, panel sessions (including academic and industry discussions), workshops (including design, technology, and career workshops), and exhibitions of posters, games, and the latest game technologies and supports from industry-leading vendors. The highlight of the games exhibition is a peer-reviewed competition of games in three categories: Indie Games, Serious Games, and Student Games.</p> <p>For Future Play 2007, Algoma University College teams up with the Ontario University Institute of Technology to give Future Play attendees the chance to interact with some of the most talented people in the gaming world today.</p>]]></par>
	</abstract>
	<publisher>
		<publisher_id>PUB27</publisher_id>
		<publisher_code>ACMNY</publisher_code>
		<publisher_name>ACM</publisher_name>
		<publisher_address>2 Penn Plaza, Suite 701</publisher_address>
		<publisher_city>New York</publisher_city>
		<publisher_state>NY</publisher_state>
		<publisher_country>USA</publisher_country>
		<publisher_zip_code>10121-0701</publisher_zip_code>
		<publisher_contact>Bernard Rous</publisher_contact>
		<publisher_phone>212 869-7440</publisher_phone>
		<publisher_isbn_prefix></publisher_isbn_prefix>
		<publisher_url>www.acm.org/publications</publisher_url>
	</publisher>
	<sponsor_rec>
		<sponsor>
			<sponsor_id>SP1813</sponsor_id>
			<sponsor_name>Algoma University College</sponsor_name>
			<sponsor_abbr></sponsor_abbr>
		</sponsor>
		<sponsor>
			<sponsor_id>SP1816</sponsor_id>
			<sponsor_name>Government of Canada, FedNor</sponsor_name>
			<sponsor_abbr></sponsor_abbr>
		</sponsor>
		<sponsor>
			<sponsor_id>SP1822</sponsor_id>
			<sponsor_name>Garage Games</sponsor_name>
			<sponsor_abbr></sponsor_abbr>
		</sponsor>
		<sponsor>
			<sponsor_id>SP1814</sponsor_id>
			<sponsor_name>University of Ontario Institute of Technology</sponsor_name>
			<sponsor_abbr></sponsor_abbr>
		</sponsor>
		<sponsor>
			<sponsor_id>SP1815</sponsor_id>
			<sponsor_name>Province of Ontario, Ministry of Economic Development and Trade</sponsor_name>
			<sponsor_abbr></sponsor_abbr>
		</sponsor>
		<sponsor>
			<sponsor_id>SP1817</sponsor_id>
			<sponsor_name>Visualization Design Institute, Sheridan Institute of Technology and Advanced Learning</sponsor_name>
			<sponsor_abbr></sponsor_abbr>
		</sponsor>
		<sponsor>
			<sponsor_id>SP1818</sponsor_id>
			<sponsor_name>Sault Ste. Marie Innovation Centre</sponsor_name>
			<sponsor_abbr></sponsor_abbr>
		</sponsor>
		<sponsor>
			<sponsor_id>SP1820</sponsor_id>
			<sponsor_name>Arcademy Games Awards Festival Arcadia</sponsor_name>
			<sponsor_abbr></sponsor_abbr>
		</sponsor>
		<sponsor>
			<sponsor_id>SP1819</sponsor_id>
			<sponsor_name>SchoolFinder</sponsor_name>
			<sponsor_abbr></sponsor_abbr>
		</sponsor>
		<sponsor>
			<sponsor_id>SP1821</sponsor_id>
			<sponsor_name>Microsoft User Research Group</sponsor_name>
			<sponsor_abbr></sponsor_abbr>
		</sponsor>
		<sponsor>
			<sponsor_id>SP1823</sponsor_id>
			<sponsor_name>Bug-Tracker.Com</sponsor_name>
			<sponsor_abbr></sponsor_abbr>
		</sponsor>
	</sponsor_rec>
	<categories>
		<primary_category>
			<cat_node/>
			<descriptor/>
			<type/>
		</primary_category>
	</categories>
	<chair_editor>
		<ch_ed>
			<person_id>PP36038922</person_id>
			<author_profile_id><![CDATA[81331495944]]></author_profile_id>
			<orcid_id></orcid_id>
			<seq_no>1</seq_no>
			<first_name><![CDATA[Bill]]></first_name>
			<middle_name><![CDATA[]]></middle_name>
			<last_name><![CDATA[Kapralos]]></last_name>
			<suffix><![CDATA[]]></suffix>
			<affiliation><![CDATA[University of Ontario Institute of Technology]]></affiliation>
			<role><![CDATA[Conference Chair]]></role>
			<email_address><![CDATA[]]></email_address>
		</ch_ed>
		<ch_ed>
			<person_id>P925261</person_id>
			<author_profile_id><![CDATA[81100424432]]></author_profile_id>
			<orcid_id></orcid_id>
			<seq_no>2</seq_no>
			<first_name><![CDATA[Mike]]></first_name>
			<middle_name><![CDATA[]]></middle_name>
			<last_name><![CDATA[Katchabaw]]></last_name>
			<suffix><![CDATA[]]></suffix>
			<affiliation><![CDATA[University of Western Ontario]]></affiliation>
			<role><![CDATA[Conference Chair]]></role>
			<email_address><![CDATA[]]></email_address>
		</ch_ed>
		<ch_ed>
			<person_id>P925243</person_id>
			<author_profile_id><![CDATA[81342508305]]></author_profile_id>
			<orcid_id></orcid_id>
			<seq_no>3</seq_no>
			<first_name><![CDATA[Jay]]></first_name>
			<middle_name><![CDATA[]]></middle_name>
			<last_name><![CDATA[Rajnovich]]></last_name>
			<suffix><![CDATA[]]></suffix>
			<affiliation><![CDATA[Algoma U]]></affiliation>
			<role><![CDATA[Conference Chair]]></role>
			<email_address><![CDATA[]]></email_address>
		</ch_ed>
	</chair_editor>
</proceeding_rec>
<content>
	<section>
		<section_id>1328203</section_id>
		<sort_key>10</sort_key>
		<section_seq_no>1</section_seq_no>
		<section_type>SESSION</section_type>
		<section_title><![CDATA[Social, ethical and cultural perspectives on games]]></section_title>
		<section_page_from>1</section_page_from>
	<article_rec>
		<article_id>1328204</article_id>
		<sort_key>20</sort_key>
		<display_label>Pages</display_label>
		<pages>8</pages>
		<article_publication_date>11-14-2007</article_publication_date>
		<seq_no>1</seq_no>
		<title><![CDATA[Towards an ethics of video gaming]]></title>
		<page_from>1</page_from>
		<page_to>8</page_to>
		<doi_number>10.1145/1328202.1328204</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1328204</url>
		<abstract>
			<par><![CDATA[<p>Video gaming continues to be an ethically contentious topic, not the least because of its claimed negative effects on individuals and the society they live within. By taking a consequentialist approach to the issue---setting out the consequences of video games and gaming, and assessing those consequences for their ethically relevant properties---video gaming can be given a partial moral defence against its critics.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[consequentialism]]></kw>
			<kw><![CDATA[ethics]]></kw>
			<kw><![CDATA[philosophy]]></kw>
			<kw><![CDATA[video games]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>K.4.1</cat_node>
				<descriptor>Ethics</descriptor>
				<type>S</type>
			</primary_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10003456.10003457.10003580.10003543</concept_id>
				<concept_desc>CCS->Social and professional topics->Professional topics->Computing profession->Codes of ethics</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003456.10003457.10003580.10003543</concept_id>
				<concept_desc>CCS->Social and professional topics->Professional topics->Computing profession->Codes of ethics</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<person_id>P766009</person_id>
				<author_profile_id><![CDATA[81309486771]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Grant]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Tavinor]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Lincoln University, Canterbury, New Zealand]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[For a philosophical account of these issues, see Walton, K. <i>Mimesis as Make-Believe.</i> Harvard University Press, Cambridge MA, 1990; one interesting account of the cognition of pretence is Nichols S. and Stich, S. "A Cognitive Theory of Pretense," in <i>Cognition</i>, 74, 2000: 115--147.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Nichols and Stich, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Plato, <i>The Republic.</i> Translated with an introduction by Desmond Lee. 2&#60;sup&#62;nd&#60;/sup&#62; edition. Penguin Books, London 1987: Book X, Part 3.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Tavinor, G. "Video Games and Interactive Fiction," <i>Philosophy and Literature</i>, April 2005, Volume 29, Number 1.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[This so-called "paradox of horror" is dealt with in Carroll, N. <i>The Philosophy of Horror or Paradoxes of the Heart.</i> Routledge, New York, 1990.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[
<i>South Park</i> Episode 147, "Make Love Not Warcraft," Comedy Central, 2006.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[See for example: Anderson, C. A., &amp; Bushman, B. J. "Effects of Violent Games on Aggressive Behavior, Aggressive Cognition, Aggressive Affect, Physiological Arousal, and Prosocial Behavior: A Meta-analytic Review of the Scientific Literature," <i>Psychological Science</i>, 12, 2001:353--359; Anderson, C. A. and Dill, D. E., "Video Games and Aggressive Thoughts, Feelings, and Behavior in Laboratory and Real Life," <i>Journal of Personality and Social Psychology</i>, 78 No. 4, 2000: 772--790; Gentile, D. A., Lynch, P., Linder, J. &amp; Walsh, D. "The Effects of Violent Video Game Habits on Adolescent Hostility, Aggressive Behaviors, and School Performance," <i>Journal of Adolescence</i>, 27, 2004:5--22.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Anderson and Dill, 2000, p.774.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Durkin, K. <i>Computer Games: Their Effects on Young People.</i> Office of Film and Literature Classification, Sydney, NSW, 1995; Freedman, J. L. <i>Media Violence and Its Effect on Aggression: Assessing the Scientific Evidence.</i> University of Toronto Press, Toronto, 2002; Griffiths, M. "Violent Video Games and Aggression: A Review of the Literature," <i>Aggression and Violent Behavior</i>, vol.4, No. 2, 1999:203--212.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Pinker, S. <i>The Blank State.</i> Penguin Books, London, 2003: p.311.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Gentile, et al, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Griffiths, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[A study by the E<i>ntertainment Association of Australia</i> presented at the <i>Australasian Conference of Interactive Entertainment</i>, held in Sydney in 2005, found that the average age for gamers in Australia was 24, and was trending upwards.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Freedman, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Nichols and Stich, 2000, p.120.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Anderson and Dill, 2000, p.772.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Grossman, D. and DeGaetano, G. <i>Stop Teaching Our Kids to Kill: A Call to Action Against TV, Movie, and Video Game Violence.</i> Crown Publishers, New York, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[
<i>Fox News</i>, 17&#60;sup&#62;th&#60;/sup&#62; April, 2007; interviewed by David Gregory, <i>MSNBC</i>, 17&#60;sup&#62;th&#60;/sup&#62; April, 2007.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[
<i>NBC News</i>, 18&#60;sup&#62;th&#60;/sup&#62; April, 2007.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[6th U.S. Circuit Court of Appeals, <i>James v. Meow Media</i>, No. 00--5922, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Carroll, N. <i>A Philosophy of Mass Art.</i> Clarendon Press, Oxford, 1998: p.301.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Utilitarians have long been aware of the problem that such a principle seems to over-value the so-called "base-pleasures" to the exclusion of refined ones. See for example Chapter 4 of Mill, J. S. <i>Utilitarianism; On Liberty; Considerations on Representative Government; Remarks on Bentham's Philosophy.</i> Dent, Tuttle, London, 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[Smuts, A. "Are Video Games Art?" <i>Contemporary Aesthetics</i>, 2004, archived at http://www.contempaesthetics.org/newvolume/pages/article.php?articleID=299.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>537939</ref_obj_id>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[Greenfield, P. M. <i>Mind and Media: The Effects of Television, Video Games, and Computers.</i> Harvard University Press, Cambridge, Mass., 1984.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>983348</ref_obj_id>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[Gee, J. P. <i>What Video Games Have to Teach Us About Learning and Literacy.</i> Palgrave Macmillan, New York, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Towards an Ethics of Video Gaming Grant Tavinor Lincoln University PO Box 84 Canterbury New Zealand 
 Phone: +64 (3) 325-3820, 8455 tavinorg@lincoln.ac.nz ABSTRACT Video gaming continues to be an ethically 
contentious topic, not the least because of its claimed negative effects on individuals and the society 
they live within. By taking a consequentialist approach to the issue setting out the consequences of 
video games and gaming, and assessing those consequences for their ethically relevant properties video 
gaming can be given a partial moral defence against its critics.  Categories and Subject Descriptors 
K.4.1 [Computers and Society]: Public Policy Issues - ethics.  General Terms Human factors, Theory. 
 Keywords Video games, ethics, consequentialism, philosophy. 1. INTRODUCTION Video games have been a 
target of moral condemnation from very early on in their short history. Often this criticism is linked 
to the apparent consequences of video gaming, and it frequently seems assumed that if games do have negative 
consequences then they are morally blameworthy for this reason. This consequential and moral fault is 
often taken to be a key reason to restrict or otherwise legislate the use of or access to video games. 
This type of approach can be criticised on at least three fronts. First, we can question whether the 
attributed consequences are real. While this is mostly an empirical issue, there are a number of theoretical 
considerations that are raised by the common claims that video games have negative effects on individuals 
and the society they live within. Second, we can question the assumption that if video games do have 
these negative consequences, that they are morally blameworthy for this fact. Finally, even if it is 
shown that video games do have negative effects, and that these do establish the moral culpability of 
gaming, it can be questioned whether this does in fact settle the issue of the rights or wrongs of playing 
such games. My discussion of each of the questions is intended to provide an ethical defence of video 
gaming, though one that is cognisant of the potential moral dangers video games do raise. Permission 
to make digital/hard copy of part of this work for personal or classroom use is granted without fee provided 
that the copies are not made or distributed for profit or commercial advantage, the copyright notice, 
the title of the publication, and its date of appear, and notice is given that copying is by permission 
of the ACM, Inc. To copy otherwise, to republish, to post on servers, or to redistribute to lists, requires 
prior specific permission and/or a fee. FuturePlay 2007, November 15-17, 2007, Toronto, Canada. Copyright 
2007 ACM 978-1-59593-943-2/07/0011...$5.00  2. VIDEO GAMES AND CONSEQUENTIALISM The ethical approach 
I will take in this paper will be basically consequentialist in form. The ethics of video gaming will 
here be assumed to be settled by first determining the consequences of these games, and then assessing 
these consequences for their ethically relevant qualities. Of course, as a normative moral principle 
consequentialism is incomplete as it owes us an explanation of just what consequences are ethically relevant. 
Utilitarianism will serve us pretty well in this case, because it often does seem to be the consequences 
gaming for the happiness or well-being of individuals that are germane to their ethical evaluation: indeed, 
many moral critics have claimed that people are demonstrably worse off in these terms given the existence 
of video gaming. Other kinds of consequences might be factored into this issue as appropriate, and so 
I will not prejudge that happiness or well-being are the only consequences that are relevant here. Well-being, 
more widely conceived, can acknowledge the values we have in fostering learning, sociability and social 
cohesion, good character and personal development, even though these things in themselves may not produce 
happiness on all occasions. Furthermore, it may be that there are non-consequential factors that we should 
acknowledge in this ethical issue: the obligation to do no harm, and the right to personal freedom being 
examples. Modern ethics is very much a mixed bag, picking and choosing among principles where those principles 
are needed to capture and explain our intuitions about a given ethical issue. This cannot be taken as 
a fault in current ethical thinking, but may be intrinsic to the process of ethics, which after all deals 
with the rather messy business of human life. Thus, ethical consequentialism gives us a manner in which 
to orientate this debate that is at least minimally empirical, and so even if problematic, it has the 
virtue of grounding an otherwise quite uncertain issue. That is, we determine the consequences of gaming, 
and then assess the ethical significance of those consequences while factoring in any other non-consequentialist 
ethical considerations that may seem relevant. The natural question to now ask is just what are the consequences 
of gaming on which their ethical evaluation might rest? Here we might for the sake of explanation make 
a distinction between the immediate consequences of gaming those that arise as the game is played and 
the non-immediate consequences those consequences that follow beyond the playing of the game. We might 
call the former internal consequences, and the latter external consequences. This is not to be taken 
as the claim that such classes can be unequivocally drawn it is, rather, an expository distinction intended 
to clarify the issues here.  3. INTERNAL CONSEQUENCES The internal consequences of a video game are 
those that arise in connection with perhaps most strongly during the duration of video gaming. So what 
are these internal consequences? There is one type of apparent consequence that we cannot count, even 
though many critics seem of the opinion that it does contribute to the moral criticism of gaming. The 
apparent violent, sadistic, and otherwise criminal events that occur within games cannot be factored 
into the consequentialist account for the very simple reason though often unacknowledged one that the 
worlds and events of video gaming are fictional. Grand Theft Auto, for example, has repeatedly been condemned 
for allowing its players to perform acts of theft, assault, murder, and worse. But these apparent actions 
are fictional ones, and really there are no such things involved in the game. Grand Theft Auto, and similar 
games, might be thought of as crime simulators, in that similar to flight simulators, they allow their 
players to indulge in immediately non-consequential behaviour that pursued in reality can be quite dangerous. 
The shearing of the behaviour from its normal consequences in fact seems to be a pre-requisite for a 
player s ability to enjoy it: if what was fictionally occurring in the world of Grand Theft Auto was 
genuinely occurring, the player would not be enjoying it quite so much! It might be thought that I am 
arguing against a straw man here, but there is an interesting way in which to show that this confusion 
actually exists. Video games are very often called violent or even ultra violent, especially in the popular 
media. Almost all gaming, however, is not in the least bit violent: it is only fictional that there is 
violence occurring. The violence engaged in is a pretence, or a game of make-believe much like that described 
by a number of philosophers and scientists in the literature on pretence, fictional works, and fictive 
appreciation [1]. This is not merely semantic disingenuousness on my part. It is the moral critic of 
gaming in their use of the term violent video game that is being semantically disingenuous. Violent video 
game is an emotive term, but one that rides carelessly over the important fact that fictions do not necessarily 
replicate the properties that they make fictional: to pretend violence does not demand that the pretender 
be actually violent, just as to pretend to use a telephone does not demand that one actually use a telephone 
[2]. And so, the putative violence of a violent video game cannot be assumed to be one of its consequences. 
It may be that willingly engaging with fictional violence and enjoying doing so has effects external 
to the games essentially the charge that Plato makes against tragedy in The Republic [3] but this would 
then become an external consequence, which I will discuss later. It is quite a different issue to question 
whether these fictionally violent, criminal, or immoral states are genuinely immoral: is fictionally 
performing a crime, and enjoying doing so, not only fictionally immoral, but also genuinely immoral? 
This is a complex question that I cannot address in full here, though it does seem to depend in part 
on a different set of internal consequences. While the scenarios depicted in most video games are fictional, 
and many of a gamer s responses and actions in regard to those scenarios are fictional [4], it is nevertheless 
the case that there are genuine facts about what is happening to the gamer. They are, for one thing, 
imaginatively engaging with what some would find as offensive or objectionable content. What one imagines, 
and what they feel about it, are not morally neutral things: consider what our moral response is to people 
who fantasise about acts of cannibalism or pedophilia. It is not clear in consequentialist terms that 
this would allow us to condemn gaming as immoral however, for the very obvious reason that gamers seem 
to enjoy this content, even if they acknowledge its dubious nature. Such an enjoyment would count not 
as a negative consequence, but as a positive one. Of course, for the critic of gaming, their tastes are 
likely to be genuinely offended by such content, and so the experience might count as a negative for 
them. But it would be perverse to blame the game for this reason, especially when such people can easily 
avoid the game given the classification and ratings legislation that has become more widespread in recent 
times. Still, one suspects that this observation will not be enough to assuage such critics, and that 
what really offends them is the idea that other people enjoy such content. Incidentally, it is an interesting 
question, indeed an almost paradoxical one, why gamers enjoy objectionable or prima facie unpleasant 
content such as that derived from violent or horror-filled games [5]. A further range of internal consequences 
follows from what gamers are not doing due to their playing of video games. A common criticism is that 
time spent playing video games is time not spent being active outdoors, playing with friends, and reading 
books. Games players are often characterised as passive, insular, and unhealthy. This is reflected most 
obviously in the stereotype of gamers as socially maladjusted nerds huddled in front of their computers: 
an image captured quite vividly in a recent episode of South Park, where Cartman and his friends are 
shown morphing into such types as a result of obsessively playing a Massively Multiplayer Online Role 
Playing Game (MMORPG) [6]. Thus, even if gaming is not harmful per se, if excessive gaming does have 
such counterfactual conditional effects if gamers had not been playing video games, they might have been 
reading a good book, interacting with friends, and playing outside then video games can be morally condemned. 
Often this issue is generated by considerations of gaming addiction, a topic of continued public interest. 
I cannot deal with this issue in full here, but I will note that the idea of gaming addiction is not 
without difficulties. The research into gaming addiction is very preliminary, and this is a very good 
reason to be more tentative than have some recent media reports in proclaiming that video games are genuinely 
addictive. Most importantly, the normative implications of addiction in this context should make us very 
wary of endorsing the attribution. Some gamers certainly play games excessively, and to the detriment 
of their physical or social health. But this is not sufficient to establish that these gamers are addicted, 
because such behaviour also arises as a result of people acting on the basis of their values. Artists, 
academics, and sportspeople are all good examples of individuals who spend their time to the exclusion 
of other potentially valuable activities. We do not necessarily label these people as addicted, however, 
because their dedicated lifestyles allow them to produce things that we hold an independent value for. 
The temptation to characterise excessive gaming as an addiction arguably betrays a lack of value in the 
activity of gaming itself: the popular media in particular is not yet comfortable with assigning intrinsic 
value to games or gaming. I will return to this issue of the apparent normative bias against gaming later 
in this paper. Still, it is clear that games are often played to the exclusion of other activities, and 
if this playing is excessive whether or not it is technically an addiction this could count as a clear 
negative in the consequentialist tally.  4. EXTERNAL CONSEQUENCES In addition to these internal consequences, 
games can be assessed on what I earlier called their external consequences. These are those consequences 
that games have outside of the immediate sphere of their playing. It is these purported consequences 
of gaming that often seem the most worrying, and that capture the public consciousness on this issue. 
In their mildest form, such worries are encapsulated in the concern that parents and educators have about 
the effects of gaming on childhood aggression or sociability, and these issues have been the topic of 
a number of recent psychological studies [7]. In their starkest form such putative consequences are illustrated 
by the frequent claims that video games bear causal responsibility for some recent notorious crimes. 
It is an often-repeated fact that Eric Harris and Dylan Klebold the perpetrators of the Columbine school 
massacre were gamers. The anti-gaming attorney Jack Thompson has brought numerous (unsuccessful) law 
suits against the games industry, charging the games with responsibility for a number of copycat murders. 
In particular, Thompson filed suit against a number of games companies, citing partial responsibility 
for the 14 year old Michael Carneal s 1997 killing of three students at Heath High School in Kentucky. 
To distinguish between these two kinds of claim which instinctively seem of very different credibility 
we might make a further expository distinction here between proximal or limited external consequences 
those following immediately on from episodes of gaming and extended consequences the attribution of causal 
responsibility for events, such as the school killings just noted, that are much more distant from gaming 
episodes. These two classes are not sharply defined, of course, and a number of theorists claim that 
the extended consequences of games can be attributed to the long term effects of the limited consequences 
of games. An example would be if an individual s desensitisation to media violence caused by exposure 
to video gaming had caused a subsequent instance of criminal behaviour. 4.1 Proximal External Consequences 
As noted, there is an increasing literature on the consequences of gaming on the immediate behaviour 
of players subsequent to gaming episodes, and effects on their proximal character, personal development, 
self-image, or values. Whether or not games have these consequences is an empirical rather than a philosophical 
issue. A number of the studies already noted do claim a perceived effect, including increased affective 
arousal, increased behavioural aggression, increased access to aggressive thoughts, and increased delinquency 
[7]. Such studies also step beyond this behavioural or physiological evidence, and make theoretical claims 
about the causes in operation here. For example, Anderson and Dill claim that the documented effects 
of violent video gaming on aggressive behaviours and thoughts can explained in terms of video games priming 
subjects to adopt violent behavioural scripts or schemas, and by increasing the player s affective arousal 
which in turn reinforces the adoption of these violent behavioural scripts [8]. Furthermore, and capturing 
a common theme of the literature, repeated exposure to graphic scenes of violence is likely to be desensitizing, 
potentially having long term effects, meaning that long term video game players can become more aggressive 
in outlook, perceptual biases, attitudes, beliefs, than they were before the repeated exposure or would 
have become without such exposure [8]. There is a natural temptation by gamers and those wanting to give 
a moral defence of gaming to reject this experimental literature out of hand, but they would be doing 
their cause a disservice by doing so. Even so, the claims of perceived effect are not beyond doubt. Several 
recent meta-studies suggest the claims of the connection between aggression and violent behaviour and 
video games may be overstated, and that there is little evidence that video games adversely affect children 
to a significant degree [9]. At the very least the evidence seems equivocal; at worst it may seem normatively 
biased. Steven Pinker suggests the latter when he notes that, Among conservative politicians and liberal 
health professionals alike it is an article of faith that violence in the media is a major cause of American 
violent crime. The American Medical Association, the American Psychological Association, and the American 
Academy of Pediatrics testified before Congress that over 3,500 studies had investigated the connection 
and only 18 had failed to find one. Any social scientist can smell fishy numbers here, and the psychologist 
Jonathan Freedman decided to look for himself. In fact, only two hundred studies have looked for a connection 
between media violence and violent behaviour, and more than half have failed to find one. The others 
found correlations that are small and readily explainable in other ways for example that violent children 
seek out violent entertainment, and that children are temporarily aroused (but not permanently affected) 
by action-packed footage. [10] There are a number of conceptual issues that threaten to disrupt such 
empirical claims and the theoretical models that are built on top of them. It is worthwhile addressing 
some of these problems here very briefly. First, a number of the psychological studies into the consequences 
of video gaming for violent behaviour or attitudes can be questioned in terms of what sort of evidence 
they provide: whether it is correlational or causal evidence. Some of the studies of the links between 
video games and aggression do seem almost entirely correlational, and admit as much [11].  Second, the 
extent of these findings and their relevance to the wider issues of violence in society and the ethics 
of video gaming can be questioned. Mark Griffiths has argued that in as much as studies have shown a 
link between video games and aggressive behaviour, they have demonstrated only a very short­term link 
evident in the play of children immediately after episodes of video gaming, and then only in very young 
children [12]. That the subjects of many of these studies are young children means that when it comes 
to assessing the ethics of video gaming, such studies can be only be of limited use, because gaming is 
in a large part an adult activity (and is becoming more so [13]), and it is already accepted by most 
reasonable gamers and members of the gaming industry that many video games are not suitable for children. 
Third, the theoretical mechanisms invoked in the psychological literature are often beset by significant 
problems. The notion of is desensitisation is especially conceptually suspect. Desensitising implies 
that one s sensitivity to images of violence is weakened by repeated exposure to such content, but is 
it a necessary consequence of this that one s sensitivity to acts of violence is thus attenuated? Jonathan 
Freedman claims that there is little evidence that exposure to images of violent real events let alone 
the fictional ones that comprise the vast proportion of video game violence does desensitise people to 
violence in the sense of giving them a blasé attitude toward genuine violence [14]. As noted, Anderson 
and Dill s account of the theoretical mechanism behind the perceived effects of video game playing on 
violent thoughts, attitudes, and behaviours, relies on a cognitive model that sees these as the result 
of the rehearsal of violent cognitive scripts. Unfortunately, in their model Anderson and Dill do not 
acknowledge a quarantine effect that is exhibited in the cognition in involved pretence and fiction. 
In their theory of pretence, Shaun Nichols and Stephen Stich note that, the events that occurred in the 
context of the pretence have only a quite limited effect on the post-pretence cognitive state of the 
pretender [15]. This cognitive quarantine is necessary because first, our ability to interpret a given 
pretence or fictional episode demands that we are able to recognise what is true in the fiction, which 
will often differ from what we believe to be true of the real world, and second, without an effective 
cognitive quarantine between pretence and belief, inferential havoc would threaten to take hold in the 
mind of the pretender. Children sometimes do mistake what is fictional for what is real, but most mature 
fiction appreciators are really quite good at distinguishing the fictional from the real, and so to claim 
that video games allow their appreciators to rehearse violent or aggressive scripts does not establish 
that these will lead to the utilisation of these scripts in the real world, unless it can also be established 
that appreciators are systematically prone to confusing fictional worlds for the real world. Furthermore, 
some putatively violent behavioural scripts that are effective in dealing with the challenges set by 
video games are not applicable to the real world because those behaviours are responses to gameplay. 
Punching the heads off zombies technically, fictionally doing so is a behavioural script particular to 
winning games of Timesplitters. Almost all video gamers are aware that as a response to the real world, 
this is a behavioural script that is utterly inappropriate: not the least for the lack of zombies in 
the real world! In reading the psychological literature on gaming, one suspects that researchers often 
have a very crude implicit model of what gaming cognition and practice amounts to. Nevertheless, it does 
seem that games do have psychological and behavioural effects on their players: gaming is not thoroughly 
isolated from the real world. This much should be obvious to gamers themselves from the phenomenology 
of their games playing. Scary games can leave one afraid; frustrating games can arouse genuine anger, 
even put you in an aggressive mood that persists beyond the game. Correspondingly, beating a frustrating 
level after many attempts can lead to genuine elation. To deny these things would be to make the appeal 
of games much more mysterious, but it is a big step from the emotional enjoyment of a fictional video 
game to the claim that such games have a formative and negative influence on player psychology.  4.2 
Extended External Consequences The more interesting cases not to mention the potentially more damning 
ones are where video games are blamed for actual crimes or behaviour far-detached from episodes of gaming. 
Anderson and Dill begin their findings by setting out the now familiar story of Eric Harris and Dylan 
Klebold, suggesting the motivating context of their study: perhaps disingenuously, given that they immediately 
deny that video games can be demonstrated as a cause of the Columbine shootings [16]. Others are not 
so reticent about making the causal claim: retired army lieutenant colonel Dave Grossman thinks that 
video games are training children to be killers [17]. Jack Thompson has blamed video games for killings 
in Kentucky, Columbine, and Virginia Tech [18]. If these were genuine effects of video gaming, the moral 
culpability of those games would seem to be more easily proved. Such claims are even harder to demonstrate 
than the proximal consequences dealt with earlier. The blame apportioned to video games for the unfortunate 
school shootings in particular is extremely tenuous for a number of reasons. First, establishing a causal 
link is bound to be difficult, because these events are just not well understood. All but the most physiological 
or instinctual behaviours have an immensely complicated conjunction of conditions as their causal antecedent, 
and isolating any one of these as a cause of some behaviour is an extraordinarily speculative affair. 
Of course, many causal relationships are statistical in nature the causal responsibility of smoking for 
lung cancer is not disproved by the fact of some smokers not developing cancer so conceivably the connection 
between video gaming and violent crime could be demonstrated statistically through a cohort study. Again, 
there is the problem that such cohort studies principally provide correlational evidence. But even a 
causal finding does not seem to be something that, if it could be demonstrated, would allow us to establish 
the causal responsibility of video games for particular crimes. The statistically demonstrated causal 
relationship between smoking and lung cancer does not have a certain bearing on the causal facts of any 
particular case of lung cancer, of course.  Furthermore, even if a causal connection between gaming 
and a particular shooting could be demonstrated, it is not clear whether this would be sufficient to 
attribute moral responsibility for the event to the video gaming. In this case games would merely be 
one aspect of a nexus of causal features antecedent to the shooting, and to isolate them as morally responsible 
ignores the fact that the vast majority of gamers commit no such acts. By any measure, to respond to 
a video game as a motivation or incitement to perform mass murder is an extraordinarily idiosyncratic 
response to that game. If we take the dozen or so mass shootings commonly attributed to video gaming 
as actually stemming from them, this set comprises a vanishingly small proportion of gamers. Even if 
we could somehow prove gaming did contribute to the crimes, the reasonable conclusion would be that such 
games were causally significant only in the vanishingly small proportion of players predisposed for whatever 
reason to commit such crimes. Surely then the causal responsibility lands with the mental or behavioural 
predisposition, and not the game. All sorts of diverse stimuli play a causal role in generating unfortunate 
effects from idiosyncratic personalities, but in such cases we feel no need to attribute to the stimuli 
moral responsibility for the effect. To take a pertinent example, the shooter in the Virginia Tech killings, 
Seung-Hui Cho, made numerous references to Jesus and the crucifixion in the video he made in the hours 
between the shootings [19]. It would be extraordinarily perverse to blame the Bible for the Cho s bizarrely 
idiosyncratic response to it. The issues here are summed nicely in the response of the appeals court 
judge in the Kentucky case: Carneal s [the killer] reaction to the games and movies at issue here [ ] 
was simply too idiosyncratic to expect the defendants to have anticipated it [ ] We find that it is simply 
too far a leap from shooting characters on a video screen (an activity undertaken by millions) to shooting 
people in a classroom (an activity undertaken by a handful, at most) for Carneal s actions to have been 
reasonably foreseeable to the manufacturers of the media that Carneal played and viewed [20]. The prevalence 
of these shooting tragedies is of course worrying, and we do have an interest in understanding their 
causes so as to avoid them in future. It would be fortunate if gaming could be proved to be the cause 
of these events, as it is the type of thing that could be somewhat effectively controlled though classification 
or censorship legislation. Unfortunately, it seems that the real reasons for these events are not so 
easily legislated against or even identified. Most worryingly, there may even be no prospect of discovering 
a generalised cause of the shootings other than geographical or media generated localisation. The historical 
precedent of campus shootings from University of Texas at Austin, to Virginia Tech, that is transmitted 
through the electronic media has clearly provided a model for behaviour even though it is debatable just 
how self­consistent the model of a school shooter is but each of the incidents may have been performed 
for reasons distinctive to the particular shooter. To think there is some sort of generalised cause of 
such events beyond this model may be entirely unwarranted. In his defence of the mass arts, the philosopher 
Noël Carroll roundly criticises the idea that we could genuinely pin down the sorts of consequences being 
attributed to games in this section, suspecting, like Pinker, that normative concerns are foremost here: 
Thus, it may be argued that since we don t know how to calculate the behavioural consequences of mass 
art for morality, we should refrain from bluffing about our knowledge of the supposed behavioural consequences 
of mass art and stop trying to invoke knowledge we do not have to justify our moral evaluations of it. 
[ ] Any group that claims to be able to predict the behavioural consequences of, for example, pornography, 
it might be said, is simply trying to advance its own sensitivities and moral preferences under the guise 
of a theory. [21]  5. POSITIVE CONSEQUENCES The truth of these consequentialist claims would not be 
enough by itself to establish the immorality of video gaming. Let us take it as accepted that video games 
do have some negative consequences. My argument is that even if this is the case, it is not sufficient 
to establish that video games are morally condemnable. The principle here, of course, is that consequentialist 
approaches must factor in the positive consequences of video gaming. This is something that is hardly 
ever acknowledged by the critics of gaming. Indeed, the tone of many criticisms seems based on a view 
that video games have no redeeming value: think in particular of Thompson s frequent characterisation 
of video gaming as mental masturbation. Video games may be shown to have links to aggressive and anti­social 
behaviour, however there are many other forms of behaviour or technological artefacts that have demonstrable 
links to such behaviour, and yet these are not condemned as wholly wicked because there is also traditional 
value held in them. Sports would be the best example. It is clearly the case that there is a link between 
the playing of sports and aggressive tendencies and behaviours external to sports. Though there is criticism 
of sport in this regard, it has nothing like the panicked moral overtones evident in the case against 
video games. Indeed the link between sports and violence not only in their playing, but also in the watching 
of sports seems in many cases far clearer than that between media and violence. Football hooliganism 
is common in many societies; riots at movie theatres or games arcades are not! The influence of sport 
on the aggressive tendencies of people is somewhat mitigated by the benefits that are gained in health 
and fitness, and also in the valuable social activities that surround the playing and watching of sport. 
Only those with an ideologically extreme bent would think of finding sport morally condemnable because 
of the link it bears to violent and aggressive behaviour in a minority of participators and spectators. 
 A survey of the potential positives of video gaming is thus important to provide balance to the rather 
negative picture of the ostensible consequences introduced in the previous parts of this paper. Again, 
whether or not video games do have these positive consequences is not something that a philosopher can 
establish (apart perhaps, from clarifying what it is that is positive about a positive consequence): 
it is instead an empirical issue. There is an incredibly obvious and significant source of positive utility 
in gaming: the fun to be had by gaming. Gaming is now among the most popular of the popular arts, and 
this widespread appeal must count as evidence of the pleasure gaming affords to a large number of people. 
Indeed, the very obvious pleasure that gamers take in games seems to some to be part of the moral problem 
of video gaming. Given the choice between a video game and a book, many young people if not most would 
opt for the game. Some see games as a superficial pursuit as engendering a base pleasure perhaps and 
so would discount this obvious pleasure to some extent. This comes close to begging the question of the 
value of gaming: lacking an argument to motivate the distinction between base and refined pleasures, 
moral critics of video gaming will not be able to discount this important source of utility [22]. Even 
if the distinction can be made, it is not clear that this would be sufficient to count against games, 
for the very reason that games are becoming extraordinarily sophisticated and refined, with a strong 
aspect of connoisseurship now existing in gaming culture. At least one writer has made a compelling defence 
of video gaming as constituting a new form of art [23]. This observation leads naturally to the next 
issue: video games are increasingly aesthetically significant, in many cases constituting artistic achievements 
to rival those in traditional artistic media. Some of the games I have played have not only been fun 
experiences, but have been aesthetically satisfying ones. The Playstation 3 game, Resistance: Fall of 
Man, for example, provides an aesthetically compelling and darkly rendered glimpse into an alternative 
reality. Graphically and stylistically the game is just one example of how digital artists have explored 
the new realm of artistic potential made possible by the invention of the video game. It also seems that 
video gaming has given rise to novel artistic forms: gameplay design in particular provides a new arena 
in which video game artists can design inventive and interesting artefacts. The rise of a new art form 
is surely a positive to go on the consequentialist ledger in favour of gaming. There is also evidence 
that video games are beneficial in terms of learning and literacy. An early assessment on the negative 
and positive effects of video games on childhood development by Patricia Greenfield concludes that the 
instrumental value in video games somewhat balances their apparent negative impact [24]. Of particular 
importance, thinks Greenfield, is the necessity of induction in discerning the patterns and rules involved 
in gameplay, the tracking of the interaction of multiple variables, and the development of spatial skills. 
James Paul Gee has also written about the potential positives of gaming in similar regards [25]. I noted 
earlier that video games are often blamed for their effects on player sociability. This claim depends 
on the assumption that gaming is necessarily an introverted or solitary affair, however. In fact, gaming 
can be a very social practice in a number of respects, some of them quite novel. It can be argued that 
gaming has the potential to make people more social, both by making social opportunities more available, 
and by extending one s social circle beyond the traditional confines of the geographically local community. 
There are a number of ways in which games are a social pursuit, or do increase a player s access to sociability. 
Multiplayer games, such as Counter-Strike, are intrinsically social affairs, indeed, they can be a good 
excuse to get together with friends and enjoy their company. MMORPGs such as Second Life or World of 
Warcraft are also obviously social affairs, and give people access to a larger social circle than they 
would otherwise have. It is an interesting fact about life in the age of the Internet that many of our 
social circles extend beyond the geographical barriers in which they were contained up until very recently. 
Some might complain that in reality these are only virtual relationships, but it is clear that online 
relationships can and do expand into real world meetings. The potential expansion of one s social circle, 
especially when we think that life in modern big cities can be solitary and alienating, is surely a positive 
consequence partly attributable to modern gaming.  6. THE FREEDOM TO DO WRONG Finally, even if turns 
out that when we tally these consequences up no one said this would be easy! and games and gaming do 
turn out to have generally negative effects, and so to be unethical, the question of how they are dealt 
with is still an open one. An assessment of the consequentialist ethics of gaming only goes part way 
to determining our proper ethical response to gaming. In cases where there is no apparent gain in allowing 
a dangerous or risky activity to exist in an unregulated fashion, that aspect will often be allowed in 
the name of freedom. Even if a given activity is found to have clear negative consequences, that behaviour 
can be ethically validated in that its restriction would count as unjust coercion. It is clear that the 
consequences for the society as a whole of some forms of potentially unethical behaviour are not always 
significant enough to legitimise legislation. This issue arises in the case of adultery: though commonly 
held to be immoral, adultery is increasingly not subject to prohibitive legislation in Western countries. 
A common argument against the legal prohibition against adultery is that it infringes on personal rights 
to perform voluntary and private acts. Correspondingly, legal systems with strong laws against adultery 
strike many as unjustly coercive. Similar arguments could be provided in the case of video gaming. These 
considerations of freedom may mitigate some of the internal or external proximal consequences of gaming: 
those that are relatively inconsequential in the long run. Considerations of personal freedom, of course, 
are not likely to provide us with clear guidance when there is evidence of consequences beyond the playing 
of the game, and that have an impact on non-gamers. If games were shown to be causing the disastrous 
effects sometimes attributed to them, and discussed in an earlier part of this paper, then it is not 
so clear they would be morally defensible in terms of considerations of personal freedom. Also, considerations 
of freedom are only likely to validate gaming when it is freely chosen by an informed adult: in principle 
here we have a reason why children s access to gaming can legitimately be legislated, because they are 
not able to recognise and to consent to the putative consequential and ethical risks of gaming.  Note 
what is happening with these considerations of freedom though: they do not show that video games are 
not unethical, rather, they establish that people should be free to pursue potentially immoral pursuits 
despite that potential immorality, because it is offset by considerations of personal liberty. In this 
paper the consequentialist issues have taken as their target gaming itself: I have asked if on balance 
gaming is or is not a good thing. Another way to forward the debate is to take gaming legislation as 
the target of explanation, and to ask whether on balance legislating or censoring games would produce 
more or less desirable consequences. If freedom is factored into the consequences as I acknowledged at 
the beginning of this paper, happiness and well-being cannot be taken to exhaust the effects we find 
valuable or if freedom is taken to be a factor that sometimes overrides consequentialist considerations, 
as deontological ethical theories suggest, then a clear case can be made for not legislating for games 
censorship, at least as far as informed and mature adult gamers are concerned. The right to personal 
freedom is in many legislative matters accepted as a trump card.  7. CONCLUSION On a consequentialist 
basis, the ethics of video games and gaming seems to rely on a number of key issues. First, assuming 
we take a consequentialist approach to the topic, what are the genuine consequences of video games? This 
in fact is only a very small part of the issue, even though it tends to dominate the popular and academic 
concern with video game morality. Second, does the presence of negative consequences exhaust the issue? 
Arguably, there are a range of positive consequences of gaming that offset their potential negative effects. 
Finally, even if games are found to be unethical through the appraisal of their consequences, this leaves 
open the nature of our response to them, including our legislative response. If the harm caused by games 
is relatively limited which in a large part will be settled by the former consequentialist part of this 
issue then people should arguably be free to play those games.  8. REFERENCES [1] For a philosophical 
account of these issues, see Walton, K. Mimesis as Make-Believe. Harvard University Press, Cambridge 
MA, 1990; one interesting account of the cognition of pretence is Nichols S. and Stich, S. A Cognitive 
Theory of Pretense, in Cognition, 74, 2000:115-147. [2] Nichols and Stich, 2000. [3] Plato, The Republic. 
Translated with an introduction by Desmond Lee. 2nd edition. Penguin Books, London 1987: Book X, Part 
3. [4] Tavinor, G. Video Games and Interactive Fiction, Philosophy and Literature, April 2005, Volume 
29, Number 1. [5] This so-called paradox of horror is dealt with in Carroll, N. The Philosophy of Horror 
or Paradoxes of the Heart. Routledge, New York, 1990. [6] South Park Episode 147, Make Love Not Warcraft, 
Comedy Central, 2006. [7] See for example: Anderson, C. A., &#38; Bushman, B. J. Effects of Violent Games 
on Aggressive Behavior, Aggressive Cognition, Aggressive Affect, Physiological Arousal, and Prosocial 
Behavior: A Meta-analytic Review of the Scientific Literature, Psychological Science, 12, 2001:353-359; 
Anderson, C. A. and Dill, D. E., Video Games and Aggressive Thoughts, Feelings, and Behavior in Laboratory 
and Real Life, Journal of Personality and Social Psychology, 78 No. 4, 2000: 772-790; Gentile, D. A., 
Lynch, P., Linder, J. &#38; Walsh, D. The Effects of Violent Video Game Habits on Adolescent Hostility, 
Aggressive Behaviors, and School Performance, Journal of Adolescence, 27, 2004:5-22. [8] Anderson and 
Dill, 2000, p.774. [9] Durkin, K. Computer Games: Their Effects on Young People. Office of Film and Literature 
Classification, Sydney, NSW, 1995; Freedman, J. L. Media Violence and Its Effect on Aggression: Assessing 
the Scientific Evidence. University of Toronto Press, Toronto, 2002; Griffiths, M. Violent Video Games 
and Aggression: A Review of the Literature, Aggression and Violent Behavior, vol.4, No. 2, 1999:203-212. 
[10] Pinker, S. The Blank Slate. Penguin Books, London, 2003: p.311. [11] Gentile, et al, 2004. [12] 
Griffiths, 1999. [13] A study by the Entertainment Association of Australia presented at the Australasian 
Conference of Interactive Entertainment, held in Sydney in 2005, found that the average age for gamers 
in Australia was 24, and was trending upwards. [14] Freedman, 2002. [15] Nichols and Stich, 2000, p.120. 
[16] Anderson and Dill, 2000, p.772. [17] Grossman, D. and DeGaetano, G. Stop Teaching Our Kids to Kill: 
A Call to Action Against TV, Movie, and Video Game Violence. Crown Publishers, New York, 1999. [18] Fox 
News, 17th April, 2007; interviewed by David Gregory, MSNBC, 17th April, 2007. [19] NBC News, 18th April, 
2007. [20] 6th U.S. Circuit Court of Appeals, James v. Meow Media, No. 00-5922, 2002. [21] Carroll, N. 
A Philosophy of Mass Art. Clarendon Press, Oxford, 1998: p.301. [22] Utilitarians have long been aware 
of the problem that such a principle seems to over-value the so-called base-pleasures to the exclusion 
of refined ones. See for example Chapter 4 of Mill, J. S. Utilitarianism; On Liberty; Considerations 
on Representative Government; Remarks on Bentham s Philosophy. Dent, Tuttle, London, 1993.  [23] Smuts, 
A. Are Video Games Art? Contemporary [24] Greenfield, P. M. Mind and Media: The Effects of Aesthetics, 
2004, archived at Television, Video Games, and Computers. Harvard University http://www.contempaesthetics.org/newvolume/pages/article.php 
Press, Cambridge, Mass., 1984. ?articleID=299. [25] Gee, J. P. What Video Games Have to Teach Us About 
Learning and Literacy. Palgrave Macmillan, New York, 2004.   
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2007</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>1328205</article_id>
		<sort_key>30</sort_key>
		<display_label>Pages</display_label>
		<pages>8</pages>
		<article_publication_date>11-14-2007</article_publication_date>
		<seq_no>2</seq_no>
		<title><![CDATA[Girls playing games]]></title>
		<subtitle><![CDATA[rethinking stereotypes]]></subtitle>
		<page_from>9</page_from>
		<page_to>16</page_to>
		<doi_number>10.1145/1328202.1328205</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1328205</url>
		<abstract>
			<par><![CDATA[<p>This paper reports on findings from a three-year, Canadian federally funded research project entitled "Education, Gender and Gaming". Our study of gender and digital game-playing was driven by two significant factors: first, that far more boys than girls play video games, and boys' early and sustained experience with gaming places them at an advantage with respect to computer competence and confidence. Second, not only are computer-based media increasingly central tools for learning and work, but in fact games are increasingly being recruited in educational contexts. This eager uptake for educational deployment of game-based learning threatens to compound and intensify girls' disadvantage. It is therefore even more urgent that educationally-based research reinvestigates stereotypical presumptions about gender as they relate to computer-based game playing for children in order to make it possible for girls to participate more fully and equally in technology-related fields. In this way, the new push to design educational games might better be informed by as full an understanding as possible of girls' perspectives on and participation in gaming, and about the kinds of games, characters, and overall approaches to "play" that might better engage and involve girls, who are already very much participating in gaming culture.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[digital game play]]></kw>
			<kw><![CDATA[gender]]></kw>
			<kw><![CDATA[girls]]></kw>
			<kw><![CDATA[social issues]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<general_terms>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P925247</person_id>
				<author_profile_id><![CDATA[81435596928]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Jennifer]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Jenson]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[York University, Toronto, Ontario]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P272576</person_id>
				<author_profile_id><![CDATA[81100489557]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Suzanne]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[de Castell]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Simon Fraser University, Burnaby, BC]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P925269</person_id>
				<author_profile_id><![CDATA[81342494566]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Stephanie]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Fisher]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[York University, Toronto, Ontario]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[AAUW: American Association of University Women (2000). <i>Tech-savvy: Educating girls in the new computer age.</i> Researched by Commission on Technology, Gender, and Teacher Education. Washington, DC: American Association of University Women Educational Foundation.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[AAUW: American Association of University Women (2004). Under the microscope: A decade of gender equity projects in the sciences. Available at: http://www.aauw.org/research/underthemicroscope.pdf. Last accessed April 20, 2007.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Beasley, B., &amp; Standley, T. C. (2002). Shirts vs. skins: Clothing as an indicator of gender role stereotyping in video games. <i>Mass Communication and Society</i>, 5 (3), 279--293.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Bryce, J., &amp; Rutter, J. (2003). The gendering of computer gaming: Experience and space. In S. Fleming &amp; I. Jones (Eds.), <i>Leisure culture: Investigations in sport, media and technology</i> (pp. 3--22). Eastbourne, UK: Leisure Studies Association.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Carr, D. (2005). Context, Gaming Pleasures and Gendered Preferences. <i>Simulation and Gaming</i>, 36, 4, p. 464--482.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Carr, D. (2007). Contexts, Pleasures, and Preferences: Girls Playing Computer Games. In S. de Castell &amp; J. Jensons (Eds.), <i>Worlds In Play: International Perspectives on Digital Games Research</i> (pp.313--322). New York: Peter Lang Publishing.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>295056</ref_obj_id>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Cassell, J. &amp; Jenkins, H. (Eds.) (1998). <i>From Barbie to Mortal Kombat.</i> Boston: The MIT Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>295075</ref_obj_id>
				<ref_obj_pid>295056</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[de Castell, S., &amp; Bryson, M. (1998). Retooling play: Dystopia, dysphoria, and difference. In J. Cassell &amp; H. Jenkins (Eds.), <i>From Barbie to Mortal Kombat</i> (pp. 232--261). Cambridge, MA: MIT Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Dietz, T. L. (1998). An examination of violence and gender role portrayals in video games: Implications for gender socialization and aggressive behavior. <i>Sex Roles</i>, 38 (5--6), 425--442.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Denner, J., Werner, L., Bean, S., &amp; Campe, S. (2005). The Girls Creating Games Program: Strategies for engaging middle school girls in information technology. <i>Frontiers: A Journal of Women's Studies.</i> Special Issue on Gender and IT, 26, 90--98.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>983348</ref_obj_id>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Gee, J. P. (2003). <i>What video games have to teach us about learning and literacy.</i> New York: Palgrave Macmillan.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Gee, J. P. (2006). The Classroom of Popular Culture. <i>Harvard Education Letter.</i>
]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Gee, J. P. (2007). Good Video Games and Good Learning: Collected Essays on Video Games, Learning and Literacy. New York: Peter Lang Publishers.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Goode, J., Estrella, R., &amp; Margolis, J. (2006). Lost in translation: Gender and high schoolcomputer science. In J. M. Cohoon &amp; W. Aspray (Eds.), <i>Women and information technology: Research on underrepresentation</i> (pp. 89--114). Cambridge, MA: MIT Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Flanagan, M., Howe, D. C. &amp; Nissenbaum, H. (2005). New Design Methods for Activist Gaming. Proceedings from DiGRA 2005, 16--20 June, Vancouver, BC, Canada]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1055076</ref_obj_id>
				<ref_obj_pid>1054972</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Flanagan, M. Howe, D. C. &amp; Nissenbaum, H. (2005). Values at Play: Design Tradeoffs in Socially-Oriented Game Design. Proceedings of the SIGCHI conference on Human factors in computing systems, p. 751--760. Portland, Or.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Flanagan, M., Howe, D. C. &amp; Nissenbaum, H. (2007). New Design Methods for Activist Gaming. In S. de Castell &amp; J. Jensons (Eds.), <i>Worlds In Play: International Perspectives on Digital Games Research</i> (pp. 241--248). New York: Peter Lang Publishing.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Hill, C. (2002). <i>Contradiction, culture and computers</i>, unpublished Master's Thesis Simon Fraser University: Burnaby, British Columbia, Canada.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Ivory, J. D. (2006). Still a Man's Game: Gender Representation in Online Reviews of Video Games. <i>Mass Communication and Society</i>, 9, 103--114.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Jansz, J. &amp; Martis, R. G. (2007). The Lara Phenomenon: Powerful Female Characters in Video Games. <i>Sex Roles</i>, 56, 141--48.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Jenson, J. (1999). <i>Girls ex machina: A school-based study of gender, culture and technology</i>, Doctoral Thesis Simon Fraser Universtity: Burnaby, British Columbia, Canada.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Jenson, J. &amp; de Castell, S. (2005). <i>Her Own Boss: Gender and the Pursuit of Incompetent Play.</i> DiGRA 2005, Vancouver, Canada.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>527173</ref_obj_id>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[Kafai, Y. B. (1995). <i>Minds in Play: Computer Game Design As a Context for Children's Learning.</i> Hillsdale, NJ: Lawrence Erlbaum Associates.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[Kafai, Y. B. (2006). Playing and Making Games for Learning: Instructionist and Constructionist Perspectives for Game Studies. <i>Games and Culture</i>, 1 (1), 36--40.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[Kaiser Family Foundation (2005). Kids &amp; Media @ The New Millennium. Program for the Study of Media and Health. Available online at: http://www.kff.org/entmedia/1535-index.cfm. Last accessed 14 April 2007.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1293055</ref_obj_id>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[Kelleher, C. (2005). Motivating Programming: Using storytelling to make computer programming attractive to middle school girls. Unpublished PhD Dissertation, Carnegie MellonUniversity, School of Computer Science]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1047346</ref_obj_id>
				<ref_obj_pid>1047344</ref_obj_pid>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[Klawe, M. (2005). Increasing the number of women in computer science, what works? <i>SIGCSE</i> 2005, p. 562.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[Krotoski, A. (2004). <i>Chicks and joysticks: An exploration of women and gaming.</i> London: Entertainment and Leisure Software Publishers Association.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1209307</ref_obj_id>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[Prensky, M. (2000). <i>Digital Game-Based Learning.</i> New York: McGraw Hill.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1197653</ref_obj_id>
				<ref_seq_no>30</ref_seq_no>
				<ref_text><![CDATA[Prensky, M. (2006) <i>Don't bother me mom, I'm learning.</i> St. Paul, Minnesota: Paragon House Publishers.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>949282</ref_obj_id>
				<ref_seq_no>31</ref_seq_no>
				<ref_text><![CDATA[Ray, S. G. (2004). <i>Gender Inclusive Game Design: Expanding the Market.</i> Hingham, Massachuetts: Charles River Media, Inc.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>32</ref_seq_no>
				<ref_text><![CDATA[Smith, S. L., Lachlan, K., &amp; Tamborini, R. (2003). Popular video games: Quantifying the presentation of violence and its context. <i>Journal of Broadcasting and Electronic Media</i>, 47 (1), 58--76.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1137764</ref_obj_id>
				<ref_seq_no>33</ref_seq_no>
				<ref_text><![CDATA[Taylor, T. L. (2006). <i>Play Between Worlds: Exploring Online Game Culture.</i> Boston: The MIT Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>34</ref_seq_no>
				<ref_text><![CDATA[Walkerdine V. (1998) Children in cyberspace, in K. Lesnik-Oberstein (Ed.) <u>Children in culture</u>, London, Macmillan]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>35</ref_seq_no>
				<ref_text><![CDATA[Walkerdine, V., Thomas A. &amp; Studdert, D. (N.D). Young children and video games: dangerous pleasures and pleasurable danger. Available at http://creativetechnology.salford.ac.uk/fuchs/projects/downloads/young_children_and_videogames.htm. Last accessed April 10, 2007.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Girls Playing Games: Rethinking Stereotypes Jennifer Jenson York University Suzanne de Castell Simon 
Fraser University Stephanie Fisher York University 4700 Keele Street 8888 University Drive 4700 Keele 
Street Toronto, Ontario Burnaby, BC Toronto, Ontario 1+ (416) 736-2100 ext. 88787 1+(778) 782-3627 1+(416) 
705-7833 jjenson@edu.yorku.ca decaste@sfu.ca stefish@yorku.ca ABSTRACT This paper reports on findings 
from a three-year, Canadian federally funded research project entitled Education, Gender and Gaming . 
Our study of gender and digital game-playing was driven by two significant factors: first, that far more 
boys than girls play video games, and boys early and sustained experience with gaming places them at 
an advantage with respect to computer competence and confidence. Second, not only are computer-based 
media increasingly central tools for learning and work, but in fact games are increasingly being recruited 
in educational contexts. This eager uptake for educational deployment of game-based learning threatens 
to compound and intensify girls disadvantage. It is therefore even more urgent that educationally-based 
research reinvestigates stereotypical presumptions about gender as they relate to computer-based game 
playing for children in order to make it possible for girls to participate more fully and equally in 
technology-related fields. In this way, the new push to design educational games might better be informed 
by as full an understanding as possible of girls perspectives on and participation in gaming, and about 
the kinds of games, characters, and overall approaches to play that might better engage and involve girls, 
who are already very much participating in gaming culture. Categories and Subject Descriptors Computers 
and society General Terms Social Issues, Theory Keywords Gender, digital game play, girls,  INTRODUCTION 
Over a remarkably short span of time, digital games have come to command an increasingly important role 
in social communications. Permission to make digital/hard copy of part of this work for personal or classroom 
use is granted without fee provided that the copies are not made or distributed for profit or commercial 
advantage, the copyright notice, the title of the publication, and its date of appear, and notice is 
given that copying is by permission of the ACM, Inc. To copy otherwise, to republish, to post on servers, 
or to redistribute to lists, requires prior specific permission and/or a fee. FuturePlay 2007, November 
15-17, 2007, Toronto, Canada. Copyright 2007 ACM 978-1-59593-943-2/07/0011...$5.00 Education, skill development, 
job training, ideology-formation, artistic endeavours and more have all come under the spell of the so-called 
stealth- learning possibilities that digital games afford (Prensky, 2000). So seen, digital games are 
a significant new medium, and game play, on this view, both depends upon and develops a kind of new literacy 
(Gee, 2005; Kafai, 2006). James Paul Gee, for example, has argued extensively that playing digital games 
constitutes a new form of literate practice, and he has referred to learning through video games as (among 
many other things) the ability to read complex semiotic scores (Gee, 2006, 2007). Alongside such work, 
is that which is looking at the playing of massively multi-player online games (MMO s) as the formation 
of complex communities of practice in which not only learning takes place but important social and cultural 
bonds are established and developed (Taylor, 2006). What we need at this point, however, is a more specific 
analysis both of the particular kinds of new literacies that gameplay purportedly develops, and no less 
importantly, a rich data set which allows us to look in depth and detail at the particulars of this widely 
endorsed general claim. Within the current very much gendered context of the development of digital games 
for instructional and educational practices, specific questions to pursue are: who plays, and what and 
how do they play, and what practices (social, cultural; insider, outsider; shared, individual) are being 
developed by boys and by girls as they play digital games? This chapter examines the results of a three-year 
after school game playing club for boys and girls aged 12-13 which looked at game choice, play discourse, 
in-game and beyond-game activities, prior game familiarity and (broadly) notions of competition as participants 
played in same sex and in mixed-sex groups. The intent of this discussion is to elucidate this popular 
conception of new game literacies , and to describe a data set which illuminates in depth and detail 
what the development of game literacy looks and feels like on the ground , what its functions and uses 
are in educational terms, and both the prospects, and the perils, of its pursuit. We are here seeking 
to move the discussion about games and gender beyond the generalities to which they have thus far been 
very largely confined, and we begin with a brief overview of the work to date on gender and digital games 
that has relied on brief ethnographic accounts of difference/s between girls and boys game play as well 
as quantitative data sets that do not consistently account for gender. Following that review, we draw 
on the broad and diverse data set we have accumulated in our own study to enable us to see in a more 
specific and nuanced way, what and how girls play games, and how these opportunities have been and remain 
gender-stratified in ways which, notwithstanding clichés about girls superior literacy , continue to 
disadvantage them in a culture that is relying more and more on the concepts, practices and literacies 
acquired through digital game play.  GIRLS IN PLAY: PASSING THROUGH Girls have had an uneasy relation 
to digital games, whether marginalized prima facie by the men/guns/toys themes and titles such as, God 
of War, Manhunt or Stalker or targeted directly by pink box titles like Rockett? s New School, Barbie: 
Horseshow or Mary Kate and Ashley: Sweet 16 that, although packaged pink and cute , are not necessarily 
fun . This is not to say that girls have not played and do not play digital games, but their market-defined 
relation to those games, the access that they have to the technology to play them and the kinds of games 
that they choose to play once they gain access are all highly contextually dependent and not necessarily 
supported by a larger cultural engagement with that new media form (Carr, 2007; Cassels and Jenkins, 
1998; Taylor, 2006). From Barbie to Mortal Kombat (1998) focused on some of the more pertinent issues 
at that time, including the development of the girls game movement, spurred on by the financial success 
of Barbie Fashion Designer. The collection was also partially motivated by the worry that while the Internet 
held a democratizing potential, if technology access and use was not carefully guided, its flourishing 
could easily result in a new and powerful means to the (re) marginalization of women and girls. It was 
argued at that time that fewer women and girls were online than men, they enjoyed fewer safe places, 
and had fewer reasons and fewer communities to access online. Moreover, women and girls were also (and 
continue to be) largely underrepresented in technological fields (Klawe, 2005), both educationally and 
vocationally. In other words, females were not as technologically skilled or as competent as their male 
counterparts. In Jenkins and Cassells collection, the papers were concerned not only with this under-representation 
but also with what they saw as the strong potential of digital gameplay to assist technological familiarity 
and skill on behalf of the player. Here also was a discussion of player preferences (1998), that is what 
sorts of games girls liked and did not like as well as a more nuanced discussion of the gendered nature 
of play (de Castell and Bryson, 1998). Following in the footsteps of the games industry focus on creating 
appealing titles for girls, girls preferences in games were at that time rather unproblematically reported, 
for example, as being collaborative and exploratory and as shying away from confrontation , competition 
and violence . Despite this blackboxing of gender, the collection still represents the strongest commentary 
on girls and gameplay to-date. However the intervening years have seen considerable shifts in focus. 
In 2000, The Sims was released and has since, through its expansions and the release of Sims 2, been 
the top selling PC game of all time. The industry, of course, took notice: girls and women were buying 
and playing the game in record numbers. The Sims, and its franchise, it has since been argued, is successful 
as a cross over hit for a number of reasons: its design team included women, its premise is that of an 
elaborate dollhouse, it provided different and frequent kinds of interaction which appealed to a female 
audience, and it was essentially non-competitive and non­violent. But the success of The Sims did not 
lead to more appealing games for girls, and women continue to be radically under-represented in the industry 
(IGDA, 2006). That said, the success of The Sims, in part, renewed an interest in designing games for 
girls. Sheri Graner Ray s work, Gender Inclusive Game Design: Expanding the Market (2004), attempts to 
tackle the question of design of video games for a non traditional market (e.g. women and girls), through 
an essentialized and highly stereotyped account of differences and preferences between male and female 
players, and how designers can design more effectively to capture a female audience, an approach fundamentally 
untouched by the critical analyses offered more than two decades ago by the original Cassells and Jenkins 
collection, and one which unproblematically reinstates the presumption that women and girls have gender-specific 
playstyles and preferences . Methodologically, we argue that this is a retrograde move which cannot help 
but obscure rather than illuminate what and how girls and women play, such that whatever advantages may 
be had from understanding and addressing girls relative under-involvement in digital games, whether playing, 
designing, producing or using for serious ends such as promoting technological interest and ability, 
will be more harmed than helped by research which follows this trajectory. While girls certainly have 
been and still are less visible as gamers, that is not to say they are not playing (Carr, 2005; Bryce 
&#38; Rutter, 2003; Taylor, 2006). Women and girls have been and are playing, very often supported in 
their play by their male relations (brothers, uncles, fathers, boyfriends, husbands), and they are creating 
communities of their own (c.f. Frag Dolls, Quake Grrls, Riot Grrls and numerous all female Counterstrike 
communities). Discourses around preferences moreover, have moved from simple binaries (violence/no violence, 
collaborative/competitive) to being recognized as highly contextual and therefore dependent on social, 
cultural, and other quotidian factors, rather than simply on what a girl might like or dislike in any 
given moment (Carr, 2005; Jenson &#38; de Castell, 2005; Krotoski, 2004). Gradually, it has begun to 
be clear that while girls do play, what and how they play is always negotiable, context dependent and 
does not necessarily happen only in the company of other girls or female players. This isn t something 
that can be seen if we begin with the assumption that play practices and preferences are a function of 
gender. It is relatively difficult to get reliable data on the play practices of girls, primarily because 
gender is often accorded statistical status in order to simply dismiss it. In quantitative surveys of 
video game ownership and play, for example, data disaggregated by gender is used to show that women and 
girls are playing games, but in no way accounts for important differences in what kinds of games, for 
how long they are played and in what relation to girl­players male peers. So this data, if useful at 
all, only serves as a kind of check mark in order to dismiss claims of a gender­hegemony with respect 
to dgital games in general, and technologies in particular. Two large, often cited surveys that publish 
data on video game players in North America are the Kaiser Family Foundation (http://www.kff.org/entmedia/) 
and the Entertainment Software Association (http://www.theesa.com). According to Kaiser s large survey 
(over 2,000 respondents and over 600 seven day media-use diaries) of media and children, the percentage 
of those girls surveyed who had a video game console in their bedroom was 33 (63 percent of boys reported 
having a video game console in their bedroom), while the percentage of girls with handheld video games 
was 48 (63 percent of boys). What these statistics do not do is give a clear picture of what kind of 
video game consoles and games respondents self-reported as having access to in their bedrooms (Barbie? 
Quake 4?). They did, however, ask respondents to indicate approximate time spent playing console and 
handheld games, concluding that there is a marked gender difference in terms of time spent on video game 
play:  Video games are clearly gender­typed. Boys are much more likely than girls to play video games 
on any given day (63% vs.40%, respectively), and to spend more than an hour daily with video games (31% 
vs. 11%). Boys spend almost three times as much time as girls playing video games (1:12 vs. 0:25) . Similarly, 
boys spend triple the time that girls spend playing console games (48 minutes vs. 14 minutes), but just 
double the time for handheld games (24 minutes vs. 11 minutes). (Kaiser Family Foundation, 2005, p. 33) 
 Unlike access (the question of access to what being elided) the issue of time spent in play submits 
more readily to the general girls are choosing not to play because they are less interested in computer 
games than boys ---a matter of rightful personal choice), so stressing that difference over any need 
to investigate differential access offers a further example of this phenomenon of raising gender in order 
to dismiss it . ESA s statistics offer yet another instantiation of this under­interrogation of gender 
and gameplay: their statistics are much more general and report only on gender as it relates to numbers 
of players, and even though they account for players by age, they do not report gender and age together, 
so it is difficult to surmise where girls fit in the picture, other than they are presumably some part 
of the 38% of female game players. Unless and until the kind of detailed and nuanced analytical study 
of gender and gameplay overtakes the essentializing and evasion of gender that continues to characterize 
the most widely read and cited work in this field, we are consigned to working within the very same categories 
of concern problematized more than two decades ago. Repetition may be instructive, but it doesn t get 
us very far ahead. Representation/Female Characters/Race in games Its by now well-rehearsed, and one 
of the first things looked at, that female players may be deterred by gendered representations in games. 
While the possibilities for choosing a female character in a video game have certainly increased, it 
is still the case that women and girls are highly under-represented in digital games generally and tend 
specifically to be more obviously sexualized than male characters (Beasley &#38; Standley, 2002; Dietz, 
1998; Ivory, 2006; Smith, Lachlan, &#38; Tamborini, 2003). Stand out characters like Lara Croft of the 
Tomb Raider series and Samus Eran from the Metroid series are often held up as examples of a changing 
tide in the video games industry toward drawing less passive, more powerful female characters for its 
(still largely male) audience to consume and play. While there might be more active roles for female 
characters, they are ongoingly drawn as highly sexualized characters with over-sized breasts and lips 
and very little clothing (Jansz &#38; Martis, 2007). Girls as game designers The first wave of interest 
in and research on girls and gaming saw gameplay as a conduit to and support for developing confidence 
and competence with new technologies. In its second wave, not merely playing games, but the more complex 
and demanding challenge of designing them has been researched and promoted as a way to encourage and 
support girls not only in computer use, but also in educationally significant levels and kinds of programming. 
In Yasmin Kafai s (1995) groundbreaking constructivist research on children as game designers, findings 
with respect to girls designs paralleled claims about girls preferences . The same kinds of results 
appeared in the later work of Valerie Walkerdine et al. (1998). Until quite recently, however, neither 
these nor similar smaller studies have taken explicitly into account the context in which and the experiential 
background from which girls designs were arrived at, and this oversight presupposes, by default, that 
for girls and boys, the videogame arena represents a level playing field for researchers to study. This 
leveling assumption is intriguing given that we have little reason to suppose, and many reasons to doubt, 
that girls and boys, no matter how young enter the arena on the same basis, equipped with the same inclinations, 
knowledge, experience and capability. Until both theory and research explicitly and actively take prior 
differences and occurrent contextual factors seriously into account, we cannot expect to find much deviation 
from the persistent gender stereotyping that has thus far dominated inquiry concerned with girls and 
gaming. Industry The video games industry has been widely criticized, both for not building games that 
appeal to girls and women, as well as for not hiring and retaining more female employees in key game 
design positions. A recent survey by Electronic Arts (a leading game design company) for example found 
that only 40% of teenage girls play console games (compared with 90% of boys), and most of those leave 
behind their game playing after a year (http://news.bbc.co.uk/2/hi/technology/5271852.stm). In an effort 
to encourage female participation in the game design and development industry, there have been a number 
of intervention­focused research projects carried out in North America to help give girls the requisite 
kinds of game programming skills, among them the Rapunsel project (Flannagan, Howe &#38; Nissenbaum 2007), 
the use of Alice and Storytelling Alice (open source software which allows users to create 3-D games) 
to learn programming (Kelleher, 2006) and Jill Denner s work with middle school girls and digital game 
creation (Denner, Werner, Bean, &#38; Tyner 2005). Doubtless due in part to the necessarily innovative 
character of these interventions, however, whether by omission or by commission, many of the recurrent 
stereotypes about what girls like have reappeared in these projects as well. For example Flannagan, et 
al. document an iterative design process in which they construct a computer game that teaches programming 
to youth. As the project was targeted specifically as an entry point for girls into computer programming, 
they convincingly argue for a value-based design process, one which views design choices as value choices 
(Flannagan, Howe &#38; Nissenbaum 2005). During the design process, they describe some of the conflicts 
that arose when project goals and/or design goals were in conflict with their beliefs about the values 
of their target audience. Such values presume that what girls want in a game is a cooperative reward 
structure that encouraged sharing of elements and ideas between players goals better matched with empirical 
findings on girls science and mathematics preferences (Flannagan, et al. 2005, p. 756). That is to say, 
the reward structure of the game was reworked to make it less competitive so that it better matched with 
research findings from very different kinds of studies. The problem here, and in much gender work related 
to digital game and digital game play, is that what holds in one context does not necessarily hold in 
another: girls have very different social, cultural and literal access to digital game play and presumptions 
made on their behalf do little else other than reinforce stereotypes. The more recent work by Kafai (2006) 
on children making games, for instance, found that when asked to build games on fractions, 10-year olds 
exhibited persistent gender differences in virtually all design aspects (Kafai, 2006, p. 38). When, however, 
the context for design shifted from fractions to science the gender-based design differences disappeared 
(Kafai, 2006).  BACKGROUND Informed by more than two decades of work which seems invariably to slip 
back into by now almost canonical assumptions that end by locating differences within a black-boxed and 
therefore essentialist conception of gender, we have in our own research efforts sought only to remove 
constraints and to support girls own enjoyment in learning and playing digital games. We have wanted 
simply to give them access to the pleasures of such play, and, as much as we possibly could, to simply 
watch, to just look and see what we could see when we demanded nothing from them and gave them every 
opportunity we could muster to find as much fun in such play as their male counterparts have so easily 
managed to do. From this standpoint, we carried out a three-year, Canadian federally funded research 
project entitled Education, Gender and Gaming . This study of gender and digital game-playing was driven 
by two significant factors previously noted: first, the by­now commonplace recognition that far more 
boys than girls play computer/video games, and the hypothesis that boys early and sustained exposure 
to and experience with gaming might place them at an advantage with respect to computer competence and 
confidence when they enter and as they continue their schooling. Second, our project was driven by equally 
commonplace acknowledgement that not only are computer-based media increasingly central tools for learning 
and work, but in fact games and simulations are increasingly being recruited as educational and instructional 
genres (Prensky 2006). This eager uptake for educational deployment of game-based learning, it is frequently 
suggested, threatens to compound and intensify girls computer disadvantage, as women continue to shy 
away from computer­related fields (AAUW 2000, 2004; Goode, et al., 2006; Klawe, 2005). It appears therefore 
even more urgent that educationally­based research reinvestigates stereotypical presumptions about masculinity 
and femininity as they relate to digital game playing for children in order to better understand the 
gendered patterns of technology access, interest, and competence and thereby make it possible for girls 
to participate more fully and equally in technology-related engagements. Moreover, the relatively new 
push to design serious games for educational purposes might better be informed by as full an understanding 
as possible of girls perspectives on and participation in gaming, and about the kinds of games, characters, 
and overall approaches to play that might better engage and involve them. From this viewpoint, we initiated 
after school gaming clubs for girls and boys at several public school in the greater Toronto area, which 
we ran over a two-year period from 2003-2005. The first year, the clubs ran separately in same sex groups; 
the second year, a mixed sex group was established but participants, with one exception, self-divided 
into same-sex groups. In the first year these clubs were developed to provide an opportunity for girls 
and boys in the intermediate division to interact with different technologies and play age-appropriate 
computer games in a supervised environment. Our main goal was to develop areas of play for students in 
which a group of girls and a group of boys could play whatever games they chose to play independent of 
one another. In the second year, our intention was to observe girls and boys play together, however they 
self­selected away from one another and indicated clearly that they were not willing to play together 
. There was one exception to this division: one young man chose to play consistently with two girls and 
never chose to play with the boys. We speculated, in part, that he preferred this arrangement because 
he was the only boy of Chinese descent in the club, one of the girls he was playing with was also Chinese, 
and, perhaps most importantly he was the only boy who reported that he did not have a game console at 
home and was not allowed to play computer games other than the ones freely available. In other words, 
this young man s experience level was more equivalent to that of girls he had chosen to play with. The 
rationale for developing the game clubs was to build an environment that would support research intended 
to help us gain a better understanding of how boys and girls respond to and interact with popular technologies 
within a supported same-sex peer group, building on earlier work on single sex groupings and new technologies 
(Hill, 2002; Jenson, 1999). In considering the discourse on using videogames as literacy and learning 
tools (Gee, 2005) and our plan was to use these clubs to: 1) study how boys and girls interact with popular 
game-based technologies; 2) gauge the role gender plays in how boys and girls approach game play; and 
3) observe and document the kinds of multimodal, multi-literate practices that boys and girls used to 
interact with and play videogames. Methods This study combined qualitative and quantitative methods to 
generate a more richly detailed understanding of gendered attitudes and play styles in console-based 
gaming environment, as well as to provide a solid empirical grounding to our interpretations of what 
we saw in participants play and play­oriented interaction. We have examined the play styles and interactions 
while gaming of boys and girls in six single-sex and one mixed -sex after school console-based gaming 
clubs. Each play session was both audio and video taped and as well as being documented through researcher 
field notes. Over 95 hours of video were then coded for interaction between and among participants and 
the video game/s. Codes were generated dynamically from viewing the footage and were cross-checked for 
reliability among the four researchers doing the coding. In total, raw video footage was broken down 
into over 1000 smaller clips of no more than two minutes, which show significant interaction between 
participants and the games they are playing and/or participants and one another. Each clip has been coded, 
and a database constructed which allows both for searching for particular clips and recoding dynamically 
on the fly if a clip has been judged to be coded improperly, or if different coders just genuinely see 
different things in the same clip, an important consequence of the analytical medium s affordances to 
which we will return. Additionally, all participants were interviewed individually and in small groups 
about their play at home, and were also asked to complete a questionnaire on the same topic. In total, 
44 boys and 60 girls were interviewed and completed a questionnaire, and 54 young adults young adults 
aged 22-24 also completed the same questionnaire.  WHO PLAYS AND HOW? In our interviews, in their answers 
to our questionnaires, and as we observed them playing it became clear that nearly all of the young women 
we were observing hadn t spent much time playing console games, in fact, even when they did claim to 
have played, upon further questioning, many would say that they played by watching their brothers, or 
uncles or fathers or male cousins play. In an on the fly gaming session, for example, one young women 
requested that her group play Need for Speed (a driving game) because she had played it before . When 
the game was changed and her group began playing, she called over the research assistant, saying, what 
do I do? I don t get it? The research assistant replied, I thought you said you have played this before? 
To which the young woman responded, Well, my brother plays and I actually watch. In our questionnaires 
and interviews, it was clear that girls had little or no consistent access to console games (despite 
every one of them having some version of a console at home), and this was made evident as we watched 
girls negotiate game play on their own, without assistance. Many did not, for example, know how to navigate 
through the more and less complex beginnings to games, they sought and opened manuals to figure out what 
buttons to press, and there was a further level of frustration early on as the girls grappled with their 
own novice abilities in navigating the games. A fieldnote from the second day of playing shows this well: 
There seemed to be a lot more interaction between the girls today. There was a lot of helping between 
partners when one did not understand the game or the controls. I find that some girls are somewhat impatient 
with the games as they are learning them. Some girls clearly have more patience and actually take out 
the manual to read. Others seem to give up much more quickly. While negotiating the games occupied many 
of these early weeks for the girls, it was also a time when the researchers were attempting many different 
approaches to running the clubs, and because of time constraints, it took five weeks before we noticed 
that we were always setting up the gaming machines. Finally, one day when we arrived late, we found all 
sixteen girls waiting for us. We asked why they hadn t started playing yet, and they said, we didn t 
know how to set up the machines . When we asked if they had any consoles at home, all said that they 
did, but that they never turned it on or set it up so we showed them how and from that time on they were 
responsible for setting up and putting away machines. This might seem like a small point, but it reminded 
us that girls/women are often very much distanced from technological know-how and/or expertise. It did 
not turn out to be the case, for example, that we had to show the boys how to plug in the machines: they 
either knew how, or they learned by doing , but either way, none of the boys ever admitted to not knowing 
how to set up one of the consoles. While the kinds of games that the girls played varied somewhat in 
the first months of the club, by the third month, they were principally playing multiplayer games which 
allowed either for them to play together on split screens, or, in the case of the run­away favorite game, 
Super Monkey Ball, to take turns playing. Because Super Monkey Ball (SMB) figured so prominently in our 
observations of the girls, it merits a brief description for those readers who might not be familiar 
with it. SMB was packaged originally with the Game Cube. Like Duck Hunt, which was package with the Nintendo 
64, it is a highly playable, novice player friendly game. In it, players can choose among a number of 
different play styles a fight sequence, a flight, landing pad sequence, a platform sequence in which 
the challenge is for players to keep their monkey (who rotates in a sphere/ball) within bounds and through 
an end point within the time allowed. In multiplayer mode/s players can play, taking turns, head-to-head, 
and it is the platform level, multiplayer mode that the girl game group categorically liked and excelled 
in. SMB is a perfect example of a console game that is designed to be both easily and highly playable 
and exceedingly pleasurable. Benevolent competition Over the course of our nearly three full school years 
of observations, we came to see interactions between and among the girls playing at all times in relation 
to two very different kinds of exchanges: a) helping and/or competitive and b) self-effacing. When female 
players helped one another, it would either be in the form of advice giving or by taking the controller 
and helping the player level up . In SMB, this was easily achieved as players rotated through each level 
and life , so if one person was not advancing as quickly, she was usually helped along by her peers. 
Competition, then, was directed at the person who was excelling, and took the form of friendly banter 
Look out or You are going to fall or You re going to die . We came to see these sorts of interactions 
as a kind of benevolent competition: never too direct, always somewhat supportive and rarely (in only 
one case in all the hours of video) meant to undermine the player who was ahead. Even when the girls 
reached a definite and observable level of proficiency with a game, in any given interaction, we would 
hear them undermining their own abilities. When they did compete directly with one another, they would 
most often not comment on whether or not their competitor was a good or poor gamer, but would instead 
be more directly related to what was happening in the game at any given time. An example of the kind 
of frequent self-effacing commentary that we saw from a handful of girls in each group (and by only one 
boy) is recorded in this field note: Chandra and Sherry were playing NBA Basketball 2004 on the X-Box 
today. Sherry has some experience on this game console, while Chandra has none. While I was observing 
them play, I noticed the amount of time Chandra spends complaining and putting herself down. Sherry is 
very patient with her while she helps her learn the game and the controls; she both encourages and gives 
her recognition when she accomplishes something. Chandra, however, keeps saying things, like I don t 
know what I m doing half of the time , I stole it (the basketball) from you sorry , But it s (Pac-Man) 
a beginners game, and I need that , I m getting very lazy right now , and Oh my gosh! Why didn t I score? 
What s wrong with me?! I have a feeling that, because of the positive attention she gets from the other 
girls who have to take care of her , she continues this behaviour. Her behaviour seems fairly exaggerated. 
Sherry stated that she thinks that Chandra is better than she thinks she is because, at one point during 
their gaming, Chandra was winning.  The boys, we observed arrived at the gaming club with varying levels 
of console-based play, but all had prior experience playing and indeed there were eight who self-reported 
playing more than 20 hours a week. In the game clubs, boys preferences for play were mostly the head-to-head 
multiplayer games like Mario Kart and Mario Superstrikers (in the second year). In the first year, when 
there were no girls present, they also opted, occasionally, to play SMB, although rarely in its turn-based 
form, but instead in the head-to-head all play mini-games that were available. In the second year, in 
the presence of the girls, the boys never chose to play SMB, significantly that was very much seen to 
be a girl s game and not something that they would be seen playing. The interactions among the boys, 
then, partly because of the games they chose to play on a regular basis, but also because of their different 
prior relations with game playing were different than that of the girls. Most typically, boys interactions 
while playing was limited to: a) seeking help questions like what do I press again? and b) direct competition 
 I beat you. I scored! . There was far less out of game chatter: while the girls would move in and out 
of the game, the boys would almost always focus on the screen in front of them, and all of their conversations 
were related to their play. In contrast to the girls, the boys actively undermined one another, referred 
to each other as good or poor gamers and established and maintained a hierarchy of more and less proficient 
players on any given game. For the boys, much more so than the girls, their game play was connected to 
their identity: they were good or bad, skilled or not skilled, and/or a winner or loser. Because their 
very identity as a game player was at stake when they played, their comments to one another, their banter, 
was often biting and cruel. As one researcher noted: Not only do the boys like their video game feats 
to be acknowledged (like finding a cool shortcut or secret move, or simply being the best), their put 
downs are of a biting personal nature. I found that what people like to term their competitive spirit 
sometimes gets out of hand in that they refuse to be fair and give up their controller in a big group 
which often leads to put downs and direct cruelty. This behavior is especially prevalent when the boys 
were playing a large group (6-8 players). The idea of boys ability being intricately linked to their 
identity can further be seen in the boys reaction to the game Dance Dance Revolution (DDR). DDR, like 
SMB, has a reputation as an easy girls game . One male commented, Hitting little squares with your feet? 
Anybody can do that! What s the point in that? DDR is a somewhat unorthodox video game that has the gamer 
step on an arrow-marked pad at the appropriate moment to replicate dancing to background music. During 
the mixed club, girls, with one exception, always played DDR. One day when DDR was not occupied, a male 
club member decided to try it, seeing how nothing else was available. He danced nervously and awkwardly, 
fully aware that the research assistant was watching him. When asked if he would play again he embarrassingly 
uttered no . It was obvious that he was uncomfortable at being watched while playing DDR because he provided 
a poor performance in a game that is deemed simple, and within eyesight of his friends. As an experienced 
gamer, his pride a) prevented regular exposure to such a game and b) clearly wounded when he failed to 
master the game instantly. Talk , gameplay and literate practices What longitudinal studies of this kind 
allow for is a more nuanced, better developed articulation of the complexities of identity in relation 
to gameplay. Over the course of this study, for example, player preferences (e.g. what girls and boys 
chose in any given session to play) changed incrementally but significantly. In year one, the girls game 
clubs were overseen by a female research assistant (Master s student) who had never taught her own class, 
but was a licensed teacher, and the boys game club was conducted by a male research assistant (Master 
s student) who had taught in a public school for six years. The female researcher had never played console 
or PC games prior to the project, but took home each of the consoles to try out the games; the male researcher 
had played games in the past and began a re-familiarization process with game playing by buying and playing 
Neverwinter Nights but had not played and did not play console-based games. For the girls clubs, this 
meant that Becky was able to provide little in the way of help as the girls navigated (many for the first 
time) navigation screens, learned how to start games and browse menu options, etc. They eventually did 
learn these things through practice and trial and error, but they limited themselves to the easier more 
novice friendly game, SMB for their primary play. For the boys, it meant that they did not have an adult 
audience or sounding board who was able to speak to them using the in game jargon , nor did they perceive 
Jason as potential competition as they played. Instead, they turned towards one another to talk about 
the game, competed head-to-head on games like Mario Kart and Need for Speed, and waited to play SMB with 
the same patience the girls exhibited. In year two, when the girls still had not migrated from SMB and 
the boys (with a single exception) would not go near it, the research assistant was a fourth-year undergraduate 
female who considered herself a gamer . Her interactions with the participants were therefore qualitatively 
different: with the girls, she was able to help them through the menus they had found off putting, explain 
purposes and rules of games, and most importantly, instruct them on the general control mechanisms when 
playing a game for the first time. The result was that the girls did not just play SMB they branched 
out to play, and played (somewhat) consistently, Mario Kart, Need for Speed, Paper Mario and Wario Ware. 
When interacting with the boys, she had often played well beyond their abilities in their two favorite 
games Mario Kart and Mario Superstrikers and was early on in the club called on to occasionally play 
along side them (Jason reported he was never invited to play with participants). What we saw over time 
was, first, a demonstrative shift in play practices and game choices by both boys and girls; and second, 
a very different account of girls and play than has been articulated in the girls and gaming literature, 
from its initial through its contemporary incarnations. The shift was noted in moving from a girls- and 
boys- only play spaces from year one to year two. This resulted in a heightened, overt competition displayed 
on the part of the boys, and on the part of the girls we witnessed an experimental enactment of play 
 they gave each other high fives, pushed at each other and enacted a kind of physicality that was very 
much absent in their male counterparts. In part, this demonstrative, more overt play performance (around 
the actual playing of the game) was opened up, we surmise, in the shift from a teacher-ly and non-gamer 
adult presence to an adult peer, gamer presence and (arguably) by the presence of opposite sex peers 
who were potential (though not often actual) spectators to game play. Secondly, and over the period of 
two years, we observed, time and again, girls who were actively, though with self-derision, competing. 
What was not at stake for them in their competition, however, was their identity (unlike the boys) as 
a particular kind of game player (good). They explicitly disavowed, often through self-derision, any 
identity as a good gamer , they teased each other a lot, laughed a lot, grabbed the controller from each 
other, talked about things outside the game, walked around the play space rather than being fixed to 
the game screen and controls, and in general saw the game clubs as an opportunity to hang out with their 
friends and play, something that they did not have access to at home or in their lives outside the club. 
  CONCLUSION/S In our surveys and interviews only four boys report playing with girls: all reported 
playing with other boys, and yet all of the girls reported playing with boys and only infrequently, with 
other girls. When girls and young women reported playing games which were decidedly not gender appropriate 
(like Halo/Halo 2, Vice City, San Andreas, or the like), they always reported playing with a male player. 
In our mixed sex club, (as we ve indicated earlier) only one boy chose to play with two other girls, 
but none of the other 8 boys ever approached any of the other girls to play with them. As we have reported 
else where [5] we think these findings might be highly significant in terms of whether and how for most 
women, transgressing gender norms in relation to playing games, occurs most frequently when it is legitimated 
by male relations (boyfriends, cousins, brothers and fathers) and therefore does not transgress gender 
stereotypes nor jeopardize a normalized, stereotypical feminine identity which is clearly outside of 
the masculine culture of video game playing. One young woman (13) we interviewed, for example, talked 
extensively about her experiences playing games, which she said she either did with her brother or alone. 
She stated that she and her brother have different games that they are interested in playing, and if 
she is playing one of her games that he does not like, he will still interrupt her game and grab the 
controller if she is having trouble. She says that this does not bother her, and that she welcomes the 
help; she would prefer to have him finish a level for her, than play it on her own and struggle with 
it In the third year of same-sex play groups, the girls insistently requested a full year game tournament 
, an explicitly competitive approach to their play, and to that end they began in earnest to keep and 
compare game scores, something that we had only seen among the boys, and which obviously challenged received 
assumptions that girls are naturally uninterested in and even aversive to competitive play. Both the 
boys and girls groups asked to play together for their last session, and when teams were put together, 
we saw for the first time boys asking girls to join their teams. We had, for the first time ever, freely 
chosen mixed sex groups, but because these were groups in which girls REALLY played, and didn t just 
watch or help , this, too, ran counter to everything we had seen before the extensive same-sex play groups 
began. Its important to be tentative in drawing conclusions here, but what we think we see is a leveling 
up of girls with boys in relation to game play, game choices, peer selection, levels and kinds of participation, 
competition and skill. The gender differences so consistently found in gender and gameplay studies, and 
no less found in our own initial work with these young people, were far less evident and some of these 
were no longer present at all, once the girls had been afforded genuine access, support, a girls-gamer 
model, and the right to choose what, when and with whom they would play. In earlier work (Bryson &#38; 
de Castell, 1998) concerned with developing girls competence and confidence with new technologies, we 
found girls only groups to be highly effective, however we suggested at that time that such a step up 
needn t be seen as a threat to the normative gender order of the school which in fact at that time required 
mixed sex grouping for instruction. We argued, but did not in that limited project determine, that it 
wouldn t be long before mixed sex groupings for technology-focused learning would be possible without 
sidelining, discouraging and intimidating the girls, as we saw to be the case in mixed sex groupings 
initially. However, this study does offer support to that supposition: that an affirmative action pedagogy 
of girls-only groups for activities and engagements in which boys traditionally appear to dominate in 
terms of both interest and skill CAN be effective in leveling the playing field . Our longitudinal study 
offers confidence to that supposition to recognize that, few of the indices (with the exception of self-ascribed 
identity as a good gamer ) which we had used at the start of the project to initially determine these 
girls play preferences, styles, activities, and identities could be used, three years later, to identify 
gender-based differences with respect to digital gameplay. Dominant cultural presumptions of progressive 
gender equality would impose upon those who discern persisting differences, the obligation to seek explanations. 
That and how these differences are contrived, produced, that they continue to be actively and ongoingly 
constructed, is not a popular story, and, given that the stories we tell are co-produced by the audiences 
we address, we should be less than surprised that accounts of gender and game play, and the theoretical 
and methodological props that support and enable these, should have shifted only fractionally since the 
earliest beginnings of research into this field. What is so difficult about gender-based work of this 
kind is to challenge the category of gender in order to resist its re­inscription in the very categories 
that we seek to dismantle e.g. preferences and play styles. The central problem, then, is to show how 
and why different girls under different conditions are induced to play different games in different ways 
--- that they chose SMB, in this context, for example, for us held no real significance. Our task is 
more to find out how to identify differences in game play without naturalizing them into an underlying 
truth of gender. This means refusing question about preference in an effort to attend more particularly 
to how and under what conditions girls and women play the way they do, without attributing to that way 
of playing in and of itself any enduring or fixed significance.  REFERENCES [1] AAUW: American Association 
of University Women (2000). Tech-savvy: Educating girls in the new computer age. Researched by Commission 
on Technology, Gender, and Teacher Education. Washington, DC: American Association of University Women 
Educational Foundation.  [2] AAUW: American Association of University Women (2004). Under the microscope: 
A decade of gender equity projects in the sciences. Available at: http://www.aauw.org/research/underthemicroscope.pdf. 
Last accessed April 20, 2007. [3] Beasley, B., &#38; Standley, T. C. (2002). Shirts vs. skins: Clothing 
as an indicator of gender role stereotyping in video games. Mass Communication and Society, 5 (3), 279-293. 
[4] Bryce, J., &#38; Rutter, J. (2003). The gendering of computer gaming: Experience and space. In S. 
Fleming &#38; I. Jones (Eds.), Leisure culture: Investigations in sport, media and technology (pp. 3-22). 
Eastbourne, UK: Leisure Studies Association. [5] Carr, D. (2005). Context, Gaming Pleasures and Gendered 
Preferences. Simulation and Gaming, 36, 4, p. 464-482. [6] Carr, D. (2007). Contexts, Pleasures, and 
Preferences: Girls Playing Computer Games. In S. de Castell &#38; J. Jensons (Eds.), Worlds In Play: 
International Perspectives on Digital Games Research (pp.313-322). New York: Peter Lang Publishing. [7] 
Cassell, J. &#38; Jenkins, H. (Eds.) (1998). From Barbie to Mortal Kombat. Boston: The MIT Press. [8] 
de Castell, S., &#38; Bryson, M. (1998). Retooling play: Dystopia, dysphoria, and difference. In J. Cassell 
&#38; H. Jenkins (Eds.), From Barbie to Mortal Kombat (pp. 232­261). Cambridge, MA: MIT Press. [9] Dietz, 
T. L. (1998). An examination of violence and gender role portrayals in video games: Implications for 
gender socialization and aggressive behavior. Sex Roles, 38 (5-6), 425-442. [10] Denner, J., Werner, 
L., Bean, S., &#38; Campe, S. (2005). The Girls Creating Games Program: Strategies for engaging middle 
school girls in information technology. Frontiers: A Journal of Women s Studies. Special Issue on Gender 
and IT, 26, 90-98. [11] Gee, J.P. (2003). What video games have to teach us about learning and literacy. 
New York: Palgrave Macmillan. [12] Gee, J.P. (2006). The Classroom of Popular Culture. Harvard Education 
Letter. [13] Gee, J.P. (2007). Good Video Games and Good Learning: Collected Essays on Video Games, Learning 
and Literacy. New York: Peter Lang Publishers. [14] Goode, J., Estrella, R., &#38; Margolis, J. (2006). 
Lost in translation: Gender and high schoolcomputer science. In J.M. Cohoon &#38; W. Aspray (Eds.), Women 
and information technology: Research on underrepresentation (pp. 89-114). Cambridge, MA: MIT Press. [15] 
Flanagan, M., Howe, D.C. &#38; Nissenbaum, H. (2005). New Design Methods for Activist Gaming. Proceedings 
from DiGRA 2005, 16-20 June, Vancouver, BC, Canada [16] Flanagan, M. Howe, D. C. &#38; Nissenbaum, H. 
(2005). Values at Play: Design Tradeoffs in Socially-Oriented Game Design. Proceedings of the SIGCHI 
conference on Human factors in computing systems, p. 751-760. Portland, Or. [17] Flanagan, M., Howe, 
D.C. &#38; Nissenbaum, H. (2007). New Design Methods for Activist Gaming. In S. de Castell &#38; J. Jensons 
(Eds.), Worlds In Play: International Perspectives on Digital Games Research (pp. 241-248). New York: 
Peter Lang Publishing. [18] Hill, C. (2002). Contradiction, culture and computers, unpublished Master 
s Thesis Simon Fraser University: Burnaby, British Columbia, Canada. [19] Ivory, J.D. (2006). Still 
a Man's Game: Gender Representation in Online Reviews of Video Games. Mass Communication and Society, 
9, 103-114. [20] Jansz, J. &#38; Martis, R. G. (2007). The Lara Phenomenon: Powerful Female Characters 
in Video Games. Sex Roles, 56, 141-48. [21] Jenson, J. (1999). Girls ex machina: A school-based study 
of gender, culture and technology, Doctoral Thesis Simon Fraser Universtity: Burnaby, British Columbia, 
Canada. [22] Jenson, J. &#38; de Castell, S. (2005). Her Own Boss: Gender and the Pursuit of Incompetent 
Play. DiGRA 2005, Vancouver, Canada. [23] Kafai, Y. B. (1995). Minds in Play: Computer Game Design As 
a Context for Children s Learning. Hillsdale, NJ: Lawrence Erlbaum Associates. [24] Kafai, Y. B. (2006). 
Playing and Making Games for Learning: Instructionist and Constructionist Perspectives for Game Studies. 
Games and Culture, 1 (1), 36-40. [25] Kaiser Family Foundation (2005). Kids &#38; Media @ The New Millennium. 
Program for the Study of Media and Health. Available online at: http://www.kff.org/entmedia/1535-index.cfm. 
Last accessed 14 April 2007. [26] Kelleher, C. (2005). Motivating Programming: Using storytelling to 
make computer programming attractive to middle school girls. Unpublished PhD Dissertation, Carnegie MellonUniversity, 
School of Computer Science [27] Klawe, M. (2005). Increasing the number of women in computer science, 
what works? SIGCSE 2005, p. 562. [28] Krotoski, A. (2004). Chicks and joysticks: An exploration of women 
and gaming. London: Entertainment and Leisure Software Publishers Association. [29] Prensky, M. (2000). 
Digital Game-Based Learning. New York: McGraw Hill. [30] Prensky, M. (2006) Don t bother me mom, I m 
learning. St. Paul, Minnesota: Paragon House Publishers. [31] Ray, S. G. (2004). Gender Inclusive Game 
Design: Expanding the Market. Hingham, Massachuetts: Charles River Media, Inc. [32] Smith, S. L., Lachlan, 
K., &#38; Tamborini, R. (2003). Popular video games: Quantifying the presentation of violence and its 
context. Journal of Broadcasting and Electronic Media, 47 (1), 58-76. [33] Taylor, T. L. (2006). Play 
Between Worlds: Exploring Online Game Culture. Boston: The MIT Press. [34] Walkerdine V. (1998) Children 
in cyberspace, in K. Lesnik-Oberstein (Ed.) Children in culture, London, Macmillan [35] Walkerdine, V., 
Thomas A. &#38; Studdert, D. (N.D). Young children and video games: dangerous pleasures and pleasurable 
danger. Available at http://creativetechnology.salford.ac.uk/fuchs/projects/downlo ads/young_children_and_videogames.htm. 
Last accessed April 10, 2007.  
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2007</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>1328206</article_id>
		<sort_key>40</sort_key>
		<display_label>Pages</display_label>
		<pages>6</pages>
		<article_publication_date>11-14-2007</article_publication_date>
		<seq_no>3</seq_no>
		<title><![CDATA[Digital game design for elderly users]]></title>
		<page_from>17</page_from>
		<page_to>22</page_to>
		<doi_number>10.1145/1328202.1328206</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1328206</url>
		<abstract>
			<par><![CDATA[<p>The current paper reviews and discusses digital game design for elderly users. The aim of the paper is to look beyond the traditional perspective of usability requirements imposed by age-related functional limitations, towards the design opportunities that exist to create digital games that will offer engaging content combined with an interface that seniors can easily and pleasurably use.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[digital game design]]></kw>
			<kw><![CDATA[elderly users]]></kw>
			<kw><![CDATA[review]]></kw>
			<kw><![CDATA[social and cognitive benefits of games]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>J.4</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010405.10010455</concept_id>
				<concept_desc>CCS->Applied computing->Law, social and behavioral sciences</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010455</concept_id>
				<concept_desc>CCS->Applied computing->Law, social and behavioral sciences</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Human Factors</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP36022994</person_id>
				<author_profile_id><![CDATA[81100032008]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Wijnand]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ijsselsteijn]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Eindhoven University of Technology, Eindhoven, The Netherlands]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P925235</person_id>
				<author_profile_id><![CDATA[81342505631]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Henk]]></first_name>
				<middle_name><![CDATA[Herman]]></middle_name>
				<last_name><![CDATA[Nap]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Eindhoven University of Technology, Eindhoven, The Netherlands]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P925273</person_id>
				<author_profile_id><![CDATA[81100272468]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Yvonne]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[de Kort]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Eindhoven University of Technology, Eindhoven, The Netherlands]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P925254</person_id>
				<author_profile_id><![CDATA[81342507668]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Karolien]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Poels]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Eindhoven University of Technology, Eindhoven, The Netherlands]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Bouwhuis, D. G. (2003). Design for person-environment interaction in older age: A gerontechnological perspective. Gerontechnology, 2, 232--246.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1105309</ref_obj_id>
				<ref_obj_pid>1104998</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Cheok, A. D., Lee, S., Kodagoda, S., Tat, K. E., &amp; Thang, L. N. (2005). A social and physical inter-generational computer game for the elderly and children: Age invaders. Proceedings of the 2005 Ninth IEEE International Symposium on Wearable Computers (ISWC'05).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Czaja, S. J., Charness, N., Fisk, A. D., Hertzog, C., Nair, S. N., Rogers, W. A., &amp; Sharit, J. (2006). Factors predicting the use of technology: Findings from the Center for Research and Education on Aging and Technology Enhancement (CREATE). Psychology and Aging, 21, 333--352.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>772101</ref_obj_id>
				<ref_obj_pid>772072</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Czaja, S. J., &amp; Lee, C. C. (2003). Designing computer systems for older adults. In J. A. Jacko &amp; A. Sears (Eds.), The Human-Computer Interaction Handbook - Fundamentals, Evolving Technologies and Emerging Applications (pp. 425). Mahwah, New Jersey: Lawrence Erlbaum Associates.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1232575</ref_obj_id>
				<ref_obj_pid>1232572</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Czaja, S. J., &amp; Lee, C. C. (2007). The impact of aging on access to technology. Universal Access in the Information Society, 5, 341--349.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Docampo Rama, M. (2001). Technology Generations Handling Complex User Interfaces. PhD Dissertation, Eindhoven University of Technology.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Drew, B. &amp; Waters, J. (1986). Video games: Utilization of a novel strategy to improve perceptual motor skills and cognitive functioning in the noninstitutionalised elderly. Cognitive Rehabilitation, 4, 26--34.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Dweck, C. S. (1986). Motivational processes affecting learning. American Psychologist, 41, 1040--1048.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Eggermont, S., Vandebosch, H., &amp; Steyaert, S. (2006). Towards the desired future of the elderly and ICT: Policy recommendations based on a dialogue with senior citizens. Poiesis &amp; Praxis 4: 199--217.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[ESA (2005). Essential Facts About the Computer and Video Game Industry; 2004 Sales, Demographics, and Usage data. Entertainment Software Association (ESA).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[ESA (2006). Essential Facts About the Computer and Video Game Industry; 2005 Sales, Demographics, and Usage data. Entertainment Software Association (ESA).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Fisk A. D., Rogers A. R., Charness N, Czaja S. J., &amp; Sharit J. (2004). Designing for Older Adults - Principles and Creative Human Factors Approaches. Boca Raton: CRC Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Goldstein, J., Cajko, L., Oosterbroek, M., Michielsen, M., van Houten, O., &amp; Salverda, F. (1997). Video games and the elderly. Social Behavior and Personality, 25, 345--352.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Griffiths, M. (2005) The therapeutic value of video games. In Raessens, J &amp; Goldstein, J. (Eds.) Handbook of Computer Games Studies (pp. 161--171). Cambridge, MA: The MIT Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[van Hees, M. (1994). Oud geleerd, oud gedaan, optimalisering van handleidingen voor ouderen. Graduation thesis, Utrecht University.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Hollander, E. K. &amp; Plummer. H. R. (1986). An innovative therapy and enrichment program for senior adults utilizing the personal computer. Activities, Adaptations &amp; Aging, 8(1), 59--68.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1238791</ref_obj_id>
				<ref_obj_pid>1238784</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[IJsselsteijn, W. A., de Kort, Y. A. W., Westerink, J., de Jager, M., &amp; Bonants, R. (2006). Virtual Fitness: Stimulating Exercise Behaviour through Media Technology. Presence: Teleoperators and Virtual Environments 15, 688--698.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Kangas, S. &amp; Lampila, P. (2006) Young people involved in developing prototypes of role games that encourage physical exercise. VTT Press Release. Retrieved 30 June 2007: http://virtual.vtt.fi/exergame/pub/consumer_press_english.pdf.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[de Kort, Y. A. W., IJsselsteijn, W. A., Midden, C. J. H., Eggen, J. H., van den Hoven, E. A. W. H. (2005). Persuasive gerontechnology. Gerontechnology 4, 123--127.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[de Kort, Y. A. W., Midden, C. J. H., &amp; van Wagenberg, A. F. (1998). Predictors of adaptive problem solving of older persons in their homes. Journal of Environmental Psychology, 18, 187--197.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[de Kort, Y. A. W., Midden, C. J. H., Aarts H., &amp; van Wagenberg, A. F. (2001). Determinants of adaptive behavior among older persons; Self-efficacy, importance and personal dispositions as directive mechanisms. International Journal for Aging and Human Development, 53 (4), 263--283]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Marqui&#233;, JC, Jourdan-Boddaert, L, Huet, N (2002). Do older adults underestimate their actual computer knowledge?. Behaviour &amp; Information Technology, 21(4), 273--280.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[Mayhorn, C. B., Lanzolla, V. R., Wogalter, M. S., &amp; Watson, A. M. (2005). Personal digital assistants (PDAs) as medication reminding tools: Exploring age differences in usability. Gerontechnology, 4, 128--140.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[McGuire, F. A. (1984). Improving the quality of life for residents of long term care facilities through video games. Activities, Adaptation &amp; Aging, 6(1), 1--7.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[Melenhorst, A.-S. (2002). Adopting communication technology in later life. The decisive role of benefits. PhD Dissertation, Eindhoven University of Technology.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[Miller, G. (2005). Society for neuroscience meeting: Computer game sharpens aging minds. Science, 310, No. 5752, p.1261.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>516154</ref_obj_id>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[Morrell, R. W. (Ed.). (2002). Older Adults, Health Information and the World Wide Web. Mahwah, New Jersey: Lawrence Erlbaum Associates.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[Nielsen Interactive Entertainment (2005). Video gamers in Europe -- 2005. Research Report Prepared for the Interactive Software Federation of Europe (ISFE).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[Nielsen, J. (2002). Usability for senior citizens. Alertbox, April 28, 2002. Retrieved 30 June 2007, http://www.useit.com/alertbox/20020428.html]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>30</ref_seq_no>
				<ref_text><![CDATA[Pratchett, R., Harris, D., Taylor, A. &amp; Woolard, A. (2005) Gamers in the UK: Digital Play, Digital Lifestyles. London: BBC.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>31</ref_seq_no>
				<ref_text><![CDATA[Riddick, C. C., Drogin, E. B., &amp; Spector, S. G. (1987). The impact of videogame play on the emotional states of senior center participants. Practice Concepts, 27, 425--427.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>32</ref_seq_no>
				<ref_text><![CDATA[Rogers, W., &amp; Fisk, A. (2000). Human factors, applied cognition, and aging. In: F. I. M. Craik &amp; T. A. Salthouse (Eds.), The Handbook of Aging and Cognition. Mahwah, NJ: LEA]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>33</ref_seq_no>
				<ref_text><![CDATA[UN (2006). World Population Prospects, The 2006 Revision. United Nations Department of Economic and Social Affairs, Population Division. Retrieved 30 June 2007, http://www.un.org/esa/population/publications/wpp2006/wpp2006.htm]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>34</ref_seq_no>
				<ref_text><![CDATA[Weisman, S. (1983). Computer games for the frail elderly. The Gerontologist, 23(4), 361--363.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>97401</ref_obj_id>
				<ref_obj_pid>97344</ref_obj_pid>
				<ref_seq_no>35</ref_seq_no>
				<ref_text><![CDATA[Whitcomb, G. R. (1990). Computer games for the elderly. Proceedings of the conference on Computers and the quality of life. George Washington University, Washington, D.C., United States, pp. 112--115.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Digital Game Design for Elderly Users Wijnand IJsselsteijn Eindhoven University of Technology Game 
Experience Lab, HTI Group Den Dolech 2, 5600 MB, Eindhoven The Netherlands  w.a.ijsselsteijn@tue.nl 
 Henk Herman Nap Eindhoven University of Technology Game Experience Lab, HTI Group Den Dolech 2, 5600 
MB, Eindhoven The Netherlands  h.h.nap@tue.nl Karolien Poels Eindhoven University of Technology Game 
Experience Lab, HTI Group Den Dolech 2, 5600 MB, Eindhoven The Netherlands  k.poels@tue.nl Yvonne de 
Kort Eindhoven University of Technology Game Experience Lab, HTI Group Den Dolech 2, 5600 MB, Eindhoven 
The Netherlands  y.a.w.d.kort@tue.nl ABSTRACT The current paper reviews and discusses digital game 
design for elderly users. The aim of the paper is to look beyond the traditional perspective of usability 
requirements imposed by age­related functional limitations, towards the design opportunities that exist 
to create digital games that will offer engaging content combined with an interface that seniors can 
easily and pleasurably use. Categories and Subject Descriptors [J.4 SOCIAL AND BEHAVIORAL SCIENCES] 
 General Terms Design, Human Factors  Keywords Digital game design, elderly users, social and cognitive 
benefits of games, review. 1. INTRODUCTION "I´m growing older, but not up." - Jimmy Buffett There are 
compelling social and financial reasons why game developers should think seriously about making their 
games Permission to make digital/hard copy of part of this work for personal or classroom use is granted 
without fee provided that the copies are not made or distributed for profit or commercial advantage, 
the copyright notice, the title of the publication, and its date of appear, and notice is given that 
copying is by permission of the ACM, Inc. To copy otherwise, to republish, to post on servers, or to 
redistribute to lists, requires prior specific permission and/or a fee. FuturePlay 2007, November 15-17, 
2007, Toronto, Canada. Copyright 2007 ACM 978-1-59593-943-2/07/0011...$5.00 interesting and accessible 
to elderly users. Digital games hold a significant promise for enhancing the lives of seniors, potentially 
improving their mental and physical wellbeing, enhancing their social connectedness, and generally offering 
an enjoyable way of spending time. From a commercial point of view, elderly users are potentially a very 
large customer base. Worldwide, the population is ageing rapidly, and this is particularly true for Europe, 
where the proportion of seniors is dramatically on the rise [33]. However, the growing 65+ demographic 
is currently not well served by the majority of commercial games on the market, creating a significant 
potential niche market for game developers. In this paper, we discuss a number of demographic characteristics 
and age-related sensory, cognitive and motor properties that may influence the senior s experience of 
interacting with digital games. To date, the interface design community has focused primarily on the 
design requirements that make interactive applications, including digital games, usable for elderly users. 
Indeed, usability is a sine qua non, and usability issues can be a serious showstopper to user acceptance. 
However, usability in itself is not a sufficient motivation to use software. What is important to realize 
is that game design for elderly users should not only focus on usability issues, but should also seriously 
investigate the motivations of seniors to engage with new technology. A perceived lack of benefits may 
be more detrimental to the adoption of digital games, than perceived costs associated with usability 
problems. We need to design for rich and rewarding experiences, combining low-threshold interaction styles 
with content that will directly speak to and engage elderly users.  2. ELDERLY GAMERS By the year 2020, 
one in four of the European population will be aged over 60, and the largest increase is expected in 
the oldest age groups (75+). Although quite a bit of demographic data is available on gamers below 65 
years of age, relatively little is known for people over 65. Recent research, commissioned by the BBC, 
shows that people over 65 watch more TV than other age groups, and are also the most likely to cite TV 
viewing as their favorite activity. Of all age groups they are least likely to be using the internet. 
If they do use it, it is mostly for practical purposes - travel, finance, education and shopping. However, 
over a third of pensioners state that they like to keep up with new technology.  It is hard to find 
reliable numbers that adequately characterize the adoption and use of digital games amongst seniors. 
A review of pioneering research in this area [35] showed that a majority of elderly users were interested 
to engage in playing digital games when they were offered the opportunity through organizational stimulation 
or study programs, and that such gameplay could yield several benefits, ranging from improvements in 
perceptual­motor speed to social and educational enrichment. However, it was also found that many of 
the games were either not enjoyable or were unsuitable because of a challenging interface (e.g., small 
size of the objects on the screen, rapid movements or reactions required). Although not addressing the 
65+ demographic, Pratchett, Harris, Taylor and Woolard [30] report that approximately one in five (18%) 
of the 51-65 year olds in their sample of UK participants played digital games, two thirds of whom play 
at least once a week. These findings may not be homogeneous across Europe, though. For example, a recent 
Finnish consumer study performed by VTT as part of the Exergames project (1,489 respondents between 13 
and 76 years) found that every second (52%) pensioner (over 65 years old) stated to play computer games, 
and every fifth (22%) pensioner stated to play games on a daily basis However, almost all pensioners 
(93%) spent less than an hour playing at a time [18]. In the US, the Entertainment Software Association 
(ESA) reports on data from almost 1500 respondents in their Essential facts about the computer and video 
game industry publication. They found that 19% of Americans over the age of 50 played video games in 
2004, an increase from 9% in 1999. In 2005, this number rose to 25% [10; 11]. Overall, it is clear that 
seniors play digital games to a lesser degree than younger aged groups, but this cannot be attributed 
to a lack of openness or interest. Despite the fact that interacting with computer technology can be 
challenging for seniors, the literature suggests that older people are generally quite receptive to using 
new technology. In a detailed study of technology adoption behavior by elderly users, Melenhorst [25] 
found that older individuals are motivated to invest in new communication technology provided they perceive 
enough benefit for their purposes. The perception of a lack of benefits, irrespective of perceived costs, 
is reason enough to reject a new technology. In line with these findings, Eggermont, Vandebosch, and 
Steyaert [9] report that, in general, elderly are proponents of technological advancement, which may 
provide valuable opportunities for them, but not at any price. For example, they do not want technology 
that replaces face-to-face contacts, but are interested in technology that supports additional social 
contacts, connecting people with similar interests (e.g., clubs), or helping them to stay in touch when 
immobile.  3. AGE RELATED CHANGES AND DIGITAL GAME DESIGN Although seniors are quite diverse in abilities 
and experience, older age is generally associated with a number of well­documented changes in sensory-perceptual 
processes, motor abilities, response speed and cognitive processes, all of which impose requirements 
on interfaces that are to be pleasurably used by the growing elderly population. We will briefly summarise 
some of the main issues here. For a more detailed treatment, we refer to Czaja and Lee [4], and Fisk, 
Rogers, Charness, Czaja and Sharit [12]. With increased age, there is a loss in static and dynamic visual 
acuity, as well as a reduction in the range of visual accommodation, a loss of contrast sensitivity, 
decreases in dark adaptation, declines in colour sensitivity, and a heightened susceptibility to problems 
with glare. Such visual decrements may make it harder for elderly people to perceive small elements on 
a display (e.g., single soldiers in a real-time strategy game), to read small print instructions or captions, 
or to locate information on complex screens. Allowing the user easy control of font, color and contrast 
setting, as well as window resizing, scroll rate and zooming, is generally recommended. These adjustments 
should not exceed appropriate boundaries for the playability of a game on a system, e.g., a 200 point-size 
font on a portable game device will not increase readability. At any moment in time, the user should 
be able to directly undo the adjustments by means of a single click. Ageing is also related to declines 
in auditory acuity, in particular sensitivity for pure tones, and high frequency tones. Problems may 
occur in localizing sound, through problems in binocular hearing. Older people may find it hard to understand 
synthetic speech, because it is often somewhat distorted. For non-speech audio signals, lower frequency 
tones (in the 500-1000 Hz range) are easier for elderly users to hear than higher pitched sounds. In 
general, it is advisable to provide redundant information through multiple modalities. For example, if 
an in-game sound effect delivers vital information, tactile (vibration) feedback through a rumblepad 
or force-feedback joystick would be helpful as well. Moreover, online social play should support both 
headsets (voice) and text messaging (keyboard) for communication. Motor impairments are diverse in their 
nature and cause, and have varying degrees of impact on the user experience. Generally though, senior 
users may experience changes in motor skills, including slower response times, declines in ability to 
maintain continuous movements, disruptions in coordination and balance, loss of flexibility, and greater 
variability in movement [32]. Thus, it may become a challenge to be steady with the mouse, or any other 
control device. Small targets and moving interface elements are known to be difficult for older people, 
and should best be avoided. Age-related changes in cognition are also likely to affect the requirements 
of interface design. Cognitive processes that decline with age include attention processes, working memory, 
discourse comprehension, problem solving and reasoning, and memory encoding and retrieval. Apparently 
easy computer tasks may put quite a stringent demand on many of the processes mentioned here. For example, 
remembering information from one screen to another could be difficult because of limits in attention 
(see [5]) and working memory. From the point of view of interface design, the focus has to be on simplicity 
and intuitiveness, providing appropriate affordances and overview, thus keeping the load on memory and 
cognitive processing to a minimum.  In addition to functional limitations, the current generation of 
seniors has not been exposed to the same level of computer technology as the younger generation. In fact, 
many pensioners have retired without needing or having used computers or the internet at all during their 
working lives. Thus, this lack of exposure may result in seniors not having an accurate mental representation 
or conceptual model of how computer technology works, what it can and cannot do. There is very little 
published literature available on the potential differences in the way mental models are built up by 
seniors as compared to the young. Van Hees [15] suggested that elderly users must unlearn some of their 
accumulated knowledge if it does not fit with the properties of new technologies. Docampo Rama [6] has 
demonstrated that in addition to an age effect (i.e., decline of function over age) there is also an 
independent effect of technology generation, that is, the dominant user interface experienced during 
the formative period in life. When confronted with a layered interface, there Docampo Rama found a pronounced 
discontinuity in the number of error between people from the electro-mechanical generation (born before 
1960) and those from the software generation (born after 1960), suggesting a generational effect. Time 
on task, on the other hand, increased linearly with age, indicating a more continuous cognitive change. 
In addition, elderly users appear to use somewhat different strategies in handling novel interfaces, 
taking a more reflective approach, rather than a trial-and-error one [6]. The functional limitations 
and ICT experience of seniors could have an impact on seniors' confidence level in playing, or starting 
to play, digital games. Within the ICT domain, seniors are less confident in their ability to perform 
than the young, which is related to poorer, computer-related, global self-efficacy beliefs [22]. Czaja, 
Charness, Fisk, Hertzog, Nair, Rogers, and Sharit [3] found that computer self-efficacy is an important 
predictor of computer anxiety. So, to decrease computer anxiety it is important that seniors receive 
encouraging feedback and experience some level of success (see [3]). Within the games industry there 
already is a lot of (heuristic) knowledge about how to provide effective positive feedback that increases 
the self­efficacy or mastery of gamers. To support inexperienced elderly users in overcoming their anxiety 
it is recommended to design games that provide enough time to learn basic necessary skills, and provide 
encouraging feedback from the start (e.g., provide positive feedback in a strategy game after having 
build a town centre, instead of providing feedback after having conquered Europe). In this context, it 
is generally beneficial to emphasize and provide feedback on learning goals rather than performance goals, 
especially when the senior s confidence in his or her present abilities is low [8]. By presenting learning 
goals, there is a focus on progress and mastery, rather than ability judgments, which will likely increase 
the senior s motivation and persistence to engage in a task that is initially perceived as challenging. 
In a quantitative study of web usability, Nielsen [29] compared the performance (tasks completed, time 
on task, number of errors) and subjective ratings of elderly users with that of younger users, and found 
that overall, seniors experience more than twice the usability problems than do younger users. He also 
found a strong positive correlation between successful performance on the various tasks, and subjective 
preference (r=0.78), indicating a strong preference for those websites that are easiest to use. In short, 
seniors are hurt more by bad design, and increasing usability will significantly increase their satisfaction. 
Although the discourse of disengagement and an age-related digital divide has dominated discussions on 
the effects of old age on ICT use, it should be noted that certainly not all seniors face difficulties 
when interacting with computers. The larger part consists of mentally and physically healthy autonomous 
adults between 55 and 75 years of age [1]. Most seniors are very well capable of acquiring computer skills, 
learning how to use the web (see, e.g., [27]), or learning how to use PDA's [23]. Moreover, retirement 
can also be considered as a time for further exploration in life, rather than withdrawing from it. Digital 
games may offer elderly users with new and exciting ways to be entertained, stimulating mental abilities, 
and supporting existing and emerging social networks, both within and across generations. The accumulation 
of knowledge and wisdom, heterogeneity of experiences, and changing social and societal roles that come 
with age also bear relevance to the design of digital games. Perhaps the most important design requirement 
we can formulate is to offer seniors the kind of content they will appreciate and engage with, even if 
this requirement is perhaps not as easily and unambiguously specified and will be more idiosyncratic. 
As the work of Melenhorst [25] has shown, it is not so much the cost of having to learn a new interface 
that elderly users find prohibitive, but a lack of perceived benefits. Thus, if a user-friendly interface 
only provides access to games that are uninteresting for the elderly user, he or she is not likely to 
engage with the content. To put it differently, Counterstrike with adjustable font size may not be the 
killer application for elderly users.  4. BENEFITS OF PLAYING DIGITAL GAMES Although little is known 
about senior adults perceived benefits of digital games, there is a small but growing body of research 
evidence in support of the notion that digital games can have a significant positive impact on the older 
person s mental and physical health and wellbeing (see [14] for a brief review). In one of the earliest 
studies in this area, Weisman [34] suggested that digital games can play a positive role in meeting seniors 
need for fun and mental stimulation, while also heightening their self­esteem. He reported that moderate 
physical and mental impairments did not prevent the nursing home patients in his study to participate, 
using four games specifically designed for this population. Hollander and Plummer [16] reported on a 
study involving a senior community in Rockville, MD, who were asked to play video games over a three 
week period. Results indicated that thought-provoking games (Trivia and Hangman) were found to be the 
most stimulating and attention-grabbing. Therapeutic effects were reported in a greater constructive 
use of leisure time, and in participants increased feelings of success and achievement.  McGuire [24] 
studied the effectiveness of digital games in improving self-esteem among elderly long-term care residents. 
Elderly residents in one wing of the institution were offered video games for a period of eight weeks, 
whereas residents of a second wing did not have the opportunity to play video games. Results demonstrated 
that the elderly that played video games had an improvement in self-esteem. Similarly, Goldstein et al. 
[13] found that playing digital games for five hours per week for five weeks improved reaction times, 
self-esteem and sense of well-being for the elderly participants in his study. It did not, however, have 
a significant effect on cognitive performance when compared to controls. Drew and Waters [7] have argued 
for the use of video games for improving hand-eye coordination, or for slowing deterioration, with age. 
A decline in perceptual-motor functions has serious consequences which affects a range of activities 
of daily living. The use of video games may ameliorate this situation for large numbers of (non-institutionalized) 
seniors. Finally, Miller [26] recently reported on a trial of 95 healthy older adults with an average 
age of 80. Those who played HiFi, a game designed to boost the function of the ageing brain, on a regular 
basis, improved their scores on tests of memory and attention. Although these studies indicate the potential 
benefits of digital gaming in older age, especially on self-esteem and mental stimulation, it should 
be noted that this research is still in its infancy, and also some contradictory findings have been reported 
(e.g., with regard to emotions; see [31]). Moreover, most studies to date employed specially designed 
games, rather than games that were already commercially available. Most commercially available games 
today require such rapid and complex responses that they are not easily accessible for seniors, who may 
find the required eye-hand coordination and cognitive processing prohibitive. Nevertheless, it is fair 
to say that digital games have potential that goes beyond their primary recreational functions, and may 
include therapeutic effects, as well as spin-off effects in terms of increased computer literacy and 
improved self­efficacy in relation to other modern technologies.  5. DESIGN OPPORTUNITIES Seniors have 
a variety of preferences, interests, tastes, abilities and experiences which make them as heterogeneous 
a group as any other. No empirical data are available as to what a typology or categorization of senior 
gamers may look like and how this would map onto potential game content. Although some of the functional 
limitations described earlier may fuel a tendency to focus on usability guidelines as an overarching 
design focus for this group, we have argued that it is the perceived benefits rather than the costs that 
will be decisive in the acceptance or rejection of digital game design. With this in mind, we see four 
main areas in which we feel there are significant design opportunities. First, and perhaps most basically, 
is the use of digital games for relaxation and entertainment. Of all possible problems seniors may encounter 
in their homes, those related to leisure time are among the least solved ones. Although many seek problem-focused 
strategies for problems such as housekeeping and personal care, often involving the use of technology 
or social support, these types of solutions are typically not sought when enjoyable leisure activities 
are frustrated [20]. Instead, in over 60 percent of reported cases, seniors gave up on their favorite 
pastime. The most pressing barriers for the adoption of technology in the service of goal attainment 
are their availability and seniors perceived self­efficacy to use these [21]. Digital gaming applications 
present a widely available class of technologies, serving a wide variety of tastes, for which perceived 
self-efficacy can be increased through accessible design and thoughtfully integrated feedback. Gaming 
technology thus has significant potential to contribute positively to seniors leisure time, as a viable 
alternative to television viewing. Secondly, many elderly enjoy games (especially of the non-digital 
sort) as a means of socializing with others within and outside their social network. Games provide a 
rich set of enjoyable topics of conversation (e.g., Trivia), as well as a common activity that can serve 
as a way of decreasing social distance (e.g., Bingo). Although many digital games can be played alone, 
digital gaming has become an increasingly social activity. A 2005 Nielsen research report commissioned 
by the Interactive Software Federation of Europe (ISFE) details that two-thirds of the gamers they sampled 
(N=2000, with equal proportions from Spain, Germany, Italy, the UK and France) play video games with 
other people for at least an hour a week. Moreover, when probed for their motivations to play, the number 
one motivation, supported by 60% of the gamers, is the social component, i.e., being able to play with 
friends [28]. The social interaction underlying games is thus a crucial motivator to engage in digital 
gaming, and this is only expected to increase in importance as one grows older. Digital games may also 
connect different age groups together while enjoying a common activity (e.g., grandparents and grandchildren). 
Such games will need to meet requirements of multiple user groups at the same time, which is an interesting 
challenge from both a game and interface design point of view, and one that recent intergenerational 
gaming projects are starting to address [2]. Third, games can be played with the explicit motivation 
of sharpening one s mind. The evidence presented earlier in this paper provides tentative support that 
challenging mental activities, such as puzzles and quizzes, may indeed be beneficial for stimulating 
memory and attentional abilities. Moreover, the sense of accomplishment and perceived self-efficacy after 
mastering a certain game can provide a significant boost to one s self-esteem. Echoing this sentiment, 
Nintendo has recently launched an active and successful marketing campaign focusing on elderly as a serious 
consumer segment. For the Nintendo DS platform they introduced their Dr Kawashima's Brain Training: How 
Old Is Your Brain? , software which puts players on a daily regimen of number games, word puzzles and 
reading exercises. It also lets players test their intelligence levels ('brain age') through quizzes 
that involve attentional and memory processes (such as the Stroop test; see Figure 1). It saves the results 
so progress can be tracked or compared with others, introducing a social component as well. Finally, 
with the advent of new interaction technologies, digital games now afford new ways of interacting that 
are both more natural in terms of affordances and engage the whole body. Examples of such embodied interaction 
devices include the Sony EyeToy (using computer vision) and the Nintendo Wii (using position and acceleration 
sensing), both of which allow for an embodied, physically active way of engaging with the game content. 
Such interaction styles can be employed for engaging the user in a virtual fitness programme, providing 
guidance and coaching that can be tailored to the individual, especially if such software is coupled 
to biometrics data, such as heart rate (see, e.g., [17]). In such a context, digital games can be regarded 
as persuasive technologies that provide an additional incentive to engage in healthy behaviour [19]. 
Indeed, the Nintendo Wii has been successfully introduced in some old people s homes, where they are 
being used to keep physically fit, as well as socially engaged with one another. As an example, Wii is 
now the latest rage at the Sedgebrook retirement community in Lincolnshire, where the average age is 
77. In particular, the Wii Bowling component of Wii Sports has members of this particular retirement 
community hooked on playing the Wii installed inside  the Sedgebrooks s clubhouse lounge.  6. CONCLUSION 
Digital games hold significant positive potential for elderly users one that has hardly been tapped 
to date. In addition to entertainment value, there can be substantial therapeutic value in playing digital 
games. Moreover, digital games allow elderly people, like other users, to bond socially, both with online 
or physically co-located others, thereby enhancing their social connectedness and potentially enlarging 
their social support structure. Despite this potential, seniors are at present proportionally underrepresented 
as consumers of digital games, creating a significant and largely untapped market opportunity. One of 
the reasons for this state of affairs has been the focus of game developer studios to develop games primarily 
for adolescent users games which do not usually resonate well with the interests, needs, abilities and 
limitations of elderly users. As a consequence of both functional limitations and a simple lack of technological 
experience, seniors are hurt more by usability problems than younger users. Most game developers are 
still very much unaware of basic game accessibility guidelines, which could benefit a range of users, 
including seniors. This situation can and should be drastically improved through extensive user testing 
with elderly users and the use of design guidelines that are specifically tailored to an elderly population. 
There is a substantial body of literature focusing on the elderly ICT user which details a number of 
specific interface design guidelines that could also be usefully applied to game design (e.g,, [4]). 
Two general design recommendations can be distilled from this literature, which are particular to the 
needs of the senior population. First, interface design for elderly users should minimize the burden 
on functions that may have suffered decline, such as demands on spatial memory, working memory, visual 
functions or motor ability. Second, interfaces should be adaptable to compensate for particular functional 
limitations (sensory, motor or cognitive) of elderly users. However, in this paper, we have argued that 
in addition to ensuring usability of games for seniors, we need to make sure that there are substantial 
perceived benefits for elderly users so that they are willing to invest their valuable time and energy 
in what could potentially be a rich and rewarding experience. To explore and understand the needs and 
motivations of elderly gamers, there is a great need for a substantial research effort, which includes 
focus group studies, interviews, surveys and general market segmentation research. In addition, further 
well-controlled studies are required to establish unambiguously the effects of different genres of digital 
games on different types of elderly gamers, putting the various hypothesized benefits to a much more 
detailed test. 7. ACKNOWLEDGMENTS We gratefully acknowledge financial support from the European Commission 
s Framework 6 IST programme. In particular, the work reported here has been supported by the FUGA project 
(part of the IST New and Emerging Science and Technology programme) and the Games@Large project (part 
of the IST Networked Audio-Visual Systems and Home Platforms programme).  8. REFERENCES [1] Bouwhuis, 
D.G. (2003). Design for person-environment interaction in older age: A gerontechnological perspective. 
Gerontechnology, 2, 232-246. [2] Cheok, A.D., Lee, S., Kodagoda, S., Tat, K.E., &#38; Thang, L.N. (2005). 
A social and physical inter-generational computer game for the elderly and children: Age invaders. Proceedings 
of the 2005 Ninth IEEE International Symposium on Wearable Computers (ISWC 05). [3] Czaja, S.J., Charness, 
N., Fisk, A.D., Hertzog, C., Nair, S.N., Rogers, W.A., &#38; Sharit, J. (2006). Factors predicting the 
use of technology: Findings from the Center for Research and Education on Aging and Technology Enhancement 
(CREATE). Psychology and Aging, 21, 333-352. [4] Czaja, S.J., &#38; Lee, C.C. (2003). Designing computer 
systems for older adults. In J.A. Jacko &#38; A. Sears (Eds.), The Human-Computer Interaction Handbook 
 Fundamentals, Evolving Technologies and Emerging Applications (pp. 425). Mahwah, New Jersey: Lawrence 
Erlbaum Associates.  [5] Czaja, S.J., &#38; Lee, C.C. (2007). The impact of aging on access to technology. 
Universal Access in the Information Society, 5, 341-349. [6] Docampo Rama, M. (2001). Technology Generations 
Handling Complex User Interfaces. PhD Dissertation, Eindhoven University of Technology. [7] Drew, B. 
&#38; Waters, J. (1986). Video games: Utilization of a novel strategy to improve perceptual motor skills 
and cognitive functioning in the noninstitutionalised elderly. Cognitive Rehabilitation, 4, 26-34. [8] 
Dweck, C.S. (1986). Motivational processes affecting learning. American Psychologist, 41, 1040-1048. 
[9] Eggermont, S., Vandebosch, H., &#38; Steyaert, S. (2006). Towards the desired future of the elderly 
and ICT: Policy recommendations based on a dialogue with senior citizens. Poiesis &#38; Praxis 4: 199 
217. [10] ESA (2005). Essential Facts About the Computer and Video Game Industry; 2004 Sales, Demographics, 
and Usage data. Entertainment Software Association (ESA). [11] ESA (2006). Essential Facts About the 
Computer and Video Game Industry; 2005 Sales, Demographics, and Usage data. Entertainment Software Association 
(ESA). [12] Fisk A.D., Rogers A.R., Charness N, Czaja S.J., &#38; Sharit J. (2004). Designing for Older 
Adults Principles and Creative Human Factors Approaches. Boca Raton: CRC Press. [13] Goldstein, J., 
Cajko, L., Oosterbroek, M., Michielsen, M., van Houten, O., &#38; Salverda, F. (1997). Video games and 
the elderly. Social Behavior and Personality, 25, 345-352. [14] Griffiths, M. (2005) The therapeutic 
value of video games. In Raessens, J &#38; Goldstein, J. (Eds.) Handbook of Computer Games Studies (pp. 
161-171). Cambridge, MA: The MIT Press. [15] van Hees, M. (1994). Oud geleerd, oud gedaan, optimalisering 
van handleidingen voor ouderen. Graduation thesis, Utrecht University. [16] Hollander, E.K. &#38; Plummer. 
H.R. (1986). An innovative therapy and enrichment program for senior adults utilizing the personal computer. 
Activities, Adaptations &#38; Aging, 8(1), 59-68. [17] IJsselsteijn, W. A., de Kort, Y. A. W., Westerink, 
J., de Jager, M., &#38; Bonants, R. (2006). Virtual Fitness: Stimulating Exercise Behaviour through Media 
Technology. Presence: Teleoperators and Virtual Environments 15, 688-698. [18] Kangas, S. &#38; Lampila, 
P. (2006) Young people involved in developing prototypes of role games that encourage physical exercise. 
VTT Press Release. Retrieved 30 June 2007: http://virtual.vtt.fi/exergame/pub/consumer_press_english.pd 
f. [19] de Kort, Y.A.W., IJsselsteijn, W.A., Midden, C.J.H., Eggen, J.H., van den Hoven, E.A.W.H. (2005). 
Persuasive gerontechnology. Gerontechnology 4, 123-127. [20] de Kort, Y.A.W., Midden, C.J.H., &#38; van 
Wagenberg, A.F. (1998). Predictors of adaptive problem solving of older persons in their homes. Journal 
of Environmental Psychology, 18, 187-197. [21] de Kort, Y.A.W., Midden, C.J.H., Aarts H., &#38; van 
Wagenberg, A.F. (2001). Determinants of adaptive behavior among older persons; Self-efficacy, importance 
and personal dispositions as directive mechanisms. International Journal for Aging and Human Development, 
53 (4), 263-283 [22] Marquié, JC, Jourdan-Boddaert, L, Huet, N (2002). Do older adults underestimate 
their actual computer knowledge?. Behaviour &#38; Information Technology, 21(4), 273-280. [23] Mayhorn, 
C.B., Lanzolla, V.R., Wogalter, M.S., &#38; Watson, A.M. (2005). Personal digital assistants (PDAs) as 
medication reminding tools: Exploring age differences in usability. Gerontechnology, 4, 128-140. [24] 
McGuire, F.A. (1984). Improving the quality of life for residents of long term care facilities through 
video games. Activities, Adaptation &#38; Aging, 6(1), 1-7. [25] Melenhorst, A.-S. (2002). Adopting communication 
technology in later life. The decisive role of benefits. PhD Dissertation, Eindhoven University of Technology. 
[26] Miller, G. (2005). Society for neuroscience meeting: Computer game sharpens aging minds. Science, 
310, No. 5752, p.1261. [27] Morrell, R.W. (Ed.). (2002). Older Adults, Health Information and the World 
Wide Web. Mahwah, New Jersey: Lawrence Erlbaum Associates. [28] Nielsen Interactive Entertainment (2005). 
Video gamers in Europe 2005. Research Report Prepared for the Interactive Software Federation of Europe 
(ISFE). [29] Nielsen, J. (2002). Usability for senior citizens. Alertbox, April 28, 2002. Retrieved 30 
June 2007, http://www.useit.com/alertbox/20020428.html [30] Pratchett, R., Harris, D., Taylor, A. &#38; 
Woolard, A. (2005) Gamers in the UK: Digital Play, Digital Lifestyles. London: BBC. [31] Riddick, C.C., 
Drogin, E.B., &#38; Spector, S.G. (1987). The impact of videogame play on the emotional states of senior 
center participants. Practice Concepts, 27, 425-427. [32] Rogers, W., &#38; Fisk, A. (2000). Human factors, 
applied cognition, and aging. In: F.I.M. Craik &#38; T.A. Salthouse (Eds.), The Handbook of Aging and 
Cognition. Mahwah, NJ: LEA [33] UN (2006). World Population Prospects, The 2006 Revision. United Nations 
Department of Economic and Social Affairs, Population Division. Retrieved 30 June 2007, http://www.un.org/esa/population/publications/wpp2006/wp 
p2006.htm [34] Weisman, S. (1983). Computer games for the frail elderly. The Gerontologist, 23(4), 361-363. 
[35] Whitcomb, G.R. (1990). Computer games for the elderly. Proceedings of the conference on Computers 
and the quality of life. George Washington University, Washington, D.C., United States, pp. 112 115. 
  
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2007</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>1328207</article_id>
		<sort_key>50</sort_key>
		<display_label>Pages</display_label>
		<pages>7</pages>
		<article_publication_date>11-14-2007</article_publication_date>
		<seq_no>4</seq_no>
		<title><![CDATA[Analyzing sociocultural perspectives on violence in digital games]]></title>
		<page_from>23</page_from>
		<page_to>29</page_to>
		<doi_number>10.1145/1328202.1328207</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1328207</url>
		<abstract>
			<par><![CDATA[<p>This article reports the results of a content analysis that tested whether a significant difference in attitude toward violent digital games occurred in the news media as a result of the Columbine school shootings. This article lists attitudinal information about violent game content for more than 30 worldwide news sources, as well as the most frequently mentioned people, institutions, and digital games mentioned by these sources. A one-way ANOVA of authors' attitudes toward violent digital games prior to and after April 20, 1999, as well as ANOVAs testing geographic location, newspaper, and article type, showed no significant attitudinal difference toward violent digital games before and after the Columbine incident. Four cultural themes that relate to the control of violent digital games are also analyzed.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Columbine]]></kw>
			<kw><![CDATA[content analysis]]></kw>
			<kw><![CDATA[cultural studies]]></kw>
			<kw><![CDATA[digital games]]></kw>
			<kw><![CDATA[game research]]></kw>
			<kw><![CDATA[mass media]]></kw>
			<kw><![CDATA[video games]]></kw>
			<kw><![CDATA[violence]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>J.4</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010405.10010455</concept_id>
				<concept_desc>CCS->Applied computing->Law, social and behavioral sciences</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010455</concept_id>
				<concept_desc>CCS->Applied computing->Law, social and behavioral sciences</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Experimentation</gt>
			<gt>Measurement</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P925215</person_id>
				<author_profile_id><![CDATA[81342513627]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Alexander]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Thayer]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Microsoft Corp., Redmond, WA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Park, B. 2001. How to Market in Korea: Small Country, Large Market for PC Games. Paper presented at 2001 Game Developers Conference, San Jose, CA, 20--24 Mar. DOI=http://www.gamasutra.com/features/gdcarchive/2001/park.doc.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Butts, S. 2000. More Video Games and Violence. DOI=http://pc.ign.com/articles/077/077032p1.html.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Laidman, J. 1999. Video Games figure in school shootings. DOI=http://www.post-gazette.com/headlines/19990427games4.asp.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Clarke, R. Video games back in US dock. DOI=http://news.bbc.co.uk/2/hi/technology/3104892.stm.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Anderson, C. A. and Bushman, B. J. 2001. Effects of Violent Video Games on Aggressive Behavior, Aggressive Cognition, Aggressive Affect, Physiological Arousal, and Prosocial Behavior: A Meta-Analytic Review of the Scientific Literature, Psychological Science 12(5): 353--359.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Williams, D. 2005. Bridging the methodological divide in game research. Simulation &amp; Gaming 36(4), 447--463.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Thayer, A., Evans, M., McBride, A., Queen, M., and Spyridakis, J. 2007. "Content Analysis as a Best Practice in Technical Communication Research", Journal of Writing and Technical Communication 37(3): 267--279.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Neuendorf, K. A. 2003. The Content Analysis Guidebook. Sage Publications, Thousand Oaks, CA.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Cooper, C. 2005. Rep. May Lou Dickerson on violent gaming. DOI=http://news.com.com/2061-12_3-5625790.html.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Sales &amp; Genre Data. 2007. DOI=http://www.theesa.com/facts/sales_genre_data.php.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Analyzing Sociocultural Perspectives on Violence in Digital Games Alexander Thayer Microsoft Corp. 
1 Microsoft Way Redmond, WA 98052 +1 (425) 882-8080 alex@alexthayer.com ABSTRACT This article reports 
the results of a content analysis that tested whether a significant difference in attitude toward violent 
digital games occurred in the news media as a result of the Columbine school shootings. This article 
lists attitudinal information about violent game content for more than 30 worldwide news sources, as 
well as the most frequently mentioned people, institutions, and digital games mentioned by these sources. 
A one-way ANOVA of authors attitudes toward violent digital games prior to and after April 20, 1999, 
as well as ANOVAs testing geographic location, newspaper, and article type, showed no significant attitudinal 
difference toward violent digital games before and after the Columbine incident. Four cultural themes 
that relate to the control of violent digital games are also analyzed.  Categories and Subject Descriptors 
J.4 [Social and Behavioral Sciences]: Sociology.  General Terms Measurement, Experimentation, Theory. 
 Keywords Content analysis, game research, video games, digital games, mass media, Columbine, violence, 
cultural studies. 1. INTRODUCTION As the digital gaming industry continues to outstrip other forms of 
media in terms of annually generated revenue, scholars struggle to keep pace with the cultural ramifications 
that digital games bring to bear on societies around the world. The sensual, immersive worlds of digital 
games drive their ever-increasing sales numbers, and help explain why digital games exceed the potential 
of other forms of media to entertain and educate. Clearly, the stakes are high as the landscape of knowledge 
about digital gaming develops. Politicians, parents, and professors alike are increasingly interested 
in controlling the content of digital Permission to make digital/hard copy of part of this work for personal 
or classroom use is granted without fee provided that the copies are not made or distributed for profit 
or commercial advantage, the copyright notice, the title of the publication, and its date of appear, 
and notice is given that copying is by permission of the ACM, Inc. To copy otherwise, to republish, to 
post on servers, or to redistribute to lists, requires prior specific permission and/or a fee. FuturePlay 
2007, November 15-17, 2007, Toronto, Canada. Copyright 2007 ACM 978-1-59593-943-2/07/0011...$5.00 games, 
especially those games that are perceived as violent or aggressive in nature. Countries such as South 
Korea and Germany settled this debate with government intervention designed to limit or prevent the sales 
of certain digital games. According to Park (2001), Games containing extremely violent or obscene content 
are not given any [rating], and [are] not allowed to be sold in Korea. This level of government control 
amounts to censorship, at least according to the US-based Entertainment Software Association (ESA). In 
the US, game vendors are free to decide whether to sell games to young customers; there are no legal 
consequences for sales of digital games in the US. This lack of consequences is the subject of a multitude 
of court cases, government hearings, and proposed laws limiting youth exposure to digital games. This 
debate first gained national attention in the aftermath of the US school shootings that occurred during 
the late 1990s. Butts (2000) summarizes a characteristic crime quite succinctly: In 1997 three students 
were shot and killed and five others wounded by 14-year old Michael Carneal when he opened fire in a 
Paducah, Kentucky high school. The families of Carneal s victims filed a lawsuit against digital game 
publishers, claiming that Michael Carneal was influenced by violent computer games such as Doom, Quake 
and Mortal Kombat (Laidman, 1999). The same suit compared the effects of playing digital games with 
watching movies and visiting violent pornography sites on the Internet (Laidman, 1999). A federal judge 
dismissed the suit, claiming that It appears simply impossible to predict that these games, movie, and 
internet sites (alone, or in what combinations) would incite a young person to violence (Clarke, 2003). 
Unfortunately, the Carneal incident is just one of several such crimes in the US. On 20 April 20 1999, 
Eric Harris and Dylan Klebold opened fire at Columbine High School, killing 13 people before killing 
themselves. Using an assortment of guns and homemade bombs, the two boys attempted to kill many more 
people at the school, but luckily many of their bombs never detonated. This massacre remains one of the 
worst in the history of the US school system, and it had a profound effect on raising the level of popular 
consciousness of school shootings. This cycle of violence, public outcry, and litigation is doomed to 
repeat itself unless the community of digital game researchers can clarify and publicize the issues that 
surround the debate over violent digital games. Using the Columbine school shootings as the point of 
reference for a quantitative content analysis of media coverage, this paper seeks to determine whether 
the Columbine incident affected public perception of violent digital games, as well as uncover the social 
and cultural issues that play into the  debate about digital games as a possible cause of violent behavior. 
 2. STUDY DESIGN AND RESEARCH QUESTIONS This study uses a quantitative content analysis to study major 
newspaper editorials, op eds, and letters to the editor that discuss violent digital games. These articles 
are examined in a specific context: Do the article or letter authors indicate whether they believe that 
digital games cause violent or anti-social behavior? The articles included in the study were written 
on or between 20 April 1998 and 20 April 2000, one year before and after the Columbine incident. The 
incident itself serves as an appropriate focal point partly because the perpetrators were avid gamers, 
especially of violent computer games such as Doom and Quake. Their interest in games helped create major 
political pressure on the digital gaming industry: President Clinton convened a general inquiry into 
the violent content of digital games, one result of which was the expanded ratings that the ESA provides 
for every digital game. Additionally, researchers such as Anderson and Bushman (2001) frequently point 
to the Columbine incident as hard evidence of digital games influence on human behavior, in one case 
drawing clear parallels between three school shootings of the late 1990s with the shooters interest in 
violent video games (353). This study centers around three research questions, the answers to which will 
develop a cultural model that will enable other researchers to gain a new, more detailed perspective 
about the issue of violent digital games and how it is perceived in cultures around the world: 1. Is 
there a significant difference among newspapers with regard to the coverage of violent digital games? 
 2. Is there a significant change of attitude in the media toward violent digital games after the Columbine 
incident? 3. Which other people, institutions, digital games, and cultural themes are discussed in articles 
that address violent digital games?  2.1 Content Analysis Methods All content analysis methods used 
in this study stem from a set of best practices published separately (Thayer et al., 2007) and from the 
Neuendorf (2003) handbook on content analysis methodology. The first step in determining what the news 
media have to say about violent digital games is to define the population of articles that will be analyzed. 
Rather than focusing on standard news stories, many of which blindly report the results of the latest 
press release or study, this study focuses on editorials, op-eds and guest editorials, and letters to 
the editor because they give authors the chance to say what they firmly believe, regardless of scientific 
knowledge or prevailing wisdom. The specific methods used in this analysis are as follows. First, a General 
News search within the Lexis-Nexis database was specified, followed by a full text search for all Major 
Newspapers using the search terms editorial and video game or computer game within the same sentence 
as violen*. the term violen* resulted in words such as ultraviolent, violence, and other variations 
on the root term, and the terms video game and computer game also result in the singular and plural forms 
of both terms. The Lexis-Nexis database was also artificially intelligent enough to associate the term 
editorial with other similar terms such as op-ed, viewpoint, and perspective. After several trial searches, 
the final set of search terms was developed and used to gather the population of articles for this analysis. 
From the population of 45 different newspapers published in 11 different countries, the search for the 
present analysis yielded 234 relevant editorials, op-eds and guest columns, and letters to the editor 
from 35 different newspapers in 5 countries. Each editorial, op-ed, and guest column was counted as 1 
article, and each letter to the editor with a separate author was also counted as 1 article. Of the 35 
newspapers that yielded relevant articles, 89.3% were published in the US, 4.7% were either published 
in Canada or Australia, and the remaining 6.0% were published in England or Israel. In this study, the 
term article is used as a reference to any editorial, op-ed, guest column, or letter to the editor. The 
articles come from the major world newspapers that are included in the Lexis-Nexis database. Although 
these newspapers do not represent the full opinion of the news media, let alone the mass media as a whole, 
this study includes those papers that are widely read and, in some cases, internationally influential 
(such as The New York Times and The Washington Post). Millions of people read these papers every day: 
For example, about 1.1 million read the daily print edition of The New York Times. Therefore, the opinions 
expressed in these sources are potentially quite influential, or at least highly noticeable compared 
to forms of news media with smaller readership or viewership.  2.2 Coding Scheme and Measures of Reliability 
A trichotomous separation of article types was used to describe each article author s attitude toward 
digital games and violent social behavior. This 3-point coding scale works in the following manner: 
If an article author specifically described digital games as a cause of violent or anti-social behavior, 
that article received a value of 3.  If an author was unclear about his or her opinion regarding digital 
games and their potential affect on behavior, that article received a value of 2. This value is roughly 
equivalent to a neutral value, although that label is misleading because some neutral articles use adjectives 
that could indicate an underlying opinion.  If an author explicitly rejected the idea that digital games 
affect behavior, that article received a value of 1.  In most cases, this coding scheme allows for manifest 
coding: Some opinions about digital games and violent social behavior are quite explicit and are easily 
coded. In other cases, the content requires latent coding, and in those situations the use of adjectives 
surrounding the phrase video game or computer game informed the coding process, as well as the larger 
context of the argument being made in the article. The data were collected by copying and pasting article 
text from Lexis-Nexis into a single text file. The content analysis was conducted using TextPack 7.5 
while the data analysis was conducted using SPSS 11.5 for Windows. TextPack is a quantitative content 
analysis program that provides frequency information, reports on keywords in context (KWIC) and keywords 
out of context (KWOC), and other textual reports. The dictionary of terms created during this content 
analysis was refined using KWIC and KWOC analyses, a process that resulted in a highly reliable coding 
instrument. For each article, the following information was recorded:  Unique ID number  Date of publication 
 Headline (if one was printed)  Type (editorial, op-ed/guest column, or letter to the editor)  Author 
(if one was printed)  Rating of attitude toward violent digital games (based on the 3-point scale described 
earlier)  Specific notes, such as quotes or relevant events that sparked the issues raised in the article 
 Using the 3-point scale, the author coded all articles on 1 December 2003. By coding all of the articles 
in one pass, with a few short breaks during the process, the highest possible consistency of measurement 
was maintained for a single coder system. The data are treated as parametric data; because the three­point 
Likert-type scores assigned to each article can be viewed as ordinal data, a parametric analysis is justified. 
The coding instrument and dictionary are available by request to the author.  3. DATA ANALYSIS This 
analysis addresses the three research questions posed earlier and examines whether significant differences 
in attitude toward digital games exist depending on the source of each article, whether the Columbine 
incident changed the attitude of the newspaper media toward digital games, and which people, institutions, 
and digital games were mentioned most frequently in the body of articles included in this study. 3.1 
Newspaper Attitudes Toward Digital Games The Columbine incident on April 20, 1999 created a tremendous 
spike in media coverage of digital games. In April 1999, there were 6 relevant articles published in 
the 19 days prior to April 20th, while 45 were published during the remaining 11 days of that month. 
The general coverage of digital games and violent social behavior trails off after June 1999, although 
violent digital games remained in the news more frequently after the Columbine incident than before. 
A one-way ANOVA that included all article types revealed no significant differences in published attitude 
toward digital games among the different newspapers included in this analysis. Separate one-way ANOVA 
tests for the editorial articles and letters to the editor also revealed no significant differences between 
the states and provinces. Additional testing revealed significant differences in opinion between specific 
news sources. However, these differences are very limited and are attributable not to locale but to the 
specific cultural and editorial perspective of each news source. 3.2 Quantitative Testing of Article 
Attitudinal Results The articles included in this study reflect no significant difference in attitude 
toward violent digital games before and after the Columbine incident. A one-way ANOVA of authors attitudes 
toward violent digital games prior to and after 20 April 1999, as well as ANOVAs testing geographic location, 
newspaper, and article type, showed no significant difference before and after this incident.  3.3 Frequently 
Mentioned People, Institutions, and Digital Games The following list shows all people, institutions, 
and digital games mentioned 20 or more times in the body of articles analyzed in this study, where the 
term mention is defined as a single printed instance of, or an indisputable reference to, the name of 
a certain person, institution, or digital game. For example, the context around a reference such as The 
president indicates whether the person is Bill Clinton or the president of some organization such as 
the National Rifle Association (NRA). A mention can also be a quote attributed to a person, institution, 
or organization; the term reference is used as a synonym for mention in the following list: Bill Clinton, 
134 references in 50 articles (incumbent President of the US during the Columbine incident)  Eric Harris, 
111 references in 65 articles (Columbine school shooter)  Dylan Klebold, 95 references in 59 articles 
(Columbine school shooter)  Hollywood, 80 references in 37 articles (reference to the movie industry) 
 Doom, 39 references in 22 articles (computer game)  NRA, 35 references in 14 articles (pro-firearms 
group in the US)  Michael Carneal, 33 references in 11 articles (Paducah, Kentucky school shooter) 
 David Grossman, 22 references in 11 articles (author and academic)  Marilyn Manson, 21 references in 
10 articles (musical performer)  God, 20 references in 10 articles  MTV, 20 references in 3 articles 
 As this list shows, former US President Bill Clinton is mentioned most frequently, followed by the 
two Columbine shooters and Hollywood as a generic description of the movie industry. After these top 
four names there is a noticeable drop in the frequency with which the remaining entities are mentioned. 
This list is interesting because, for example, performer Marilyn Manson outstrips 10 people or institutions 
directly related to subjects discussed in the articles while Manson himself had no direct connection 
to any of the subjects discussed in the articles. It is also worth noting that Leonardo DiCaprio, Nintendo, 
and the musical group KMFDM made it into the top 40 most referenced people and institutions. Clearly 
another study should examine the reasons why MTV and Marilyn Manson, for example, are frequently associated 
with violent crime in news articles about digital games and social violence.   4. THEMATIC ANALYSIS 
As the list of frequently mentioned people, institutions, and digital games shows, there are a variety 
of agendas at play within articles that discuss violent digital games. The content analysis performed 
for this study yielded four broad yet recurrent themes that relate to the desire for control over violent 
digital games and the people who play such games. The themes are as follows: Gun control and US government 
policy  US Constitutional and legal issues  Adult authority and youth autonomy  Religious beliefs, 
personal beliefs, and corporate interests  There are different fields of tension at play within the 
articles that discuss these themes; the themes and their related fields of tension are examined in detail 
in the following sections. Each field of tensions is illustrated as a triangle centered around the issue 
at stake, which is always US government policy or youth access to digital games. The triangular method 
of illustrating these fields of tension is used because, for each theme, three main groups or sets of 
stakeholders emerged, each wanting to sway public opinion with respect to each issue at stake. None of 
the four aforementioned themes reflected more than three different stakeholders; therefore, the present 
triangular models are justified. 4.1 Theme #1 Gun Control and US Government Policy Due in part to the 
use of guns in several school-based killings, the theme of gun control is a frequent topic within many 
articles in this analysis. The authors of these articles typically tackle the issue of blame: Where should 
the blame for these school shootings be placed? The following arguments emerge with regard to placing 
blame for school shootings and other violent crime: If the government would outlaw guns, these crimes 
would become much more difficult to commit.  Guns have become the scapegoat in these crimes; they should 
not be unfairly attacked when their owners are actually the ones at fault.  Gun control is unnecessary: 
If the government would crack down on violent digital games, people would lose their inspiration to commit 
crimes.  The government should consider some balance between regulating violent digital games and guns, 
particularly because the people who commit these crimes are mentally imbalanced and should not have access 
to guns in the first place.  In some of the articles included in the present analysis, the NRA publicly 
defend their interests by citing violent digital games as the reason behind Columbine and other school 
shootings. Other articles point out that the NRA is attempting to deflect attention away from the tools 
used to commit the crimes: the guns themselves. Some article writers blame digital games and guns equally 
for the crimes, while others either ignore or defend digital games and subsequently blame the guns, the 
parents, and other possible reasons for the crimes. A specific political battle emerges from the content 
analysis of the articles in this study. This battle centers around the need for violent digital game 
legislation. There is a triangular field of tension between the NRA, the producers and defenders of digital 
media (such as the ESA and the Motion Picture Association of America, or MPAA), and anti-violence groups 
(such as the National Campaign Against Youth Violence). At stake in this battle is US public policy on 
digital games and guns. Figure 1 illustrates these tensions, with the US government centered within the 
triangle since the object of the battle is to affect the laws related to digital games. Figure 1. Political 
tensions related to the issue of gun control and US government policy on digital games. Each of the three 
groups listed in Figure 1 is attempting to affect US government policy by using the news media to sway 
public opinion toward their point of view. Gun control remains a contentious political and social issue 
in the US, and this controversy almost always surfaces when violent digital games are discussed. As a 
staff editorial at the Houston Chronicle points out, balancing the violent reality of firearms against 
constitutional guarantees of freedom will never be easy (4/24/98).  4.2 US Constitutional and Legal 
Issues There is a spectrum of possible actions that the US government could take with regard to violent 
digital games and their content. At one end of the spectrum is censorship: outright prohibition of digital 
games that include violent content. At the other end is tolerance: all digital games are constitutionally 
protected from government censorship. The authors included in this study advocate these extremes as well 
as many compromise solutions. One of the most frequently advocated compromises involves age restrictions 
on the sales of certain digital games. A test case of age restrictions occurred in Washington State: 
Congresswoman Mary Lou Dickerson introduced legislation that would have set age limits on digital game 
sales, requiring resellers to verify the age of their customers before selling certain game titles (Cooper, 
2005). Although the result of this case falls outside the date range of the articles analyzed here (the 
courts eventually threw out this legislation), people took note of this proposed legislature and many 
authors cited this solution as one method for dealing with teen violence.  Figure 2 illustrates the 
tensions behind the theme of censorship and government regulation of digital game sales. Figure 2. Political 
tensions related to US Constitutional issues, other legal issues, and the digital media industry with 
regard to US government policy on digital games. The anti-violence group (which typically includes politicians) 
competes with the First Amendment, which protects digital games from censorship as they are covered under 
provisions for free speech, and with the digital media industry, which is interested in selling as much 
media content as possible (members include the ESA, the MPAA, and so on). The digital media industry 
experiences some tension with the First Amendment because their members attempt to provide voluntary 
ratings for all of their content: TV programs, movies, and digital games all include relatively detailed 
ratings. Although the First Amendment does not require any content ratings, the digital media industry 
wants to protect freedom of speech while they sell their products. Digital game ratings are strictly 
an attempt at self-policing to satisfy the politicians and the anti-violence group members, in part so 
they will not attempt to modify the First Amendment. This argument over digital game content is reflected 
in the articles studied as part of this analysis. Many of the same authors who defend gun ownership as 
detailed in the Second Amendment of the US Constitution also defend digital game violence under the First 
Amendment. However, some authors reject the First Amendment entirely and call for a ban on violent digital 
games. This perspective produces quotes such as this one from Jack Thompson: Colorado and other states 
must immediately move to ban [violent digital game] sale to and play by children before our schools become 
like prisons (Denver Post, 5/30/99). This sort of quote produces an immediate political reaction, but 
long-term modifications to policy remain elusive in the US. The theme of digital game regulation is becoming 
as politically charged as abortion and gun control, in part because any legislation related to digital 
games represents a possible modification to the First Amendment. Government controls on digital games 
is a highly divisive issue; the articles in this analysis suggest a strong amount of disagreement on 
how to deal with the potential regulation of digital games  4.3 Adult Authority and Youth Autonomy The 
majority of digital game players, particularly computer games, are adults. Of the digital games sold 
in the year 2002, 13.2% were rated Mature (M), while by 2006 that percentage had climbed to 15.0% (Sales 
and Genre Data, 2007). Mature games receive this rating because the game in question is intended for 
people over 17 years of age. Of course, this demographic citation comes from a digital media group (the 
ESA), which means the validity of this statistic is somewhat questionable. However, one thing is certain: 
millions of children (aged 3 to 18) around the world play digital games, yet their parents ostensibly 
limit their choices in terms of which games they are allowed to play. The family authority that parents, 
guardians, and older siblings exercise affects the types of games that children can play at home, or 
at their friends homes. This type of authority is different from the general social authority that affects 
children away from their homes. At school, as well as at digital game arcades and retail stores, the 
adults in charge exercise some amount of control over which games children can play, and whether game 
play is allowed at all (such as in an academic environment). Much like the issue of digital game censorship, 
this theme has a spectrum of possible authoritarian responses to digital game play among children. The 
spectrum includes total denial of access to digital games at one end and total allowance of access at 
the other end. The theme of authority versus autonomy occurs in many articles as authors attempt to convince 
family and social authority figures to either restrict or allow digital game play. Figure 3 shows the 
tensions at play within the theme of familial and social authority, and their relationship to youth autonomy. 
 Figure 3. Social tensions related to the issue of family-based authority, socially-constructed authority, 
and youth autonomy with regard to youth access to digital games. Parents decide which games their children 
can own and play, if they exercise this control at all. In the extreme case, parents can choose to prevent 
their children from all exposure to digital games, as Mike Dillion might suggest: Parents who allow their 
children access to violent media and video games are committing a form of child abuse and potentially 
posing a threat to the community (Plain Dealer, 4/24/99).  This sort of comment reflects the tension 
between family authority and social authority: Can outsiders tell parents how to raise their own children? 
Can the government legislate private life to this degree? And, moving in the opposite direction, parental 
interests can clash with social interests: Which digital games are installed on school computers? Which 
stores sell or rent violent titles to kids? Or, when parents are quite permissive, how do strict teachers 
discipline children for playing digital games or emulating violent or anti-social game behavior at school? 
The autonomy of the children themselves comprises the third corner of this triangle of tensions. Kids 
are likely to rebel against highly authoritarian family members, and against some social authorities 
as well. As the amount of youth autonomy increases, the amounts of both types of authority decrease. 
How to find the proper balance is a popular theme in many articles in this study: Some authors provide 
possible courses of action to help kids who are addicted to digital games, while others offer tips on 
how to decide which digital games are appropriate. This theme is a particularly rich area for future 
study, as many personal beliefs affect how each family member and social authority responds to the issue 
of violent digital games.  4.4 Religious Beliefs, Personal Beliefs, and Corporate Interests The final 
theme that emerged from this study is the presence of religious beliefs in many of the articles. Some 
authors religious beliefs evidently affected their opinions with regard to digital games, particularly 
when the issue of youth access to the more violent games is at stake. As Figure 4 shows, in this study 
there is identifiable tension between authors religious beliefs and their own personal beliefs. Figure 
4. Political tensions related to the issue of religious beliefs, personal beliefs, and corporate interests 
with regard to youth access to digital games. In a few articles included in this study, the authors personal 
and religious interests are entirely harmonious, which means there is no tension between these two points 
of the triangle. These authors tend to cite God and Satan as specific forces in people s lives, and they 
call for more of the former and less of the latter in American culture. For example, Theresa A. Gonzales 
of Denver (Rocky Mountain News, 7/1/99) writes that We live in a valueless society, and by doing this, 
we have allowed Satan into our lives. In most articles, though, the authors indicate their personal opinions 
(anti-censorship, for example) and express the resulting inner conflict with their moral and religious 
beliefs. For instance, with regard to the Jenny Jones Show, Mike Littwin (Rocky Mountain News, 5/16/99) 
asks how do I, in good conscience, defend violent video games in one week and then blast trash TV in 
the next? Uneasily, that's how. This sort of internal moral dilemma is relatively common within the articles 
in this study. The spectrum of possible responses associated with the religious/personal belief theme 
is similar to the spectrum of authority and autonomy discussed earlier. At one end of the religious/personal 
spectrum, the religious beliefs of a person dictate his or her opinion about youth access to digital 
games. This reliance upon external beliefs resembles social authority. At the other end of the religious/personal 
belief spectrum, religious beliefs do not affect a person s opinion about youth access to digital games; 
the choice is based purely upon personal opinion and experience. This reliance upon internal beliefs 
resembles familial authority in the sense that a family is insular when compared to society in general. 
Corporate interests represent the third corner of this triangle of tension over youth access to digital 
games. Corporate interests clash with religious and personal beliefs because the goal of every company 
is to turn a profit, while many people are more concerned with children playing violent digital games 
than with media companies making money. This battle for the attention and pocket money of children under 
the age of 18 reflects the struggle to restrict youth exposure to pornography and other forms of adult 
media. However, unlike digital games, pornography is restricted by law to those people over 18 years 
of age. Even movie theatres enforce relatively strict limits on movie ratings and the respective ages 
of their patrons: Movies rated R or NC-17 are intended for people over 17 years of age. Personal beliefs 
can change, however, based on what is said in the news media, which is one reason why the corporate interests 
of the entertainment media industry have a strong voice in the popular press. Entertainment media representatives 
frequently point out that the US government considers playing digital games a matter of personal choice. 
Former MPAA president Jack Valenti claimed that the entertainment industry became an easy target for 
blame in the wake of school shootings: Politicians know that when you trash the movie industry -- it's 
'soiling the culture' --your numbers go up. They're looking for something to fix it quickly (Washington 
Post, 6/3/99). Obviously, media corporations want consumers to have the personal choice of which entertainment 
media to consume, rather than allowing the government to regulate these media.  5. CONCLUSIONS AND FUTURE 
RESEARCH The findings of this study represent an important step toward a more thorough tabulation of, 
and understanding of, how the news media reports on violent digital games. The primary discovery in this 
study is that the Columbine incident had no significant effect on the attitudes expressed in editorial 
coverage of violent digital games. In fact, the overall balance shifted slightly away from blaming violent 
digital games for violent and anti-social behavior.  This finding is important in part because of the 
rising number of school shooting victim lawsuits filed against digital game publishers and developers. 
In some cases, the criminals families have even filed lawsuits against high-profile digital game companies 
such as Nintendo, Sega, and Sony. To date, all of these cases have been dismissed for one primary reason: 
a lack of evidence demonstrating a direct correlation between playing violent digital games and committing 
criminal acts such as murder and manslaughter. The design of this study provides an avenue to explore 
the issue of digital game regulation in more detail, particularly in terms of press coverage of this 
issue. It is possible that in the US, certain digital games might become subject to the same federal 
legislation as pornography, which is only legal because of the ostensibly artistic vision of those who 
create pornographic materials. A larger study that examines whether digital game portrayals in the news 
media affect public opinion about digital games would be useful, particularly coupled with a content 
analysis that determines how frequently news articles present a balanced perspective on the debate over 
violent digital games. Many news articles that present negative findings fail to report that such a debate 
exists, whereas articles that present positive or neutral findings frequently seem to offer a counterpoint 
argument in the same article. Generally speaking, and given the global popularity of digital games, it 
seems worthwhile to analyze how particularly violent games are covered in the media, especially in the 
wake of events such as the Columbine incident. Many of the materials developed for the present study, 
including the coding dictionary and list of terms that resulted from this content analysis, are ready 
to be put to use in future studies of this sort.  6. ACKNOWLEDGMENTS My thanks to the helpful comments 
and suggestions from the attendees of the 2007 Gamers in Society symposium hosted by the University of 
Tampere Hypermedia Laboratory, from Daniel Pargman and Talmadge Wright, and from the peer reviewers of 
the 2007 FuturePlay conference.  7. REFERENCES [1] PARK, B. 2001. HOW TO MARKET IN KOREA: SMALL COUNTRY, 
LARGE MARKET FOR PC GAMES. PAPER PRESENTED AT 2001 GAME DEVELOPERS CONFERENCE, SAN JOSE, CA, 20­24 MAR. 
DOI= HTTP://WWW.GAMASUTRA.COM/FEATURES/GDCARCHIVE/2001/ PARK.DOC. [2] BUTTS, S. 2000. MORE VIDEO GAMES 
AND VIOLENCE. DOI= HTTP://PC.IGN.COM/ARTICLES/077/077032P1.HTML. [3] LAIDMAN, J. 1999. VIDEO GAMES FIGURE 
IN SCHOOL SHOOTINGS. DOI= HTTP://WWW.POST-GAZETTE.COM/HEADLINES/19990427GAMES4.ASP. [4] CLARKE, R. VIDEO 
GAMES BACK IN US DOCK. DOI= HTTP://NEWS.BBC.CO.UK/2/HI/TECHNOLOGY/3104892.STM. [5] ANDERSON, C. A. AND 
BUSHMAN, B. J. 2001. EFFECTS OF VIOLENT VIDEO GAMES ON AGGRESSIVE BEHAVIOR, AGGRESSIVE COGNITION, AGGRESSIVE 
AFFECT, PHYSIOLOGICAL AROUSAL, AND PROSOCIAL BEHAVIOR: A META-ANALYTIC REVIEW OF THE SCIENTIFIC LITERATURE, 
PSYCHOLOGICAL SCIENCE 12(5): 353-359. [6] WILLIAMS, D. 2005. BRIDGING THE METHODOLOGICAL DIVIDE IN GAME 
RESEARCH. SIMULATION &#38; GAMING 36(4), 447-463. [7] THAYER, A., EVANS, M., MCBRIDE, A., QUEEN, M., 
AND SPYRIDAKIS, J. 2007. CONTENT ANALYSIS AS A BEST PRACTICE IN TECHNICAL COMMUNICATION RESEARCH , JOURNAL 
OF WRITING AND TECHNICAL COMMUNICATION 37(3): 267-279. [8] NEUENDORF, K.A. 2003. THE CONTENT ANALYSIS 
GUIDEBOOK. SAGE PUBLICATIONS, THOUSAND OAKS, CA. [9] COOPER, C. 2005. REP. MAY LOU DICKERSON ON VIOLENT 
GAMING. DOI= HTTP://NEWS.COM.COM/2061-12_3­5625790.HTML. [10] SALES &#38; GENRE DATA. 2007. DOI= HTTP://WWW.THEESA.COM/FACTS/SALES_GENRE_DATA.PHP. 
  
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2007</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	</section>
	<section>
		<section_id>1328208</section_id>
		<sort_key>60</sort_key>
		<section_seq_no>2</section_seq_no>
		<section_type>SESSION</section_type>
		<section_title><![CDATA[Pervasive games]]></section_title>
		<section_page_from>30</section_page_from>
	<article_rec>
		<article_id>1328209</article_id>
		<sort_key>70</sort_key>
		<display_label>Pages</display_label>
		<pages>8</pages>
		<article_publication_date>11-14-2007</article_publication_date>
		<seq_no>1</seq_no>
		<title><![CDATA[Pervasive games in ludic society]]></title>
		<page_from>30</page_from>
		<page_to>37</page_to>
		<doi_number>10.1145/1328202.1328209</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1328209</url>
		<abstract>
			<par><![CDATA[<p>In this paper we chart how pervasive games emerge from the intersection of two long-standing cultural trends, the increasing blurring of fact and fiction in media culture, and the movements struggling over public space. During the past few decades a third trend has given a new meaning to media fabrication and street cultures: the rise of ludus in the society through maturation of the gamer generations. As more and more activities are perceived as games in the contemporary society, fabricated media expression and performative sports pave the way for a new way of gaming. Born in the junction of playful, ordinary and fabricated, pervasive games toy with conventions and configurations of contemporary media.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[fabrication]]></kw>
			<kw><![CDATA[game]]></kw>
			<kw><![CDATA[ludus]]></kw>
			<kw><![CDATA[magic circle]]></kw>
			<kw><![CDATA[paidia]]></kw>
			<kw><![CDATA[pervasive game]]></kw>
			<kw><![CDATA[play]]></kw>
			<kw><![CDATA[pretence]]></kw>
			<kw><![CDATA[public space]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>K.8.0</cat_node>
				<descriptor>Games</descriptor>
				<type>S</type>
			</primary_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010405.10010476.10011187.10011190</concept_id>
				<concept_desc>CCS->Applied computing->Computers in other domains->Personal computers and PC applications->Computer games</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10011007.10010940.10010941.10010969.10010970</concept_id>
				<concept_desc>CCS->Software and its engineering->Software organization and properties->Contextual software domains->Virtual worlds software->Interactive games</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003251.10003258</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Multimedia information systems->Massively multiplayer online games</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010476.10011187.10011190</concept_id>
				<concept_desc>CCS->Applied computing->Computers in other domains->Personal computers and PC applications->Computer games</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10011007.10010940.10010941.10010969.10010970</concept_id>
				<concept_desc>CCS->Software and its engineering->Software organization and properties->Contextual software domains->Virtual worlds software->Interactive games</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003251.10003258</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Multimedia information systems->Massively multiplayer online games</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Human Factors</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P925240</person_id>
				<author_profile_id><![CDATA[81342512372]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Jaakko]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Stenros]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Tampere]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP43131808</person_id>
				<author_profile_id><![CDATA[81342504968]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Markus]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Montola]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Tampere]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P697958</person_id>
				<author_profile_id><![CDATA[81100467682]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Frans]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[M&#228;yr&#228;]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Tampere]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Alexander, B. 2006. Antecedents to Alternate Reality Games. In Martin, Adam (ed.) IGDA 2006 Alternate Reality Games White Paper. http://www.igda.org/arg/whitepaper.html (ref. 29.6.2007)]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Apter, M. J. 1991. A Structural-Phenomenology of Play. In Apter, M. J. &amp; Kerr, J. H. (eds.) Adult Play: A Reversal Theory Approach. Swets &amp; Zeitlinger, Amsterdam.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1196681</ref_obj_id>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Bartle, R. 2003. Designing Virtual Worlds. New Riders.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Bateson, G. 1972. A Theory of Play and Fantasy. In Salen, K. &amp; Zimmerman, E. (eds.) 2006. The Game Design Reader. A Rules of Play Anthology. The MIT Press, Massachusetts.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Boal, A. 2002. Games for Actors and Non-Actors. Second Edition. London, Routledge.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Caillois, R. 1958. Les jeux et les homes Referred English translation: 2001. Man, Play and Games. University of Illinois Press; Urbana and Chicago.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Costikyan, G. 2002. I Have No Words &amp; Must Design: Toward a Critical Vocabulary for Games. In M&#228;&#228;yr&#228;, F. (ed.) CGDC Conference Proceedings. Tampere, Tampere University Press, 2002. 9--33.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Davies, M. M. 1997. Fake, Fact, and Fantasy: Children's Interpretations of Television Reality. Hillsdale, NJ, Lawrence Erlbaum.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[De Zengotita, T. 2005. Mediated. How the Media Shapes Your World and the Way You Live in It. London, Bloomsbury.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Doyle, M. W. 2002. Staging the Revolution: Guerrilla Theater as a Countercultural Practice, 1965--1968. Ref. www.diggers.org/guerrilla_theater.htm, originally published in Braunstein, P. &amp; Doyle, M. W. (eds.) Imagine Nation. The American Counterculture of the 1960s &amp; 70s. London &amp; New York, Routledge.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Ericsson, M. 2004. Play to Love: Reading Victor Turner's "Liminal to "Liminoid, in Play, Flow, and Ritual; An Essay in Comparative Symbology". In Montola, M. &amp; Stenros, J. (eds.): Beyond Role and Play. Tools, Toys and Theory for Harnessing the Imagination. Vantaa, Ropecon. 15--27.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Forn&#228;s, J. 1998. Kulttuuriteoria. Originally: Cultural Theory and Late Modernity. Vastapaino, Tampere.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Heli&#246;, S. 2004. Role-Playing: A Narrative Experience and a Mindset. In Montola, M. &amp; Stenros, J. (eds.): Beyond Role and Play. Tools, Toys and Theory for Harnessing the Imagination. Vantaa, Ropecon. 15--27.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Huizinga, J. 1938. Homo Ludens. Versuch einer Bestimmung des Spielelements der Kultur. Referred English translation 1955. Homo Ludens - A Study of Play Element in Culture. Boston, Beacon Press and Finnish translation 1967. Leikkiv&#228; ihminen. Yritys kulttuurin leikkiaineksen m&#228;&#228;rittelemiseksi. Porvoo, WSOY.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Juul, J. 2003. Half-Real: Video Games between Real Rules and Fictional Worlds. Doctoral dissertation, IT University of Copenhagen.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Klein, N. 2000. No Logo. Flamingo, London.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1178569</ref_obj_id>
				<ref_obj_pid>1178477</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Lindley, C. A. 2005. Game Space Design Foundations for Trans-reality Games. Advances in Computer Entertainment, ACE 2005, Polytechnic University of Valencia (UPV), Spain.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Malaby, T. M. 2007. Beyond Play. A New Approach to Games. In Games and Culture, April 2007, Sage.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1292900</ref_obj_id>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[McGonigal, J. 2006. This Might Be a Game: Ubiquitous Play and Performance at the Turn of the Twenty-First Century. Doctoral dissertation in Performance Studies, University of California, Berkeley]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[McGonigal, J. 2003. A Real Little Game. The Performance of Belief in Pervasive Play. In DiGRA 2003 Level Up Conference Proceedings.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Montola, M. 2005. Designing Goals for Online Role-Players. In de Castell, Suzanne &amp; Jenson, Jennifer (eds.) (2005): Changing Views: Worlds in Play. Proceedings DVD of DiGRA 2005 conference, June 16.-20. Vancouver, Simon Fraser University.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Montola, M. 2005. Exploring the Edge of the Magic Circle. Defining Pervasive Games. DAC 2005 conference, December 1.--3. IT University of Copenhagen.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1279553</ref_obj_id>
				<ref_obj_pid>1279540</ref_obj_pid>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[Nieuwdorp, E. 2007. The Pervasive Discourse: An Analysis. In ACM Computers in Entertainment, Vol. 5, No. 2 Article 13.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[Pine, B. J. &amp; Gilmore, J. H. 1999. The Experience Economy: Work Is Theatre and Every Business A Stage. Boston (MA): Harvard Business School Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[Postman, N. 1982. The Disappearance of Childhood. New York, Delacorte.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[Postman, N. 1985. Amusing Ourselves to Death: Public Discourse in the Age of Show Business. New York, Penguin.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[Postman, N. 1993. Technopoly: The Surrender of Culture to Technology. New York, Vintage.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1215723</ref_obj_id>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[Salen, K. &amp; Zimmerman, E. 2004. The Rules of Play. Game Design Fundamentals. Massachusetts, MIT Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[Schechner, R. 2002. Performance Studies. An Introduction. Ref. Second Edition (2006). Routledge, London.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>30</ref_seq_no>
				<ref_text><![CDATA[Stenros, J., Montola, M., Waern, A. &amp; Jonsson, S. 2007. Play it for Real: Sustained Seamless Life/Game Merger in Momentum. Forthcoming in DiGRA 2007.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>31</ref_seq_no>
				<ref_text><![CDATA[Sternberg, E. 1999. The Economy of Icons: How Business Manufactures Meaning. Westport (CT): Praeger Publishers.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>526517</ref_obj_id>
				<ref_seq_no>32</ref_seq_no>
				<ref_text><![CDATA[Turkle, S. 1995. Life on the Screen: Identity in the Age of the Internet. New York: Simon and. Schuster.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1077258</ref_obj_id>
				<ref_obj_pid>1077246</ref_obj_pid>
				<ref_seq_no>33</ref_seq_no>
				<ref_text><![CDATA[Walther, B. K. 2005. Atomic Actions -- Molecular Experience: Theory of Pervasive Gaming. In Computers in Entertainment vol. 3, issue 3. (July 2005).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>34</ref_seq_no>
				<ref_text><![CDATA[Veal, A. J. 2004. A brief history of work and its relationship to leisure. In Haworth, John T. and Veal, A. J. (eds.) Work and Leisure. New York, Routledge.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1159988</ref_obj_id>
				<ref_obj_pid>1159982</ref_obj_pid>
				<ref_seq_no>35</ref_seq_no>
				<ref_text><![CDATA[Yee, N. 2006. The Demographics, Motivations and Derived Experiences of Users of Massively-Multiuser Online Graphical Environments. PRESENCE: Teleoperators and Virtual Environments, 15, 309--329.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Pervasive Games in Ludic Society Jaakko Stenros, Markus Montola, Frans Mäyrä Hypermedia Laboratory, 
University of Tampere FIN-33014 University of Tampere {firstname.lastname}@uta.fi ABSTRACT In this paper 
we chart how pervasive games emerge from the intersection of two long-standing cultural trends, the increasing 
blurring of fact and fiction in media culture, and the movements struggling over public space. During 
the past few decades a third trend has given a new meaning to media fabrication and street cultures: 
the rise of ludus in the society through maturation of the gamer generations. As more and more activities 
are perceived as games in the contemporary society, fabricated media expression and performative sports 
pave the way for a new way of gaming. Born in the junction of playful, ordinary and fabricated, pervasive 
games toy with conventions and configurations of contemporary media. Categories and Subject Descriptors 
K.8.0. [Personal computing]: General Games.  General Terms Human Factors, Theory.  Keywords Pervasive 
game, game, play, magic circle, public space, ludus, paidia, fabrication, pretence 1. INTRODUCTION The 
term pervasive gaming is only a few years old. It was inspired and heavily influenced by the idea of 
pervasive computing, having a plethora of smart everyday things embedded with a computing network, creating 
an internet of things . Many definitions of pervasive gaming emphasize this connection to technology 
(e.g. [17], [33], see also [23]). We have abandoned these technology-based definitions and instead opted 
for a more constructivist one. We see pervasive games as games that expand spatial, temporal and social 
boundaries of traditional games (see [22] for an explanation of the definition). Usually games are played 
by certain people, at a decided time, in a set place. Pervasive games bend the contract of gaming regarding 
at least one of these characteristics. Permission to make digital/hard copy of part of this work for 
personal or classroom use is granted without fee provided that the copies are not made or distributed 
for profit or commercial advantage, the copyright notice, the title of the publication, and its date 
of appear, and notice is given that copying is by permission of the ACM, Inc. To copy otherwise, to republish, 
to post on servers, or to redistribute to lists, requires prior specific permission and/or a fee. FuturePlay 
2007, November 15-17, 2007, Toronto, Canada. Copyright 2007 ACM 978-1-59593-943-2/07/0011...$5.00 Technological 
advances have been a necessity in the birth of pervasive gaming. Especially the design space of non­technological 
pervasive games is very narrow, and it s very difficult to come up with a variety of game concepts without 
the support of information technology. However, technology is not at the core of the activity. Looking 
at the current state and the history of pervasive games and related activities clearly shows that the 
historical influences of pervasive games far precede personal computing. These influences are tied to 
three cultural trends, two of which have long histories and one that has emerged more recently. Pervasive 
games can emerge and be recognized as games when late modern media culture blurring fact and fiction 
is combined with the practices indicative of the struggle over public space. This synthesis opens exiting 
new opportunities for the development of gamer cultures.  2. GAMES THEN AND NOW Games are perceived 
in different ways depending on their cultural environment. Our way of understanding game depends on how 
we perceive dichotomies such as work and leisure, sacred and secular, and fact and fiction. Swedish artist 
and game designer Martin Ericsson [11] has directed attention to The Games at Abydos, as described by 
Greek historian Herodotus1, as a live-action role-playing game (larp). In the climax of the ritual, the 
Pharaoh, playing the part of Osiris, slays a hippopotamus portraying Seth, ending the ceremonies in a 
great feast. According to the descriptions, thousands of citizens participated in the rituals, and the 
ritual drama was enacted by armies fighting with blunt weapons. Just as Ericsson makes the claim that 
Games at Abydos could be seen as an ancient form of larp, they can also be seen as a pervasive game, 
breaking the boundaries between fiction and fabrication, extending outside prepared ritual grounds and 
times, and involving outsiders whether they want to or not. Yet, directly applying the contemporary concept 
of game, as defined by recent research (e.g. Costikyan [7], Juul [15], Salen and Zimmerman [28]) would 
be sloppy. Johan Huizinga [14] discusses play through its relationship with ordinary life , that which 
is not a game. Like the relationships of fact and fiction, spiritual and corporeal, private and public, 
and work and leisure, the relationship of play and ordinary is subject to change over time. Appliance 
of contemporary terms to analyze distant events would probably hide their historic meaning. As Ericsson 
points out, it is likely that it was not seen as pretence or art when [the Pharaoh] rode his gilded divine 
wagon through the 1 An Account of Egypt translated by George Macaulay Campbell, in www.gutenberg.org/etext/2131. 
 streets followed by thousands of common citizens who took an active part in the action as the armies 
and feasting worshippers of the conflicting forces . Below we trace changes in the cultural climate that 
may herald a new shift in the way these concepts are evolving, using pervasive games and related phenomena 
as an example. This paper is conceived of as a think piece, asking why pervasive games have only recently 
been thought of as pervasive games , even though they have been around for a long while. The answers, 
we believe, can be found in the way the cultural position of the games has changed during the past few 
decades.  3. BLURRING THE REAL AND THE FICTIVE IN MEDIA The dividing line between truth and story, the 
real and the fictive has been blurring especially with the proliferation of electronic media. Once what 
was printed in the local newspaper or said by a trusted news anchor was considered fact and could be 
trusted. This unilateral view started to fragment due to the emergence of fast communication, multicultural 
viewpoints, relativism and the establishing of various cultural spheres where one might present different 
aspects of oneself. Popular culture has reflected this shift. Stories built on the premise that a person 
cannot even trust his eyes have become popular during and after the 1990 s. David Fincher s seminal film 
The Game (1997) was one of the first mainstream movies to reflect this shift. In the film, the protagonist 
signs up for a game, which is then supposedly cancelled, but in fact the cancellation is part of the 
game. He then spends the rest of the film on the run, unsure of what is ordinary and what is just a game 
. The two become inseparable. A year later The Truman Show (1998) took this one step further. Here the 
protagonist lives in a village that is in fact a stage of a reality television show he unknowingly stars 
in. He is the only person who thinks his life is real everyone else is an actor following a script. 
Similar themes have later been explored in eXistenZ (1999) and The Matrix (1999), while the marketing 
effort for The Blair Witch Project (1999) claimed that the events depicted in the horror film were in 
fact true. Conspiracy theory fiction strikes a similar chord. Some of these works deal with real world 
issues (Oliver Stone s JFK (1990)), others with flights of fancy (The X-Files), but as Umberto Eco shows 
in Foucault s Pendulum (1988), distinguishing these two has become increasingly difficult. The X-Files 
slogan I Want to Believe excellently illustrates the gratification of somewhat plausible conspiracy fiction. 
These works did not spring from nothing. A number of other films and books have explored the issue, but 
only during the 1990 s they achieved mainstream popularity. Similar themes and structures can be found 
in literary hoaxes and other kinds of ludic literature. Bryan Alexander [1], charting the antecedents 
of alternate reality games (ARG), lists use of pseudonyms, mixing factual history with fictional characters, 
faking documentaries and the citing of both real and fictitious sources as methods that have informed 
game design later on. The playful indulgences that used to be the private fort of select authors and 
their privileged audience have become a ubiquitous part of the contemporary play in media. Other influences 
include Candid Microphone (1947) and Camera (1948) and their imitators. Fake documentaries and reality 
television have surged in popularity during the last 15 years. In a way all of these are descendants 
of Orson Welles War of the Worlds (1938), which used the format of a radio news show for presenting the 
events of its narrative. The difference is that substituting fiction for fact, or vice versa, has evolved 
into a haze between the two: reality TV is both real and scripted, tabloid celebrities lives are full 
of staged events and photoshopped pictures, and the 24 hour news services are awash with commentator 
speculation before first-hand information is acquired. 3.1 The Actual and the Fabricated in Internet 
Culture Distinguishing between factual and fabricated is also increasingly hard on the Internet, where 
direct observation and hard evidence generally do not exist. Urbanization created anonymity based on 
population density, which allowed an individual to present a certain persona in one place and different 
in another. On the Internet, this identity play is omnipresent: people enjoy the anonymity given by pseudonyms, 
and can consciously project desired identities and play with them freely. Anonymity of sorts is even 
the default choice in an environment where proving one s identity can be challenging. Intentional identity 
play takes place everywhere on the Internet; in virtual worlds, instant messengers, chat rooms, IRC channels 
and websites. The popular forms range from posting fabricated dating ads to discussing with pseudonyms 
and creating whole websites projecting the desired identities. A peculiar example is gender-swapping 
in virtual worlds, which dates back to the late 70 s [3], and the act of playing the opposite gender 
is still common [35]. Attitudes towards gender play are also changing; what was once conceived as misrepresenting 
oneself [32] is now considered as a normal part of play. Of course, there are different levels of involvement: 
some regard their avatars as non­gendered even when their sex is clear, while others attempt to role-play 
a certain character in virtual worlds. A third group, the masqueraders, enjoy pretending that the person 
sitting in front of the screen is of the opposite sex [3]. Other fabrications include the extremely popular, 
fictional video blog of lonelygirl15, and ARGs based on fake websites (e.g. The Beast [19]). Similar, 
though not equally popular activity is scambaiting, pretending to be scammed by an email spammer in order 
to see how far the scammer is going to go in order to finish his con.2 The consciousness regarding roles, 
both in the sociological and theatrical connotation of the term, that people can choose to play in ordinary 
life has also proliferated (see also [9]). Reflectivity, self-awareness and performativity are standard 
tools for everyone and thus play with meaning, speculation, fabrication and fluid identity become ubiquitous 
parts of everyday activities, truth and real dissolve into opinions, stances and points of view. Toying 
around with one s identity is not only fun, but also a utilitarian activity. As truth has become a point 
of view, the act of self-definition has become more challenging as more options are  2 See www.419eater.com. 
available. As the perception of self is tied to a cultural context, the malleability of self leads to 
the cultural contexts being malleable as well. As a result, the struggle for the discursive power to 
establish hegemonic truths or shared cultural contexts has become both an everyday and less serious activity, 
as political pressure groups, spin doctors and countercultural public space movements show.  4. PUBLIC 
AND URBAN SPACE MOVEMENTS Leisure time, as we recognize it today, was born during industrialization, 
as ideas regarding time, progress and material rewards of work changed [34]. As people moved from the 
countryside to the cramped cities and worked in factories, a need emerged for wider spaces where leisure 
time could be spent. Public space, as it is understood today, was born in the same period. Johan Fornäs 
[12] connects industrialization to a wider history of modernity, describing it as a set of economical, 
cultural and political processes such as rise of capitalism, industrialization, urbanization, democratization 
and secularization. The concepts of private and public also went through a shift during this development. 
Public parks facilitated the need for leisure space, but marketplaces and streets became living rooms 
as well. The graffiti movement from the 1970 s has been one focal point of the collision between different 
views on public space, raising the question of who decides how urban area is to be used. What can be 
done with private property in a public space, what are permissible acts in public places and who gets 
to decide what the correct usages are? Even though private entities and governments legally own buildings, 
the public space is inhabited by thousands of people. Political movements provoking discussions on use 
and control of public space often hold that the people inhabiting an area, not just the owners, should 
have a say in how it is used, decorated and developed. If public space is a canvas for graffiti artists, 
it s also a stage for street theatre. More obtrusive forms of street performance include guerrilla theatre 
[10], which performs message-heavy plays in parks and on the streets, whereas invisible theatre [5] stages 
scenes in public places such as subway cars and seeks to directly engage the audience without any markers 
that would distinguish the play from reality. Demonstrations, marches and the sit-ins of the hippie movement 
are all part of a long tradition of using the street as a political arena. The Reclaim the Streets movement 
[16] is political, yet playful, movement that also uses the streets as its arena, but the target is also 
to redefine streets. It sees the potential of urban environment being wasted in all-consuming traffic. 
According to this ideology, streets belong to people rather than vehicles. Street parties and flash mobs 
are methods for driving this agenda. Traveling is a central use of cityscape, and many countercultural 
movements have aimed at questioning the division of street users to pedestrians and cars. Skateboarding 
is an early form of urban, playful and performative travel that can be seen as an inspiration for later 
forms, such as Le Parkour (aka freerunning) and trainsurfing. These styles of moving are not all about 
efficient traveling from one place to another, but the playful athletic performance is an end in itself. 
A recent addition to the lot is the way transgressive travel videos are finding their way to the Internet; 
for example people shoot films where they drive through traffic in record times and escape from police 
chasing them. The struggle for urban space today takes forms, some of which are more confrontational. 
Skateboarders trespassing on private backyards and using the empty swimming pools to play3 is an example 
of appropriating private instead of public space. Another example is urban exploration, an activity where 
the participants try to get behind the scenes of a city, into the sewers, maintenance tunnels, backyards 
and abandoned industrial sites. The practice of squatting is a confrontational way of claiming obsolete 
private space for public use. Occasionally these activities bring true change as they are condoned retroactively 
by a general public or local government. The constant drive to renegotiate the accepted uses of public 
space is a struggle to wrestle the defining power from the hegemony to the countercultural movements. 
Playful activities in public are both a central tool and the aim of many of these movements.  5. THE 
RISE OF LUDUS IN SOCIETY The concepts of play and game, playing and gaming are also in flux. Recently 
the Western world has been moving into the direction of becoming a culture of gamers. Digital games have 
played in considerable part in this shift: the generations that have been brought up with digital games 
do not grow up and stop playing. This means that each passing year the average age of gamers goes up 
and a culture of players is emerging. Though the roots of this shift can be tracked back to the 1960 
s, the turning point came in the late 70 s and early 80 s. That was the time when both digital video 
games and role-playing games achieved mainstream success. The popularity of digital games has boomed 
since the age of arcade machines. While the popularity of role-playing games has waned, they have been 
very influential in game design. In creating his classic game model Juul [15] states that there has been 
a specific, popular, and fairly constant way of structuring games, a model that appears to have been 
constant for thousands of years, but is only now being supplemented with new game forms . According to 
Juul, this change started in 1960 s with the appearance of role-playing and video games, but he asserts 
that the classic game model applies to hundreds of games through the millennia before that. According 
to Juul, [a] game is a rule-based system with a variable and quantifiable outcome, where different outcomes 
are assigned different values, the player exerts effort in order to influence the outcome, the player 
feels attached to the outcome, and the consequences of the activity are optional and negotiable. [15] 
In claiming this, Juul draws a powerful conclusion that e.g. freeform play and hypertext fiction should 
be excluded from the definition, just as open ended simulations and games of pure chance should be borderline 
cases of games. In the terminology of Roger Caillois [6], Juul constructs a category for a specific form 
of ludus, or formal play, as opposed to paidia, free play. The shift, which Juul perceives as breaking 
point of the classic games , we see as a move to categorize an increasing portion of playful activities 
as ludus. Activities that would have previously 3 See the documentary film Dogtown and Z-Boys (2001), 
directed by Stacy Peralta.  been viewed as paideic are now regarded as ludic, perhaps because they had 
incorporated ludic structures. As digital games have gained considerable economical significance, the 
design space of games has grown. On the one hand, more paideic elements have been included. On the other, 
video gaming has given a boost to other forms of gaming from board games to various forms of role-playing 
games. The combination of (ludic) wargames and (paideic) storytelling has lead to role-playing games, 
while combining dancing and singing with digital games lead more recently to Dance Dance Revolution and 
Singstar. Yet the question remains: was there a cultural change in the 60 s that irrevocably changed 
the gaming culture, or was there a change in perception of what is included in the (Western) denotation 
of the word game ? As a culturally defined concept, game is also subject for renegotiation and change. 
Nowadays the aforementioned playful activities are usually considered games , even though winning, losing 
and points are often irrelevant for performative players. If there is a reward for a good performance, 
it s given by the other players, not by the system. The concepts of winning and losing are equally problematic 
when discussing never-ending, persistent online role­playing games, where temporary victories and setbacks 
can be experienced but no chain of events is ever permanently concluded. (See [21].) In these games which 
feature elements of both paidia and ludus, the player is also a performer and an audience for other performers. 
Huizinga [14] describes play as an activity not yielding material profit, but this does not hold true 
to all gamers. Professional sports, gambling and gold farming are ludic practices that show the blur 
in games as well. These people, whether they are top athletes getting superstar salaries or teenagers 
making real money in a virtual environment, cannot claim to pretend that the games they play were any 
less real than ordinary life. The alternation and playful adoption of various identities also ties into 
this. For example, building a work persona, which can in ludic terms be discussed as an avatar for the 
office , is easy and logical if one has played a lot of role-playing games and adapted to what Heliö 
[13] calls the role-playing mindset. The reality of contemporary economics underlying the late industrial 
society has also been under debate. In the quartile economics millions of dollars in stock market value 
can be created or lost in minutes, depending on the future expectations of analysts. Rather than fundamental 
use value, the new economics is based on image and performance and should be analyzed from the perspective 
of semiotics or iconography, as Ernest Sternberg [31] has argued. Some of the contemporary keywords for 
industrial leaders include experience economy where work is theatre and every business a stage as the 
subtitle of an influential business philosophy book by B. Joseph Pine II and James H. Gilmore [24] suggests. 
If the emerging gamer generations follow this trend to a logical conclusion, we can talk about living 
in a ludic society : a society where playful and experimental attitude is present in all key social domains, 
ranging from work and leisure to education and human relationships.  6. PLAYFUL CONTEXTS AND MINDSETS 
In order to understand the meaning associated with pervasive games, we need to move away from the technological 
origins of the ludic form and look at it in cultural contexts. We see the three trends sketched above 
both as important shifts in culture in general as well as specific changes in the climate that enables 
and frames pervasive games. In order to understand pervasive games, we need to delve deeper into how 
play is brought into spaces, times and social situations that are usually considered as ordinary. In 
order to understand this phenomenon, we have to discuss both the social contexts and the relevant mindset. 
The two basic contexts we distinguish here are playful context and ordinary context. Playful contexts 
are socially, physically and temporally constrained environments where one could expect to encounter 
play; they are constructed socially, and are defined by discourse, architecture and other cultural properties. 
Clearly visible borders surprisingly often frame these areas, as Huizinga [14] describes. Ordinary contexts 
are social and physical environments where everyday activities are typically situated. The mindset, understood 
as a subjective state of mind or a mental frame (or bubble ), also divides into two groups (cf. [2]). 
People are typically in a playful mindset4 when they play games, watch entertaining fictional movies 
and sing drinking songs. Correspondingly they are typically in a serious mindset when engaging in utilitarian 
activities such as eating, working or traveling. Together the contexts and the mindsets help to understand 
what kind of activities take place. The two contexts and two mindsets allow us to construct four categories 
for activities (see Figure 1). Within traditional forms of play a playful mindset is combined with a 
playful context. Likewise, activities of everyday life combine ordinary context with serious mindset. 
The more contradictory activities are more interesting: trainsurfers and urban explorers bring playful 
mindsets to ordinary contexts, thus appropriating these contexts for play. In a diagonally opposite manner, 
professional athletes, gamblers and goldfarmers (real-money traders of virtual property) appropriate 
a playful context for their serious mindsets. These transgressive practices have all encountered societal 
resistance in various forms: Professional athletes were allowed in the Olympic games only during the 
1970 s, while trainsurfing remains illegal in the Western world. While the emergence of activities carried 
out in a playful mindset in an ordinary context is part of the rise of ludus in society, the professionalization 
of games can be seen both as part of a countercurrent and as part of the trend. On the one hand, 4 Apter 
[2] discusses the playful mindset as paratelic and the serious mindset as telic, in order to avoid the 
unwanted connotations of playful and serious . It s important to note that both these categories are 
meant to be very broad. Many serious activities can be pleasant just as playful activities can be boring. 
Generally it can be said that in a telic mindset the activity that one engages in is an end in itself 
whereas in a paratelic mindset the activity has a more specific goal and a purpose. Salen &#38; Zimmerman 
[28] call these self-contained experiences autotelic; the purpose of playing is the play itself.  traditional 
areas of play are being colonized by serious, utilitarian activities. On the other, the ludic structure 
of games is still intact. The mindset that one experiences is subjective, whereas the context is primed 
by both the active subjects present as well as by the cultural context as a whole. Urban explorers experience 
their travels mostly in a playful mindset yet even if they are the only ones present in a given locations, 
the context remains ordinary as often these spaces are, through legislation and common practice, officially 
reserved for some other, utilitarian purpose. Figure 1: Example activities primed by contexts and mindsets 
6.1 Form and Function of Play The discussion on the metaphorical concept of magic circle has been central 
in recent ludology. While the term was originally coined by Huizinga [14], Salen and Zimmerman [28] picked 
it up and used it to denote the idea of a special place in time and space created by a game . However, 
going back to Huizinga s ideas about play will paint a more elaborate picture. He describes play as a 
free activity standing quite consciously outside ordinary life as being not serious , but at the same 
time absorbing the players intensely and utterly. It is an activity connected with no material interest, 
and no profit can be gained by it. It proceeds within its own proper boundaries of time and space according 
to fixed rules and in an orderly manner. [14] Obviously, the metaphoric magic circle, as conceived by 
Huizinga and Salen &#38; Zimmerman, best fits around activities that combine a playful mindset with a 
playful context. Applying the metaphor to the two contradictory activities requires careful reading of 
Huizinga. Practices such as goldfarming, professional gambling and professional sports combine serious 
mindset with playful context. Usually these activities have been considered to take place within the 
magic circle. However, the outcomes of these activities tend to leak into the everyday life, which has 
attracted criticism towards the whole concept of a magic circle (see for example [18]). As these games 
are connected with material interest and participants may gain profit, the element of play is only present 
in the ludic form of the activity, not in its playful function. Practices such as Le Parkour and urban 
exploration combine playful mindset with ordinary context. This we have discussed earlier (e.g. [22]) 
as an expanded magic circle; play is taken out of its spatial, temporal and social context. The activity 
still has the playful function, even though it pervades its proper boundaries and enters the ordinary 
world (see below). The serious-minded activities in an ordinary context clearly fall outside of the magic 
circle.  6.2 Fabrication and Metacommunication The boundaries between the two types of contexts and 
mindsets are hardly clear-cut. In order to extend our analysis, we must include the earlier discussion 
on fabrication in media culture. Fabrication can be defined as intentional misrepresentation done in 
order to mislead the subject. According to Gregory Bateson [4], games and play are framed as such through 
implicit metacommunication:5 [T]he statement This is play looks something like this: These actions in 
which we now engage do not denote what those actions for which they stand would denote. [4] Even among 
playing animals, a playful nip may stand for a bite, but it has a different meaning than an actual bite. 
In a sense, Huizinga s magic circle is merely a frame invoked through metacommunication. This metacommunication 
is typically implicit and often unconscious. Misrepresentation is based on false metacommunication: framing 
contexts as something they are not. Candid Camera frames an artificial and playful problem into an ordinary 
context, in order to provoke authentic reactions from the subject. When metacommunication of play is 
obscured, a gray zone is created between the playful and the ordinary. This takes place on all three 
levels; in the context, the mindset and the action thus primed. The gray area between playful and ordinary 
context is utilized by, for example, Candid Camera and lonelygirl15.6 This fabricated context is created 
when a context is playful to some and serious to others, due to intentional secrecy and misrepresentation. 
The events taking place during the candid camera shoot are physical and actual, and the video clips of 
fabricated blogs are actual video clips. But as the metacommunication is altered, these contexts are 
framed as ordinary instead of playful. The other gray area is located between playful and serious mindsets. 
We call it the pretending mindset, something that is both serious and playful. Often this mindset is 
colored by performance, portraying a role that may be both theatrical and social. Participants of Big 
Brother reality television show are not quite playful but not serious either. Their behavior life within 
the Big Brother house are not truly genuine (whatever that means), but rather explicitly competitive 
performance aimed at other participants and the viewers. Creative metacommunication is used here as well: 
the selling point of reality television is the way it is framed as reality even though the social situations 
it creates are notvery immediate, authentic or genuine. (See Figure 2.) 5 Richard Schechner [29] discusses 
dark play, secret play that is not framed as non-serious. Pervasive games are close relatives of dark 
play: dark play can be considered a form of pervasive paidia, while pervasive games are a pervasive form 
of ludus. 6 Fabrication and pretence are not the only gray areas between playful and serious mindsets 
and playful and ordinary contexts. We focus on these two, since they shed light into the societal change 
discussed in this paper.  Figure 2: The gray areas of activities created by contexts and mindsets. 
Both fabrication and pretence are asymmetric, which creates a power imbalance. In Candid Camera the crew 
operates in the mindset of pretence in an ordinary context; their work is all about fooling people into 
doing something stupid or funny. The filmed subject enters a fabricated context in a serious mindset, 
thinking that the weirdness encountered is a serious matter of everyday life. The subject operates in 
the context fabricated by camera crew, believing it as ordinary, at least until he starts to suspect 
fabrication. Navigating these gray areas requires a double consciousness where the participant is simultaneously 
aware of both the playful and the serious or the ordinary interpretation (see also [1]). The practice 
of scambaiting is particularly revealing, since it happens in the intersection of fabricated context 
and pretended action. The scammer fabricates letters, typically in order to swindle money from the recipient. 
The recipient is conscious of two possible reading, suspects a fabrication, and pretends to be fooled 
by it, fabricating a context for the scammer. It is also noteworthy that the activity is subjective and 
can change from moment to moment. The cameraman in Candid Camera is working in an ordinary context, though 
there is an element of pretence while the subject is in an ordinary context in a serious mindset unless 
fabrication is suspected. The pretence mindset primes the fabricated context.  7. PERVASIVE GAMING 
For the contemporary gamer generations both the transgressive activities questioning contexts of public 
space, and the blur of fact and fiction in media culture offer creative opportunities for entertainment 
and recreation. Pervasive games have a tendency to play wildly with the different contexts and mindsets, 
leading into various different activities. We have chosen three examples for analysis. Killer is a game 
of assassination that is mostly played in the gray zones. The basic idea is that players live their ordinary 
life, while trying to elegantly murder other players with weapons such as vinegar (poison), water guns 
and alarm clocks (time bomb). The assassin can strike at any time anywhere, so the player is never safe, 
not at home or at work and certainly not when walking on a public street. The game cannot be paused or 
exited. The only way out is either though murdering all other players, or by dying spectacularly in the 
hands of an enemy. The players of Killer steadily alternate between serious and pretending mindsets, 
depending on whether they are about to murder someone, attend a lecture with friends at the university, 
or both. The context is ordinary, unless someone tries to move in for a kill in secret: only when you 
drink the deadly dose of poison, the taste of vinegar (meta)communicates the playful nature of your context. 
Prospopeia Bardo 2: Momentum [30] was a pervasive larp seeking to create as perfect and seamless a merger 
of life and game as possible. During the five weeks of gameplay it used the full arsenal of contexts 
and mindsets, as the role-players had to engage in private and public interactions with outsiders, other 
players, game masters and specially instructed bystanders. For example, historically orthodox Enochian 
rituals (as taught by angels to John Dee in the late 16th century) were conducted on the street where 
Swedish Prime Minister Olof Palme was murdered in order to channel mystical energy to the Other Side. 
Factual political history, pre-existing occult texts, fabricated game world, and performative player 
pretence blended together. From the player s perspective a discussion with an instructed outsider is 
pretence in a fabricated context, but players never knew if an outsider was instructed, they might equally 
well end up pretending in an ordinary context. If the outsider was fooled by the role-played act, she 
was then seriously engaged with an intended albeit badly targeted fabrication (see Table 1, next page). 
The Beast [19] was an alternate reality game built around dozens of websites. In order to find your way 
to the start of the game, the players had to solve puzzles planted in an advertisement campaign for a 
film. Only by applying a playful approach to the ordinary context could the player-to-be find his way 
to game websites. Tapping on the aesthetics described in previous chapters, The Beast utilized an aesthetic 
dubbed as This Is Not a Game : the players were not directly informed about the gameness of the game, 
allowing them to pretend to believe [20] that the game was real. Still, the vast majority of gameplay 
was done in a playful mindset in a playful context, as all game websites cunningly metacommunicated their 
non-ordinariness through the fact that they were dated in year 2142. The Beast pretended to pretend to 
be real in order to allow the players to pretend the game was real as well. Still, it can be said that 
the game did not strive for an illusion of realness, as all websites openly displayed obviously fictitious 
elements. (See also [19].)  Table 1: Examples of different activities, defined by mindset­context combinations, 
from the pervasive game Momentum. Playful-Playful: Obvious larping in secluded game areas, such as the 
underground complex accessible only to the players. Playful-Ordinary: Vulgar ritual performances on streets. 
Both bystanders and the police did pay attention. Serious-Playful: Remote working (ordinary job) with 
a laptop within game areas. Serious-Ordinary: Going to work while the game was running. The game never 
paused; players or non-player characters (NPC) could call you anytime. Playful-Fabricated: Players hearing 
the fake cancellation of the game but not believing it, correctly considering it a part of the game instead. 
Pretending-Playful: Game masters pretending, as a part of the game, that the game was cancelled. Pretending-Fabricated: 
Player pretending not to be a part of the game when unwittingly chatting with an undercover NPC. Pretending-Ordinary: 
Players visiting an unsuspecting art gallery in order to obtain a specific painting. Gallerists were 
unaware of the game. Serious-Fabricated: The unsuspecting gallery workers. It was an ordinary day until 
pretenders entered their gallery.  8. CONCLUSIONS Pervasive games break the traditional spatial, temporal 
and social boundaries of game. As they do this, they toy with cultural contexts, encouraging people in 
both playful and serious mindsets to interact. They challenge social codes and norms relating to public 
space and to what is accepted behavior in the public sphere. Finally, as they do this they bring the 
thrill of the real into games and the fun of playing into ordinary life. In this paper we have featured 
a substantial number of practices, ranging from ancient rituals to post-modern political art. While most 
of these forms were not created as games, or are not conceived as such even today, the resemblances are 
often striking. However we have limited our discussion in this paper to modern cultural contexts of the 
Western world. Categorizing the ancient ritualistic mindset of The Games at Abydos as playful, serious 
or pretending is equally nonsensical as trying to understand the contexts of the ritual in terms of ordinary, 
playful and fabricated. If the Games at Abydos were recreated today, they would most certainly be understood 
as an art performance or a pervasive game. The conceptual distinctions outlined in this paper are thus 
characteristically modern. The rise of ludus is an ongoing societal trend. The reality television shows 
that have descended from Candid Camera are increasingly ludus-like, with competitions, prizes and popularity 
contests. The status of skateboarding has moved towards formal sport with competitions, sponsorships, 
designated skate parks and rehearsed performances. Even the identity play of lonelygirl15 has taken in 
features from alternate reality games. The contemporary gamer generations know how to both produce and 
enjoy games. The question remains: How to account for this kind of developments in media, games and society? 
It would be easy to simply celebrate the increasing playfulness of culture, and claim that the modernist 
distinctions between fact and fiction are breaking down, and that pervasive games and reality fiction 
are something that will liberate us from the confines of capitalist society. However, equally easy is 
to adopt a warning voice and claim that these developments are warning signs of a society that is no 
longer capable of maintaining its fundamental sense of reality something that critics of media culture 
have long been arguing (e.g. [25], [26] and [27]). On the other hand, more qualified studies of media 
and games take into account the increasing media (and games) literacy and enhanced understanding that 
contemporary people are using to approach, use and make sense of these forms of culture in their everyday 
lives. Even children appear to have much more abilities to make distinctions between fake, fact and fantasy 
in media than is commonly believed [8]. Rather than considering the blurring of boundaries that we have 
discussed in this paper to be inherently good or bad for the society, we merely want to point out that 
this kind of contemporary trend exists, that it is crossing from media to games and other forms of urban 
life as well, and that with its long roots in the social and cultural history. We consider this development 
significant enough to warrant for more dedicated research into the emergence of ludic society and its 
hybrid playful and serious practices. 9. ACKNOWLEDGEMENTS We are grateful for Satu Heliö, Johanna Koljonen 
and Annika Waern for their invaluable comments. This paper was written for the Integrated Project on 
Pervasive Gaming IPerG. 10. REFERENCES [1] Alexander, B. 2006. Antecedents to Alternate Reality Games. 
In Martin, Adam (ed.) IGDA 2006 Alternate Reality Games White Paper. http://www.igda.org/arg/whitepaper.html 
(ref. 29.6.2007) [2] Apter, M. J. 1991. A Structural-Phenomenology of Play. In Apter, M. J. &#38; Kerr, 
J. H. (eds.) Adult Play: A Reversal Theory Approach. Swets &#38; Zeitlinger, Amsterdam. [3] Bartle, R. 
2003. Designing Virtual Worlds. New Riders. [4] Bateson, G. 1972. A Theory of Play and Fantasy. In Salen, 
K. &#38; Zimmerman, E. (eds.) 2006. The Game Design Reader. A Rules of Play Anthology. The MIT Press, 
Massachusetts. [5] Boal, A. 2002. Games for Actors and Non-Actors. Second Edition. London, Routledge. 
[6] Caillois, R. 1958. Les jeux et les homes Referred English translation: 2001. Man, Play and Games. 
University of Illinois Press; Urbana and Chicago. [7] Costikyan, G. 2002. I Have No Words &#38; Must 
Design: Toward a Critical Vocabulary for Games. In Mäyrä, F. (ed.) CGDC Conference Proceedings. Tampere, 
Tampere University Press, 2002. 9 33.  [8] Davies, M. M. 1997. Fake, Fact, and Fantasy: Children's Interpretations 
of Television Reality. Hillsdale, NJ, Lawrence Erlbaum. [9] De Zengotita, T. 2005. Mediated. How the 
Media Shapes Your World and the Way You Live in It. London, Bloomsbury. [10] Doyle, M. W. 2002. Staging 
the Revolution: Guerrilla Theater as a Countercultural Practice, 1965-1968. Ref. www.diggers.org/guerrilla_theater.htm, 
originally published in Braunstein, P. &#38; Doyle, M. W. (eds.) Imagine Nation. The American Counterculture 
of the 1960s &#38; 70s. London &#38; New York, Routledge. [11] Ericsson, M. 2004. Play to Love: Reading 
Victor Turner s Liminal to "Liminoid, in Play, Flow, and Ritual; An Essay in Comparative Symbology . 
In Montola, M. &#38; Stenros, J. (eds.): Beyond Role and Play. Tools, Toys and Theory for Harnessing 
the Imagination. Vantaa, Ropecon. 15-27. [12] Fornäs, J. 1998. Kulttuuriteoria. Originally: Cultural 
Theory and Late Modernity. Vastapaino, Tampere. [13] Heliö, S. 2004. Role-Playing: A Narrative Experience 
and a Mindset. In Montola, M. &#38; Stenros, J. (eds.): Beyond Role and Play. Tools, Toys and Theory 
for Harnessing the Imagination. Vantaa, Ropecon. 15-27. [14] Huizinga, J. 1938. Homo Ludens. Versuch 
einer Bestimmung des Spielelements der Kultur. Referred English translation 1955. Homo Ludens - A Study 
of Play Element in Culture. Boston, Beacon Press and Finnish translation 1967. Leikkivä ihminen. Yritys 
kulttuurin leikkiaineksen määrittelemiseksi. Porvoo, WSOY. [15] Juul, J. 2003. Half-Real: Video Games 
between Real Rules and Fictional Worlds. Doctoral dissertation, IT University of Copenhagen. [16] Klein, 
N. 2000. No Logo. Flamingo, London. [17] Lindley, C. A. 2005. Game Space Design Foundations for Trans-reality 
Games. Advances in Computer Entertainment, ACE 2005, Polytechnic University of Valencia (UPV), Spain. 
[18] Malaby, T. M. 2007. Beyond Play. A New Approach to Games. In Games and Culture, April 2007, Sage. 
[19] McGonigal, J. 2006. This Might Be a Game: Ubiquitous Play and Performance at the Turn of the Twenty-First 
Century. Doctoral dissertation in Performance Studies, University of California, Berkeley [20] McGonigal, 
J. 2003. A Real Little Game. The Performance of Belief in Pervasive Play. In DiGRA 2003 Level Up Conference 
Proceedings. [21] Montola, M. 2005. Designing Goals for Online Role-Players. In de Castell, Suzanne &#38; 
Jenson, Jennifer (eds.) (2005): Changing Views: Worlds in Play. Proceedings DVD of DiGRA 2005 conference, 
June 16.-20. Vancouver, Simon Fraser University. [22] Montola, M. 2005. Exploring the Edge of the Magic 
Circle. Defining Pervasive Games. DAC 2005 conference, December 1.-3. IT University of Copenhagen. [23] 
Nieuwdorp, E. 2007. The Pervasive Discourse: An Analysis. In ACM Computers in Entertainment, Vol. 5, 
No. 2 Article 13. [24] Pine, B. J. &#38; Gilmore, J. H. 1999. The Experience Economy: Work Is Theatre 
and Every Business A Stage. Boston (MA): Harvard Business School Press. [25] Postman, N. 1982. The Disappearance 
of Childhood. New York, Delacorte. [26] Postman, N. 1985. Amusing Ourselves to Death: Public Discourse 
in the Age of Show Business. New York, Penguin. [27] Postman, N. 1993. Technopoly: The Surrender of Culture 
to Technology. New York, Vintage. [28] Salen, K. &#38; Zimmerman, E. 2004. The Rules of Play. Game Design 
Fundamentals. Massachusetts, MIT Press. [29] Schechner, R. 2002. Performance Studies. An Introduction. 
Ref. Second Edition (2006). Routledge, London. [30] Stenros, J., Montola, M., Waern, A. &#38; Jonsson, 
S. 2007. Play it for Real: Sustained Seamless Life/Game Merger in Momentum. Forthcoming in DiGRA 2007. 
[31] Sternberg, E. 1999. The Economy of Icons: How Business Manufactures Meaning. Westport (CT): Praeger 
Publishers. [32] Turkle, S. 1995. Life on the Screen: Identity in the Age of the Internet. New York: 
Simon and. Schuster. [33] Walther, B. K. 2005. Atomic Actions Molecular Experience: Theory of Pervasive 
Gaming. In Computers in Entertainment vol. 3, issue 3. (July 2005). [34] Veal, A. J. 2004. A brief history 
of work and its relationship to leisure. In Haworth, John T. and Veal, A. J. (eds.) Work and Leisure. 
New York, Routledge. [35] Yee, N. 2006. The Demographics, Motivations and Derived Experiences of Users 
of Massively-Multiuser Online Graphical Environments. PRESENCE: Teleoperators and Virtual Environments, 
15, 309-329.   
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2007</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>1328210</article_id>
		<sort_key>80</sort_key>
		<display_label>Pages</display_label>
		<pages>8</pages>
		<article_publication_date>11-14-2007</article_publication_date>
		<seq_no>2</seq_no>
		<title><![CDATA[Sensor networks as video game input devices]]></title>
		<page_from>38</page_from>
		<page_to>45</page_to>
		<doi_number>10.1145/1328202.1328210</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1328210</url>
		<abstract>
			<par><![CDATA[<p>In this work we are motivated by creating a network of sensors that can be used as input devices for video games. Our goal is to create an inexpensive network of off-the-shelf sensors that are used to force proper movement and engagement of the player. Our experience shows that a distributed set of sensors around the body prevents the player from cheating the system by using motion of the device alone to trick the system. In this work we show that a relatively simple sensor network configuration can enforce proper form and ensure that the player is actively participating in the game context.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[accelerometer]]></kw>
			<kw><![CDATA[entertainment technologies]]></kw>
			<kw><![CDATA[human computer interaction]]></kw>
			<kw><![CDATA[sensor networks]]></kw>
			<kw><![CDATA[video games]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>H.5.1</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>J.m</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010405</concept_id>
				<concept_desc>CCS->Applied computing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003251</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Multimedia information systems</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Experimentation</gt>
			<gt>Human Factors</gt>
			<gt>Performance</gt>
			<gt>Security</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P444250</person_id>
				<author_profile_id><![CDATA[81100051534]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Anthony]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Whitehead]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Carleton University, Ottawa, Ontario, Canada]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P925264</person_id>
				<author_profile_id><![CDATA[81342492190]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Nick]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Crampton]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Carleton University, Ottawa, Ontario, Canada]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P925253</person_id>
				<author_profile_id><![CDATA[81342494677]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Kaitlyn]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Fox]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Carleton University, Ottawa, Ontario, Canada]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P925234</person_id>
				<author_profile_id><![CDATA[81416605846]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Hannah]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Johnston]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Carleton University, Ottawa, Ontario, Canada]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[L. Bao. <i>Physical Activity Recognition from Acceleration Data under Semi-Naturalistic Conditions.</i> M. Eng. Thesis, Massachusetts Institute of Technology, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[L. Bao and S. Intille, Activity Recognition from User-Annotated Acceleration Data. In PERVASIVE 2004, LNCS 3001, pp. 1--17, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[J. B. Bussmann, W. L. Martens, J. H. Tulen, F. C. Schasfoort, H. J. van den Berg-Emons, and H. J. Stam. Measuring daily behavior using ambulatory accelerometry: the Activity Monitor. <i>Behavior Research Methods, Instruments, &amp; Computers</i>, 33(3): 349--56, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[B. P. Clarkson. <i>Life Patterns: Structure from Wearable Sensors.</i> Ph.D. Thesis, Massachusetts Institute of Technology, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>954544</ref_obj_id>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Richard O. Duda, Peter E. Hart. Pattern Classification. by Wiley Interscience. (1973)]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[F. Foerster, M. Smeja, and J. Fahrenberg. Detection of posture and motion by accelerometry: a validation in ambulatory monitoring. <i>Computers in Human Behavior</i>, 15:571--583, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[N. Kern, B. Schiele, and A. Schmidt. Multi-sensor activity context detection for wearable computing. In <i>European Symposium on Ambient Intelligence (EUSAI).</i> 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Eugene F. Krause. <i>Taxicab Geometry.</i> Dover. 1987.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>612858</ref_obj_id>
				<ref_obj_pid>612824</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[S.-W. Lee and K. Mase. Activity and location recognition using wearable sensors. <i>IEEE Pervasive Computing</i>, 1(3):24--32, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>741494</ref_obj_id>
				<ref_obj_pid>647988</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[P. Lukowicz, H. Junker, M. Stager, T. V. Buren, and G. Troster. WearNET: a distributed multi-sensor system for context aware wearables. In G. Borriello and L. E. Holmquist, editors, <i>Proceedings of UbiComp 2002: Ubiquitous Computing</i>, volume LNCS 2498, pages 361--70. Springer-Verlag, Berlin Heidelberg, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[J. Mantyjarvi, J. Himberg, and T. Seppanen. Recognizing human motion with multiple acceleration sensors. In <i>Proceedings of the IEEE International Conference on Systems, Man, and Cybernetics</i>, pages 747--52. IEEE Press, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[P. C. Mahalanobis, On the generalised distance in statistics, <i>Proceedings of the National Institute of Science of India</i> 12 (1936) 49--55.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[NPD Group Market Research, Port Washington, N.Y. 2007]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>881089</ref_obj_id>
				<ref_obj_pid>862896</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[K. Van Laerhoven, A. Schmidt, and H.-W. Gellersen. Multi-sensor context aware clothing. In <i>Proceedings of the 6th IEEE International Symposium on Wearable Computers</i>, pages 49--56. IEEE Press, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1152244</ref_obj_id>
				<ref_obj_pid>1152215</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Kenichi Yamazaki and Toshiki Iso. Gait Analyzer based on a Cell Phone with a Single Three axis Accelerometer, <i>Proceedings of MobileHCI</i>, pages 141--144, ACM, 2006]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Sensor Networks as Video Game Input Devices Anthony Whitehead, Nick Crampton, Kaitlyn Fox, Hannah Johnston 
Carleton University 1125 Colonel By Dr Ottawa, Ontario, Canada K1S 5B6 +1-613-5200-2600 {awhitehe,ncrampto,kfox,hjohnsto}@connect.carleton.ca 
ABSTRACT In this work we are motivated by creating a network of sensors that can be used as input devices 
for video games. Our goal is to create an inexpensive network of off-the-shelf sensors that are used 
to force proper movement and engagement of the player. Our experience shows that a distributed set of 
sensors around the body prevents the player from cheating the system by using motion of the device alone 
to trick the system. In this work we show that a relatively simple sensor network configuration can enforce 
proper form and ensure that the player is actively participating in the game context. Categories and 
Subject Descriptors H.5.1 [Multimedia Information Systems] Evaluation &#38; methodology J.m [Computer 
Applications] Game Technologies General Terms Algorithms, Performance, Design, Experimentation, Security, 
Human Factors. Keywords sensor networks, video games, human computer interaction, accelerometer, entertainment 
technologies. 1. INTRODUCTION Nintendo has once again created a market splash by turning the input system 
for video games upside-down. Nintendo is benefiting, of course. In April 2007, it outsold the Xbox360 
2:1 and the PS3 4:1. Current deployment estimates, as of April 2007, state 5.6 million Xbox360, 2.8 million 
Nintendo Wii and 1.4 million PS3 (US figures)[13]. The Wii system has changed the standard input system 
dramatically and players are embracing the ideology whole heartedly. In fact, players are creating their 
own terminology: wiinjury a wii related injury, wii-kling a person who is not playing well, wii-ner 
 a person who plays too much. All of this supports the premise that game players are indeed looking for 
novelty in today s games and not just another graphics Permission to make digital/hard copy of part of 
this work for personal or classroom use is granted without fee provided that the copies are not made 
or distributed for profit or commercial advantage, the copyright notice, the title of the publication, 
and its date of appear, and notice is given that copying is by permission of the ACM, Inc. To copy otherwise, 
to republish, to post on servers, or to redistribute to lists, requires prior specific permission and/or 
a fee. FuturePlay 2007, November 15-17, 2007, Toronto, Canada. Copyright 2007 ACM 978-1-59593-943-2/07/0011...$5.00 
enhanced version of a decade old concept. As players push for more novelty in their gaming experience, 
issues such as immersion and realistic game play elements will become more and more desirable. It is 
to this end that we believe there is much fertile ground to be sewn in the area of sensor networks used 
to monitor and interpret player movements, and emotional feedback as a fundamental part of the game processing 
loop. Our work has been inspired primarily by the novelty introduced by Nintendo, but also our displeasure 
with a number of issues quickly found once you start using the system. The first is what we call the 
lazy-wii phenomenon. Once a player realizes that a quick flick of the wrist will suffice rather than 
a full and complete tennis swing, the rear-end gravitates back to couch fairly quickly. The second is 
the issue of lack of form: proper form and technique do not play a significant factor in performing the 
motions. As well our goal is to create a system of sensors that is also inexpensive and our budget for 
the entire system should be small. For our basic system with a wire connection to the computer the cost 
is under $100.00 and this price point could be dramatically reduced in volume. Accelerometers without 
a USB interface are significantly less expensive and a system could be put together for under 30 dollars. 
Initial estimates to put a simple wireless network of accelerometers together are about $500.00. Our 
first sensor network is a collection of accelerometers placed on strategic parts of the body. Our small 
network includes an accelerometer on each hand, and one on each leg. These four accelerometers give us 
enough information about the orientation of the limbs to allow significantly advanced pose detection 
of a subject wearing the sensors. The pose detection can be done fast enough to not affect the processing 
requirements of games that use it. We are achieving more than 1200 readings and pose classifications 
per second. We have also created a number of examples in the spirit of games such as Dance Dance Revolution 
and Guitar Hero. The idea here was to show that these popular games can indeed increase the immersion 
and reality of their play value by integrating a simple, inexpensive sensor network to be used as an 
input device. This paper continues by looking at some previous work and explaining some of the capabilities 
and limitations of accelerometers as input devices. We continue by explaining our method of pose detection 
followed by a brief explanation of the kinds of games where this type of input would be particularly 
useful. We follow up with a set of experiments that outline our pose detection capabilities and discuss 
some shortcomings of the method and possible areas for improvements. Finally we expose our development 
efforts on our own games using the sensor network as an input device and conclude with future areas of 
research and development.  2. REVIEW OF ACCELEROMETER INPUT SYSTEMS There is much recent interest into 
the use of accelerometers for various different applications, especially since their inclusion into cellular 
phones [15]. Although prior work discusses physical activity recognition using acceleration [9,3] or 
a fusion of acceleration and other data modalities [10], it is unclear how most prior systems will perform 
under real-world conditions because of their limited development of the application in question. Wearable 
computer systems have already been prototyped that use acceleration, audio, video, and other sensors 
to recognize user activity [4]. See [1] for an in-depth summary of other work. Although the literature 
supports the use of acceleration for physical activity recognition, little work has been done to validate 
the idea under real-world circumstances. Most prior work on activity recognition using acceleration relies 
on data collected in controlled laboratory settings [2] within the context of wearable computing or having 
no concrete application in mind. Much of the prior art focuses on recognizing a special subset of physical 
activities trained in a laboratory environment such as motion or gesture. However, [6] examines nine 
activities which is considered a larger set in the literature. For our game context, we have nine different 
classes to recognize for even the simplest of games. Interestingly, [6] demonstrated 95.8% recognition 
rates for data collected in the lab but these success rates dropped to 66.7% for experiments in real 
world environments. No work directly addresses placement of the accelerometers in order to provide the 
best data for recognizing activities. Though it has been suggested that for some activities, more sensors 
improve recognition [14]. Within the context of our application, the recognition rates are fundamentally 
important to the playability of the game. Without reasonable recognition rates, the game will not be 
a feasible venture. Most of the prior work has typically been conducted with only 1­2 accelerometers, 
typically bi-axial, not tri-axial, and worn at different locations on the body, with only a few using 
more than 2 [2, 7, 11, 14]. 2.1 Accelerometer Theory Accelerometers can provide some useful information 
about the orientation and instantaneous distance, velocity and acceleration information. Whilst in theory, 
this data would be extremely beneficial in the design of an input system; practically, they suffer from 
drift and inversion effects which we shall explain next. However, there is still a lot of information 
that can be taken from an accelerometer such as rotation, orientation and force feedback. Force feedback 
can be used by directly taking the acceleration or velocity readings and using those readings to indicated 
some level of force applied to the move. For example, in a tennis game setting, high acceleration readings 
would indicate a smash while low acceleration readings on the swing would indicate a drop shot. 2.1.1 
Computing Velocity &#38; Distance (single axis) Given acceleration (a) and a period of time (.t), it 
is possible to calculate the change in velocity over the time period. If the original velocity is known, 
then the velocity at the end of the time period can also be computed. Given the change of velocity and 
a time period, the change in position is computable. Finally, if the original position is known (or perhaps 
set to 0) the position (or relative position) at the end of the time period can also be computed. 2.1.2 
Computing Change in Velocity Upon taking acceleration readings at time ti and time ti+1 applied on the 
axis. Given .t is the difference between time ti and time ti+1, the change in velocity (.v) is given 
as: .v=a.t (1) 2.1.3 Computing Final Velocity Given .v from (1) and an initial velocity (v0), the current 
velocity is given as: v=v0+.v (2) 2.1.4 Computing Change in Distance Given v from (2), an initial velocity 
(v0), and our time slice .t the distance traveled over the time slice is given as: (v0 + v) .d =.t (3)2 
 2.1.5 Distance Given .d from (3) and an initial distance traveled prior to the time slice the current 
distance traveled since time 0 is given as: d=d0+.d (4) At the end of these calculations, we have both 
the final velocity (v) and the final distance (d). This information can be used as the initial values 
in the next time slice, resulting in a continuous flow of acceleration, velocity, and distance data. 
It is fundamentally important to note that while in theory we can compute displacement; and by using 
more accurate discrete integration techniques the error can be reduced, in practice these values are 
error prone due to noise regardless of the method used to compute them. In practice these calculations 
provide no tangible information to our application at hand and are not used directly. However, instantaneous 
velocity and distance calculations can be useful in other game related contexts.  2.2 Drift and Inversion 
As mentioned earlier, the above computations suffer from drift and inversion. Drift happens when the 
distance calculations become more and more erroneous as minor errors in the calculations compound. Imagine 
you have a rounding error each calculation that gets folded into your subsequent computations. Another 
issue comes from acceleration due to gravity. A slight tilt towards the axis in question will result 
in constant acceleration readings (due to gravity) and will cause the distance calculations to increase 
over time, even if the sensor is not moving at all. In order to remove this type of error, we must compute 
and negate the effects of acceleration due to gravity. However under motion, it is impossible to tell 
how much of the sensors reading is coming from static rotation vs. dynamic motion. i.e. there are two 
unknowns, acceleration caused by rotation and acceleration caused by motion, with only a single information 
source making the problem mathematically underdetermined.  Another important issue comes from what we 
call the inversion problem. As the sensor slows down abruptly, the sensor will read deceleration (or 
negative acceleration) and compute negative distance values even though the sensor is still moving forward, 
but slowing down.  2.3 Rotation: Pitch, Roll and Yaw The acceleration data can also be used to find 
how much rotation the sensor is under. This is possible because the acceleration due to gravity is constantly 
being read by the sensor with 1g of acceleration. If the sensor is placed on a flat surface (parallel 
to the earths surface) and is completely motionless, all of that acceleration will be read from the Z-axis. 
The acceleration on the X and Y axes will be zero, disregarding noise. When the sensor is rotated on 
its side ninety degrees, the axis that is now pointing toward the earth will read 1g and the Z-axis will 
read 0, again disregarding noise. Getting the angle from the readings on an axis can be done two different 
ways. The simplest way, although it is not very exact, is to multiply the acceleration on the axis by 
90. For a much more exact value, take the inverse sine of the acceleration readings. Rotation = asin(acceleration) 
(5) 2.4 Dual-Axis Rotation Sensing Presently dual-axis (X, Y) accelerometers are often used in rotation-sensing 
applications where the force of gravity is used as an input to determine the orientation of an object. 
The sensor is most responsive to changes in rotation when the sensing axis is perpendicular to the force 
of gravity. The sensor is least responsive to changes in rotation when the sensitive axis is such that 
a single axis is reading +1g or 1g (i.e. 90 degrees rotation). A dual-axis (X,Y) accelerometer prevents 
accurate sensing beyond 45° along either axis. Also, the absence of a Z-axis sensor means the accelerometer 
cannot detect an inversion, potentially causing improper computations. Figure 1: Axes, Pitch, Roll and 
Yaw Assignments for tri-axis accelerometer. accurately compute both pitch and roll. Moreover they would 
have to be mounted in such a way as to ensure they create an orthonormal basis. The use of a tri-axis 
(X, Y, Z) accelerometer in our application provides the Z-axis that functions with the rotated axes to 
sense the inversion of the accelerometer, thus permitting a full, unrestricted range of rotation. However 
it should be noted that the range of motion for a human being prevents most body parts from having a 
360 degree range, but they are sufficiently large that mounted sensors can become inverted.  2.5 Tri-Axis 
Rotation Sensing When using a tri-axis accelerometer the Z-axis can be combined with both of the rotating 
axes to improve rotation computation precision. We use the following pitch and roll assignments and axes 
orientation described in Figure 1. Basic rotation angles (°) can be generated from the accelerometer 
readings and equation 5 since the X- and Y-axes follow the sine function. However rotation around the 
Z-axis follows the cosine function and is computed by: RotationZ = acos(acceleration) (6) This allows 
rotation angles greater than 45° to be sensed accurately. Both pitch (ø) and roll (.) can be sensed simultaneously 
using the readings of all three axes: X,Y and Z .. X ø = arctan . . (7). Y 2 +Z 2 . . . .. Y . = arctan 
. . (8). X 2 +Z 2 . . . There is still an additional way to improve rotation sense precision. When the 
X-axis rotation is approximately 90°, the same X-axis sensor output voltage can represent two different 
angles. The Z-axis can be combined with the other axes to maintain constant sensitivity through all 360° 
of rotation. Sign of the Z axis reading is also important because rotations of 45° and 135° are represented 
by the same sensor output. This ambiguity can be resolved by monitoring the sign of the Z-axis readings. 
In this case, when the accelerometer is rotated around the X axis (pitch) at 45°, the Z-axis output is 
a positive value. When the accelerometer is rotated to 135°, the Z-axis output is a negative value. The 
sign of the Y-axis readings and the Z-axis readings will indicate in which quadrant the accelerometer 
is being rotated into. Acceleration Values Quadrant Y accel. Z accel. 1 - ve + ve 2 - ve - ve 3 + ve 
- ve 4 + ve + ve Table 1: Acceleration Values through Quadrants for rotationThese problems can be addressed 
by mounting the accelerometer around the X axis (Pitch). vertically, thereby creating an X, Z sensor. 
However in this case we would require an additional dual axis accelerometer to In practice these calculations 
give very accurate results and are independent of any previous readings or calculation i.e. they are 
not dynamic. As a result, they do not suffer from drift or inversion.  Equations 7 and 8 allow us to 
determine accurately a rotation between 0 and 90 degrees. Consequently we can compute the precise rotation 
and a range of motion of 360 degrees. Table 1 and Table 2 shows the expected signs for each output in 
each quadrant for pitch and roll. Acceleration Values Quadrant X accel. Z accel. 1 + ve + ve 2 + ve - 
ve 3 - ve - ve 4 - ve + ve Table 2: Acceleration Values through Quadrants for rotation around the Y 
axis (Roll).  2.6 Computing Yaw Yaw is not directly computable from a single accelerometer. Recall that 
pitch causes a change in readings in the Y axis accelerometer due to gravity. The same is true for roll 
and the X axis. However, yaw is the rotation around the Z axis that does not change any orthogonal axis 
reading on the sensor. However given two accelerometers that are in a planar configuration located distance 
d1 and d2 (d2 > d1 ) from the centre of rotation and parallel to the earths surface we can compute the 
angular rate (.) and therefore the yaw. Y 2 -Y1 (9)d 2 .=- The angular rate divided by the time slice 
gives us our rotation around the Z-axis. However it should be noted that the configuration of the two 
accelerometers is very difficult to achieve in an unconstrained environment. Our studies have shown that 
any configuration that is not perfectly parallel to the earth s surface suffers from the effects of acceleration 
readings due to gravity and results in an underdetermined mathematical system similar to drift mentioned 
above. 3. Sensor uses in games Overall, there is a lot of information we can collect from a very small 
sensor network of two accelerometers (Yaw, Pitch, Roll, Distance, Velocity and Accleration). However, 
the reliability of the readings in an unconstrained motion environment makes for some challenging decisions 
as to how to decipher the inputs from multiple accelerometers and use them as input to the video game. 
Fortunately, complete accuracy is not necessary in the gaming context, and instantaneous readings of 
distance, velocity and yaw can also prove useful. For a combat game like martial arts, the damage that 
a blow causes can be directly a result of the instantaneous velocity of the accelerometer attached to 
the hands or feet. Our use of the data is just a start into examining how we can use a collection of 
sensors. We have decided to examine the reliable readings first to determine the types of input we can 
achieve and the types of games that would benefit from our input system. 3.1.1 Pose Detection Our sensor 
network is comprised solely of tri-axis accelerometers attached to the body. Affectionally called the 
Wii-suit, four USB­based accelerometers are attached to the arms and legs via capsules and strapping 
we call motion-bands, are connected to a small hub that is then fed to the computer via a USB cable or 
optionally a wireless USB hub. As well we have another tri-axis device that has two buttons integrated 
that we have placed into a hand held device shown in Figure 2. We use the rotation sensing capabilities 
of the acclerometers and their placements in order to determine poses that the player re­creates. We 
have taken the pose recognition system and successfully created a number of dancing oriented games that 
has the user recreate the dance position in time with the music. Our pose recognition system is based 
on a training phase followed by a recognition phase (game playing). We have examined a number of difference 
metrics as part of a nearest mean classifier [5] inlcuding taxi-cab distance [8], Mahalanobis distance 
[12], and the common Euclidean distance. Figure 2: Top: Hand held form with two buttons and a tri-axis 
accelerometer. Bottom: Capsules holding accelerometer chipset  3.1.2 Training The training phase consists 
of a number of trials where the subject will enter the pose, hold for a short period of time while serveral 
hundred to several thousand readings will be taken, then break the pose. Repeating for K trials. Once 
the K trials are complete, we treat the readings as points in n-dimensional space and compute the centroid 
of the volume created by all of the sample points. The centroid represents the average position of the 
the sensors for all K trials. We subsequently compute the variance and the standard deviation of the 
data set. The data is then stored for subsequent use in the game(s).  During the game creation process 
the number (C) and types of poses are specified for training. Typically these are relatively small data 
sets. The poses are trained and stored for subsequent use in the game in question. The game, as part 
of its intialization process will load all of the statistics from the training and is ready If the covariance 
matrix is the identity matrix, the Mahalanobis distance reduces to the Euclidean distance. If the covariance 
matrix is diagonal, then the resulting distance measure is called the normalized Euclidean distance: 
for the recognition task. .. n -   3.1.3 Recognition We use a minimum mean distance rule classifier 
as our recognition system. It characterizes each category by mean and standard deviations of the components 
of its training feature vectors. The distance between an unknown sample M (input move) and the mean of 
the features of class m (trained pose), d(M , m) , is then computed. The unknown sample is then assigned 
to class m* (recognized as move m*) for which such distance d(M , m) is minimum. Formally: m* = Min d(M, 
mi) { i = 1,2 . . C} (10) and d(M, mi) is one of the distance metrics discussed next and compared in 
graphical form in Figure 3. Figure 3: Contours of constant distances for Euclidean, Manhatten and Mahalanobis 
metrics. 3.1.3.1 TAXICAB (Manhatten) DISTANCE The taxicab distance between two points in a Euclidean 
space with fixed coordinate system (typically Cartesian) is the sum of the lengths of the projections 
of the line segment between the points onto the coordinate axes [8] The taxi-cab distance between two 
points P = (p1,p2, ,pn) and Q=(q1,q2, qn) is defined as: .= n i 1 | - | pi qi (`11) )2 ( p qi i 
1 si where si is the standard deviation of the xi over the sample set. The Mahalanobis distance is simply 
the distance of the test point .= from the center of mass divided by the width of the ellipsoid in the 
direction of the test point. 4. Experimental Results We have conducted a number of experiments to test 
the recognition rates of our classifier. The first set of experiments test to see how well a person can 
play against their own training data vs. another person s training data. This experiment has significant 
impact on the practicality of the system. In this context, the user was given a pose to get into and 
a set amount of time to get into the pose. Once the pose was called for, the system checked continuously 
for the pose for the prescribed amount of time, typically less than a few seconds. As Figure 4 shows, 
with self training data the recognition rate is always 100 percent. This means that within the context 
of these experiments, the users were always able to duplicate the poses that they trained. This is fundamentally 
interesting because it allows the game developer to ensure that the game is playable by everyone, regardless 
of physical limitations. The game developer only needs to incorporate a training phase (which is common 
among most games already) into their game. i d(p, q) (13) 2 .= 3.1.3.2 EUCLIDEAN DISTANCE The Euclidean 
distance between two points P = (p1,p2, ,pn) and Q=(q1,q2, qn), in Euclidean n-space, is defined as: 
 n i 1 100 80 60 40 12345678 Pose Self Trained Other Trained Figure 4: Recognition rates for self trained 
data vs training done by a different (single) person over all trials. Poses demonstrated above. )2 (12) 
(  - p qi i 20  3.1.3.3 MAHALANOBIS DISTANCE 0 Mahalanobis distance is a distance measure introduced 
by P. C. Mahalanobis in 1936 [12]. It is based on correlations between variables by which different patterns 
can be identified and analysed. It is a useful way of determining similarity of an unknown sample set 
to a known one. It differs from Euclidean distance in that it takes into account the correlations of 
the data set and is scale-invariant.  The overall recognition rate for all trials and all moves is 73.75% 
when testing against training data created by a different individual. We believe that the issue with 
pose 4 having a 0 recognition rate is related to dimensionality of the person doing the training and 
the person doing the trial. Our training subject was tall, but not all of our test subjects were. 5 Number 
of Errors the development studio and played by most players out of the box. Another factor affect the 
recognition rates is the allowable distance from the mean that would classify a sample move M into class 
m. As Figure 7 shows, the recognition rates increase as the threshold of acceptability increases. However, 
it should be noted that if the distance is allowed to be too large, then the inherent risk of false recognition 
becomes an issue. Within our application the false recognition has not appeared to be a problem yet, 
however as poses become more similar in appearance this problem will invariably come up. When using multiple 
persons training the poses, we expect the recognition rate to improve because we are getting a better 
sample of different human limitations into the training data. In Figure 8, we show that with multiple 
people training of the poses, the recognition rates for people inside the training remain at 100 percent, 
but the recognition rates for those outside the training group go up. However the possibility remains 
for false classification rate increasing as a result of overlapping distributions or sensor readings. 
In practice, we did not experience this effect due to the number of sensors being high. 4 3 2 1 0 1234 
Player 1 Trial Number (Times played) Player 2 Figure 5: Number of errors on subsequent plays. In Figure 
5 however, we see that the error rate drops after the player has more experience playing the game, and 
most significantly after the first trial. This is an expected side effect of 100.00% practicing the game 
and, in fact, should be expected and desirable from a game design point of view and it further indicated 
in Figure 6 above where there is a general trend for better success as the number of plays increases. 
Recognition Rate 90.00% 80.00% 70.00% 60.00% 50.00%  Figure 6: Trendlines for learning curves of 7 
different subjects. If we remove the first trial because test subjects typically didn t understand the 
process or the poses well, and ignore pose 4 which constantly gave us 0 recognition rate; the recognition 
rates increase dramatically. The overall recognition rate for all trials and all moves under this configuration 
is 91.07% when testing against training data created by a different individual. These recognition rates 
are suitable to allow the game to be trained in 0.3 0.45 0.525 0.6 Distance (Normalized) Figure 7: Graph 
of recognition rates against distance values used to classify a sample M as part of class m. 100 80 60 
40 20 0 12345678 vs. Self Training Pose vs. Group Training Figure 8: Recognition rates for self trained 
data vs training done by a group of people over all trials.  The overall recognition rate for all trials 
and all moves is 97.5% when testing against training data created by an individual. i.e. the training 
data creator is also the recognition trial. As well we have shown that with sufficient practice, players 
can become better (or learn) the required poses. Clearly different players will learn at different rates, 
but within 15 trials most players are able to bring their recognition rates up by more than 30%. These 
recognition rates are suitable to allow the game to be trained in the development studio by multiple 
people and subsequently played by most players without the need for a training phase being built into 
the game. Finally, it is worth noting that certain poses may be extremely difficult for some players 
to reach or maintain creating a level of frustration for the player. An interesting consequence of this 
development is that of real-time adaptive thresholding algorithms would be useful to help remove frustration 
points, yet also keep the game challenging. This, in our opinion would be preferable over a self training 
scheme.    4.1 Pose Based Gaming We have several created games to use the sensor network, but our 
focus for this work is posed based games. Posemania, our game that allows you to dance to music requires 
the player be in the proper pose as the right time. The poses scroll up the screen and the player must 
duplicate the pose as they reach the top, in a similar fashion to Dance Dance Revolution (DDR). Figure 
9: Screen shot of Posemania dancing game created to use recognition system. A second game developed, 
also in the spirit of DDR, is robo-paint where the player needs to match the dance of the animated robot. 
As poses are correctly matched the robot s body gets painted and the game continues until the entire 
robot has been successfully recoloured. 5. CONCLUSION AND DISCUSSION In this work we have shown that 
pose detection is a possible input source with a relatively inexpensive sensor network that is comprised 
solely of accelerometers. A nearest mean classifier using Mahalanobis distance has shown to perform the 
best for recognizing poses from our network or sensor data. We have created a number of pose based games 
and can foresee that this type of input network would be useful in games that are dance related, tai-chi 
and yoga training, as well as less game related applications such as physiotherapy and training modules. 
 Due to the limited number of moves in a game, relative to other larger data sets such as DNA sequences, 
it would appear that classical methods of classification such as our nearest mean distance classifier 
will perform well enough to meet the computational demands of video games. We have shown that pose classification 
of an accelerometer sensor network to be a feasible technology in the creation of games. In theory smaller 
networks could be created using currently available controllers such as the Wii-mote and Sony s six-axis 
controllers. For example, a very simple network can be created using two Wii­motes, one in each hand. 
Our future work includes a number of areas for exploration including dynamic gesture (punch) recognition 
combined with proper form enforcement as well as examinations into better training and classification 
techniques. Furthermore, we ware looking to expand into more complex poses and determine whether or not 
there exists an upper limit to the number of sensors in the network. As well, we are looking to branch 
off into non­homogeneous sensor networks.  6. REFERENCES [1] L. Bao. Physical Activity Recognition from 
Acceleration Data under Semi-Naturalistic Conditions. M.Eng. Thesis, Massachusetts Institute of Technology, 
2003. [2] L. Bao and S. Intille, Activity Recognition from User-Annotated Acceleration Data. In PERVASIVE 
2004, LNCS 3001, pp. 1 17, 2004. [3] J.B. Bussmann, W.L. Martens, J.H. Tulen, F.C. Schasfoort, H.J. van 
den Berg-Emons, and H.J. Stam. Measuring daily behavior using ambulatory accelerometry: the Activity 
Monitor. Behavior Research Methods, Instruments, &#38; Computers, 33(3):349 56, 2001. [4] B.P. Clarkson. 
Life Patterns: Structure from Wearable Sensors. Ph.D. Thesis, Massachusetts Institute of Technology, 
2002. [5] Richard O. Duda,. Peter E. Hart.. Pattern Classification. by Wiley Interscience. (1973) [6] 
6. F. Foerster, M. Smeja, and J. Fahrenberg. Detection of posture and motion by accelerometry: a validation 
in ambulatory monitoring. Computers in Human Behavior, 15:571 583, 1999.  [7] N. Kern, B. Schiele, and 
A. Schmidt. Multi-sensor activity context detection for wearable computing. In European Symposium on 
Ambient Intelligence (EUSAI). 2003. [8] Eugene F. Krause. Taxicab Geometry. Dover. 1987. [9] S.-W. Lee 
and K. Mase. Activity and location recognition using wearable sensors. IEEE Pervasive Computing, 1(3):24 
32, 2002. [10] P. Lukowicz, H. Junker, M. Stager, T.V. Buren, and G. Troster. WearNET: a distributed 
multi-sensor system for context aware wearables. In G. Borriello and L.E. Holmquist, editors, Proceedings 
of UbiComp 2002: Ubiquitous Computing, volume LNCS 2498, pages 361 70. Springer-Verlag, Berlin Heidelberg, 
2002. [11] J. Mantyjarvi, J. Himberg, and T. Seppanen. Recognizing human motion with multiple acceleration 
sensors. In Proceedings of the IEEE International Conference on Systems, Man, and Cybernetics, pages 
747 52. IEEE Press, 2001. [12] P.C. Mahalanobis, On the generalised distance in statistics, Proceedings 
of the National Institute of Science of India 12 (1936) 49-55. [13] NPD Group Market Research, Port Washington, 
N.Y. 2007 [14] K. Van Laerhoven, A. Schmidt, and H.-W. Gellersen. Multi­sensor context aware clothing. 
In Proceedings of the 6th IEEE International Symposium on Wearable Computers, pages 49 56. IEEE Press, 
2002. [15] Kenichi Yamazaki and Toshiki Iso. Gait Analyzer based on a Cell Phone with a Single Three 
axis Accelerometer, Proceedings of MobileHCI, pages 141-144, ACM, 2006  
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2007</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>1328211</article_id>
		<sort_key>90</sort_key>
		<display_label>Pages</display_label>
		<pages>8</pages>
		<article_publication_date>11-14-2007</article_publication_date>
		<seq_no>3</seq_no>
		<title><![CDATA[Where is the answer?]]></title>
		<subtitle><![CDATA[the importance of curiosity in pervasive mobile games]]></subtitle>
		<page_from>46</page_from>
		<page_to>53</page_to>
		<doi_number>10.1145/1328202.1328211</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1328211</url>
		<abstract>
			<par><![CDATA[<p>Today games are increasingly recognized not only for their entertainment value, but also for their positive impact on social interaction, educational potential, technical interests, publicity and economical power. A new game genre of pervasive games extends a virtual game world into the real world environment, allowing players to move seamlessly from one to the other. Our research is focused on identifying the elements that are important in a pervasive playful application that can trigger the interest of different individuals towards the reflection and understanding of the knowledge surrounding them. Our findings suggest that stimulating the curiosity of players is one of these key elements, and that it should be considered in the design of serious mobile games with pervasive characteristics, while looking to enrich the informal learning. In addition, mobile phones are well accepted as play tools. These results are based on the feedback given by 45 players of our game entitled SciMyst, which is a mobile adventure game with pervasive and multiplayer characteristics. In SciMyst the player has to solve different types of enigmas, which are based on the information from the real world. The player is required to become familiar with the surroundings in order to succeed, and at the same time s/he is learning from the environment in a playful manner. The game was in action and the data collection took place during SciFest 2007, a science festival in Joensuu, Finland, in March 2007.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[environment and player]]></kw>
			<kw><![CDATA[mobile games]]></kw>
			<kw><![CDATA[mobile learning]]></kw>
			<kw><![CDATA[pervasive games]]></kw>
			<kw><![CDATA[pervasive learning]]></kw>
			<kw><![CDATA[playful learning]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>K.8.0</cat_node>
				<descriptor>Games</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>H.5.2</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10003120.10003121</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003251.10003258</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Multimedia information systems->Massively multiplayer online games</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10011007.10010940.10010941.10010969.10010970</concept_id>
				<concept_desc>CCS->Software and its engineering->Software organization and properties->Contextual software domains->Virtual worlds software->Interactive games</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010476.10011187.10011190</concept_id>
				<concept_desc>CCS->Applied computing->Computers in other domains->Personal computers and PC applications->Computer games</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Experimentation</gt>
			<gt>Human Factors</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P925223</person_id>
				<author_profile_id><![CDATA[81342510620]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Carolina]]></first_name>
				<middle_name><![CDATA[Islas]]></middle_name>
				<last_name><![CDATA[Sedano]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Joensuu, Joensuu, Finland]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P925271</person_id>
				<author_profile_id><![CDATA[81363599899]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Teemu]]></first_name>
				<middle_name><![CDATA[H.]]></middle_name>
				<last_name><![CDATA[Laine]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Joensuu, Joensuu, Finland]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P925262</person_id>
				<author_profile_id><![CDATA[81416598116]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Mikko]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Vinni]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Joensuu, Joensuu, Finland]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14051782</person_id>
				<author_profile_id><![CDATA[81100117225]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Erkki]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Sutinen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Joensuu, Joensuu, Finland]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>557640</ref_obj_id>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Alessi, S. and Trollip, S.(2001). Multimedia for Learning Methods and Development. 3th ed. Ed. Allyn and Bacon.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Becker, K. (2006). Design Paradox: Instructional Games. In Future Play conference proceedings. (Ontario, Canada),]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Brodbeck, D. (2006). How Can Experimental Psychology Inform Game Design?. In Future Play conference proceedings. (Ontario, Canada).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Chalmers, M.; et al. Gaming on the Edge: Seams in Pervasive Games. In PerGames 2005 proceedings (Munich, Germany), pages 11--18.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Cohen, L. and Manion L. (1990) Research Methods in Education. 3rd. Edition. Ed. Routledge, NY, USA.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[de Souza e Silva, A. and Delacruz, G. Hybrid Reality (2006) Games Reframed: Potential Uses in Educational Contexts. SAGE Publications. Games and Culture Vol. 1, 231--251.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Helms, N. and Hundelb&#248;l, J. (2006) Pervasive Learning Environments. In Proceedings of Society for Information Technology and Teacher Education International Conference. (Orlando, Florida, USA).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Holleis, P.; et al. Playing with the Real World. In PerGames 2005 proceedings (Munich, Germany), pages 43--50.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[IPerG. URL: http://www.pervasive-gaming.org Last view: February 20th, 2007]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Malone, T. (1980). What makes things fun to learn? A study of intrinsically motivating computer games. Cognitive and Instructional Sciences Series CIS-7 (SSL-80-11). Pslo Alto, CA: XEROX Palo Alto Research Center.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Moses, L. (1986). Think and Explain with Statistics. Ed. Addison-Wesley.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Paelke, V.; et al. Vision-Based Interaction - A first Glance at Plazing MR GAmes in the REal-World Around Us. In PerGames 2005 proceedings (Munich, Germany), pages 92--97.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Pervasive Learning. URL: http://www.pervasivelearning.org Last view: February 20th, 2007]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Resnick, M. (2006). Computer as Paint Brush: Technology, Play and the Creative Society. In Singer, D., Golikoff, R., and Hirsh-Pasek, K. (eds.), Play = Learning: How play motivates and enhances children's cognitive and social-emotional growth. Oxford University Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1215723</ref_obj_id>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Salen, K. and Zimmerman, E. (2003). Rules of Play: Game Design Fundamentals. MIT Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Semacode. URL:http://semacode.org/ Last view: March 16th, 2007]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[SciFest. URL: http://www.scifest.fi Last view: February 20th, 2007]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[SciMyst, URL: http://www.SciMyst.fi Last view: September 20th, 2007.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1167604</ref_obj_id>
				<ref_obj_pid>1167601</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Siobh&#225;n, T. (2006) Pervasive learning games: Explorations of hybrid educational gamescapes. SAGE Publications. Simulation &amp; Gaming, Vol. 37, No. 1, 41--55 (2006)]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Walz, Steffen; et al. Cell Spell-Casting: Designing a Locative and Gesture Recognition Multiplayer Smartphone Game for Tourists. In PerGames 2006 proceedings (Dublin, Irland), pages 151--158.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Where is the answer? The importance of curiosity in pervasive mobile games Carolina Islas Sedano Teemu 
H. Laine Mikko Vinni Erkki Sutinen cislas@cs.joensuu.fi thlaine@cs.joensuu.fi mvinni@cs.joensuu.fi sutinen@cs.joensuu.fi 
Department of Computer Science and Statistics, University of Joensuu P.O. Box 111 FI-80101 Joensuu, Finland 
+358 13 251 7929  ABSTRACT Today games are increasingly recognized not only for their entertainment 
value, but also for their positive impact on social interaction, educational potential, technical interests, 
publicity and economical power. A new game genre of pervasive games extends a virtual game world into 
the real world environment, allowing players to move seamlessly from one to the other. Our research is 
focused on identifying the elements that are important in a pervasive playful application that can trigger 
the interest of different individuals towards the reflection and understanding of the knowledge surrounding 
them. Our findings suggest that stimulating the curiosity of players is one of these key elements, and 
that it should be considered in the design of serious mobile games with pervasive characteristics, while 
looking to enrich the informal learning. In addition, mobile phones are well accepted as play tools. 
These results are based on the feedback given by 45 players of our game entitled SciMyst, which is a 
mobile adventure game with pervasive and multiplayer characteristics. In SciMyst the player has to solve 
different types of enigmas, which are based on the information from the real world. The player is required 
to become familiar with the surroundings in order to succeed, and at the same time s/he is learning from 
the environment in a playful manner. The game was in action and the data collection took place during 
SciFest 2007, a science festival in Joensuu, Finland, in March 2007. Categories and Subject Descriptors 
K.8.0 [Computer Milieux]: Personal Computing General games. H.5.2 [Information Interfaces and Presentation]: 
User Interfaces. Permission tomakedigital/hardcopyof part of this workfor personal or classroomuseisgranted 
without fee provided thatthecopies are not madeordistributed for profitor commercialadvantage,thecopyright 
notice,thetitleofthepublication,and itsdateof appear,and noticeis given thatcopying is by permission 
of the ACM, Inc. Tocopy otherwise, to republish, topost on servers, orto redistributeto lists,requiresprior 
specificpermission and/ora fee. FuturePlay 2007, November 15-17, 2007, Toronto, Canada. Copyright 2007 
ACM 978-1-59593-943-2/07/0011...$5.00  General Terms Design, Experimentation, Human Factors.  Keywords 
pervasive games, pervasive learning, environment and player, playful learning, mobile games, mobile learning. 
 1. INTRODUCTION Games can be designed and used for a wide range of purposes: for individual entertainment 
[8], as a catalyst of social interaction [12], for teaching-learning [1], as an experimental platform 
for new technologies and design concepts [4], and as a publicity campaign, to name but a few. In addition, 
games present a wide range of genres, independently of their digital or non digital nature. The actual 
taxonomies for games depend on the parties who define them, e.g. game designers or educational scientists. 
In the information society era the ongoing debate and tension between instructional designers and game 
designers makes the development of digital instructional games, or serious games, a difficult task [2]. 
One interesting intersection where the instructional designers and game designers might be able to join 
efforts easily is with the use of mobile and ubiquitous technologies. This is due to the fact that for 
both disciplines the use and experiences of this type of technologies is new. From these technological 
trends and from the expansive world of games, we can find a relatively "new" game experience: pervasive 
gaming. According to IPerG [9] pervasive games are a radically new game form that extends gaming experiences 
out into the physical world . At the same time there is an open invitation by Helms [7] and de Souza 
e Silva [6] on how to work with knowledge and learning in pervasive environments, making use of the possibility 
to look at familiar spaces from unfamiliar perspectives and at content learned in classroom from different 
point of view . Inspired by the concept of pervasive gaming, merged with the idea to engage players into 
scientific or cultural expositions, and with the main goal to trigger their interest and to make use 
of the informal learning, we ventured ourselves in the creation of a mobile game with pervasive characteristics: 
SciMyst. In SciMyst the player explores the physical environment in order to solve different types of 
problems. Moreover, the reason for combining these ideas in the design of the game, is the need to seek 
an answer to the following question: how can one trigger the interest of different individuals of different 
ages towards the reflection and understanding of the knowledge surrounding them, and to encourage them 
to collaborate with each other in the process?.  In this paper we explain the concepts and development 
of SciMyst, a mobile game with pervasive and multiplayer characteristics. We start by presenting the 
fundamentals of this type of games and our motivation for it. Next comes an explanation of the SciMyst 
features followed by the game description. We continue by presenting the main technical concepts and 
the game definitions, followed by the research methodology description and research findings. Finally, 
we wrap up the study with discussion and conclusions.  2. RELATED WORK AND MOTIVATION The terms we use 
affect our attitude towards all activities and things. Before developing any application or tool, we 
should grasp and understand the basic idea of what we want to develop and define the terms we use to 
describe it with. In case of creating an educational game, instructional game, or serious game, as it 
is nowadays referred to, we understand the creation process by using the terminology analysis made by 
Resnick [14]. In his work, he explains clearly the dichotomy of games and learning. According to his 
own words: [i]n fact, you are likely to learn the most, and enjoy the most, if you are engaged as an 
active participant, not a passive recipient. The terms play and learning (things that you do) offer a 
different perspective from entertainment and education (things that others provide for you) . Therefore, 
understanding how we refer to things impacts the way we develop and use them. Consequently, it is in 
our best interest to focus on the things we do: playing and learning. We sought a solution to the challenge 
to involve the richness of the knowledge that our surroundings offer us for learning in a playful manner. 
As a result, we found Siobhán's [13, 19] definition of pervasive learning. He mentions that [p]ervasive 
learning is a social process that connects learners to communities of devices, people, and situations 
so that learners can construct relevant and meaningful learning experiences, that they author themselves, 
in locations and at times that they find meaningful and relevant." In order to create playful learning 
concepts involving the environment, we must explore pervasive learning as well, which in turn can be 
related with pervasive gaming experiences. At the time when we were making this concept analysis, the 
SciFest 2007 science festival [17] coordinated by University of Joensuu was in its organisational phase. 
Therefore, we decided to explore this type of pervasive gaming concept within the festival arena. The 
main idea was to offer an application that would trigger the interest of the participants, at any time 
and for any individual, towards the exhibitions and workshops at SciFest. Based on this idea we created 
a multiplayer mobile game with pervasive characteristics, keeping in mind learning as part of it. This 
was done by impelling the immersion of the players in the different stands and their content in a playful 
learning manner. The game was entitled SciMyst [18]. Our theoretical foundations and inspirational elements 
were provided by diverse studies conducted on this topic. For example, we used the outlined principles 
that Brodbeck [3] suggests from experimental psychology: acquisition, asymptote, extinction and spontaneous 
recovery in order to maintain an adequate learning curve and flow in the game. The development most similar 
to our application that we found is the German game REXplorer [20]. It is a pervasive mobile game for 
tourists to explore the culture and history of Regensburg, Germany. The main differences between REXplorer 
and SciMyst are the target group and the way to interact with the environment. For REXplorer the target 
group is young adults between 13 and 30, while SciMyst is targeted to virtually any ages. The audio guide 
that is triggered in the gameplay of REXplorer does not depend of the location of the player nor of his/her 
interaction with the environment. This in comparison within SciMyst, where within the gameplay, a dependency 
exists and, in specific moments, interaction with the environment is needed in order to continue playing. 
Furthermore, REXplorer has been strictly defined to be used as a game for tourists at certain locations 
only, while SciMyst can be used practically anywhere.  3. SCIMYST CONCEPT The main goal of the game 
design was to bring together the technology, people, playing, learning and the environment (see Figure 
1). These elements are described briefly in this section. Figure 1. Graphical representation of the 
main concepts of SciMyst -Technology (simple tools). In this case our focus is on mobile phones, which 
are devices that almost anyone can own, and everybody can use. By its nature a phone can be considered 
a social instrument, in that it is used mainly for communication. Additionally, many mobile phones nowadays 
present multimedia capabilities such as cameras that can be exploited for creative purposes. -Playing. 
Our aim is that anyone can play the game and enjoy it, from youngsters to elders. The only requirement 
for playing is that the player is willing to use a mobile phone and to move around in the physical playing 
area looking for answers to presented problems. We seek to support an individual flow of game experience 
for different types of players by granting them control of the game progression. However, limitations 
can be set on the length of the game to assure that the same players will not be occupying the game for 
the entire day and that the players will not get frustrated by the sheer size of the game. Furthermore, 
the amount of content created for the game effectively limits the maximum length of the game.  -People. 
We wanted to enhance social interaction between the players by introducing a collaborative feature in 
the game. If a player is stuck with some game task, s/he can request help from another player. The decision 
to contact someone else or to help another player depends on the player her/himself. If the other player 
accepts the help request, both players are directed to a physical meeting point where the actual collaboration 
to resolve the enigma initiates. A player who successfully helps another player to solve an enigma (i.e. 
a question or task to be solved) is rewarded with special helping points which are added to the total 
score. In addition to this social interaction between players, the game encourages the player to talk 
with the expositors to get information either for resolving a question or because s/he got interested 
in the exposition content. -Learning. Even though our focus is in informal learning, we took into account 
the recommendations of instructional designers on how to create enigmas which enhance learning and are 
suitable to be presented on mobile devices. The enigmas should be brief, clear and challenging. Each 
set of enigmas is different and randomised for each player. The overall goal is that the player can resolve 
as many enigmas as possible, thus showing her/his ability to find the answers. -Environment. The game 
uses the information of the real environment in a playful manner to trigger players' interest on the 
subject. Every part of the game is intrinsically embedded in the environment. In this way, the game creates 
a bridge between the virtual world and the real world. 3.1 In-game definitions This section describes 
the enigma types, the game modes and the help. We consider these elements crucial for SciMyst. Enigma 
Types As mentioned previously, enigmas are questions or tasks to be solved during the game. The concept 
of the game presents three types of enigmas: multiple choice, take-a-picture and find-a­picture. These 
enigmas are briefly described in Table 1. Nevertheless, due to the nature of the SciFest event, we only 
tested Multiple choice and Take-a-picture enigma types. The reason for this is that the festival was 
set up just some hours before the opening of the event. This increased the challenge for the creation 
of the content. However, find-a-picture enigmas would be possible to use in locations such as museums 
or galleries where the content is in place for a longer period of time.  Game Modes SciMyst presented 
two game modes: casual and battle mode. -Casual mode. The objective of this mode is to explore and enjoy 
the environment in a free and relaxed manner. There is no time pressure for resolving the enigmas. Correct 
answers to enigmas yield an enigma-specific amount of points, and the penalty of a wrong answer is that 
the next time the player tries to resolve the same enigma again, there will be less points available. 
The help features of the game are available in this mode. Additionally, the player can relocate her-/himself 
to any other area at any moment. -Battle mode. The battle mode consists of a set of random enigmas and 
a timer; the more enigmas the player solves in a fixed amount of time the more points s/he earns. Wrong 
answers diminish the score. After the battle is over, the game ends and the final score is recorded in 
the Hall of Fame. The help feature is not available in this mode. The battle has the function similar 
to the final opponent (i.e. the big boss) or the final challenge in many video games. Table 1. Enigma 
descriptions Enigma Type Description Multiple Text based questions bundled with alternative choice answers 
from which the player must choose the correct one. According to educators well written multiple choice 
questions can do a good job of assessing comprehension, problem solving and other higher order skills 
[1]. Furthermore, multiple choice questions are particularly advantageous in a mobile environment where 
text input is usually cumbersome. Take a picture Textual queries challenging the player to locate a specific 
object within the exposition. After reading a description of the object, the player has to find it and 
take a picture of a special tag attached to it. This type of enigma can be considered a matching type 
of question which, according to educators, are more suitable for simple factual and verbal learning in 
comparison to the multiple choice questions [1]. Find a picture Differs from the previous enigma types 
by not inquiring the player via text. In find-a-picture enigma a picture is displayed to the user on 
the mobile phone screen including a possible keyword. With this information the player has to find the 
object presented on the picture within the game space. Once s/he finds it, s/he has to take a picture 
of the tag that belongs to the question. This type of enigma can as well be considered as matching type 
of questions.  Help According to diverse experts [1,15] help and feedback are important elements that 
should always be present in playing and in learning. In the case of SciMyst, we paid special attention 
to these elements. With the help feature we specifically looked to offer the players the tools to facilitate 
the game play. The help consists of the game instructions, controls of the game, map of the environment, 
and collaborative help. In pervasive games like SciMyst, collaborative help presents a social interaction 
channel. When a player contacts another one via collaborative help feature to request her/him to assist 
resolving a specific enigma, both players are guided to meet each other physically in an agreed meeting 
point. This specific location is shown to players before they start to play. When a player accepts a 
collaborative help request, s/he is rewarded with a predetermined amount of points when the enigma in 
question is solved correctly. Once the players meet each other, they can decide whether to start playing 
together or continue playing separately.   3.2 Game setting description The game was running constantly 
at the SciFest 2007 science festival organised by the University of Joensuu, Finland. The 2 physical 
area consisted of 14,600 mfloor space and its floor plan is shown in Figure 2. For the game purposes 
the area was divided into four sub areas by colour code: red, violet, green and yellow. There were eight 
Nokia N80 mobile phones available for the game play. These phones were loaned to anyone who wanted to 
play the game, if her/his phone did not meet the technical requirements of SciMyst. The phones were equipped 
with 3 megapixel camera, WLAN connection, Java support, screen size of 352x416 pixels and 18 MB RAM memory. 
Once the player had a phone that supported the SciMyst application a short introduction to the game was 
given to her/him. This was done to ensure that the player understood the concept. After the introduction 
s/he was on her/his own to start to play the game. The game began in casual mode and the game play consisted 
of two main activities: changing areas and solving enigmas at current area. There was no restriction 
for changing the area constantly, but after changing an area at least one enigma had to be answered, 
if there were unanswered enigmas in that area. When the player had solved at least two enigmas of each 
area s/he was given the permission to enter the battle mode. After finishing the battle mode, the game 
ended and told the player to return the device back to the stand where the game had started. After returning 
the device, the player was given a questionnaire to fill in. Figure 2. Floorplan of the SciFest 2007 
arena As we recognised the importance of properly created and authored content for a successful game 
experience and learning, the game content was created in collaboration with the content matter experts. 
This made the content relevant and interesting both from the players' and the exhibitors' points of view. 
 3.3 Technical Features SciMyst was designed so that it can be adapted easily to any setting (museum, 
building, expo, or outdoors). However, the main limitation of the game space is the connectivity of the 
mobile phones. At this moment the game has been designed to run inside a WLAN. This design decision was 
made in order to avoid the costs of mobile data when connections of mobile operators are used. The usage 
of WLAN might bring challenges of the connectivity, if the network is not well planned and implemented 
(i.e. is not accessible everywhere in the game area). Theoretically, the game works smoothly in any high 
bandwidth mobile network such as 3G. As taking pictures is one activity in the game, we use the Semacode 
library [16] to provide two-dimensional bar codes (i.e. tags, see Figure 3). Each bar code represents 
a tag string and a picture taken from the bar code can be decoded in order to discover the corresponding 
tag string. Bar codes are used in the game to relocate a player or to tag potential answers for take-a­photo 
enigmas. The reason of using tags is because automatic decoding of tags is more feasible than identifying 
real objects from photographs. A simple, attractive and intuitive user interface (UI) is fundamental 
for SciMyst design, and is intimately related to the game concept. As in any software or device meant 
to be used by a human, the design decisions in the UI greatly affect the usability of the system. In 
order to make the UI intuitive and attractive, we used short texts, icons, high contrast colour scheme 
and minimised the number of keys used for controlling the game. Figure 3. 2D bar codes: a player is 
relocating herself The SciMyst system was built on the Java-based MUPE platform (Multi-User Publishing 
Environment) developed by Nokia. MUPE is based on a client-server approach in which the server pushes 
XML content to the client which in turn renders it to Java content viewable on the mobile phone. The 
idea behind this approach is that the application developers do not have to be concerned about updating 
clients as all the content can be pushed to the clients via XML. Topmost elements of the XML content 
are UI sheets representing drawable canvases and forms, both of which can contain other elements such 
as strings, text fields, lists and buttons. Dynamic content update can be done by embedding server method 
calls to the UI sheets and by pushing the XML content from the server to the clients at any time.  
4. RESEARCH METHODOLOGY The subjects of the study, who represented different ages and genders, came voluntarily 
to play the game. None of the subjects had played a pervasive game before. The language used was mainly 
English. However, on the last day of SciFest the game content was also introduced in Finnish.  The research 
consisted of two parts: observation and questionnaire. In the observation part the subjects were approached 
one by one and they were offered to play the game. The researchers monitored the subjects' actions. The 
subjects were aware that they were being monitored. After the subjects finished playing, they were asked 
to fill in the questionnaire. During the observation the researchers monitored the users' reactions to 
the game, paying special attention to (1) the total playing time per player; (2) if the players ever 
got stuck with the program; (3) players' movements along the exposition; (4) the players' general reactions 
to the game. The questionnaire consisted of nine questions in four sections. In section I, the focus 
was to detect which element was the most important reason for the subjects to finish the game. The questions 
were based on the elements suggested by Malone's [10] research outcomes (challenge, fantasy and curiosity). 
We added the fourth element, personal control, to discover how important having a control over the game 
was for the player. Section II focused on what the players learnt indirectly from the festival through 
the game. Section III sought to measure the game experience and the game itself, while section IV attempted 
to measure the usage and perception of mobile technology as a pervasive game controller. In this paper 
we focus on reporting the findings of the sections I and IV. The sections consisted of statements or 
questions. Statements were presented with four alternatives: strongly agree, agree, disagree, and strongly 
disagree. The four statements for the section I were: Rate the reasons for completing the game I wanted 
to know what happens next (curiosity)  I wanted to win (challenge)  I wanted to be in charge of what 
was happening (personal control)  I liked to pretend that I was an "agent" (fantasy)  The three statements 
and the question for the section IV were as follows: It was easy to use the phone as a tool for playing 
 The icons were easy to understand  It was fun to play with the phone  What were your major problems 
with the phone?   5. RESEARCH FINDINGS 5.1 Observations We noticed that the players' pace and concentration 
differed significantly. However, specific connections to players' age or gender and their behaviour were 
not perceived. We observed that towards the end of the game the subjects began to resolve the questions 
faster and with more confidence, moving smoothly around the game area, as they began to see to which 
concepts they should pay attention. We also noticed that adult players in particular stopped occasionally 
to observe a stand or to talk with another person, thus leaving the game waiting. After a while these 
players resumed the game. It was interesting to notice that children often teamed up with their parents 
to solve enigmas. Both parents and children seemed to enjoy the game; the children were primarily in 
control but they asked help from their parents if they met a challenge. Another observation was that 
a group of friends often shared a phone to play together as a team. In addition, we could witness another 
kind of team play when two girls, both having their own mobile device to play with, started playing together 
despite the different sets of enigmas. These girls seemed to know each other before the game play. Even 
though the game offered a multiplayer feature as a form of help requesting, it was not used. This was 
probably due to fact that the feature was placed in the help menu of the program, thus being hidden from 
normal game play.  5.2 Questionnaire The purpose of section I in the questionnaire was to identify which 
element was the major reason for the players to finish the game. The results are shown in Table 2. For 
each question, the player should select one option between Strongly Agree (SA), Agree (A), Disagree (D), 
Strongly Disagree (SD). The option of no answer (NA) was not given to the player. However, for the visualization 
of the information it was added to the table. Table 2. Results of the questionnaire section I. Question 
SA A D SD NA I wanted to know what happens next 4 35 3 2 1 I wanted to win 4 20 6 2 3 I wanted tobeincharged 
of what was happening 4 23 12 1 5 I like to pretend that I was and agent 11 15 12 4 3 Graphical representation 
of the results to the section I is shown in Figure 4.  Table 3. Results of the questionnaire section 
IV Question SA A D SD NA It was easy to use the phone as a tool for playing 15 18 8 1 3 The icons were 
easy to understand 15 25 1 1 3 It was fun to play with the phone 17 25 1 0 2  Figure 5. Technology feedback 
The last question of the section IV was an open question: what were your major problems with the phone? 
From the gathered information, we distinguished patterns according to similarities and differences of 
the answers [5]. Based on the patterns, we categorised the problems, as shown in Table 4. Table 4. Major 
problems with mobile phone Problem Frequency Slow response 7 Connectivity problems (network) 9 Problem 
taking the photos 15 Keyboard (the physical keyboard of the phone) 8 Hardware (mobile phone itself as 
a whole) 2 Language 1 Starting 1 Pop-up windows 1 No problems reported 14 Looking for a clearer understanding 
if the motives that players selected for finishing the game (curiosity, challenge, fantasy and control) 
are dependent of each other or not, an inferential statistical analysis was performed. According to a 
chi-square test for independence algorithm [11], we compared all the categories pairwise. The results 
of this analysis assure us that each criteria is independent of each other.   6. DISCUSSION We noticed 
that even though the subjects did not have previous experience playing this type of game they were willing 
to try SciMyst. Although we do not know the reason for not invoking the collaborative help feature, the 
lack of its use suggests that it is important to build the user interface as intuitive as possible. Furthermore, 
the collaborative help should be integrated firmly to the normal game play rather than keep it hidden 
under the help menu. During the observation we noticed two interesting aspects: (1) players often stopped 
playing in order to receive more information from exhibitors, and (2) players often teamed up with their 
friends and family to solve the enigmas together. This is a clear indicator that the main idea of SciMyst 
to have the visitors interact more with the exhibition was realized. In addition, it suggests that the 
use of the common environment as a playground seems to be a path for the social interaction of different 
types of players playing at the same time. According to Table 2, the main driving force for finishing 
the game was curiosity followed by challenge. After the statistical analysis, we know that these four 
criteria are independent of each other. This result might be due to the fact that SciMyst was played 
through different areas with unpredictable questions and tasks. Another possibility is that the game 
was new for them, or that new mobile devices naturally can catch people's interest. We suggest that a 
further study on the possible ways to motivate players to finalize this type of games can give more detailed 
answers. In Table 3 the overall results for the UI are favourable. However, in further studies the intuitiveness 
of the user interface should be properly measured and improved according to the results. Regarding the 
adoption of the technology, the use of mobile phones as a play tool is considered fun and they are easy 
to use, receiving high acceptance among the participants. Nevertheless, according to Table 4, in order 
to enhance the game experience with this type of technology some improvements should be made. Firstly, 
the tag recognition system should be improved or a better alternative should be discovered. Secondly, 
the network stability should be increased. An alternative system for tagging could be RFID (Radio-Frequency 
Identification) or NFC (Near Field Communication) technologies which might be available in mobile devices 
on a larger scale within a few years. Better network stability can be achieved by using high quality 
access points and stable mobile devices. As a consequence of resolving the two previous points, the problem 
of slow response might be solved as well. The challenge regarding the physical keyboard affects the UI 
and the game experience, hence this device feature should be taken into account while considering the 
equipment. None of the feedback we received or the observations we made suggest that there was any fear 
towards the familiar mobile phones used as play tools. Therefore we conclude that our initial assumption 
that mobile phones are nowadays so common and well accepted that using them for playing allows the players 
to concentrate more on the game without having to pay any special attention to the play tool itself. 
For this reason a mobile phone as a play tool or controller in pervasive gaming has significant potential. 
After the observation of the 45 participants, there is a clear need to reanalyze and improve the game 
design and user interface for successful multiplayer and collaboration experience. From our experience 
with developing SciMyst, we can say that the design of a serious mobile game with pervasive characteristics 
nowadays needs to incorporate knowledge from very different areas such as technology, education, aesthetics, 
game studies and usability. It is difficult to implement a tool without emphasising some of these areas 
at the cost of others. We reinforce the knowledge that it is difficult, but not impossible, and it can 
be an arena where game designers and instructional designers can join their efforts. Combining these 
aspects and paying attention to all of them at the same time complicates the design and implementation 
task immensely. 7. CONCLUSIONS A definitive answer to the question how one can trigger the interest 
of different individuals of different ages towards the reflection and understanding of the knowledge 
surrounding them, and to encourage them to collaborate in the process, cannot be given at this moment. 
However, our experiences with SciMyst suggest that the rise of curiosity on this type of games is an 
important factor in order to keep different users playing. Taking advantage of the environment's information 
content is already one way to trigger the curiosity in the game. Furthermore, our experience also shows 
that proper content creation embedded in the environment in combination with the players' curiosity and 
desire to win, guides them to give attention to the content of the festival. In addition to curiosity, 
challenge offered by the game play was considered an important element for completing the game. Results 
of this experience suggest as well that the overall usability and operation of SciMyst was good. We received 
valuable feedback for improving the game further. Moreover, the use of the common environment as a playground 
seems to be a unifying factor between different types of players. To investigate deeper for an answer 
of the research question of this paper, the results of our experiences raise other questions for further 
research such as: How are the curiosity and the challenge related? How can we enhance informal learning 
with pervasive mobile applications, including games? What is the role of technology in this informal 
learning process during an enjoyable game experience? For the future we intend to continue developing 
and testing SciMyst in different environments. The remaining two sections of the questionnaire will be 
analysed in future publications as well. In order to discover the effects of cultural differences we 
intend to set up the game setting in other countries besides Finland. One further challenge is also to 
establish a real time pervasive game between two distant locations. 8. ACKNOWLEDGMENTS SciMyst would 
not be possible without the hard work of all the developers. Special thanks go to Ekaterina Kuts, Laura 
Cheptegei, Alvaro Muñoz, Alex Casado and Ahmed Hashim. An important amount of support has been offered 
by Riku Suomela, who trained us with MUPE and offered us his expertise and opinions. Thanks also go to 
Georgina Schweikert-Islas for her graphic design support, and last but not least professor Johannes Cronje 
for his valuable assistance on the creation of the questionnaire.  9. REFERENCES [1] Alessi, S. and 
Trollip, S.(2001). Multimedia for Learning Methods and Development. 3th ed. Ed. Allyn and Bacon. [2] 
Becker, K. (2006). Design Paradox: Instructional Games. In Future Play conference proceedings. (Ontario, 
Canada), [3] Brodbeck, D. (2006). How Can Experimental Psychology Inform Game Design?. In Future Play 
conference proceedings. (Ontario, Canada). [4] Chalmers, M.; et al. Gaming on the Edge: Seams in Pervasive 
Games. In PerGames 2005 proceedings (Munich, Germany), pages 11-18. [5] Cohen, L. and Manion L.(1990) 
Research Methods in Education. 3rd.Edition.Ed. Routledge, NY, USA. [6] de Souza e Silva, A. and Delacruz, 
G. Hybrid Reality (2006) Games Reframed: Potential Uses in Educational Contexts. SAGE Publications. Games 
and Culture Vol. 1, 231-251. [7] Helms, N. and Hundelbøl, J. (2006) Pervasive Learning Environments. 
In Proceedings of Society for Information Technology and Teacher Education International Conference. 
(Orlando, Florida, USA). [8] Holleis, P.; et al. Playing with the Real World. In PerGames 2005 proceedings 
(Munich, Germany), pages 43-50. [9] IPerG. URL: http://www.pervasive-gaming.org Last view: February 20th, 
2007 [10] Malone,T. (1980). What makes things fun to learn? A study of intrinsically motivating computer 
games. Cognitive and Instructional Sciences Series CIS-7 (SSL-80-11). Pslo Alto, CA: XEROX Palo Alto 
Research Center. [11] Moses, L. (1986). Think and Explain with Statistics. Ed. Addison-Wesley. [12] Paelke, 
V.; et al. Vision-Based Interaction -A first Glance at Plazing MR GAmes in the REal-World Around Us. 
In PerGames 2005 proceedings (Munich, Germany), pages 92­ 97. [13] Pervasive Learning. URL: http://www.pervasivelearning.org 
Last view: February 20th, 2007 [14] Resnick, M. (2006). Computer as Paint Brush: Technology, Play and 
the Creative Society. In Singer, D., Golikoff, R., and Hirsh-Pasek, K. (eds.), Play = Learning: How play 
motivates and enhances children's cognitive and social­emotional growth. Oxford University Press. [15] 
Salen, K. and Zimmerman, E. (2003). Rules of Play: Game Design Fundamentals. MIT Press. [16] Semacode. 
URL:http://semacode.org/ Last view: March 16th, 2007 [17] SciFest. URL: http://www.scifest.fi Last view: 
February 20th, 2007 [18] SciMyst, URL: http://www.SciMyst.fi Last view: September 20th, 2007.  Tourists.In 
PerGames 2006 proceedings (Dublin, Irland), pages 151-158. [19] Siobhán, T. (2006) Pervasive learning 
games: Explorations of hybrid educational gamescapes. SAGE Publications. Simulation &#38; Gaming, Vol. 
37, No. 1, 41-55 (2006) [20] Walz, Steffen; et al. Cell Spell-Casting: Designing a Locative and Gesture 
Recognition Multiplayer Smartphone Game for   
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2007</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	</section>
	<section>
		<section_id>1328212</section_id>
		<sort_key>100</sort_key>
		<section_seq_no>3</section_seq_no>
		<section_type>SESSION</section_type>
		<section_title><![CDATA[Graphics, visual techniques, and sound in games (part 1)]]></section_title>
		<section_page_from>54</section_page_from>
	<article_rec>
		<article_id>1328213</article_id>
		<sort_key>110</sort_key>
		<display_label>Pages</display_label>
		<pages>7</pages>
		<article_publication_date>11-14-2007</article_publication_date>
		<seq_no>1</seq_no>
		<title><![CDATA[The virtual window simulator]]></title>
		<page_from>54</page_from>
		<page_to>60</page_to>
		<doi_number>10.1145/1328202.1328213</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1328213</url>
		<abstract>
			<par><![CDATA[<p>Most virtual reality systems offer the option of viewing the space using a head mounted display or a head coupled display. These can provide a comfortable way of providing a 3D display while detecting head motion and using that to change the viewing position and angle. However, head mounted displays typically have limited resolution, can create neck and eye strain, and can create user disorientation. Head coupled displays, where the display is usually projected onto a screen and the head mount is used for 3D and orientation only, are now a focus of attention in research and in production systems. They are used in, and in fact have spurred the development of, systems like the <i>CAVE, Immersadesk</i>, and <i>IWall</i> to name just three. However, their use is limited by their high cost, fixed nature, and space requirements, and a focus of research is on making head-coupled displays more easily usable and less expensive. The <i>VirtualWindow</i> project is a simulation of a head-coupled display that can be used to develop software for such systems without the expense of owning one, or at least without using the very expensive space. The simulator uses two webcams to perform 3D head tracking rather than instrumenting the user, and provides a set of useful operations that enhance the development and the viewing experience.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[graphics]]></kw>
			<kw><![CDATA[video gameo]]></kw>
			<kw><![CDATA[virtual reality]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.7</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010226.10010239</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Image and video acquisition->3D imaging</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010226.10010239</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Image and video acquisition->3D imaging</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Human Factors</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P925232</person_id>
				<author_profile_id><![CDATA[81342507425]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Eric]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Penner]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Calgary]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP43124683</person_id>
				<author_profile_id><![CDATA[81321496403]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[J.]]></first_name>
				<middle_name><![CDATA[R.]]></middle_name>
				<last_name><![CDATA[Parker]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Calgary]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Intel OpenCV library http://www.intel.com/research/mrl/research/opencv/.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>515322</ref_obj_id>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Edward Angel, &#60;b&#62;Interactive Computer Graphics&#60;/b&#62;, Addison Wesley, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>134039</ref_obj_id>
				<ref_obj_pid>133994</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Michael Deering, &#60;b&#62;High Resolution Virtual Reality&#60;/b&#62;, <i>Proc. 19th annual conference on Computer Graphics and Interactive Techniques</i>, pp 195--202, 1992.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>903929</ref_obj_id>
				<ref_obj_pid>903893</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Kiran J. Fernandes, V. Raja, and J. Eyre, &#60;b&#62;Cybersphere: The Fully Immersive Spherical Projection System&#60;/b&#62;, <i>CACM</i> 46 (9) pp141--146, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>846312</ref_obj_id>
				<ref_obj_pid>846276</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[I. Guskov, S. Klianov, and B. Bryany, &#60;b&#62;Trackable Surfaces&#60;/b&#62;, <i>Proc. SIGGRAPH/Eurographics Symposium on Computer Animation</i>, pp. 251--257, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>769974</ref_obj_id>
				<ref_obj_pid>769953</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[A. Hogue, M. Robinson, M. Jenkin, and R. Allison, &#60;b&#62;A Vision-Based Head Tracking System for Fully Immersive Displays&#60;/b&#62;, <i>Proc. of the Workshop on Virtual Environments</i>, pp. 179--187, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>569017</ref_obj_id>
				<ref_obj_pid>569005</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Qiang Ji and Zhiwei Zhu, Eye and &#60;b&#62;Gaze Tracking for Interactive Graphic Display&#60;/b&#62;, <i>Proc. 2nd Int. Symposium on Smart Graphics</i>, pp. 79--85, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>765894</ref_obj_id>
				<ref_obj_pid>765891</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[T. Konrad, D. Demirdjian, and T. Darrell, &#60;b&#62;Gesture + Play: Full Body Interaction for Virtual Environments&#60;/b&#62;, <i>Proc CHI'03</i>, pp 620--621, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>237289</ref_obj_id>
				<ref_obj_pid>237170</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Ed Lantz, &#60;b&#62;The Future of Virtual Reality: Head Mounted Displays versus Spatially Immersive Displays&#60;/b&#62; (Panel), <i>Proc. 23 Annual Conf. on Computer Graphics and Interactive Techniques</i>, pp. 485--486, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>566607</ref_obj_id>
				<ref_obj_pid>566570</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[J. Lee et. al., &#60;b&#62;Interactive Control of Avatars Animated With Human Motion Data&#60;/b&#62;, <i>Proc. 29 Annual Conf. on Computer Graphics and Interactive Techniques</i>, pp. 491--500, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>507109</ref_obj_id>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Eric Lengyel, &#60;b&#62;Mathematics for 3D Game Programming and Computer Graphics&#60;/b&#62;, Charles River Media, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>594357</ref_obj_id>
				<ref_obj_pid>594351</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Diego Lopez de Ipina, Paulo R. S. Mendonca, and Andy Hopper, &#60;b&#62;Trip: A Low-cost Vision based location system for Ubiquitous Computing&#60;/b&#62;, <i>Personal Ubiquitous Computing</i>, 6(3), pp. 206--219, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>769978</ref_obj_id>
				<ref_obj_pid>769953</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[J. D. Mulder, J. Jansen, and A. van Rhijn, &#60;b&#62;An Affodable Optical Head Tracking System for Desktop VR/AR Systems&#60;/b&#62;, <i>Proc. Workshop on Virtual Environaments</i>, pp. 215--233, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>835777</ref_obj_id>
				<ref_obj_pid>832288</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[J. D. Mulder and Robert van Liere, &#60;b&#62;Enhancing Fish Tank VR&#60;/b&#62;, <i>Virtual Reality</i>, pp. 91--98, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Woo Neider and Davis Shreiner, OpenGL Programming Guide (3rd Ed.), Addison Wesley, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>558008</ref_obj_id>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Linda Shapiro and G. C. Stockman, &#60;b&#62;Computer Vision&#60;/b&#62;, Prentice-Hall, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>237282</ref_obj_id>
				<ref_obj_pid>237170</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Andrei State, G. Hirota, D. Chen, W. Garrett, and M. Livingston, &#60;b&#62;Superior Augmented Reality Registration by Integrating Landmark Tracking and Magnetic Tracking&#60;/b&#62;, <i>23 Annual Conf. on Computer Graphics and Interactive Techniques</i>, pp. 429--438, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Alexander Stevenson, &#60;b&#62;Calibrating Head Coupled Virtual Reality Systems&#60;/b&#62;, Masters thesis, The University of British Columbia, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>513884</ref_obj_id>
				<ref_obj_pid>513867</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Henrik Tramberend, &#60;b&#62;A Display Device Abstraction for Virtual Reality Applications&#60;/b&#62;, <i>Proc. 1st Int. Conf. on Computer Graphics, Virtual Reality, and Visualization</i>, pp. 75--80, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>169066</ref_obj_id>
				<ref_obj_pid>169059</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Colin Ware, Kevin Arthur, and Kellogg S. Booth, &#60;b&#62;Fish Tank Virtual Reality&#60;/b&#62;, <i>Proc. CHI'93</i>, pp. 37--42, 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>234975</ref_obj_id>
				<ref_obj_pid>234972</ref_obj_pid>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Colin Ware and Glen Franck, &#60;b&#62;Evaluating Stereo and Motion Cues for Visualizing Information Nets in Three Dimensions&#60;/b&#62;, <i>ACM Transactions on Graphics</i>, 15(2), pp. 121--140, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>311587</ref_obj_id>
				<ref_obj_pid>311535</ref_obj_pid>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Zachary Wartell, L. F. Hodges, and William Ribarsky, &#60;b&#62;Balancing Fusion, Image Depth, and Distortion in Stereoscopic Head-Tracked Displays&#60;/b&#62;, <i>Proc. 26th Annual Conference on Computer Graphics and Interactive Techniques</i>, pp. 351--358, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>215650</ref_obj_id>
				<ref_obj_pid>215585</ref_obj_pid>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[Jiann-Rong Wu and Ming Ouhyoung, &#60;b&#62;A 3D Tracking Experiment on Latency and its Compensation Methods in Virtual Environments&#60;/b&#62;, <i>Proc. 8th Annual ACM Symposium on User Interface and Software Technology</i>, pp. 41--49, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>507100</ref_obj_id>
				<ref_obj_pid>507072</ref_obj_pid>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[Zhiwei Zhu, Kikuo Fujimura, and Qiang Ji, &#60;b&#62;Real Time Eye Detection and Tracking Under Various Light Conditions&#60;/b&#62;, <i>Proc. Symposium on ETRA 2002</i>, pp. 139--144, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 The Virtual Window Simulator Eric Penner and J. R. Parker Digital Media LaboratoryUniversity of Calgary403 
220 6784 ABSTRACT Most virtual reality systems offer the option of viewing the .play. These can provide 
a comfortable way of providing a 3D display while detecting head motion and using that to change the 
viewing position and angle. However, head .ate neck and eye strain, and can create user disorientation. 
.jected onto a screen and the head mount is used for 3D and orientation only, are now a focus of attention 
in research and in production systems. They are used in, and in fact have spurred the development of, 
systems like the CAVE, Immersadesk, and IWall to name just three. However, their use is limited by their 
high cost, fixed nature, and space requirements, and a focus of research is on making head­coupled displays 
more easily usable and less expensive. The VirtualWindow.pled display that can be used to develop software 
for such systems without the expense of owning one, or at least without using the very expensive space. 
The simulator uses two webcams to perform 3D head tracking rather than ..ence. Categories and Subject 
Descriptors I.3.7 Three-Dimensional Graphics and Realism   General Terms Algorithms, Human Factors 
 Keywords Video gameo, graphics, virtual reality. 1. INTRODUCTION In the past ten years a significant 
amount of work has been .mented Reality (AR)[17] systems. VR/AR systems have existed for many years, 
but only relatively recently has the technology reached the stage where it is effective. The Permission 
to make digital or hard copies of all or part of this work for personal or classroom use is granted without 
fee pro­vided that copies are not made or distributed for profit or commer­cial advantage and that copies 
bear this notice and the full citation on the first page. To copy otherwise, or republish, to post on 
serv­ers or to redistribute to lists, requires prior specific permission and/or a fee. FuturePlay 2007, 
November 15-17, 2007, Toronto, Ontario. Copyright 2007 ACM 978-1-59593-943-2/07/0011...$5.00 required 
technologies include haptic (touch) feedback, high .plays or head coupled displays. A head mounted display 
(HMD) is a system with two screens which are small video displays that are placed over the user s eyes. 
Often a head tracking system is attached to the HMD so that head movements, both up/down and left/ right, 
can be noted and used to update the view frustrum [13,22,23]. An HMD offers an immersive experience, 
but the resolution leaves something to be desired, and neck and eye strain are frequent side effects. 
User disorientation can also be a problem, because while the display shows what appears to be motion, 
the user s inner ear tells the brain that no motion is occurring. This kind of sensory discrepancy is 
.ably enough tells the stomach to become empty. The result is uncomfortable. Head coupled displays (HAD 
s, or fish tank displays [14,20], or head tracked displays) consist of one or more large stationary displays 
linked to a head or eye tracking device [7,24]. The view on the screens varies as the user s head orientation. 
The displayed virtual space can extend both in front of and behind the physical display surface. Head 
coupling has been shown to be quite useful for real .cial products such as the CAVE, IWall, and Immersadesk 
are available off the shelf [4]. In spite of this, there are few such systems in actual use due to the 
prohibitive costs associated with the installations and their operation. In a typical CAVE application, 
as just one example, a single bulb for one projector (of perhaps 4) costs upwards of $6000. A goal of 
the work here is to create a basic HCD simulation and development environment and to design and test 
an inexpensive instantiation that uses .tion. Finally we will develop and demonstrate rendering software 
and show the final effect used to play a 3D driving game.  2. RELATED WORK The display technology for 
both graphics and sound has improved quite a bit over the past 10-12 years, and this has enabled the 
development of useful and practical VR and AR systems. For example, small video cameras (webcams) can 
now be purchased for as little as $20, high fidelity 7.1 channel audio systems are easily available, 
and even digital projectors are becoming within the price range of a family. Some development work on 
low-cost VR systems has already been completed.  2.1. Webcam Based Tracking Systems A webcam typically 
has a resolution of 640x480 pixels and ..cessful work on the use of two webcams to perform tracking in 
three dimensions [12,21]. This is normally accomplished by identifying landmarks or feature points with 
the images captured by each camera. Assuming that both cameras are directed towards the same target and 
that they are a known distance apart, the corresponding points in the two images are identified. The 
points in the 2D images actual represent a possible line in 3D space, and the intersection of the two 
lines determines the 3D position of the feature point. Why do we wish to do this? The webcam pair can 
be used to track the motions of the user s head in real time, and thereby determine its position and 
orientation. This process is not a fast as the use of more advanced tracking methods, but is much cheaper 
and does not require that the user be instrumented. Lag times as small as 60 ms have been reported using 
this technology [6,16]. 2.2. Single Display Systems .vantage of allowing the user s field of view to 
contain other objects in addition to those being controlled and displayed .gle display also limits the 
ability of the system to display objects that lie in front of the display screen s surface. When an object, 
which should be in front of the display, is .ceived as though it were behind the display. To make this 
problem worse, if stereo display and vision methods are being used, the object is occluded to a different 
degree by each eye. This results in visual interpretations that can be distracting. .ception problems: 
Cadre viewing and tunnel viewing. Both ensure that an invalid stereo pair is never used to generate displayed 
pixels. The Cadre viewing scheme uses an opaque rectangle (the cadre) placed in front of each eye to 
to obstruct parts of the scene that the other eye can t see. When using tunnel viewing, a cylinder is 
placed so that one end is placed in front of the display, and the other end is behind the display. The 
cylinder wall (the tunnel) us used as a clipping surface so that essentially the same view will be presented 
to each eye. Both of these techniques correct the problems associated with displaying 3D objects with 
correct perspective, but seem awkward and artificial. In both cases the field of view is reduced, and 
both eyes can t see the same amount of the object.  3. OFF AXIS VIEWING A standard projection matrix 
used in a 3D perspective transformation presumes that the viewer is positioned directly in front of the 
display some specified distance [2,11]. This matrix works properly so long as the viewer stays in the 
same position, but if they move then the image becomes distorted relative to the true perspective transform. 
All head coupled displays use a custom projection matrix which is determined for each frame using the 
position of the viewer s eye and the position of the display screen. Building the projection matrix in 
this way frequently results in a view frustrum that is not symmetric. Non-symmetric frustra are called 
off-axis projections. .ated using standard graphics libraries. When using OpenGL [15], the normal way 
to specify a frustrum is with the glFrustrum procedure, in which the near and far clipping ..sect the 
near plane. If we temporarily choose the near .ters to glFrustrum can be computed as: 1. Determine an 
orthonormal basis for the display screen .  2. Calculate the vector that runs from the location of the 
eye to the bottom left corner of the display. The projected length of this vector onto the X, Y, and 
Z axes of the basis .tively.  Figure 2: Calculating an orthonormal basis for the display.  3. The 
right and top clipping planes are found by adding the .dinates, respectively. 4. To use an arbitrarily 
placed near clipping plane, scale the left, right, top, and bottom values by the ratio of the new clipping 
plane to the old one. 5. .tance than the near plane.  4. THE VIRTUAL WINDOW SIMULATOR Now that the 
off axis projection matrix can be determined .dow system and simulator can be constructed. This will 
permit off-line software development for VR systems in ..tion provides virtual (emulated) capabilities 
associated with the target system. It is much cheaper than using the actual system, and has debugging 
advantages too. The VirtualWindow Simulator is a flexible HCD simulation that is independent of specific 
hardware. It can be used to .sen for each display and to write fully functional software for real HCD 
systems without the need for special head tracking equipment or other special purpose devices. The mouse 
is used to view the display from different angles as if their head was moving around the display [5]. 
4.1. Display Specification Since head coupled display systems can have between one and six physical displays 
of any size and orientation, it is important to have a flexible way to specify the properties of .fication. 
It is also useful to have a 3D model of the displays being simulated so as to give a clear sense of what 
is being ..mat. OBJ files are normally used to describe a model of a 3D object to a graphics display 
program like a video game. The extension we have made allows displays to be speci.fied too. A display 
is simply described as a face, but has no .  4.2. Simulating Displays A useful simulation of a head 
coupled display would permit the virtual displays to be viewed from arbitrary angles, so ..dered correctly 
in 3D space. We do this by rendering each display onto a 2D texture which is then mapped onto a polygon 
in the 3D scene. Other techniques will certainly work, but the texture is very useful for verifying that 
the off-axis projection is correct. Using OpenGL.lowed by a call to glCopyTexImage2D. This call copies 
the frame buffer into the texture, following which it can be mapped onto the display in 3D. With head-coupling 
  v -0.5 0.5 -0.5 v 0.5 0.5 -0.5  . . . f 1 2 3 f 2 1 4 f 2 4 5 f 2 5 6 . . . display 1 2 3 4 display 
5 6 7 8 Figure 3: Example display specification file. enabled the texture is updated every frame, maintaining 
the 3D illusion in the simulator. 5. HEAD COUPLED DISPLAY ENHANCEMENTS When using a single display HCD, 
there are some problems that don t occur with multiple display systems. Most of these problems occur 
at the edges of the screen display. One such problem is the distortions created when an object in front 
of the display is occluded by the screen edge. This results in a conflict of the depth cues used to compute 
3D position, and results in the object looking as if it is behind the display. If a stereoscopic display 
is in use the problem becomes more severe since it results in an invalid pair of stereo images, and they 
won t be fused by the human visual system into a 3D scene. Indeed, these can cause headaches. In order 
to test the VirtualWindow simulator, a new tech.nique has been developed for use in the simulator to 
correct these problems. It is called frustrum capping.   5.1. Frustrum Capping The theory of frustrum 
capping is fairly simple. Instead of trying to use one or both eyes to correct the stereo image, the 
object itself is chopped off or clipped so that each eye can see the same amount of the object. This 
is done by using four clipping planes that start at the four edges that bound the display and converge 
at a point that lies within the frustra created by each eye. .ducing a new one: the user can now see 
inside of the object. To fix this we simply place a small plane, or cap, over the hole in the object. 
The stencil buffer is used to count the number of front facing and back facing polygons drawn. If the 
number of back facing polygons is greater than the number of front facing ones then the object is exposed 
there, and the cap can be drawn at that specific pixel. 5.2. Screen Veil Depth Cue A problem common 
to all VR systems is conflicting depth queues. The human visual system and associate perception modules 
have many systems in place that judge the size and ..tion, or at the very least in a less immersive experience. 
Possibly the most difficult depth cue to simulate is how the visual system accommodates.ent distances. 
Traditional VR systems tend to display all objects at a constant distance from the viewer with respect 
to focus (I.E. at the display surface) No VR hardware has yet been devised that can simulate this phenomenon 
even approximately, and so all systems must simply work around . A combination of accommodation and 
knowledge of the screen s position can cause an additional difficulty on HCDs. When an object is determined 
to be in front of the display it gets projected back onto the display surface .tion depth cue has conflicting 
(opposing, in fact) the other depth cues. In particular, where the object should be getting closer to 
the viewer, accommodation suggests that it is actually getting further away. Our way of compensating 
for this problem is to render a semi-transparent set of object pixels is rendered in the 3D scene that 
represents the display surface. The parts of an object that lie in front of the display will protrude 
through this surface, or veil, providing the user with another cue that helps determine the object s 
location. This does not fix .forcement (Figure 7)  5.3. Simulating Tracker Lag A major problem with 
head coupled displays is the issue of 3D tracker lag. HCD function relies heavily on knowing the correct 
location of the viewer s head, and any time delay involved in the tracking hardware will result in an 
incorrect perspective view to be displayed whenever they move, at least for a few moments.Too much lag 
results in the objects appearing to stretch as the user moves, and can cause eye strain and even nausea. 
Since tracker lag is a key issue for all HCD systems, it is important to understand its effects when 
building such a .dow simulator allows the specification of an arbitrary degree of tracker lag. To enable 
this, the user s input is Figure 6: On the left is the projection of an object onto the display. Right, 
the intended depth cue is shown beside the cue that is created by the VR system by projecting backwards. 
  .ics are played back subject to the specified lag. This has been shown to be useful in understanding 
lag effects on users and in determining the bounds for the amount of lag that is acceptable in the final 
(real) system. Our own experi.ence has shown that 50 ms of lag is quite acceptable, while 100 ms causes 
noticeable problems and more than 200 ms is unacceptable.  6. VIRTUALWINDOW IMPLEMENTATION .tem relies 
heavily on a 3D tracker that can quickly and accurately track the location of the user s head. Most sys..netic 
or acoustic trackers for this task. With the recent release of inexpensive webcams having high resolution, 
3D tracking using two of these devices is now a cheap possibil..pensive, this is the tracker that is 
used. .nents needed to build a basic 3D tracker. Unfortunately this .sor time for everything else. Thus, 
we used a software wrapper that permitted the tracker to run on a different computer on a local network. 
The 3D tracker works by first calibrating the cameras [18] .bration), then determines a camera matrix 
that maps world .era matrix is calculated using a least squares solution from numerous points on a fixed 
calibration pattern. Once the camera matrix has been computed, a ray can be found for any given 2D image 
point by using two depth values and solving for two 3D points. Determining 3D position of an object then 
involves simply finding the point of intersection (or closest approach) of the two rays.  7. TEST CASE 
- VIDEO GAMES AND FLIGHT/DRIVING SIMULATORS After the VirtualWindow simulator was built, we used a simple 
3D object viewer as a test of functionality.; close-up inspection of 3D objects is a common use for VR 
systems. The VirtualWindow system and simulator was the basis for the extension of a 3D car driving game, 
PrimeTime, which was written in C++ and designed and implemented by a team that included the authors. 
Computer games and flight/driving simulators usually allow the player to look in the direction of motion. 
Looking out of a side or rear window while trying to drive forward is confusing, and the player quickly 
loses track of where thay are looking relative to where they are steering. Using the VirtualWindow system 
we can permit the player to look around in a much more natural way (. moving their head, the player can 
look left or right while not changing the relative apparent motion of the other objects in the virtual 
world. The player is also able to keep track of their view into the world by seeing where their head 
is relative to the screen. This is quite analogous to the .dow [10]. .plished in two stages. First, the 
VirtualWindow simulator was ported from OpenGL into DirectX, which allowed the . The controls of the 
game did not change, but now the mouse was used to control the simulator. Moving from the simulator to 
the real VirtualWindow system was quite easy, since most of the issues were ironed out in the simulator 
first (.    8. CONCLUSION A collection of techniques have been presented that, it is hoped, could 
enable the more widespread use of head cou­pled displays. Specifically, the VirtualWindow simulator can 
be used to develop software for HCDs in the absence of a real system, and the VirtualWindow system is 
an inexpen­sive HCD for end users. New methods, such as frustrum capping and the display veil allow single 
display systems to be more accurate and give a more immersive effect. Together, these tools and techniques 
should allow for an ease of development and a smaller cost that could allow such systems to be used in 
homes and schools. 9. REFERENCES [1] Intel OpenCV library http://www.intel.com/research/ mrl/research/opencv/. 
[2] Edward Angel, Interactive Computer Graphics, Add­ison Wesley, 2003. [3] Michael Deering, High Resolution 
Virtual Reality, Proc. 19th annual conference on Computer Graphics and Interactive Techniques, pp 195-202, 
1992. [4] Kiran J. Fernandes, V. Raja, and J. Eyre, Cybersphere: The Fully Immersive Spherical Projection 
System, CACM 46 (9) pp141-146, 2003. [5] I. Guskov, S. Klianov, and B. Bryany, Trackable Sur­faces, Proc. 
SIGGRAPH/Eurographics Symposium on Computer Animation, pp. 251-257, 2003. [6] A. Hogue, M. Robinson, 
M. Jenkin, and R. Allison, A Vision-Based Head Tracking System for Fully Immersive Displays, Proc. of 
the Workshop on Virtual Environments, pp. 179-187, 2003. [7] Qiang Ji and Zhiwei Zhu, Eye and Gaze Tracking 
for Interactive Graphic Display, Proc. 2nd Int. Sympo­sium on Smart Graphics, pp. 79-85, 2002. [8] T. 
Konrad, D. Demirdjian, and T. Darrell, Gesture + Play: Full Body Interaction for Virtual Environ­ments, 
Proc CHI 03, pp 620-621, 2003. [9] Ed Lantz, The Future of Virtual Reality: Head Mounted Displays versus 
Spatially Immersive Dis­plays (Panel), Proc. 23 Annual Conf. on Computer Graphics and Interactive Techniques, 
pp. 485-486, 1996. [10]J. Lee et. al., Interactive Control of Avatars Ani­mated With Human Motion Data, 
Proc. 29 Annual Conf. on Computer Graphics and Interactive Tech­niques, pp. 491-500, 2002. [11]Eric Lengyel, 
Mathematics for 3D Game Program­ming and Computer Graphics, Charles River Media, 2002. [12]Diego Lopez 
de Ipina, Paulo R.S. Mendonca, and Andy Hopper, Trip: A Low-cost Vision based location sys­tem for Ubiquitous 
Computing, Personal Ubiquitous Computing, 6(3), pp. 206-219, 2002. [13]J.D. Mulder, J. Jansen, and A. 
van Rhijn, An Affod­able Optical Head Tracking System for Desktop VR/ AR Systems, Proc. Workshop on Virtual 
Environa­ments, pp. 215-233, 2003. [14]J.D. Mulder and Robert van Liere, Enhancing Fish Tank VR, Virtual 
Reality, pp. 91-98, 2000. [15]15.Woo Neider and Davis Shreiner, OpenGL Program­ming Guide (3rd Ed.), 
Addison Wesley, 1999. [16]Linda Shapiro and G.C. Stockman, Computer Vision, Prentice-Hall, 2001. [17]Andrei 
State, G. Hirota, D. Chen, W. Garrett, and M. Livingston, Superior Augmented Reality Registra­tion by 
Integrating Landmark Tracking and Mag­netic Tracking, 23 Annual Conf. on Computer Graphics and Interactive 
Techniques, pp. 429-438, 1996. [18]Alexander Stevenson, Calibrating Head Coupled Virtual Reality Systems, 
Masters thesis, The Univer­sity of British Columbia, 2000. [19]Henrik Tramberend, A Display Device Abstraction 
for Virtual Reality Applications, Proc. 1st Int. Conf. on Computer Graphics, Virtual Reality, and Visualiza­tion, 
pp. 75-80, 2001. [20]Colin Ware, Kevin Arthur, and Kellogg S. Booth, Fish Tank Virtual Reality, Proc. 
CHI 93, pp. 37-42, 1993. [21]Colin Ware and Glen Franck, Evaluating Stereo and Motion Cues for Visualizing 
Information Nets in Three Dimensions, ACM Transactions on Graphics, 15(2), pp. 121-140, 1996. [22]Zachary 
Wartell, L.F. Hodges, and William Ribarsky, Balancing Fusion, Image Depth, and Distortion in Stereoscopic 
Head-Tracked Displays, Proc. 26th Annual Conference on Computer Graphics and Interac­tive Techniques, 
pp. 351-358, 1999.  [23]Jiann-Rong Wu and Ming Ouhyoung, A 3D Tracking Experiment on Latency and its 
Compensation Meth­  ods in Virtual Environments, Proc. 8th Annual ACM [24]Zhiwei Zhu, Kikuo Fujimura, 
and Qiang Ji, Real Time Symposium on User Interface and Software Technology, Eye Detection and Tracking 
Under Various Light pp. 41-49, 1995. Conditions, Proc. Symposium on ETRA 2002, pp. 139­ 144, 2002.  
  
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2007</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>1328214</article_id>
		<sort_key>120</sort_key>
		<display_label>Pages</display_label>
		<pages>8</pages>
		<article_publication_date>11-14-2007</article_publication_date>
		<seq_no>2</seq_no>
		<title><![CDATA[Guidelines for 3D positioning techniques]]></title>
		<page_from>61</page_from>
		<page_to>68</page_to>
		<doi_number>10.1145/1328202.1328214</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1328214</url>
		<abstract>
			<par><![CDATA[<p>In this paper, we present a set of guidelines for designing 3D positioning techniques. These guidelines are intended for developers of object interaction schemes in 3D games, modeling packages, computer aided design systems, and virtual environments. The guidelines promote intuitive object movement techniques in these types of environments.</p> <p>We then present a study comparing 3D positioning techniques based on these guidelines with 2D and 3D/6D devices across VR display technologies. Display technologies such as stereoscopic graphics and head-coupled perspective provide additional depth cues and could affect how a user perceives and thus interacts with a 3D scene -- regardless of the input device/technique used. Thus they are examined as well. The results suggest that 2D devices using "smart" movement algorithms can outperform 3D devices.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[3D object positioning]]></kw>
			<kw><![CDATA[guidelines]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>H.5.1</cat_node>
				<descriptor>Artificial, augmented, and virtual realities</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>H.5.2</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10003120.10003121</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003121.10003124.10010866</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)->Interaction paradigms->Virtual reality</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003121.10003124.10010392</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)->Interaction paradigms->Mixed / augmented reality</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387.10010866</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces->Virtual reality</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Experimentation</gt>
			<gt>Human Factors</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P925266</person_id>
				<author_profile_id><![CDATA[81392615854]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Robert]]></first_name>
				<middle_name><![CDATA[J.]]></middle_name>
				<last_name><![CDATA[Teather]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[York University, Toronto, Ontario]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P301046</person_id>
				<author_profile_id><![CDATA[81100214718]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Wolfgang]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Stuerzlinger]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[York University, Toronto, Ontario]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>319135</ref_obj_id>
				<ref_obj_pid>319120</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[E. Bier. Skitters and Jacks: Interactive 3D Positioning Tools. In Proc. of Interactive 3D Graphics 1986, pp. 183--196, January 1987.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>261168</ref_obj_id>
				<ref_obj_pid>261135</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[J. Boritz, and K. S. Booth. A Study of Interactive 3D Point Location in a Computer Simulated Virtual Environment. In ACM VRST 1997, pp. 181--187, September 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>836115</ref_obj_id>
				<ref_obj_pid>522258</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[J. Boritz, and K. S. Booth, A Study of Interactive 6 DOF Docking in a Computerised Virtual Environment. In Proc. of the Virtual Reality Annual International Symposium, pp. 139--146, March 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>323667</ref_obj_id>
				<ref_obj_pid>323663</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[D. Bowman, D. Johnson, and L. Hodges. Testbed Evaluation of Virtual Environment Interaction Techniques. In Proc. of VRST99, pp. 26--33, December 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[H. Baradaran, W. Stuerzlinger, A Comparison of Real and Virtual 3D Construction Tools with Novice Users. In CGVR'06, pp. 10--15, June 2006.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[J. Chen, M. A. Narayan, and M. A. Perez-Quinones. "The Use of Hand-held Devices for Search Tasks in Virtual Environments," In Proc. of the IEEE Virtual Reality 2005 workshop on New Directions in 3DUI, pp. 15--18, March 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>147199</ref_obj_id>
				<ref_obj_pid>147156</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[D. Brookshire Conner, S. Snibbe, K. Hemdon, D. Robbins, R. Zeleznik, and A. van Dam. Three Dimensional Widgets. In Proc. of Symposium on Interactive 3D Graphics, June 1992.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[K. Dave, K. Dinesh. CInDeR: Collision and Interference Detection in Real-time using graphics hardware. In Proc. of Graphics Interface, pp. 73--80, May 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>229466</ref_obj_id>
				<ref_obj_pid>229459</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[M. Deering. The Holosketch VR Skething System. Communications of the ACM, 39, 5, pp. 55--61, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>174304</ref_obj_id>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[D. Diner, and D. Fender. Human Engineering in Stereoscopic Viewing Devices. Plenum Press, New York, 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>844178</ref_obj_id>
				<ref_obj_pid>844174</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[N. Govindaraju, S. Redon, M. Lin, and D. Manocha. CULLIDE: interactive collision detection between complex models in large environments using graphics hardware. SIGGRAPH Workshop on Graphics Hardware, pp. 25--32, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1166257</ref_obj_id>
				<ref_obj_pid>1166253</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[T. Grossman, and R. Balakrishnan. The Design and Evaluation of Selection Techniques for 3D Volumetric Displays. In ACM Symposium on User Interface Software and Technology 2006, pp. 3--12, 2006.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2229366</ref_obj_id>
				<ref_obj_pid>2229212</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[J. Hsu, Z. Pizlo, D. Chelberg, C. Babbs, and E. Delp. Issues in the Design of Studies to Test the Effectiveness of Stereo Imaging. In IEEE Transactions on Systems, Man and Cybernetics, Part A, 26, 6, pp. 810--819, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>302995</ref_obj_id>
				<ref_obj_pid>302979</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[R. W. Lindeman, J. L. Sibert, J. K. Hahn. Towards Usable VR: an empirical study of user interfaces for immersive virtual environments. In Proc. of CHI '99, pp. 64--71, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[S. Obayashi, T. Suhara, K. Kawabe, T. Okauchi, J. Maeda, Y. Akine, H. Onoe, and A. Iriki. Functional brain mapping of monkey tool use. NeuroImage 14, pp. 853--861, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1014173</ref_obj_id>
				<ref_obj_pid>1014167</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[J.-Y. Oh, W. Stuerzlinger. A system for desktop conceptual 3D design. In Virtual Reality 7, pp. 198--211, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1089541</ref_obj_id>
				<ref_obj_pid>1089508</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[J.-Y. Oh, W. Stuerzlinger. Moving Objects with 2D Input Devices in CAD Systems and Desktop Virtual Environments. In Proc. of Graphics Interface 2005, pp. 195--202, 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[I. Poupyrev, S. Weghorst, M. Billinghurst and T. Ichikawa, Egocentric object manipulation in virtual environments: empirical evaluation of interaction techniques. In Eurographics '98, pp 41--52, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1320072</ref_obj_id>
				<ref_obj_pid>1319726</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[B. Shneiderman. Direct manipulation: A step beyond programming languages, IEEE Computer 16, 8, pp. 57--69, 1983.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>781003</ref_obj_id>
				<ref_obj_pid>780986</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[G. Smith, T. Salzman and W. Stuerzlinger. 3D Scene Manipulation with 2D Devices and Constraints. In Graphics Interface '01, pp. 135--142, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>134089</ref_obj_id>
				<ref_obj_pid>133994</ref_obj_pid>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[P. Strauss and R. Carey. An Object-Oriented 3D Graphics Toolkit. In Proc. of SIGGRAPH 2002, pp. 341--349, July 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[W. Stuerzlinger, D. Dadgari, J.-Y. Oh. Reality-Based Object Movement Techniques for 3D, CHI 2006 Workshop: "What is the Next Generation of Human-Computer Interaction?", April 2006.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[Z. Szalav&#225;ri, M. Gervautz, The Personal Interaction Panel, A Two-Handed Interface for Augmented Reality, Eurographics '97, pp. 335--346, September 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>267136</ref_obj_id>
				<ref_obj_pid>267135</ref_obj_pid>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[C. Ware, K. Lowther. Selection Using a One-Eyed Cursor in a Fish Tank VR Environment. In ACM Transactions on Computer-Human Interaction, 4, 4, pp. 309--322, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>614518</ref_obj_id>
				<ref_obj_pid>614286</ref_obj_pid>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[Z. Wartell, L. F. Hodges, W. Ribarsky, A geometric comparison of algorithms for fusion control in stereoscopic HTDs. IEEE TVCG, 8, 129--143, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[C. Wickins, J. Hollands, Spatial displays, in Engineering psychology and human performance, Prentice-Hall 3&#60;sup&#62;rd&#60;/sup&#62; Edition, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>191822</ref_obj_id>
				<ref_obj_pid>191666</ref_obj_pid>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[S. Zhai, W. Buxton, P. Milgram. The "Silk Cursor": Investigating Transparency for 3D Target Acquisition. In Proc. of CHI '94, pp. 459--464, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Guidelines for 3D Positioning Techniques Robert J. Teather Wolfgang Stuerzlinger rteather@cse.yorku.ca 
wolfgang@cse.yorku.ca Department of Computer Science and Engineering York University Toronto, Ontario 
ABSTRACT In this paper, we present a set of guidelines for designing 3D positioning techniques. These 
guidelines are intended for developers of object interaction schemes in 3D games, modeling packages, 
computer aided design systems, and virtual environments. The guidelines promote intuitive object movement 
techniques in these types of environments. We then present a study comparing 3D positioning techniques 
based on these guidelines with 2D and 3D/6D devices across VR display technologies. Display technologies 
such as stereoscopic graphics and head-coupled perspective provide additional depth cues and could affect 
how a user perceives and thus interacts with a 3D scene regardless of the input device/technique used. 
Thus they are examined as well. The results suggest that 2D devices using smart movement algorithms can 
outperform 3D devices.  Categories and Subject Descriptors H.5.1 [Information Interfaces and Presentation]: 
Multimedia Information Systems virtual reality. H.5.2 [Information Interfaces and Presentation]: User 
Interfaces input devices, interaction styles, standardization, theory and methods. General Terms Experimentation, 
Human Factors.  Keywords 3D object positioning, guidelines. 1. INTRODUCTION To this day very few, if 
any, games support the kind of full­featured 3D object manipulation that many naïve users believe to 
be possible in VR (virtual reality) environments. This is at least in part due to the lack of suitable 
input devices as well as the lack of intuitive interaction techniques for these devices. Manipulating 
3D objects requires the handling of 6 degrees of freedom (DOFs), i.e. there are 3 axes of movement and 
3 axes of rotation for every object. A large body of VR research focuses on using 3D input devices such 
as 6DOF trackers and wands for 3D manipulation tasks. The motivation for this is that they allow the 
user to Permission to make digital/hard copy of part of this work for personal or classroom use is granted 
without fee provided that the copies are not made or distributed for profit or commercial advantage, 
the copyright notice, the title of the publication, and its date of appear, and notice is given that 
copying is by permission of the ACM, Inc. To copy otherwise, to republish, to post on servers, or to 
redistribute to lists, requires prior specific permission and/or a fee. FuturePlay 2007, November 15-17, 
2007, Toronto, Canada. Copyright 2007 ACM 978-1-59593-943-2/07/0011...$5.00 simultaneously position and 
orient a virtual object, and thus provide the most efficient manipulation interface compared to input 
devices that control less DOFs. However, most users are extensively familiar with 2D input devices, in 
particular the mouse. Furthermore, practically all commercially successful 3D graphics systems (including 
3D modeling packages and computer games) are based on a mouse­based user interface. Using a mouse for 
3D interaction introduces the problem of mapping 2D mouse motions into 3D operations. While several solutions 
have been proposed, all of them require that users mentally translate 2D mouse movements into low-level 
3D operations, which is unsuitable for naïve users. However, there is evidence that 2D input devices 
can outperform 3D devices for certain 3D positioning tasks, through the use of software techniques that 
map mouse movement to intuitive 3D object movement. Based on this observation, we present a list of guidelines 
for developing intuitive 3D manipulation techniques that can be used both in games and VR environments 
when using a mouse (or other 2D devices) for input. Based on these guidelines, we developed and compared 
three object manipulation techniques with different input devices in a fish tank VR environment. Additionally, 
because fish tank VR typically uses stereoscopic graphics and head-coupled perspective, each of these 
interaction techniques was tested in several display modes to assess possible interactions between display 
mode and input technique. 1.1 Related Work Most VR systems include the ability to modify or move objects 
with various techniques using different input devices. We first discuss 3D manipulation work with 3/6DOF 
devices and then with 2DOF devices. For the latter category we also look at stereoscopic graphics and/or 
head tracking, as there are few, if any, studies that investigate the effect of these visualization techniques 
on 3D object manipulation tasks with 2D devices. We also summarize related studies that examine the general 
benefits of stereoscopic graphics, and particularly those that aim to quantify the benefits of stereo 
on 3D interaction tasks. Two previous works present taxonomies of 3D selection/manipulation techniques 
[4, 18]. Poupyrev et al. compared selection and manipulation with ray-casting and a virtual hand metaphor 
[18]. They found that there was no clear winner each technique tested had advantages and disadvantages, 
depending on factors such as distance to the target, object size and visual feedback. Bowman et al. presented 
a study that compared several techniques created from basic 3D interaction components, and evaluates 
them in a selection and manipulation test-bed [4]. They found that selection based on ray-casting and 
occlusion was significantly faster than selection techniques requiring 3D hand/cursor movement. For manipulation, 
they found that the degrees of freedom of the manipulation task had a significant effect on task completion 
time. In fact, they note that it dominated the results, with 2DOF techniques significantly outperforming 
6DOF techniques, on average.  Zhai et al. [27] conducted a study of their silk cursor , a technique 
utilizing transparency and volumetric selection for 6DOF selection tasks. They compared their semi-transparent 
volumetric cursor to a wire-frame volumetric cursor, as well as stereo to mono graphics. They found that 
in addition to significant differences by cursor type, the stereoscopic display significantly improved 
user speed and accuracy. Their results suggest that both (partial) occlusion and stereopsis are beneficial 
in depth perception, but using both simultaneously provides an even stronger depth cue. Boritz and Booth 
[2, 3] conducted a series of studies on 6DOF input devices for 3D interaction tasks. They first studied 
the use of 6DOF input devices for selection tasks [2]. In their study, they compared stereoscopic to 
monoscopic display with and without head tracking, as well as different target positions. Their second 
study also considered orientation of the target [3], requiring users to dock a cursor with a target, 
matching both position and orientation. Both studies showed that stereo viewing was significantly better 
than mono, allowing quicker task completion, but no significant effect was found for head tracking. The 
authors reason that their tasks required only minimal head movement after the initial discovery of target 
locations. They note that although positional error was reduced in the stereo viewing mode, display mode 
showed no significant difference between stereoscopic and monoscopic for rotational error. It is interesting 
to note that, with the exception of the docking task in Boritz et al. s second study [3], all studies 
mentioned above used only 3DOF of the six afforded by the 6DOF input devices used, during manipulation. 
In all but the docking study, the 6DOF input device was only used for positioning, not orientation. Only 
Boritz and Booth s second study involved a real 6DOF task. Other work points out that 2D interface devices 
work well for 3D interaction when ray casting is used for selection and manipulation [17, 18, 20, 24]. 
Ware and Lowther conjecture that users rarely wish to interact with totally occluded objects, and as 
ray-casting allows the user to pick any (even only partially) visible object [24] this is sufficient. 
It is interesting to point out in this context that a 2D image of a 3D scene is already fully representative 
of all visible objects in that scene. Ware and Lowther s study found that a ray-casting based 2D selection 
technique using a cursor rendered to a single eye in a stereo display was more accurate than a 3D selection 
cursor. Manipulation is less straightforward than selection, since it is a 6DOF task, and the mouse only 
affords the simultaneous manipulation of two degrees of freedom. Thus, 2D input must be mapped to 3D 
operations. One solution used in most modeling and commercial CAD systems is 3D widgets or handles [7, 
21], which separate the DOFs by explicitly breaking the manipulation down into its individual components. 
Small handles are provided for movement along each of the three axes, and for each axis of rotation. 
This is usually complemented by different simultaneous orthogonal views of the same scene. Bier s skitters 
and jacks technique [1] provides a similar solution by interactively sliding the 3D cursor over objects 
in the scene via ray-casting, and attaching a transformation coordinate system to the object where it 
was positioned. The downside of such manipulation techniques is that users need to mentally decompose 
every movement into individual operations along the axes of the coordinate system which don t necessarily 
align with the axes of the scene. The simple solution of allowing users to change the axes for the widgets 
increases the user interface complexity greatly and carries the potential for the well-known problem 
of mode errors. Another approach is to constrain the movement of objects according to physical laws such 
as gravity and the inability of solid objects to inter-penetrate each other. Such constraints can also 
be used to limit object movement according to human expectations [20], e.g. chairs sit on the floor, 
and desk lamps sit on top of desks. However, this approach lacks generality, as it requires object-specific 
constraints to be designed a priori for each available type of object. For games, constraints may be 
suitable as they typically support only a limited set of objects in a restricted environment. A more 
general approach is based on the observation that in the real world (almost) all objects are attached 
to other objects and hence remain in contact with other objects at all times [16, 17]. To achieve this, 
the movement algorithm presented in that work uses the surfaces occluded by the moving object to determine 
the current movement surface, while still avoiding collisions. An extension allows users to also move 
objects partially behind other objects. If an object is moved over the background, it moves in free space 
on a plane orthogonal to the viewer. The result is that the object being moved always slides over the 
remainder of the scene in a very natural, predictable way, consistent with recent results from visual 
perception research. The algorithm does not use the notion of gravity, i.e. one can move objects from 
the floor to walls or onto the ceiling and back. For efficiency, most of the computations are performed 
in graphics hardware. Some researchers have also considered combinations of 2D and 3D UI components [6, 
9, 14, 23]. These approaches either use 2D interface widgets in a virtual environment and allow interaction 
via 6DOF devices [9], use physical props to constrain 2D interface components to a surface [14, 23] or 
provide a secondary 2D interface that controls the 3D environment, such as a tablet PC [6]. However, 
these approaches still involve a very strict separation of 2D and 3D interface components, thus increasing 
the cognitive overhead for the user. It is also interesting to note that while a large number of games 
use a mouse for 3D navigation (e.g. Doom3, Half-Life, etc.), few games allow 3D manipulation of any degree. 
On recent exception, Black &#38; White 2 from Lionhead Studios (see http://www.lionhead.com/bw2) allows 
movement of 3D objects in the game world using the mouse as a metaphorical hand. Clicking objects picks 
them up and holds them in-hand. The game s physics engine constrains objects to move according to user 
expectations when objects are released or thrown. However, orientation of objects is seldom, if ever, 
relevant to the game, and other than rotating the view around an object before grasping it, no facility 
is provided for rotating objects.  2. GUIDELINES FOR 3D MOVEMENT TECHNIQUES This paper presents a set 
of guidelines based on observations from previous work [2, 3, 4, 5, 9, 16, 17, 18, 20] as well as recent 
research in perception. The intent of these guidelines is to provide suggestions to designers of games 
and virtual environments for developing intuitive 3D manipulation techniques.  We work under the assumption 
that a typical 3D manipulation task can be decomposed into the following 3 distinct phases: 1. The selection 
phase, during which the user indicates which object they intend to manipulate. 2. A positioning phase, 
where the selected object is brought into the vicinity of the target area. 3. A fine-tuning phase, where 
the object is rotated and  positioned relative to the target. The distinction between the first and 
second phase is the same as in Bowman et al. s taxonomy [4]. The third phase is based on the observation 
that few people, if any, rotate and move the object simultaneously. While experts may rotate and translate 
an object simultaneously, this is something that novices do not appear to do. We do not believe that 
further decomposition of these manipulation phases is warranted, at least for novice users. We propose 
that the entire act of positioning an object be handled at once, without requiring the user to think 
in terms of movement along each of the three separate axes. As 3D rotations introduce a whole new layer 
of complexity to the problem, we limit ourselves to the 3DOF task of positioning objects in 3D, in the 
scope of this paper. In this context, we introduce the following set of guidelines for designing 3D object 
movement techniques, which also encapsulate the most important design decisions for 3D object movement 
techniques. Most of these guidelines are based on results of experiments with novice users, i.e. users 
who have no or limited 3D computer graphics experience. While it may be possible that expert users can 
achieve higher performance with techniques that ignore these guidelines, we believe that for many kinds 
of routine scene modifications even expert users will greatly benefit from them. 2.1 Avoid floating objects. 
In the real world, (almost) all objects are attached or connected to other objects. Floating objects 
are exceptional and our experimental observations suggest that most novice users are surprised when an 
object starts to float when moved. That indicates that the correct default for any 3D object movement 
technique is that objects should stay in contact with the rest of the world! However, most 3D modeling/CAD 
systems by default allow objects to float in space, which we see as an area ripe for improvement. Solutions 
to this problem include gravity, contact detection to always keep objects in contact with others, or 
other similar techniques. 2.2 Objects should not interpenetrate each other. Many novice users get confused 
if objects interpenetrate each other, particularly for complex objects, because it is difficult to tell 
which components belong to what object. Furthermore, they can t easily figure out how to resolve such 
problems. Incorporating collision detection/avoidance into movement techniques solves this problem. Today, 
the necessary computations are easily performed in real-time, even for complex scenes (see e.g. [8, 11]). 
Note that there may also be certain situations where relaxing this guideline may be beneficial. As an 
example, attempting to insert a peg into a tight hole may actually be easier if the objects can pass 
through one another. However, in general, major collisions should not occur. 2.3 Support relative positioning 
of objects by bringing them in contact with one another. The paradigm of sliding an object on the surface 
of another until it reaches the desired position is a very natural way to position objects. This is easily 
demonstrated by watching a child position toy blocks. To implement this in a computer system, one must 
choose a movement surface from the set of surfaces of the static scene and then displace the moving object 
relative to that surface. One good way to realize this is by using constraints on object movement, see 
section 1.1. Another option is to ensure that objects always remain in contact with the rest of the scene. 
 2.4 Only visible objects can be manipulated. Users typically do not even try to manipulate objects that 
are not visible. Instead, they tend to rotate or move the viewpoint so that the desired object becomes 
visible. One indication for this is that previous work found that the most efficient techniques are based 
on the notion of ray casting [12, 18, 24] or occlusion [4]. Ray casting identifies the first object that 
is visible along an infinite ray from the manipulation device into the scene. Occlusion is similar, except 
involves the user blocking the object to be selected with their hand, or another object. Hence, we suggest 
that it is sufficient to allow the user to select all objects from a 2D image [24], rather than using 
full 3D cursor selection techniques. And indeed, researchers argue that all ray casting techniques can 
be approximated as 2D techniques [18]. This is also true of occlusion techniques using an occluding 2D 
shape as a cursor. 2.5 The most important cues for judging 3D position in real scenes are perspective 
and occlusion. As documented by research into visual perception, people judge 3D position based on several 
depth cues. Besides perspective, the most important cue for 3D position is occlusion [26]. In our previous 
work, we found that for scenes without floating objects (see 2.1), perspective and occlusion combined 
with the ability to quickly move the viewpoint are usually sufficient to allow humans to understand the 
3D position of an object in relation to other objects. Finally, it is interesting to note that recent 
research confirmed that from an end-user s point of view, most stereo technologies are not very mature 
and are tiresome and/or problematic if used on a daily basis [10, 25]. In other words, the addition of 
stereo viewing to a system does not appear to increase the usability of the system.  2.6 Avoid technical 
computer graphics techniques such as handles and 3 orthogonal views . Using handles or widgets to move 
an object in 3D is an instance of an indirect manipulation technique. In the domain of (2D) desktop environments 
this idea was very rapidly eclipsed by the idea of direct manipulation [19], as this paradigm proved 
to be much simpler to understand. Furthermore, it has been shown that novice users can manipulate 3D 
objects more effectively in a single perspective view and without handles when intelligent manipulation 
techniques are used [17].  2.7 In general, 3DOF or 6DOF input devices provide less precision than 2DOF 
input devices. A human hand held in free space will jitter more than a hand that is supported by a physical 
surface. That means that any input device that is physically limited to 2DOF tends to be more precise 
and hence usually affords also more efficient manipulation. In VR/AR research, this has been already 
realized through the adoption of techniques such as the Personal Interaction Panel [23], or physical 
props [6, 14], which effectively transforms a 6DOF input device into a physical 2DOF input device. 2.8 
Use the entire area of visual overlap of the moving object with the static background scene when deciding 
the position of the object. Practically all techniques for 3D object motion use only the current position 
of the cursor to compute the 3D position of a moving object. This effectively reduces the computation 
to a point mapping problem. However, research into vision in primates discovered that the perceptive 
field for an object that is being held in the hand covers the whole object [15]. In other words, there 
is strong evidence that the whole visual area of an object is used to judge 3D position. And indeed, 
previous studies have shown that point-based techniques do not work as well as area-based techniques 
[17].  3. ISSUES IN COMPARING 3D POSITIONING TECHNIQUES To assess the value of these guidelines, we 
designed an experiment to compare how various 3D positioning techniques perform relative to each other. 
We made the following choices to ensure the validity of our results. 3.1 3D Positioning Techniques For 
our initial study, we implemented three positioning techniques, based to varying degrees on the guidelines 
above. All of them use 2D ray casting for selection of 3D objects. The first technique used the mouse, 
with the assistance of the 3D sliding movement algorithm presented in [17]. This technique is fully based 
on the above guidelines. In this mode, an object being moved slides on other objects in the scene. Effectively, 
this algorithm reduces the dimensionality of the movement task from 3D to 2D and permits the use of the 
mouse to perform common 3D object positioning tasks. The second input technique used a 3D wand/tracker 
input device, but used only two axes of motion. The Y (up-down) motion of the wand was mapped to cursor 
movement in Y on the screen, and the X (side-to-side) motion of the wand was mapped to cursor movement 
in X. The depth of the moved object was controlled automatically via the same sliding algorithm described 
in [17]. In other words, the user had no direct control of the Z (depth) axis in this mode; they merely 
move the input device in X and Y, and the software handled the depth. In effect, this creates a mouse 
emulation mode, although a mouse is pushed away to move the cursor up, while our technique requires the 
user to move the wand up for this. We used this mode to investigate the differences between 2DOF and 
3DOF input devices. This technique is referred to as the WandSlide technique for the remainder of the 
paper. It supports all of the guidelines listed above, except 2.7 the observation that 2DOF devices 
tend to provide grater accuracy. The third input technique also used the 3D wand/tracker, but object 
movement was directly mapped to 3D position of the device. This mode did not use the sliding algorithm 
described above. Selection, however, was still based on ray casting. Upon selection of an object, the 
object moves in 3D according to the 3DOF motion of the wand. No collision detection/avoidance was used 
in this mode, which makes this a raw 3D direct manipulation mode. This is representative of traditional 
VR object movement techniques and ignores most of the guidelines above. We refer to this technique as 
the Wand3D technique.  3.2 3D Positioning Tasks We chose two different positioning tasks for the study 
presented here. The first task, depicted in Fig. 1, involved the selection and movement of the red target 
cube to the top of the pedestal. This task was based on a similar tasks used in previous work [4]. It 
was chosen because the motion required to position the cube is relatively simple to perform with any 
input device and thus it can serve as a representative abstract movement task. While somewhat overly 
simplistic, it may give indications of how a series of movements comprised of such simple, short movements 
performs with different positioning techniques. Also, because the cubes were positioned in the foreground, 
and the target pillar was placed in the background, we hypothesized that this task would help us analyze 
any potential benefits of the extra depth cues provided by stereoscopic graphics and head tracking. 
The second task was the assembly of a chair from several pieces (see Fig. 2). This task was chosen as 
a representative real-world assembly task. It is slightly harder than the cube placement task, as it 
requires the accurate placement of multiple objects. This task was also previously used to compare the 
mouse sliding movement technique to 3D widgets [17].  Note that this task cannot be adequately handled 
by techniques that use only gravity and collision avoidance. The chair task involves the backrest (part 
#5 in fig. 2), that must be attached horizontally to the support behind it (part #3). Using gravity alone 
it is impossible to perform this attachment. The sliding paradigm easily handles cases like this, as 
the backrest can be slid up the support up to the desired position. The object then remains affixed to 
the position where it was released. Hence, we believe the sliding movement technique to be more appropriate 
for assembly type tasks compared to traditional approaches.  4. USER STUDY We conducted a user study 
to compare the input techniques described above and to determine if stereo graphics and head tracking 
provide any benefits to 3D positioning using these techniques. Furthermore, this study also indirectly 
validates the proposed guidelines. 4.1 Hypotheses 4.1.1 3D positioning technique We hypothesize that 
the mouse mode will outperform the two conditions with the 3D input device. In addition to the effect 
of extensive user familiarity with the mouse, the reduced hand jitter in this condition will favor 2D 
input over 3D input. Another factor that should play a role here is the lack of collision detection in 
the Wand 3D mode. 4.1.2 Stereoscopic graphics We hypothesize that the addition of stereoscopic graphics 
will improve the participants ability to position objects in 3D, thus reducing task performance time 
and improving accuracy due to the extra depth cue provided. In other words, stereo should make it easier 
to perform 3D object positioning, even with 2D input devices. 4.1.3 Head-coupled perspective We hypothesize 
that the addition of head coupled perspective will also improve accuracy, despite previous findings that 
suggested little benefit from it [2]. The extra motion depth cue provided by head coupling should assist 
users in gauging depth better thus obviating the need to rotate the entire scene.  4.2 Participants 
Twelve paid volunteers participated in the study, with age ranging from 23 to 34 years, mean 25.7. Seven 
participants were male. Nine of the twelve reported using a mouse for 10 or more years, the remainder 
reported 5 10 years of experience. Since approximately 8% of the population is incapable of fusing stereo 
pairs [13], participants were also screened for stereoscopic viewing ability. Participants game playing 
habits were also recorded, as it is possible that they are a confounding factor. We found in a pilot 
study to this work that gamers tend to skew the results of studies of 3D interaction with 2D input devices, 
performing significantly better that those with limited game experience. Only one participant reported 
playing games more often than once per week. Two others reported playing games roughly once every week, 
and the rest played approximately once per month, or less frequently. Based on similar reasoning, we 
also asked participants about prior experience with 3D modeling tools. The majority of the participants 
had little to no experience with 3D modeling, with seven having never used such software, and the remaining 
five only using it approximately once per month, or less frequently. 4.3 Equipment Tasks were performed 
in a fish tank VR system. The system was an AMD Athlon 64 1.81GHz with 1GB of RAM, and an NVIDIA Quadro 
FX3400 graphics card. A standard desktop optical mouse was used as input device in one condition, and 
an Intersense 6DOF wand was used in the other two. Stereoscopic graphics was provided using a Stereographics 
emitter and CrystalEyes shutter glasses. An Intersense IS900 was used for 3D head tracking and 3D wand. 
The head tracking sensor was mounted on the shutter glasses. The display was a Silicon Graphics monitor 
at 1024x768 @ 120HZ. The software used was written in C++ with OpenGL. In stereo mode, using the system 
cursor with stereo graphics produces a dual cursor effect when a user focuses on the cursor. To avoid 
this, the software was modified to only draw the mouse cursor synchronized with the dominant eye, as 
discussed in [24]. This one-eyed cursor was aligned to the position of the operating system cursor, to 
allow accurate selection of faces and objects as required by the experimental tasks. 4.4 Procedure Participants 
completed a series of object movements for each trial, using the tasks described in section 3.2. In each 
trial, they used one of the three movement modes from section 3.1. For the chair task, participants were 
informed of the order in which parts should be assembled, and were asked not to move the chair s wheels. 
Hence, they started with part #1 in Figure 2 (the base of the chair). This ensured that the experiment 
was not testing 3D construction skills, but only the input techniques and display modes. Prior to both 
tasks, participants were given a brief practice period of up to 5 minutes to familiarize them with the 
3D sliding movement algorithm used in the system, as well as the various input devices. During the experiment, 
participants repeated each task twice. In all trials, participants were asked to complete the assembly 
or placement task as quickly and accurately as possible. Prior to each trial, participants were informed 
of the status of each of the experimental factors, namely, whether head-tracking and stereo graphics 
were on or off, and which input device and technique was for this trial.  4.5 Design The experiment 
was a 3×2×2×2 design. The independent variables were movement technique (Mouse, WandSlide and Wand3D 
mode), display mode (monoscopic or stereoscopic), head tracking (enabled or disabled), and task (chair 
assembly or cube placement) respectively. All factors were within-subjects and there were two repetitions 
of each condition. The orderings of display type, head tracking mode, input device and task were counter-balanced 
according with a balanced Latin square to compensate for possible asymmetric learning effects across 
conditions. Participants wore shutter glasses during all trials, to mitigate any confounding effect of 
the glasses themselves. The glasses reduce the amount of light seen by the viewer, which can adversely 
affect the user s stereoacuity [13].  Figure 3. Mean task completion times by input technique and task. 
Error bars show standard error. Every participant completed every combination of movement technique and 
display mode twice, for a total of 48 trials. Participants took approximately 1 hour to complete this 
series of trials. We had considered splitting the conditions into two separate experiments, one to compare 
the movement techniques, and the other to compare just the display modes. However, this would have made 
determining potential interactions between conditions nearly impossible. Since we were interested in 
comparing combinations of the conditions, we opted instead to include all in this single experiment. 
This way, we could determine if the addition of stereo and/or head-tracking aided any specific positioning 
technique more than others.  4.6 Results We performed a repeated-measures ANOVA on the task completion 
times for all trials. A significant difference for positioning technique (F2,22=34.348, p<<.01) was found. 
Tukey Kramer post-hoc analysis revealed that all three techniques were different, with Mouse (mean 19.3s) 
outperforming the WandSlide technique (27.3s), which in turn outperformed the Wand3D technique (33.6s). 
There was no significant difference for stereo or head tracking. Participants performed significantly 
better upon the second repetition of each trial (F1,11=0.491, p<.05), as is to be expected without training. 
The mean completion time was 40.9s for the chair task, and 12.5s for the cube task; these were also significantly 
different, (F1,11=64.053, p<<.01). Beyond that, there were no significant differences, with the exception 
of a significant interaction between task and positioning technique (F2,22=17.574, p<<.01). Accuracy 
was measured by summing the total error distance for each object in the scene compared to the target 
scene. There was a significant difference in accuracy for positioning technique (F2,22=17.122, p<<.01) 
and for task (F1,11=17.172, p<<.01). There was also significant difference for stereo mode (F1,11=7.982, 
p<.05). The mean errors by positioning technique were 4.8 cm for the Mouse mode, 5.89 cm for WandSlide, 
and 15.6 cm for Wand3D. Post-hoc comparisons indicated no significant difference in accuracy between 
the Mouse and WandSlide modes both of these modes were significantly more accurate than the 3DOF movement 
technique. Figure 4. Mean error distance by input technique and task. Error bars show standard error. 
 4.7 Discussion The significant difference in speed between tasks was unsurprising. Intuitively, the 
cube placement task was far simpler than the chair assembly, requiring only a single precise object placement, 
rather than multiple actions. The fact that full 3DOF movement with the wand took longer than the other 
two modes confirmed our first hypothesis. There are several likely causes for these results. The first, 
as mentioned, is the participants familiarity with the mouse compared to the wand. Essentially, the participants 
were already experts with the mouse but had no experience with the wand. This gives a major advantage 
to the mouse. Second, because the Wand3D condition used neither collision detection nor front-face sliding 
like the Mouse and WandSlide movement modes, participants required additional time to accurately position 
the manipulated object in 3D. Some participants commented on this, that the lack of collision detection 
and/or collision feedback made it difficult to judge when the object was positioned correctly. Another 
aspect is that hand jitter and fatigue combined with the relative sensitivity of the wand reduced the 
accuracy of the Wand3D technique significantly, compared to the other two techniques. We believe that 
the participants took extra time trying to correct for this reduced accuracy, eventually giving up when 
the scene looked good enough . This is substantiated by the significantly worse accuracy with this technique. 
Third, observations made during the experiment suggest that participants came to rely on the front-face 
sliding movement after they had been exposed to it in the WandSlide and Mouse conditions, often leaving 
objects floating well in front of their intended target in the Wand3D condition an oversight that the 
2D sliding algorithm automatically accounts for. This even occurred during stereo and head-tracked trials, 
where we believed that the additional depth cues provided would aid the users accuracy. This suggests 
that the input technique has a much stronger effect on accuracy and speed than either stereo or head 
tracking. Finally, the 2D sliding algorithm used in both the Mouse and WandSlide modes effectively reduces 
the dimensionality of the movement task from 3D to 2D. This is a clear benefit over full 3D movement 
techniques, as the user is only required to position the object accurately in two dimensions rather than 
three. Phrased differently the user is only required to line up the image of the object being moved with 
the image of the target. This strongly suggests that smart 3D movement algorithms can overcome the limitations 
of an input device (e.g. degrees of freedom) and can allow such input devices to outperform devices that 
seem to be better suited to the problem. Although this is technically no longer a 3D positioning task, 
but rather a 2D positioning task, the end result is the same the object has been moved to a new 3D location 
in the scene.  Despite the relative quantitative performance of the input techniques, several of the 
participants commented that they found the Wand3D mode to be the most fun to use. Given the recent success 
of the Nintendo Wii game console, which uses a similar input device (www.nintendo.com), this is not very 
surprising. However, several users also commented that it was frustrating to use, and that they preferred 
using the mouse. Interestingly, no participants chose the WandSlide technique as their favorite. Fun 
factor is an important consideration in interface design as well, especially for games, and suggests 
that if 3DOF interaction techniques could be made as effective as 2DOF techniques (e.g. by following 
the guidelines suggested above) they may be a clear winner. Our hypothesis regarding stereoscopic graphics 
was confirmed by the significant effect observed on accuracy. This conforms to previous studies, and 
as indicated, the extra depth cue allowed the users to more easily perceive the distances between objects. 
To our surprise, head tracking had no effect on accuracy or completion time. This is likely because the 
participants seldom intentionally used head tracking. One possible reason for this is that they simply 
forgot about it during the trials when it was active, despite being informed about the status of each 
factor at the beginning of each trial. It is also possible that they did not understand the full value 
of head tracking or felt the effect was too subtle to be useful. One participant even commented that 
the scene rotation by head movement would be more useful if rotation was exaggerated beyond realism. 
A third possibility is again related to the apparent reliance of the users on the front-face sliding 
movement algorithm the users may have been assuming that the objects were sliding and that this feature 
was ensuring their accuracy, hence they felt they had no need to use the head tracking. Objects were 
often left floating far in front of the target, but appeared properly positioned in 2D. A subtle shift 
of the head in head-tracked mode would have revealed the distance between the cube and the target. Finally, 
it has been previously suggested that more complex scenes require more reliance on stereo and head-tracking 
[2]. Because the scenes used in our experiment were fairly small, consisting of only a few objects, only 
minimal view movements were required by the participants to determine the relative 3D location of the 
objects, which is yet another way to explain the lack of effect. The interaction effect noted between 
task and positioning technique is interesting, as it suggests that some input devices are particularly 
well suited to specific tasks. Figure 3 shows that times for the Wand3D positioning mode were much closer 
to the WandSlide positioning mode for the cubes task than for the chair task. This is likely due to both 
the lack of collision detection (in this case, beneficial because the user could just move the cube through 
the others), and the fact that the 3D wand allowed for effectively a straight-line movement towards the 
target pedestal upon selecting the cube. Comparatively, the chair assembly task was much more difficult, 
requiring numerous accurate placements. Consequently, the wand fares worse under this higher accuracy 
requirement especially in the 3DOF positioning mode. Finally, it is interesting that there was no significant 
difference in accuracy between the Mouse and WandSlide modes, while there was a significant difference 
in speed. We believe that the reason is that the table on which the mouse slides provides a firm foundation 
upon which the participants can rest their hand and thus gain accuracy. Another factor is that the friction 
between mouse and table enables users to fairly rapidly stop their movement, compared to stopping a wand 
movement in the air. The wand, however, does not provide these benefits. Previous findings support this 
as well [6, 14]. Furthermore, the 2D sliding algorithm makes it quite easy to correct minor misplacements 
very quickly, hence the participants seemed more inclined to trade a bit of time for improved accuracy 
in this condition. Correcting such mistakes in 3DOF mode requires a significantly greater amount of work 
due to jitter and the additional axis that needs to be controlled simultaneously.  5. CONCLUSION We 
presented several guidelines for the design of 3D positioning techniques based on observations from prior 
research. We then performed an evaluation of several 3D positioning techniques, two of which were based 
on the guidelines. The evaluated techniques included mouse-based 3D positioning with an intelligent sliding 
movement algorithm, and two techniques using a 3D wand. One of them used only 2DOF and the same intelligent 
sliding algorithm and the other allowed full 3D movement. The mouse was significantly faster than the 
2DOF wand mode, which was significantly faster times than the 3DOF wand technique. However, no significant 
difference was found in accuracy between the mouse and the 2DOF wand modes. Additionally, we evaluated 
the effects of stereoscopic graphics and head coupled perspective on 3D positioning tasks. Stereoscopic 
graphics had a significant effect on accuracy, but head tracking did not. 5.1 Future Work We are interested 
in determining how the guidelines presented above apply to more general virtual reality environments 
such as CAVEs. Due to the inherent reliance on 3D tracking equipment, it seems plausible that our results 
for fish tank VR systems can also generalize to other VR environments as well.  6. ACKNOWLEDGMENTS Thanks 
to Rob Allison for the usage of his lab equipment for the user study.  7. REFERENCES [1] E. Bier. Skitters 
and Jacks: Interactive 3D Positioning Tools. In Proc. of Interactive 3D Graphics 1986, pp.183-196, January 
1987. [2] J. Boritz, and K. S. Booth. A Study of Interactive 3D Point Location in a Computer Simulated 
Virtual Environment. In ACM VRST 1997, pp. 181-187, September 1997. [3] J. Boritz, and K. S. Booth, A 
Study of Interactive 6 DOF Docking in a Computerised Virtual Environment. In Proc. of the Virtual Reality 
Annual International Symposium, pp. 139-146, March 1998.  [4] D. Bowman, D. Johnson, and L. Hodges. 
Testbed Evaluation of Virtual Environment Interaction Techniques. In Proc. of VRST99, pp. 26-33, December 
1999. [5] H. Baradaran, W. Stuerzlinger, A Comparison of Real and Virtual 3D Construction Tools with 
Novice Users. In CGVR'06, pp. 10-15, June 2006. [6] J. Chen, M.A. Narayan, and M.A. Perez-Quinones. The 
Use of Hand-held Devices for Search Tasks in Virtual Environments, In Proc. of the IEEE Virtual Reality 
2005 workshop on New Directions in 3DUI, pp. 15-18, March 2005. [7] D. Brookshire Conner, S. Snibbe, 
K. Hemdon, D. Robbins, R. Zeleznik, and A. van Dam. Three Dimensional Widgets. In Proc. of Symposium 
on Interactive 3D Graphics, June 1992. [8] K. Dave, K. Dinesh. CInDeR: Collision and Interference Detection 
in Real-time using graphics hardware. In Proc. of Graphics Interface, pp. 73-80, May 2003. [9] M. Deering. 
The Holosketch VR Skething System. Communications of the ACM, 39, 5, pp. 55 61, 1996. [10] D. Diner, 
and D. Fender. Human Engineering in Stereoscopic Viewing Devices. Plenum Press, New York, 1993. [11] 
N. Govindaraju, S. Redon, M. Lin, and D. Manocha. CULLIDE: interactive collision detection between complex 
models in large environments using graphics hardware. SIGGRAPH Workshop on Graphics Hardware, pp. 25-32, 
2003. [12] T. Grossman, and R. Balakrishnan. The Design and Evaluation of Selection Techniques for 3D 
Volumetric Displays. In ACM Symposium on User Interface Software and Technology 2006, pp. 3-12, 2006. 
[13] J. Hsu, Z. Pizlo, D. Chelberg, C. Babbs, and E. Delp. Issues in the Design of Studies to Test the 
Effectiveness of Stereo Imaging. In IEEE Transactions on Systems, Man and Cybernetics, Part A, 26, 6, 
pp. 810-819, 1996. [14] R. W. Lindeman, J.L. Sibert, J. K. Hahn. Towards Usable VR: an empirical study 
of user interfaces for immersive virtual environments. In Proc. of CHI 99, pp. 64-71, 1999. [15] S. Obayashi, 
T. Suhara, K. Kawabe, T. Okauchi, J. Maeda, Y. Akine, H. Onoe, and A. Iriki. Functional brain mapping 
of monkey tool use. NeuroImage 14, pp. 853-861, 2001. [16] J.-Y. Oh, W. Stuerzlinger. A system for desktop 
conceptual 3D design. In Virtual Reality 7, pp. 198-211, 2004. [17] J.-Y. Oh, W. Stuerzlinger. Moving 
Objects with 2D Input Devices in CAD Systems and Desktop Virtual Environments. In Proc. of Graphics Interface 
2005, pp. 195­202, 2005. [18] I. Poupyrev, S. Weghorst, M. Billinghurst and T. Ichikawa, Egocentric object 
manipulation in virtual environments: empirical evaluation of interaction techniques. In Eurographics 
98, pp 41-52, 1998. [19] B. Shneiderman. Direct manipulation: A step beyond programming languages, IEEE 
Computer 16, 8, pp. 57-69, 1983. [20] G. Smith, T. Salzman and W. Stuerzlinger. 3D Scene Manipulation 
with 2D Devices and Constraints. In Graphics Interface 01, pp. 135-142, 2001. [21] P. Strauss and R. 
Carey. An Object-Oriented 3D Graphics Toolkit. In Proc. of SIGGRAPH 2002, pp. 341-349, July 2002. [22] 
W. Stuerzlinger, D. Dadgari, J.-Y. Oh. Reality-Based Object Movement Techniques for 3D, CHI 2006 Workshop: 
"What is the Next Generation of Human-Computer Interaction? , April 2006. [23] Z. Szalavári, M. Gervautz, 
The Personal Interaction Panel, A Two-Handed Interface for Augmented Reality, Eurographics 97, pp. 335-346, 
September 1997. [24] C. Ware, K. Lowther. Selection Using a One-Eyed Cursor in a Fish Tank VR Environment. 
In ACM Transactions on Computer-Human Interaction, 4, 4, pp. 309-322, 1997. [25] Z. Wartell, L. F. Hodges, 
W. Ribarsky, A geometric comparison of algorithms for fusion control in stereoscopic HTDs. IEEE TVCG, 
8, 129-143, 2002. [26] C. Wickins, J. Hollands, Spatial displays, in Engineering psychology and human 
performance, Prentice-Hall 3rd Edition, 1999. [27] S. Zhai, W. Buxton, P. Milgram. The Silk Cursor : 
Investigating Transparency for 3D Target Acquisition. In Proc. of CHI 94, pp.459-464, 1994.   
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2007</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>1328215</article_id>
		<sort_key>130</sort_key>
		<display_label>Pages</display_label>
		<pages>8</pages>
		<article_publication_date>11-14-2007</article_publication_date>
		<seq_no>3</seq_no>
		<title><![CDATA[Effective use of the periphery in game displays]]></title>
		<page_from>69</page_from>
		<page_to>76</page_to>
		<doi_number>10.1145/1328202.1328215</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1328215</url>
		<abstract>
			<par><![CDATA[<p>The human eye can perceive visual information with high acuity within a narrow foveal view; outside the foveal view (in the periphery), vision has progressively less resolution, and ability to perceive colour is reduced. In this paper, we argue that game displays can be improved by accounting for the part of the visual field in which information is displayed. We present two games in which information is visually encoded for presentation in the periphery. We conclude that the use of peripheral displays may be an interesting way of improving the challenge and entertainment of games involving rich informational displays.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[computer games]]></kw>
			<kw><![CDATA[display design]]></kw>
			<kw><![CDATA[peripheral display]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>H.5.2</cat_node>
				<descriptor>Screen design (e.g., text, graphics, color)</descriptor>
				<type>S</type>
			</primary_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10003120.10003123</concept_id>
				<concept_desc>CCS->Human-centered computing->Interaction design</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003121.10003125.10011666</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)->Interaction devices->Touch screens</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003123</concept_id>
				<concept_desc>CCS->Human-centered computing->Interaction design</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003121.10003125.10011666</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)->Interaction devices->Touch screens</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Human Factors</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P925255</person_id>
				<author_profile_id><![CDATA[81536885056]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Kevin]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Grad]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Queen's University, Kingston, Ontario, Canada]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP43123987</person_id>
				<author_profile_id><![CDATA[81392599672]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[T.]]></first_name>
				<middle_name><![CDATA[C. Nicholas]]></middle_name>
				<last_name><![CDATA[Graham]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Queen's University, Kingston, Ontario, Canada]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP43126578</person_id>
				<author_profile_id><![CDATA[81100264012]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[A.]]></first_name>
				<middle_name><![CDATA[James]]></middle_name>
				<last_name><![CDATA[Stewart]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Queen's University, Kingston, Ontario, Canada]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>1228204</ref_obj_id>
				<ref_obj_pid>1228175</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Altosaar, M., Vertegaal, R., Sohn, C., and Cheng, D. Auraorb: using social awareness cues in the design of progressive notification appliances. In <i>OZCHI '06</i> (2006), ACM Press, pp. 159--166.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>286750</ref_obj_id>
				<ref_obj_pid>286498</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Dahley, A., Wisneski, C., and Ishii, H. Water lamp and pinwheels: ambient projection of digital information into architectural space. In <i>CHI 98 conference summary on Human factors in computing systems</i> (1998), ACM Press, pp. 269--270.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>986035</ref_obj_id>
				<ref_obj_pid>985921</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[De Guzman, E. S., Yau, M., Gagliano, A., Park, A., and Dey, A. K. Exploring the design and use of peripheral displays of awareness information. In <i>CHI '04 extended abstracts on Human factors in computing systems</i> (2004), pp. 1247--1250.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Duchowski, A., Cournia, N., and Murphy, H. Gaze-contingent displays: A review. <i>CyberPsychology and Behaviour 7</i>, 6 (2004), 621--634.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Hecht, E. <i>Optics, 2nd edition.</i> Addison Wesley, 1987.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Ima, C., and Mann, D. Lightbar design: The effect of light color, lightbar size and auxiliary indicators on tracking and monitoring performance. <i>Agricultural Engineering International ERG 03</i>, 1 (2003).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>355032</ref_obj_id>
				<ref_obj_pid>355017</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Loschky, L., and McConkie, G. User performance with gaze contingent multiresolutional displays. In <i>Eye Tracking Research Symposium</i> (2000), pp. 97--103.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>332438</ref_obj_id>
				<ref_obj_pid>332040</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Maglio, P. P., and Campbell, C. S. Tradeoffs in displaying peripheral information. In <i>CHI '00: Proceedings of the SIGCHI conference on Human factors in computing systems</i> (2000), pp. 241--248.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>642642</ref_obj_id>
				<ref_obj_pid>642611</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Mankoff, J., Dey, A., Hsieh, G., Kientz, J., Lederer, S., and Ames, M. Heuristic evaluation of ambient displays. In <i>ACM CHI</i> (2003), pp. 169--176.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1101447</ref_obj_id>
				<ref_obj_pid>1101389</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Shen, X. An intrusive evaluation of peripheral display. In <i>Proceedings of the 3rd International Conference on Computer Graphics and Interactive Techniques in Australasia and Southeast Asia</i> (2005), pp. 289--292.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Virsu, V., Nasanen, R., and Osmoviita, K. Cortical magnification and peripheral vision. <i>Journal of the Optical Society of America A 4</i>, 8 (1987), 1568--1652.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Effective Use of the Periphery in Game Displays Kevin Grad, T.C. Nicholas Graham, A. James Stewart School 
of Computing Queen s University Kingston, Ontario, Canada K7L 3N6 {kevin,graham,stewart}@cs.queensu.ca 
 ABSTRACT The human eye can perceive visual information with high acuity within a narrow foveal view; 
outside the foveal view (in the periphery), vision has progressively less resolution, and ability to 
perceive colour is reduced. In this paper, we argue that game displays can be improved by accounting 
for the part of the visual .eld in which information is displayed. We present two games in which information 
is visually en­coded for presentation in the periphery. We conclude that the use of peripheral displays 
may be an interesting way of improving the challenge and entertainment of games involv­ing rich informational 
displays. Categories and Subject Descriptors H.5.2 [Information Interfaces and Presentation]: User Interfaces 
Screen design  General Terms Human Factors Keywords Computer games, display design, peripheral display 
1. INTRODUCTION Video games often require players to perceive, process and act on extensive time-sensitive 
information. For example, in a real-time strategy game, players must simultaneously monitor the state 
of di.erent locations on a large map, while managing combat, resource gathering and production. In a 
multiplayer .rst-person shooter, players must monitor the locations and activities of their teammates 
and opponents while rapidly moving, aiming and .ring. Often, what dis­tinguishes a poor game player from 
a pro.cient one is the ability to deal with such a profusion of time-sensitive data. The design of informational 
displays is therefore an impor­tant part of creating a challenging and entertaining experi­ence for players. 
Permissionto makedigital/hard copy of partofthis work for personalor classroomuse is granted withoutfee 
providedthat the copiesarenot madeor distributedforprofit or commercialadvantage, thecopyright notice, 
thetitleof thepublication,and itsdate of appear, andnotice is giventhat copying is by permission of the 
ACM, Inc.To copy otherwise, torepublish,to postonservers,orto redistribute to lists,requiresprior specificpermissionand/or 
a fee. FuturePlay 2007, November 15-17, 2007, Toronto, Canada. Copyright 2007 ACM 978-1-59593-943-2/07/0011...$5.00 
Attributes of the human visual system in.uence the success of informational displays. For example, it 
is more di.cult to perceive information presented in the periphery of the visual .eld than in the centre 
of the visual .eld (the fovea ). In a typical real-time strategy game, a player .xating on the centre 
of the screen may be unable to perceive the contents of a mini-map in the upper-right corner of the display, 
or a chat window in the lower-left corner. We propose that game design can be improved by visually encoding 
information appropriately for its position in the player s visual .eld. We expect that information encoded 
for peripheral view can provide a novel twist to informa­tion display. Players will be challenged to 
become expert in the parallel interpretation of data available from numerous sources and unfamiliar formats. 
Designing e.ective peripheral displays is challenging. In this paper, we provide two examples of game 
display that encode peripheral and foveal information di.erently, with the goal of improving the performance 
of expert players. Testing showed the .rst example to be unsuccessful, and the second to be successful. 
We use these examples to illustrate both the di.culties and bene.ts of creating displays intended for 
viewing in the periphery. There are two fundamental challenges in creating peripheral displays. First, 
we must .nd appropriate ways of encoding information for peripheral view. While experiments done by earlier 
researchers and knowledge of the physiology of the eye provide hints as to what kinds of encodings may 
be successful, our own experience is that designing such en­codings is highly challenging. Second, we 
must determine whether requiring players to attend to peripheral displays in addition to their primary 
foveal display produces a form of information overload, where the additional information fails to improve 
performance, or even worsens it. Our two example games illustrate these issues. The paper is organized 
as follows. We .rst review the dif­ferences between foveal and peripheral vision, and discuss previous 
research in peripheral displays. We then present CoOp Tetris and City Flyer, the two games that we have 
developed for our case studies, and report our .ndings about the e.ectiveness of their use of peripheral 
displays.  Figure 1: A lightbar is used as a peripheral display in a tractor to show deviance from 
the tractor s in­tended path [6] 2. PERIPHERAL VISION AND RELATED WORK The retina is a light-sensitive 
layer of photoreceptors at the back of the eye. Photoreceptors are sensitive to photons and are of two 
types: rods, which are sensitive mainly to intensity, and cones, which are sensitive mainly to colour. 
Rods also provide more sensitivity to motion detection and to low illumination. The fovea is a small 
area on the retina that contains only cones and provides an acute, or highly detailed, image of the world 
within about two degrees of the line of sight. Around the fovea is a greater concentration of rods. This 
peripheral area of the retina is better at de­tecting motion and low illumination, but worse at detecting 
colour [5]. Any information that projects to this periph­ery may be visually encoded to exploit the properties 
of the periphery. Manko. [9] has studied the characteristics of peripheral dis­plays and determined eight 
heuristics for building a good peripheral or ambient display. The most useful of these include: the display 
should be designed to convey enough information but not too much; the display should contain only useful 
and relevant information; the display should keep users continuously informed through appropriate and 
timely feedback; the display should be unobtrusive unless it requires the user. Ss attention; and the 
display should be should be easy for its users to monitor. Shen [10] also pro­vides three guidelines 
to a good peripheral display, incuding that the information presented closest to the primary screen should 
be the most important, and that animation should be either slow or smooth in order to reduce distraction. 
Gaze contingent displays (GCDs) degrade the display resolu­tion in peripheral regions in order to reduce 
computational requirements during image transmission, retrieval, or dis­play [4]. The region near the 
user s line of sight is rendered in high detail, while the peripheral regions are coarsely ren­dered. 
The high resolution region moves with the user s line of sight, which is determined with an eye tracker. 
Loschy has summarized six separate studies of gaze contingent dis­plays [7]. Most peripheral displays 
are used to convey alerts, such as the arrival of email or of an instant message [3]. Most such displays 
rely on animation, which the research cited above tells us can be easily perceived in the periphery. 
For exam­ple, email arrival under Microsoft Windows shows a small, animated alert box in the lower-left 
corner of the display. The idea behind this kind of display is to inform the user of some event of interest, 
so that he may turn his attention to a di.erent task [8, 1]. A more di.cult case with peripheral displays 
is to present a stream of information that is pertinent to the user s central task. Here, the system 
provides a continuous stream of in­formation rather than a simple alert prompting the user to change 
his focus of attention. An early example of such a display is Dahley et al. s use of pinwheel lights 
to project a wall display representing current network state; the network speed in.uences the speed at 
which the pinwheel display ro­tates. The user can therefore continuously perceive the state of the network 
using her peripheral vision [2]. A perhaps more practical novel peripheral display was de­veloped by 
Ima and Mann [6] for harvester guidance. Large harvesters are di.cult to drive and mis-steering can result 
in missed crops or twice-harvested strips. Ima and Mann s system uses a GPS to track the harvester s 
position, and uses an LED strip, placed in the driver s peripheral vision, to guide the driver (see .gure 
1). Ima and Mann experi­mented with the size of the lightbar and the colours of the LEDs, and found that 
the use of blue LEDs resulted in signif­icantly less steering error than red LEDs, and that steering 
improved with the size of the lightbar. In the periphery, icon colour and icon size must be carefully 
chosen. 2.1 Peripheral Vision and Games Both the alert-based and streaming-information styles of pe­ripheral 
displays are widely used in computer games. Fig­ure 2 shows a display from the game Eve Online.The left 
image is what is displayed on the player s screen. Signi.cant information is displayed in the periphery: 
 Chat messages appear in the lower-left corner. When a new chat message arrives, the chat tab blinks, 
pro­viding an alert to the player.  A column of buttons runs along the left side of the dis­play. As 
events occur, these buttons .ash, indicating, for example, the arrival of mail, the sale of an item in 
the galactic market, or the completion of training of a skill.  A box in the upper-right corner of the 
screen shows a list of all other ships, stations or items in the player s vicinity. When ships with bad 
reputation arrive in sensor range, their line on this display blinks red, alert­ing the player to a possible 
dangerous situation.  Therightimageshowshowtheeye perceivesthisdisplay, while .xated on the centre 
of the image. The centre of the display is in full resolution. Detail progressively decays with distance 
from the centre. Alerts such as red, .ashing text will be visible, but the text itself is not legible 
unless the player shifts his visual focus. Analogous peripheral displays can be found in many real­time 
strategy and .rst-person shooter games where a mini­mapisusedtodisplay atop-downoverviewofthe vicinity. 
 Figure 2: A display from CCP s Eve Online (left), and what the eye perceives when focusing on the centre 
of the display (right). Similarly to .gure 2, the contents of mini-maps cannot be seen while the player 
is .xating on the centre of the display; mini-maps are often used to convey .ashing alerts to engage 
the player s attention. An interesting entry to the area of peripheral displays for games is Nintendo 
s DS portable game platform (.gure 3.) The DS has two physically separate displays. In the Mario Kart 
DS game, one display shows a third person view, while the other shows a top-down overview. Only one display 
can be visually processed at a time, so the player must shift attention between them. We see from these 
examples that games frequently use dis­plays that appear in the player s periphery. It is therefore important 
for game developers to understand how such dis­plays are best designed. 2.2 Guidelines for Design of 
Peripheral Dis­plays From our knowledge of the physiology of the eye and from the results of earlier 
researchers, we can propose some simple guidelines for the design of displays intended to be perceived 
in the periphery. Increase size of visual elements: As visual elements move further into the periphery, 
they must be larger to be perceived in the same way [11]. Reduce reliance on colour: In the periphery, 
there are fewer cones than in the fovea. As cones are the eye s receptors for colour, peripheral displays 
should avoid reliance on colour. Ima and Mann found that blue Figure 3: Nintendo s DS handheld computer 
o.ers color is better than red in attracting the attention of two displays. When a player focuses on 
one display, subjects, and would, therefore, be better in the design the other is in the periphery. of 
peripheral displays [6]. In general, short wavelength lights are better perceived in the periphery than 
long wavelength lights.    Figure 4: Experimental set-up: a Tobii eye tracker is used to determine 
where the players are looking during experiments. Use motion: The periphery has far more rods than cones. 
Rods are e.ective at perceiving motion. There­fore, motion may be a useful peripheral indicator.  3. 
CASE STUDIES In order to demonstrate how these guidelines can be applied, we have created two example 
games that visually encode information for viewing in the periphery. Both games at­tempt to convey streaming 
information to the player rather than simple alerts. The .rst, CoOp Tetris, was unsuccess­ful, showing 
how following the standard design guidelines is insu.cient to guarantee a successful peripheral display. 
The second, City Flyer, successfully conveys information in a peripheral display. We .rst discuss the 
equipment we used to test the games, then introduce their designs, and .nally discuss what these games 
teach us about the design of pe­ripheral displays. 3.1 Experimental Equipment We tested both games using 
a PC equipped with a Tobii eye tracker (.gure 4). The eye tracker recorded where the subjects were looking 
while playing the game, allowing us to determine whether they were accessing information using their 
peripheral vision, or instead looking directly at the pe­ripheral display. The Tobii eye tracker runs 
at 50 Hz with an accuracy of 0.5 degrees. This means that when subjects are seated a normal distance 
from the monitor, the eye tracker records the focus of their gaze within an accuracy about the size of 
a quarter. The eye tracker works by beaming infrared light at the subject, and triangulating the re.ection 
of this light from the subject s pupils via cameras with infrared .l­ters. Players were seated 46 cm 
from a 34 computer display. A chin rest was used to ensure that players position remained constant with 
respect to the display. Both games were instrumented to log where players were looking throughout the 
game session. Positions were recorded as coordinates relative to the upper-left corner of the display. 
 3.2 Example: CoOp Tetris Many computer games involve cooperative play, where play­ers must coordinate 
their activities to be successful. For ex­ample, in real-time strategy games, players must be aware of 
their teammates movements, resource gathering, and com­bat. In a World of Warcraft battleground, players 
must be aware of their teammates locations, targets and health. Our .rst example game explored whether 
a peripheral dis­play can be used to convey awareness in a computer game. Providing awareness of other 
players activities is an ideal application of peripheral displays: the player s foveal view can be reserved 
for his central game task, while the periph­ery can be used to represent the state of his teammates. 
We designed and implemented CoOp Tetris to use a periph­eral display to represent teammate awareness 
information. We intended that the use of the peripheral display would in­crease players performance in 
a cooperative task, and that players would prefer the specially-encoded peripheral display to a standard 
display. This design did not succeed in these goals: performance did not improve when the peripheral 
display was available (and in some cases actually degraded.) Furthermore, players reported that they 
preferred the stan­dard display. These results indicate the di.culties involved in designing a peripheral 
display, and highlight the impor­tance of careful design and experimentation. Our study il­lustrates 
that simply providing a peripheral display does not guarantee that either players performance or enjoyment 
of the game will improve. CoOp Tetris is a two-player version of Tetris in which play­ers collaborate 
to maximize their scores. While there are numerous multiplayer Tetris games, CoOp Tetris is the only 
version of the game of which we are aware where players co­operate rather than compete. The goal in the 
standard game of Tetris is to position falling blocks of di.erent shapes so as to form solid horizontal 
lines. Additional points are given for forming multiple solid lines simultaneously. The game ends when 
the player s game well is .lled up so that there is no remaining space for new pieces to occupy. Our 
cooperative version extends Tetris by allowing two play­ers to play simultaneously. The score for the 
game is the sum of both players scores, and play terminates when one player has lost. Therefore, it is 
in each player s interest for the other player to play successfully. Play is cooperative in that the 
score is the sum of the players scores and that a loss by one player is a loss by both.  Figure 5: 
CoOp Tetris: The well on the left shows the player s own view; the well on the right shows the well of 
the player s partner.  Figure 6: CoOp Tetris where where the display of the partner s well is encoded 
for viewing in the pe­riphery. Figure 5 shows CoOp Tetris, where both players game wells are shown side-by-side 
on the same screen. The player con­trols the left game well, and the right game well is controlled by 
the player s partner. The right game well is a form of awareness display, allowing the player to see 
the state of his partner s game. If the player focuses on his own game well, the awareness display will 
appear in his periphery. The dis­play in .gure 5 is the same as the partner s primary display, and is 
therefore not specially encoded for peripheral view. As described so far, the game allows two people 
to play together, but does not allow them to cooperate.We further extend the game to allow players to 
swap pieces as they are falling. Either player can invoke a swap by pressing the space bar. The other 
player is not given any choice as to whether the swap takes place, but can of course use her own swap 
key to change the pieces back. Invoking swap causes the two players falling pieces to be exchanged. The 
pieces remain in the same orientation. A piece that is swapped is positioned at the same height and horizontal 
position as the piece that it replaces. The only communication between the two game wells is through 
swapping. Swapping introduces interesting dynamics to the game. In Tetris, players frequently wait for 
a particular piece in order to complete a row or set of rows. If the player s partner receives that piece, 
swapping can allow the player to make the desired move, increasing his score. To take advantage of this 
potential for swapping, players must be aware of the other player s current piece. Since the game is 
cooperative, it is not su.cient just to know what is the other player s piece. Sometimes, initiat­ing 
a swap can harm the partner more than it helps the player. Perhaps the partner was waiting for the same 
piece, or perhaps the swap will confuse the partner, leading her to make a poor move. It is particularly 
bad to swap when the partner s piece is nearing its destination or when the partner s pile of dropped 
pieces is high. Therefore, players require more detailed knowledge of the partner s game state, indicating 
how much a swap will inconvenience the partner, allowing the player to balance the bene.t to him against 
the harm to his partner. 3.2.1 Peripheral Encoding of Awareness Information The game display of .gure 
5 provides su.cient information for players to decide whether it is helpful to swap pieces. Since the 
player sees the entire state of his partner s game well, he can see whether the piece is one of particular 
use to the partner, how close the piece is to the bottom of the game well, and how much space the partner 
has left in her well. Therefore, the player has all necessary information to judge the impact of swapping 
on his partner. While all necessary information is present, however, the problem is that it may not be 
easy for player to take ad­vantage of it. The partner s well falls within his peripheral vision and therefore, 
the player has to move his focus from his own well to the partner s well to decide whether to swap. His 
lack of attention to his own well in the meantime may negatively impact his performance. We therefore 
created a new version of the partner s well intended for view in the periphery. The goal is that players 
should be able to .xate on their own well at all times, while gaining awareness in­formation through 
their peripheral vision. The peripheral encoding is a simpli.ed presentation of the normal game well. 
It does not add new information and does not syn­thesize views from multiple sources of existing information. 
Figure 6 shows the encoded version of the game. We encode three things that are critical to deciding 
when to swap pieces: the shape of the partner s falling piece; the height of the partner s pile of dropped 
pieces; and the dis­tance of the partner s falling piece to its destination directly below. Three peripheral 
icons are used, following the guidelines listed in section 2.2. The partner s falling piece is enlarged, 
since larger items are detected more easily in the periphery. A spinning rod is used to show the distance 
of the partner s piece to its destination below; as the distance increases, the rod spins faster. This 
takes advantage of the fact that mo­tion is easily detected in the periphery. Finally, a vertical thermometer-like 
gauge is used to show the height of the partner s pile of dropped pieces.  Figure 7: City Flyer: Players 
attempt to .y over a city while avoiding bombs. When a square appears in the peripheral display, pressing 
the space bar gives a brief speed boost. 3.2.2 CoOp Tetris: Results Results of experimenting with CoOp 
Tetris were disappoint­ing. We found no signi.cant di.erence in players scores be­tween the detailed 
and encoded versions. When surveyed, players indicated no clear preference between the detailed and encoded 
versions. Worse, we found that players using the encoded display attained lower scores than in our con­trol 
case of a single-player version of the game. That is, use of the peripheral display actually lowered 
players scores. A survey of Co-Op Tetris players indicated that most did not use the vertical bar (representing 
the height of the part­ner s pile of dropped pieces.) Most reported that, while they could sense the 
spinning bar (representing the distance of the partner s piece to it s destination), they did not use 
it. Subjects principally used the large version of the partner s piece to decide when to swap, taking 
no account of whether this would harm the partner s gameplay. CoOp Tetris display was successful in that 
players could correctly perceive the information it showed. However, in the heat of gameplay, they did 
not use this information be­yond the most simple use of the large symbol showing the partner s current 
piece. We believe that this problem hinged on the limit of players attention. Just to manage their own 
well, players need to keep track of the current falling piece, determine where best to put it, and maneuver 
it ap­propriately. As the game speeds up, this consumes all of the player s attention. Even though players 
can in theory keep track of the state of their partner s well, in practice they do not have su.cient 
cognitive capacity to do so without sacri.cing the quality of play in their own game well. This indicates 
a signi.cant limitation in presenting stream­ing information in a peripheral display. Players attending 
to a primary task must have su.cient cognitive resources to be able to attend to the information presented 
in this peripheral display in addition to their primary task. The following section shows an example 
of a successful game where the demands of the peripheral display have been de­signed to be considerably 
lower. 3.3 Example: City Flyer Figure 7 shows City Flyer, our second attempt at a game in which streaming 
peripheral information is used. In City Flyer, players attempt to navigate a city landscape without being 
destroyed. Players scores are based on the distance they traverse before being hit with a bomb. The player 
controls a ship represented as a box at the bottom of the display. Arrow keys are used to move the ship 
left and right. The city landscape scrolls vertically, giving the player the sense of travelling. The 
player must avoid bombs of di.erent shapes, sizes and speeds as they cascade down the screen. As the 
game progresses, its di.culty increases by presenting more and faster bombs. A shape display shows a 
set of shapes (circles, triangles and squares) that continuously morph from one to another. Figure 7 
shows a triangle that is in the process of morphing into a square. The ordering of shapes is randomized 
so that players cannot predict when a particular shape will next ap­pear. When the display shows a square, 
if the player presses the space bar, he receives a brief speed boost, thereby allow­ing him to travel 
more distance and consequently increase his score. If the player makes a mistake and presses the space 
bar when the second display is not showing a square, his speed is brie.y slowed, reducing his score. 
Therefore, it is to the player s advantage to attend to the information in the shape display. However, 
the brief speed boost is not worth risking being hit by a bomb, so players must retain their attention 
on the primary display. In testing City Flyer, we found that Based on eye tracking information, players 
do use the second display as a peripheral display. They retain their visual focus on the main display, 
and make deci­sions about the content of the shape display without directly looking at it.  Players 
accuracy with the shape display is close to 100%. That is, players rarely press the space bar at a time 
when there is no square in the second display.  At easier levels, players tend to correctly identify 
and use all squares that appear in the shape display. As the game progresses and becomes more di.cult, 
how­ever, players cease using the information in the shape display. That is, they allow squares to come 
and go in the shape display without reacting to them.  We consider these observations to indicate that 
the shape display is a successful peripheral display. Players are able to use the shape display without 
directly looking at it. At lower levels, players are able to process the information from the shape display. 
However, as the game progresses, all of their attention is required to simply stay alive, and so information 
from the shape display is no longer processed. 3.4 Discussion We have proposed that game information 
should be encoded according to its position in the fovea or periphery. Our case studies show that players 
.nd it challenging to process infor­mation presented in the periphery when the game s central task is 
consuming all available cognitive resources. In the design of peripheral displays, care should be taken 
to follow the design guidelines presented in section 2.2. As was seen in .gure 2, most visual information 
appearing at the edges of displays cannot be perceived if the player is viewing the centre of the display. 
If the designer s goal is simply to alert players to important events and draw their attention to another 
part of the display, then it is su.cient to provide .ashing or animated alerts. The more di.cult (and 
more interesting) case is where the designer wishes to provide streaming information that the player 
will continu­ously perceive in the periphery without diverting attention from the central task. Our guidelines 
suggest that using techniques such as increasing size of information and using motion help a great deal. 
However, as illustrated by our CoOp Tetris game, these tech­niques alone are not su.cient. Players attention 
is lim­ited. If games provide an overload of information, they will not have su.cient cognitive power 
to process it, even if the player can correctly interpret the display. Our City Flyer game allowed us 
to see that this cognitive overload is pro­gressive as players advance in level, they become so busy 
with the central task of avoiding bombs that they cease to be able to use the information in the peripheral 
display. It is important for designers to understand the bene.ts that pe­ripheral encoding can bring 
while recognizing peoples limits in how much information they can process and react to.  4. CONCLUSION 
We have discussed the importance of designing game dis­plays to take account of the capabilities of the 
human visual system. Much information shown in game displays cannot be seen in full resolution by game 
players who are focused on their central game task. We have discussed the design of two games. The .rst, 
CoOp Tetris, showed that despite fol­lowing the standard rules for design of peripheral displays, players 
could not process information better than using a fully detailed display. The second, City Flyer, showed 
that it is possible to design peripheral displays that are e.ective up to the point that the player s 
cognitive resources are con­sumed. From this we conclude that it is pro.table to encode information in 
the extremes of the display in forms that are suitable for viewing in peripheral vision, but that designers 
must perform considerable experimentation to ensure that such designs are e.ective. Acknowledgments We 
gratefully acknowledge the support of the Natural Sci­ence and Engineering Research Council and the NECTAR 
research network in carrying out this work. The design of the CoOp Tetris and City Flyer games greatly 
bene.ted from the feedback of our colleagues in the EQUIS laboratory. We thank Niko Troje for his help 
in the design of our experi­ments, and the Queen s Biological Communication Centre for the use of their 
laboratory facilities. 5. REFERENCES [1] Altosaar, M., Vertegaal, R., Sohn, C., and Cheng, D. Auraorb: 
using social awareness cues in the design of progressive noti.cation appliances. In OZCHI 06 (2006), 
ACM Press, pp. 159 166. [2] Dahley, A., Wisneski, C., and Ishii, H. Water lamp and pinwheels: ambient 
projection of digital information into architectural space. In CHI 98 conference summary on Human factors 
in computing systems (1998), ACM Press, pp. 269 270. [3] De Guzman, E. S., Yau, M., Gagliano, A., Park, 
A., and Dey, A. K. Exploring the design and use of peripheral displays of awareness information. In CHI 
04 extended abstracts on Human factors in computing systems (2004), pp. 1247 1250. [4] Duchowski, A., 
Cournia, N., and Murphy, H. Gaze-contingent displays: A review. CyberPsychology and Behaviour 7, 6 (2004), 
621 634. [5] Hecht, E. Optics, 2nd edition. Addison Wesley, 1987. [6] Ima, C., and Mann, D. Lightbar 
design: The e.ect of light color, lightbar size and auxiliary indicators on tracking and monitoring performance. 
Agricultural Engineering International ERG 03, 1 (2003). [7] Loschky, L., and McConkie, G. User performance 
with gaze contingent multiresolutional displays. In Eye Tracking Research Symposium (2000), pp. 97 103. 
[8] Maglio, P. P., and Campbell, C. S. Tradeo.s in displaying peripheral information. In CHI 00:  Proceedings 
of the SIGCHI conference on Human factors in computing systems (2000), pp. 241 248. [9] Mankoff, J., 
Dey, A., Hsieh, G., Kientz, J., Lederer, S., and Ames, M. Heuristic evaluation of ambient displays. In 
ACM CHI (2003), pp. 169 176. [10] Shen, X. An intrusive evaluation of peripheral display. In Proceedings 
of the 3rd International Conference on Computer Graphics and Interactive Techniques in Australasia and 
Southeast Asia (2005), pp. 289 292. [11] Virsu, V., Nasanen, R., and Osmoviita, K. Cortical magni.cation 
and peripheral vision. Journal of the Optical Society of America A 4, 8 (1987), 1568 1652.   
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2007</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	</section>
	<section>
		<section_id>1328216</section_id>
		<sort_key>140</sort_key>
		<section_seq_no>4</section_seq_no>
		<section_type>SESSION</section_type>
		<section_title><![CDATA[Psychology ("mind games")]]></section_title>
		<section_page_from>77</section_page_from>
	<article_rec>
		<article_id>1328217</article_id>
		<sort_key>150</sort_key>
		<display_label>Pages</display_label>
		<pages>6</pages>
		<article_publication_date>11-14-2007</article_publication_date>
		<seq_no>1</seq_no>
		<title><![CDATA[Video game play]]></title>
		<subtitle><![CDATA[effects on nighttime dreams]]></subtitle>
		<page_from>77</page_from>
		<page_to>82</page_to>
		<doi_number>10.1145/1328202.1328217</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1328217</url>
		<abstract>
			<par><![CDATA[<p>Two sets of content analyses were computed on 56 dreams of 27 hard core video game players gathered during semi-structured interviews in the winter term of 2006 at a Canadian college. The standard dream content analysis system from Hall and VandeCastle [19] was used to analyze these dreams as was another content analysis focused upon lucid/control dreaming. As expected gamers dreamt about gaming and indeed well over half of the dreams reported included easily recognized references to games. Since emotional regulation is thought to be a central feature of dreams, emotions of gaming which range from joy to anger and sadness were investigated in their social contexts in dreams with mixed results. Although gamers evidenced more self negativity in these dreams other indicates of positive emotional environments were present. If hard core gaming created distorted world views at a deep level of consciousness (i.e., in dreams) then this would be expected to appear in their dreams. However, despite the differences from norms, the overall picture is one of dreams reflecting game play while not dramatically distorting their emotional lives as depicted in dreams.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[consciousness]]></kw>
			<kw><![CDATA[dreams]]></kw>
			<kw><![CDATA[lucid dreams]]></kw>
			<kw><![CDATA[video games]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>A.1</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10002944.10011122.10002945</concept_id>
				<concept_desc>CCS->General and reference->Document types->Surveys and overviews</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002944.10011122.10002945</concept_id>
				<concept_desc>CCS->General and reference->Document types->Surveys and overviews</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Human Factors</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP43128749</person_id>
				<author_profile_id><![CDATA[81342495027]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Jayne]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Gackenbach]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Grant MacEwan College, Edmonton, Alberta]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P925236</person_id>
				<author_profile_id><![CDATA[81342503935]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Ian]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Matty]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Grant MacEwan College, Edmonton, Alberta]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P925219</person_id>
				<author_profile_id><![CDATA[81342501248]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Bena]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kuruvilla]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Grant MacEwan College, Edmonton, Alberta]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Anderson, C. A. and Dill, K. E. 2000. Video games and aggressive thoughts, feelings, and behavior in the laboratory and in life. Journal of Personality and Social Psychology, 784, 772--790.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Barrett, D. 2001. Trauma and dreams. Cambridge, MA: Harvard University Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Belicki, K. Recalling dreams. an examination of daily variation and individual differences. In: Gackenbach, J. Ed Sleep and Dreams: a Sourcebook. Garland, New York, 1986: 187--206.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Bertolini, R. and Nissim, S. 2002 Video games and children's imagination. Journal of Child Psychotherapy, 283, 305--325.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Blackmore, S. 2004 Consciousness: An introduction. NY: Oxford University Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Bulkeley, Kelly 2004 Dreaming is play II: Revonsuo's threat simulation theory in Ludic context. Sleep and Hypnosis, 63, 119--129.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Foulkes, David 2002 Children's Dreaming and the Development of Consciousness. Cambridge, MA: Harvard University Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Gackenbach, J. I. 1988 The psychological content of lucid dreams. In J. I. Gackenbach and S. P. LaBerge Eds., Conscious mind, sleeping brain: Perspectives on lucid dreaming, N.Y.: Plenum.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Gackenbach, J. I. 2006 Video Game Play and Lucid Dreams: Implications for the Development of Consciousness. Dreaming, 162, 96--110.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Gackenbach, J. I. and Kuruvilla, B. 2007 Dreams and Media Use. Paper presented at the annual meeting of the International Association for the Study of Dreams, Sonoma, CA. (June 2007) Retreived Sept. 20, 2007 from www.spiritwatch.ca.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Gackenbach, J. I., Snyder, T. J., Rokes, L., and Sachau, D., 1986 Lucid dreaming frequency in relationship to vestibular sensitivity as measured by caloric stimulation. In R. Haskel Ed. Cognition and Dream Research: The Journal of Mind and Behavior special issue, (7) 2and3, 277--298.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Greenfield, P. M, Brannon, C. and Lohr, D. 1996 Two-dimensional representation of movement through three-dimensional space: The role of video game expertise. In P. M. Greenfield and R. R. Cocking Eds., Interacting with video. Advances in applied developmental psychology, 11, pp. 169--185. Norwood, NJ: Ablex Publishing.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Kramer, Milton 2007 The dream experience: A systematic exploration. New York, NY, US: Routledge/Taylor and Francis Group.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[LaBerge, Stephen and Gackenbach, Jayne 2000 Lucid dreaming. In Cardena, Etzel Ed; Lynn, Steven Jay Ed; Krippner, Stanley Ed. Varieties of anomalous experience: Examining the scientific evidence. Washington, DC, US: American Psychological Association pp. 151--182.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Miles, M. and Huberman, A. 1994 Qualitative Data Analysis. Second edition. Thousand Oaks, CA: Sage.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Nielsen, Tore A., Saucier, Sebastien, Stenstrom, Philippe, Lara-Carrasco, and Jessica, Solomonova, Liza 2007 Interactivity in a virtual maze task enhances delayed incorporations of maze features into dream content. Paper presented at the 21st Annual Meeting of the Associated Professional Sleep Societies, Minneapolis. (June 2007)]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Nielsen, Tore, Kuiken, Don, Ve Alain, Genevie, Stenstrom, Philippe, and Powell, Russell 2004 Immediate and delayed incorporations of events into dreams: Further replication and implications for dream function. Sleep Research, 13, 327--336.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Preston, J. 1998 From mediated environments to the development of consciousness. In J. I. Gackenbach Ed., Psychology and the Internet. San Diego: Academic Press, p. 255--291.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Revonsuo, A. 2006 Inner Presence: Consciousness as A Biological Phenomenon. Cambridge, MA: MIT Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Schneider, A., and Domhoff, G. W. 2006 The Quantitative Study of Dreams. Retrieved December 10, 2006 DOI=http://www.dreamresearch.net/.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Schredl, M., Anders, A., Hellriegel, S. and Rehm, A. 2006 TV viewing, computer game playing and nightmares in school children. Dreaming, under editorial review.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Stickgold R, Malia A, Maguire D, Roddenberry D, and O'Connor M. 2000 Replaying the game: Hypnagogic images in normals and amnesics. Science, 2905490, 350--353.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[VandeCastle, Robert 1994 Our Dreaming Minds. NY: HarperCollins.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[Van den Bulck, J. 2004 Media use and dreaming: The relationship among television viewing, computer game play, and nightmares or pleasant dreams. Dreaming, 141, 43--49.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[Wright, J. and Koulack, D. 1987 Dreams and contemporary stress: A disruption-avoidance-adaptation model. Sleep, 10, 172--179.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Video Game Play: Effects on Nighttime Dreams Jayne Gackenbach gackenbachj@macewan.ca Ian Matty olgc@shaw.ca 
Bena Kuruvilla KuruvillaB0@mymail.macewan.ca Department of Psychology Grant MacEwan College 6-394, 10700 
- 104 Avenue Edmonton, Alberta T5J 4S2 708-633-3892 ABSTRACT Two sets of content analyses were computed 
on 56 dreams of 27 hard core video game players gathered during semi-structured interviews in the winter 
term of 2006 at a Canadian college. The standard dream content analysis system from Hall and VandeCastle 
[19] was used to analyze these dreams as was another content analysis focused upon lucid/control dreaming. 
As expected gamers dreamt about gaming and indeed well over half of the dreams reported included easily 
recognized references to games. Since emotional regulation is thought to be a central feature of dreams, 
emotions of gaming which range from joy to anger and sadness were investigated in their social contexts 
in dreams with mixed results. Although gamers evidenced more self negativity in these dreams other indicates 
of positive emotional environments were present. If hard core gaming created distorted world views at 
a deep level of consciousness (i.e., in dreams) then this would be expected to appear in their dreams. 
However, despite the differences from norms, the overall picture is one of dreams reflecting game play 
while not dramatically distorting their emotional lives as depicted in dreams. Categories and Subject 
Descriptors A.1 [General Literature] General - introductory and survey General Terms Human Factors, 
Theory  Keywords Video games, dreams, lucid dreams, consciousness 1. INTRODUCTION Video game play effects 
have been viewed from a variety of perspectives. These range from the concerns regarding aggression in 
real life [1] to the claims of enhanced cognitive skills [12]. Few researchers have examined their effects 
on night time dreams. In part this is due to western cultures shunning of dreams as an unimportant element 
in the life of the mind [22]. Permission to make digital/hard copy of part of this work for personal 
or classroom use is granted without fee provided that the copies are not made or distributed for profit 
or commercial advantage, the copyright notice, the title of the publication, and its date of appear, 
and notice is given that copying is by permission of the ACM, Inc. To copy otherwise, to republish, to 
post on servers, or to redistribute to lists, requires prior specific permission and/or a fee. FuturePlay 
2007, November 15-17, 2007, Toronto, Canada. Copyright 2007 ACM 978-1-59593-943-2/07/0011...$5.00 However, 
scientific research in the last half century has established that dreams are important for memory consolidation, 
emotional regulation and general information processing. Even though most people in North America do 
not remember their nightly dreams [3] they all dream every night from 4 to 5 times and this nighttime 
mentation is doing it s job. The question in this paper is what are the effects of hard core video game 
play on these experiences of the night? Are the effects simply alterations in dream content or are their 
more substantial effects? Finally what are the implications of any effects on dreams for waking life? 
The importance of nighttime dreams has come a long way since the days of Freud s 1900 Interpretation 
of Dreams where he claimed that dreams were the royal road to the unconscious. Although Freud did a lot 
for introducing the serious study of dreams into a culture that rejected them as unimportant, he also 
labeled dreams as the area where the individual s unconscious instinctual impulses are stored. Since 
the discovery of rapid eye movement and the development of sensitive electrophysiological recording techniques, 
this one sided view, which essentially pathologizes dreams, has changed. In the last half century a body 
of work, while not absent of controversy, has generally shown that nighttime dreams are functional to 
the life of the brain. Various researchers have postulated dream functions and these include adaptation 
to stressful events [24] or the lack thereof as in the case of post traumatic stress nightmares [2]. 
Emotional regulation has been viewed as a central function of dreams beyond just stress response integration 
[13]. Evidence for memory consolidation comes most recently from a virtual maze task which was then dreamt 
about that night and a week later [17]. An evolutionary theory is that of Revonsuo [19] who postulates 
that themes concerned with ancestral and current survival threats should be prevalent in dreams. Finally, 
dreams as practice for later events, is a view which has also received empirical and theoretical attention 
[6]. Furthermore, it has been suggested that dreams offer a better model of the nature of consciousness 
itself than the currently favored visual attention model [19]. This function is particularly important 
in this inquiry as Revonsuo suggests that both dreams and virtual reality (VR) simulations are world 
simulations that result in models of self in the world. In other words, Revonsuo notes that we can conclude 
from our experience of dreams and VR, where self is in an artificially generated world (biologically 
driven in dreams and technologically driven in VR), that normal waking reality is also a world simulation 
. This is one of various bodies of work that have taken the position that self in the world is a creation 
[5]. In any case, these models of self in the world (dreams, VR, waking reality) impact each other and 
sometimes in profoundly. For instance, the nightmares of trauma victims often wake them from sleep, making 
it difficult to cope with the trauma, no less get back to sleep. Sometimes the impact between these experiences 
of self as a construction is less profound, such as in playing a video game for so long that standing 
up from the sofa results in dizziness as one acclimates to the new world of waking reality from that 
of VR. In the present inquiry the dreams of hard core video game players were examined in order to see 
if their dream content was potentially affected by game play and if so how. Also of concern are the implications 
of any dream changes resulting from game play. Some previous research on video gaming and dreams has 
found such a relationship. Specifically, [24] found that computer games were less likely to show up in 
nightmares than television but that computer games were also present in pleasant dreams for the children. 
Players of the puzzle type game called Tetris reported intrusive, stereotypical, visual images of the 
game at sleep onset [22]. Bertolini and Nissim [4] recognized fragments or characters from the video 
games in the material of children s dreams. Finally, Nielsen, et al, [16] found that a VR maze task showed 
increased incorporation into dreams when actively engaged in with a computer mouse than when passively 
watched on TV. While these studies suggest that yes video game content is incorporated into dreams it 
is important to consider the implications of such incorporation. So for instance, Schredle, et al [21] 
reported that interindividual differences in nightmare frequency were not explained by interindividual 
differences in TV viewing or computer game playing habits of 11 to 13 year olds. In other words, contrary 
perhaps to parental concerns about excessive game play, playing computer games in children does not cause 
nightmares as watching some types of horror movies which does affect subsequent dreams in children [7]. 
Nielsen et al s [16] finding has implications for memory consolidation in terms of various time based 
cycles. Bertolini and Nissim [4] concluded that due to this radical change in children s play patterns, 
i.e. playing video games, they must now incorporate such game play into their child therapy practice. 
Thus video games seem to be affecting dreams and these affects have theoretical as well as practical 
implications. Another dream change that seems to be occurring as a function of video game play is the 
emergence of lucidity in gamers dreams [9]. That is, gamers report knowing they are dreaming during the 
dream more so than others. This dream experience can be viewed as a metacognitive skill or as an example 
of enhanced self awareness [14]. Relatedly, Gackenbach [9] has also found that gamers evidence more dream 
control. Both lucidity and control, one could argue, come directly from practice in the world simulation 
during waking of VR (game play) translating into the world simulation of dreams that night. In other 
words, if you are used to knowing you re in an artificial reality while gaming it s not such a stretch 
that such awareness becomes learned and then applied in sleep to the artificial reality called dreams. 
Based upon previous research it is hypothesized that hard core gamers will evidence gaming related images 
in their dreams and that such images will illustrate the emotional regulation dream function. Secondly, 
fundamental structural characteristics of their dreams will also occur. That is, they will be more likely 
to know they are dreaming and to control their dreams.  2. METHOD The type of inquiry used in this study 
is a qualitative approach which allows a relatively open ended inquiry with limited assumptions [15]. 
The limits of this type of inquiry is that one must always be aware of experimenter bias which becomes 
part of the data collected in the form of notes by the researcher. However the strength is that it allows 
information to be gathered without the constraints of typical quantitative data gathering approaches. 
Subjects were solicited through posters placed around campus which listed the selection criteria (see 
below) and explained that participants would be interviewed both about their video gaming experiences 
and their nighttime dreams. Twenty-seven hard core college student gamers were interviewed in a face 
to face setting in the first authors office. Four of the 12 interview questions dealt with dreams and 
thus 56 dreams were collected from 27 high end gamers. The gamers who were interviewed had to report 
playing video games several times a week with a typical playing session of about 2 hours. They also had 
to have played 50 or more games and to have begun such video game play in grade 3 or earlier. Thirty 
three individuals answered the advertisements for participants over a two month period in early 2006. 
They agreed to be interviewed with 27 actually being interviewed. These included 25 men and two women 
with 85% of those being 25 years of age or younger; 12 participants were 19 years old or younger and 
11 gamers were 20 to 25 years of age. Three of the interviewees were between 25 and 30 and one was between 
30 and 39 years of age. When interviews were scheduled, either by phone or email, the selection criteria 
were confirmed. They were again confirmed, after signing an informed consent, upon the participant s 
arrival in the first authors office for the face to face actual interview. The interview was semi-structured 
beginning with questions about the players favorite and most frequently played games. Following these 
closed ended questions a series of open ended questions were asked in the same order. Each question was 
followed by prompts which may or may not have been used depending on how forthcoming the interviewee 
was with their answers. The order of the questions was from the least psychologically invasive to the 
most. Thus the questionnaire started with confirmation of game play frequency type questions, gender 
and age. Type of game play preferences information was next followed by various open ended inquiries 
into the gamers experiences of self during play. Then a series of question regarding dreams was asked 
and finally ones about altered states of consciousness while playing were inquired about. The dream questions 
included: Do video games come up in your dreams? If so how?; Tell me your most recent dream.; Tell me 
your most recent dream which in some way included video games.; Finally, would you tell me you re most 
noteworthy video game dream? It is important to note that while lucidity and control, among other things, 
were probed for (i.e., When did you have this dream? Were video games in some way part of the dream? 
Was it lucid? Could you control it? Were you watching the action?), it was only after the dream was told 
to the interviewer. There were no direct inquires for gamers to report lucid or control dreams. The 
entire audio taped interviews were transcribed including the dream portions. For the purposes of the 
present inquiry the dream portions, including discussions of the dreams and follow­up prompts were separated 
out for content analysis.  3. RESULTS These dreams were content analyzed in two ways. First the Hall 
and Van de Castle system as delineated by Schneider and Domhoff [20] was used. Analyses were computed 
using the latter s DreamSAT spreadsheet which analyzes the codes and automatically generates percentages 
and group-profiles. Since all but two of the interviewees were male, norm comparisons were for males 
only. Two coders were trained on eight dreams until they attained congruence in coding. Percent matches 
averaged 77% agreement. The remainder of the dreams were randomly assigned to each coder for the remaining 
dream coding. The second content analysis was done by a third coder based upon a system of coding taken 
from the interview questions and elaborated upon from the literature on dream lucidity and dream control 
(i.e., summarized in Gackenbach [8]). In this content analysis, the same 56 dreams from these hard core 
gamers were coded in terms of palpable sensations, balance, video game or media content, lucidity, control 
and observer perspectives. These were content variables not available in a Hall and VandeCastle approach 
to content analysis. 3.1 Hall and VandeCastle Analysis The most comprehensive analysis is presented in 
Table 1 below which lists some of the various subscales of the Hall and VandeCastle approach with the 
percent of each category evidenced in the gamer interview dreams relative to male norms. The number of 
instances for each set of dreams is also given as N . Finally the p values are listed comparing these 
hard core gamers to male norms. Subscale Interview series Male Norms p vs. males N for Inter-views N 
for Male Norms Characters Male/Female Percent 67% 67% .937 45 873 Familiarity Percent 58% 45% * .026 
81 1108 Friends Percent 16% 31% ** .002 81 1108 Family Percent 15% 12% .429 81 1108 Dead &#38; Imaginary 
Percent 21% 00% ** .000 92 1180 Animal Percent 04% 06% .485 92 1180 Social Interaction Percents Aggression/Friendliness 
Percent 100% 59% ** .000 25 546 Aggressor Percent 33% 40% .598 18 253 Physical Aggression Percent 86% 
50% ** .000 35 402 Settings Indoor Setting Percent 47% 48% .805 43 586 Familiar Setting Percent 56% 62% 
.560 32 320 Self-Concept Percents Self-Negativity Percent 84% 65% * .028 25 809 Bodily Misfortunes Percent 
00% 29% * .024 4 205 Negative Emotions Percent 81% 80% .941 16 282 Dreamer-Involved Success Percent 40% 
51% .496 10 141 Torso/Anatomy Percent 27% 31% .720 22 246 Dreams with at Least One: Aggression 32% 47% 
* .023 57 500 Friendliness 02% 38% ** .000 57 500 Sexuality 00% 12% ** .000 57 500 Misfortune 07% 36% 
** .000 57 500 Good Fortune 00% 06% ** .000 57 500 Success 09% 15% .165 57 500 Failure 09% 15% .142 57 
500 Striving 18% 27% .102 57 500 Table 1: Hall and VandeCastle Content Analysis Results The largest 
effect size for these video game players dreams was evidenced in higher dead and imaginary characters, 
aggression/friendless percentage and physical aggression than the Hall and Van de Castle norms. Large 
effect sizes were also found where gamer s dreams were lower in bodily misfortunes and lower in dreams 
with at least one instance of friendliness. Several other variables also showed significant deviations 
from the norms. Gamer s dreams had more familiar but fewer friendly characters. In addition to what has 
been mentioned, dreams with at least one element, which differed significantly from the norms, included 
fewer aggression, sexuality, misfortunes and good fortunes. Interestingly although there was more physical 
aggression in their dreams overall and a higher aggression/friendless percent overall, when examined 
in terms of the number of dreams reporting at least one instance there were significantly fewer aggressive 
dreams with one instance of aggression than the norms. In part this may be due to the low sample size 
of dreams but it may also be that when gamer s dream of aggression there is more of it in those dreams 
but they don t dream of it as often. However, this aggressiveness theme is also evidenced in the fewer 
friends relative to the norms. Interestingly, the fewer bodily misfortunes would seem to indicate that 
they are winning at their aggressive dream battles. This is not surprising given all their practice while 
awake in virtual reality battles. That is, the majority of the interviewees expressed a preference for 
role playing games with a battle motif (i.e., World of Warcraft) or first person shooters. However, this 
interpretation is somewhat at odds with the gamer higher self­negativity percent. In terms of the positive 
social interactions, gamers dream characters were more likely to be familiar but they were not as likely 
to have friends in their dreams as with the male norms. Importantly, no difference was found in the incidence 
of family members in the dreams. Additionally, gamers had fewer friendly, sexual and good fortune themes 
in at least one dream than norms. But they also had fewer dreams with aggression and misfortune with 
no difference in success, failure or striving, one incident per dream, from the male norms. Thus no clear 
cut theme of a positive or negative social nature emerged for this group of hard core gamers. Another 
interesting finding is the higher incidence of dead and imaginary characters. This certainly seems to 
characterize the virtual world of many of today s games showing up in their dreams. In fact, in interviews 
one gamer commented that generally there is no reason to be a human in a game as they have fewer powers 
than other types of creatures.  3.2 Lucid/Control Analyses In terms of the second set of content analyses 
chi squares on each content variable were significant with the exception of control of events. Specifically 
very few dreams had palpable sensations while none had an explicit reference to physical balance, emotional 
balance was more often absent than present but most often not mentioned. Given that the subjects were 
explicitly asked about their video game dreams not surprisingly over half of the dreams reported included 
such. Other media were less often mentioned. Only 10 of the 56 dreams were seen as lucid by the judge 
with one of those unsure. Dream control was evaluated along several dimensions including control of dream 
self, events, characters, and scenery. Control of self in the dream was seen as high in 39 of the 56 
dreams while control of events ranged across the five frequency categories. Control of characters was 
rarely seen while control of scenery was as often reported as not. Of particular interest in these dreams 
was the stance of the dream ego. This information was obtained due to the probing of the interviewer 
and resulted in some dreams as being reported as experienced outside the dream ego in a position of a 
watcher. Additionally, when in the watcher position, there still tended to be an emotional attachment 
to the events as they progressed. A limited factor analysis was then computed on the major variables 
of interest in the lucid/control content analysis. This is portrayed in Table 2 below. Variables 1 2 
3 4 words in dream (hi is lot) .071 .789 .283 .095 palpable recoded (hi is lot) .187 .669 -.115 -.517 
balance emotions (hi is lot) .889 .045 .213 .096 video game dreams (hi is lot) -.454 .306 .517 -.121 
media dreams (hi is lot) .203 -.124 .785 .003 lucid dreams (hi is lot) -.079 .714 .027 .262 sense of 
self location in dream (hi is watcher &#38; lo is self in body) .026 .206 -.131 .869 emotions of watcher 
in dream (hi neutral) .945 .076 -.048 -.156 mean of control variables ((hi is lot) -.016 .377 .659 -.096 
 Table 2: Factor Analysis of Selected Lucid/Control Dream Content Variables It can be seen in this varimax 
rotation that the first and most important factor loaded balanced emotions and emotions of the watcher 
as neutral along with a lack of video game content and might be called emotional detachment. Factor two 
loaded the number of words in the dream with palpable sensations, video game content, lucidity and control 
and constitutes the hypothesized relationship between video game dreams and lucid/control dreaming. This 
is called lucid/control gaming. The third factor also loaded video game content along with media dreams 
and control of dreams and might be labeled media. Finally factor 4 was marked by a lack of palpable sensations 
associated with a sense of self as a watcher which makes sense in that to watch from the third person 
perspective presumably would entail loosing some sense of the dream egos body sensations.  4. DISCUSSION 
Two sets of content analyses were computed on 56 dreams of 27 hard core video game players gathered during 
semi-structured interviews in the winter term of 2006 at a Canadian college. The standard dream content 
analysis system from Hall and VandeCastle [20] was used to analyze these dreams as was another content 
analysis focused upon lucid/control dreaming. As expected gamers dreamt about gaming and indeed well 
over half of the dreams reported included easily recognized references to games. Since emotional regulation 
is thought to be a central feature of dreams, emotions of gaming which range from joy to anger and sadness 
were investigated in their social contexts in dreams with mixed results. Although gamers evidenced more 
self negativity in these dreams other indicates of positive emotional environments were present. Specifically, 
less misfortunes and more familiar characters were high. In sum, while there were more negative social/emotional 
elements (n=7) than positive ones (n=4) favoring gamers, 12 social/emotional elements resulted in no 
gamer-norm differences. Thus one might say that these dreams are doing the emotional regulation needed 
for gamers while not dramatically distorting their dream lives from norms. If hard core gaming created 
distorted world views at a deep level of consciousness then this would be expected to appear in their 
dreams. However, despite the differences from norms, the overall picture is one of dreams reflecting 
game play while not dramatically distorting their emotional lives as depicted in dreams. The lucid/control 
hypothesis was supported in the second set of content analysis although not asked for explicitly in the 
interviews. This was in order to ensure a spontaneous report. When probed 10 of the 56 dreams were lucid 
and 39 were seen as evidencing control of the dream self. The third person perspective which is not even 
scored for in most dream content analysis systems, including the Hall and VandeCastle, was seen in some 
of these dreams. It may be that more people s dreams have this third person perspective, it s just not 
noticed unless carefully looked for. The factor analysis on these content variables resulted in the hypothesized 
relationship between lucidity/control and video games. Factor 2 loaded these three dream variables with 
palpable sensations and number of words. The last is a rough approximation of dream recall which is typically 
high for lucid dreams [8]. Gackenbach, et al [11] have shown that kinesthetic/vestibular sensations are 
better in lucid dreamers and more prevalent in lucid dreams [8]. However, no mention of physical balance 
was part of these dreams but there were palpable sensations mentioned. Indeed the general lack of motion 
sickness reported by the present group of gamers while gaming would indicate more presence in gaming 
and thus a sense of spatial orientation requiring the vestibular sense might translate later into the 
altered, but constructed, reality of dreams [18] and thus their recognition (i.e. lucidity). The limitations 
of this study are that this was a small number of interviewees and thus a small set of dreams. Although 
the interviewees were told in advance that their dreams would be asked about in addition to other game 
playing related experiences, some came to the interview with little to no dreams to report. This is consistent 
with the low recall characteristic of most people in terms of nightly dream recall but also if you ask 
someone for any dream from any time they typically remember something. The query into most recent dream 
was at times a night before dreams and at other times one form years earlier. Another limitation is 
the self report nature of the data collection which is always a cause for concern. Data is currently 
being analyzed looking at 152 dreams from the night before they were recorded as well as media use data 
from the previous day. In preliminary analysis of this data set [10] lucid/control dreaming was associated 
with gaming but also with all media use. This factor analysis found that the more interactive the media 
the more lucid/control elements entered the dream in morning after reports. Content analysis of these 
morning-after dreams is now being done and dream diary research is planned on these questions. In conclusion, 
dream content shows a moderate change associated with gaming supporting the idea that dreams are emotionally 
regulating the intense experiences of gaming experienced in the daytime. Although these experiences of 
play show up in gamers dreams their dreams are not generally significantly more disturbed than male norm 
dreams. Additionally, the lucid/control association to video game play is indirectly supported with the 
association of these dream structural dimensions to video game content as well as to palpable sensations 
and dream recall. 5. REFERENCES [1] Anderson, C. A. and Dill, K.E. 2000. Video games and aggressive 
thoughts, feelings, and behavior in the laboratory and in life. Journal of Personality and Social Psychology, 
784, 772-790. [2] Barrett, D. 2001. Trauma and dreams. Cambridge, MA: Harvard University Press. [3] 
 Belicki, K. Recalling dreams. an examination of daily variation and individual differences. In: Gackenbach, 
J. Ed Sleep and Dreams: a Sourcebook. Garland, New York, 1986: 187 206. [4] Bertolini, R. and Nissim, 
S. 2002 Video games and children's imagination. Journal of Child Psychotherapy, 283, 305-325. [5] Blackmore, 
S. 2004 Consciousness: An introduction. NY: Oxford University Press. [6] Bulkeley, Kelly 2004 Dreaming 
is play II: Revonsuo s threat simulation theory in Ludic context. Sleep and Hypnosis, 63, 119-129. [7] 
Foulkes, David 2002 Children's Dreaming and the Development of Consciousness. Cambridge, MA: Harvard 
University Press. [8] Gackenbach, J. I. 1988 The psychological content of lucid dreams. In J. I. Gackenbach 
and S. P. LaBerge Eds., Conscious mind, sleeping brain: Perspectives on lucid dreaming, N.Y.: Plenum. 
[9] Gackenbach, J.I. 2006 Video Game Play and Lucid Dreams: Implications for the Development of Consciousness. 
Dreaming, 162, 96-110. [10] Gackenbach, J.I. and Kuruvilla, B. 2007 Dreams and Media Use. Paper presented 
at the annual meeting of the International Association for the Study of Dreams, Sonoma, CA. (June 2007) 
Retreived Sept. 20, 2007 from www.spiritwatch.ca. [11] Gackenbach, J. I., Snyder, T. J., Rokes, L., 
and Sachau, D., 1986 Lucid dreaming frequency in relationship to vestibular sensitivity as measured by 
caloric stimulation. In R. Haskel Ed. Cognition and Dream Research: The Journal of Mind and Behavior 
special issue, (7) 2and3, 277-298. [12] Greenfield, P. M, Brannon, C. and Lohr, D. 1996 Two­dimensional 
representation of movement through three­dimensional space: The role of video game expertise. In P. M. 
Greenfield and R. R. Cocking Eds., Interacting with video. Advances in applied developmental psychology, 
11, pp. 169-185. Norwood, NJ: Ablex Publishing. [13] Kramer, Milton 2007 The dream experience: A systematic 
exploration. New York, NY, US: Routledge/Taylor and Francis Group. [14] LaBerge, Stephen and Gackenbach, 
Jayne 2000 Lucid dreaming. In Cardena, Etzel Ed; Lynn, Steven Jay Ed; Krippner, Stanley Ed. Varieties 
of anomalous experience: Examining the scientific evidence. Washington, DC, US: American Psychological 
Association pp. 151-182. [15] Miles, M. and Huberman, A. 1994 Qualitative Data Analysis. Second edition. 
Thousand Oaks, CA: Sage. [16] Nielsen, Tore A., Saucier, Sebastien, Stenstrom, Philippe, Lara-Carrasco, 
and Jessica, Solomonova, Liza 2007 Interactivity in a virtual maze task enhances delayed incorporations 
of maze features into dream content. Paper presented at the 21st Annual Meeting of the Associated Professional 
Sleep Societies, Minneapolis. (June 2007) [17] Nielsen, Tore, Kuiken, Don, Ve Alain, Genevie`, Stenstrom, 
Philippe, and Powell, Russell 2004 Immediate and delayed incorporations of events into dreams: Further 
replication and implications for dream function. Sleep Research, 13, 327 336. [18] Preston, J. 1998 
From mediated environments to the development of consciousness. In J.I. Gackenbach Ed., Psychology and 
the Internet. San Diego: Academic Press, p. 255-291. [19] Revonsuo, A. 2006 Inner Presence: Consciousness 
as A Biological Phenomenon. Cambridge, MA: MIT Press. [20] Schneider, A., and Domhoff, G. W. 2006 The 
Quantitative Study of Dreams. Retrieved December 10, 2006 DOI= http://www.dreamresearch.net/. [21] Schredl, 
M., Anders, A., Hellriegel, S. and Rehm, A. 2006 TV viewing, computer game playing and nightmares in 
school children. Dreaming, under editorial review. [22] Stickgold R, Malia A, Maguire D, Roddenberry 
D, and O'Connor M. 2000 Replaying the game: Hypnagogic images in normals and amnesics. Science, 2905490, 
350­ 353. [23] VandeCastle, Robert 1994 Our Dreaming Minds. NY: HarperCollins. [24] Van den Bulck, J. 
2004 Media use and dreaming: The relationship among television viewing, computer game play, and nightmares 
or pleasant dreams. Dreaming, 141, 43-49. [25] Wright, J. and Koulack, D. 1987 Dreams and contemporary 
stress: A disruption-avoidance-adaptation model. Sleep, 10, 172 179. Additional authors include Alexis 
Zederayko, alexisz@ualberta.ca, Jordan Olischefski, OlischefskiJ@mymail.macewan.ca, Ashley Nicole Samaha, 
asamaha@hotmail.com, Department of Psychology, Grant MacEwan College, 6-394, 10700 - 104 Avenue, Edmonton, 
Alberta T5J 4S2, 708-633-3892.  
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2007</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>1328218</article_id>
		<sort_key>160</sort_key>
		<display_label>Pages</display_label>
		<pages>7</pages>
		<article_publication_date>11-14-2007</article_publication_date>
		<seq_no>2</seq_no>
		<title><![CDATA["It is always a lot of fun!"]]></title>
		<subtitle><![CDATA[exploring dimensions of digital game experience using focus group methodology]]></subtitle>
		<page_from>83</page_from>
		<page_to>89</page_to>
		<doi_number>10.1145/1328202.1328218</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1328218</url>
		<abstract>
			<par><![CDATA[<p>This paper focuses on digital game experience: the feelings and experiences people have when they play digital games. Digital game experience is not a one-dimensional concept. Great variety exists in game genres and game players, and game experiences will differ accordingly. To date, game experience is studied in a rather fragmented way. As such, the field still lacks a common vocabulary and a shared taxonomy of the different dimensions of game experience. In this paper we describe a focus group study and present a tentative, but comprehensive categorisation of game experience. Focus groups with various types of gamers were organised to capture a full first-hand account of game experiences and second, findings were discussed in an expert meeting in which empirical findings were consolidated with existing theoretical findings. The categorisation bears relevance for both game theorists and game developers wanting to get to the heart of digital game experience.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[categorisation]]></kw>
			<kw><![CDATA[digital game experiences]]></kw>
			<kw><![CDATA[emotions]]></kw>
			<kw><![CDATA[focus group methodology]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>J.4</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010405.10010455</concept_id>
				<concept_desc>CCS->Applied computing->Law, social and behavioral sciences</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010455</concept_id>
				<concept_desc>CCS->Applied computing->Law, social and behavioral sciences</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Human Factors</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P925254</person_id>
				<author_profile_id><![CDATA[81342507668]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Karolien]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Poels]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Eindhoven University of Technology, Eindhoven, The Netherlands]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P925273</person_id>
				<author_profile_id><![CDATA[81100272468]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Yvonne]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[de Kort]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Eindhoven University of Technology, Eindhoven, The Netherlands]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP36022994</person_id>
				<author_profile_id><![CDATA[81100032008]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Wijnand]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Ijsselsteijn]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Eindhoven University of Technology, Eindhoven, The Netherlands]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Bartle, R. A. (1996). Hearts, clubs, diamonds and spades: players who suit MUDs. http://www.mud.co.uk/richard/hcds.html.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Bracken, C. C., Lange, R. L., and Denny. J. (2005). Online video games and gamers' sensations of spatial, social, and co-presence. Proceedings of the annual FuturePlay conference]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>986048</ref_obj_id>
				<ref_obj_pid>985921</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Brown, E. and Cairns, P. (2004). A grounded investigation of game immersion. ACM CHI 2004, 1297--1300.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Csikszentmihalyi, M. (1990). Flow. The Psychology of Optimal Experience. New York: Harper &amp; Row.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Ermi, L. and M&#228;yr&#228;, F. (2005). Fundamental components of the gameplay experience: Analysing immersion. In: S. de Castell &amp; J. Jenson (eds.), Changing Views: Worlds in Play. Selected papers of the 2005 Digital Games Research Association's Second International Conference.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1067372</ref_obj_id>
				<ref_obj_pid>1067343</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Gilleade, K. M. and Dix, A. (2004). Using frustration in the design of adaptive videogames. ACM ACE 2004, 228--232.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[IJsselsteijn, W. A., de Kort, Y. A. W., &amp; Poels, K. (in preparation). Development of the Game Experience Questionnaire (GEQ).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Klimmt, C. (2003). Dimensions and determinants of the enjoyment of playing digital games: a three-level model. In: Copier, M., and Raessens, J. (Eds.), Level up: Digital games research conference. Utrecht University, Faculty of Arts.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Klimmt, C., Rizzo, A. S., Vorderer, P., Koch, J., and FIscher, T. (2007). Suspense as dimension of video game enjoyment. Paper presented to the Game Studies special interest group at the annual conference of the International Communication Association, San Francisco, CA.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[De Kort, Y. A. W., IJsselsteijn, W. A., &amp; Poels, K. (submitted). Digital Gaming Devices as Social Presence Technology: Development of the Social Presence in Gaming Questionnaire (SPGQ).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Lunt, P. &amp; Livingstone, S. (1996). Rethinking the focus group in media and communications research. Journal of Communication, 46(2), 79--98.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Merton, R. K. (1987). The focused interview and focus groups: continuities and discontinuities. Public Opinion Quarterly, 51, 550--556.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Miller, L. et al. (1996). Female participants' Preferences in Software Design: Insights from a Focus Group. Interpersonal Computing and Technology, 4(2), 27--36.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1077253</ref_obj_id>
				<ref_obj_pid>1077246</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Sweetser, P &amp; Wyeth, P. (2005). GameFlow: A model for evaluating player enjoyment in games. ACM Computers in Entertainment, 3 (3), 1--24.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Yee, N. (2002). <i>Facets: 5 motivation factors for why people play MMORPG's.</i> http://www.nickyee.com/facets/home.html.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 " It is always a lot of fun! " Exploring Dimensions of Digital Game Experience using Focus Group Methodology 
 Karolien Poels Yvonne de Kort Wijnand IJsselsteijn Eindhoven University of Technology Eindhoven University 
of Technology Eindhoven University of Technology Game Experience Lab, HTI Group Game Experience Lab, 
HTI Group Game Experience Lab, HTI Group Den Dolech 2, 5600 MB, Eindhoven Den Dolech 2, 5600 MB, Eindhoven 
Den Dolech 2, 5600 MB, Eindhoven The Netherlands The Netherlands The Netherlands  k.poels@tue.nl y.a.w.d.kort@tue.nl 
w.a.ijsselsteijn@tue.nl ABSTRACT This paper focuses on digital game experience: the feelings and experiences 
people have when they play digital games. Digital game experience is not a one-dimensional concept. Great 
variety exists in game genres and game players, and game experiences will differ accordingly. To date, 
game experience is studied in a rather fragmented way. As such, the field still lacks a common vocabulary 
and a shared taxonomy of the different dimensions of game experience. In this paper we describe a focus 
group study and present a tentative, but comprehensive categorisation of game experience. Focus groups 
with various types of gamers were organised to capture a full first-hand account of game experiences 
and second, findings were discussed in an expert meeting in which empirical findings were consolidated 
with existing theoretical findings. The categorisation bears relevance for both game theorists and game 
developers wanting to get to the heart of digital game experience. Categories and Subject Descriptors 
[J.4 SOCIAL AND BEHAVIORAL SCIENCES]  General Terms Design, Human Factors  Keywords Digital game experiences, 
focus group methodology, categorisation, emotions 1. INTRODUCTION It is impossible to come up with a 
single word or concept that embraces what people feel or experience when playing digital games. For example, 
people can have great fun when playing virtual tennis on the Nintendo Wii console, whereas feelings of 
Permission to make digital/hard copy of part of this work for personal or classroom use is granted without 
fee provided that the copies are not made or distributed for profit or commercial advantage, the copyright 
notice, the title of the publication, and its date of appear, and notice is given that copying is by 
permission of the ACM, Inc. To copy otherwise, to republish, to post on servers, or to redistribute to 
lists, requires prior specific permission and/or a fee. FuturePlay 2007, November 15-17, 2007, Toronto, 
Canada. Copyright 2007 ACM 978-1-59593-943-2/07/0011...$5.00 frustration can also come into play when 
people continuously hit the ball out. Some people enjoy playing online MMORPG's like World of Warcraft 
which render the player into a immersive state by getting him or her fully drawn into a fantasy world. 
Others prefer social games like the quiz game Buzz or the karaoke game Singstar which are oriented towards 
pure amusement, and enjoyment in a social context. Given this variety in game genres and game players, 
game experience has to be studied as a multi­dimensional and multi-layered concept. In spite of the rise 
in academic game research, the actual experience of playing digital games still is underrepresented in 
the gaming literature. Existing studies on game experience have mostly focused on a single dimension 
of game experience, such as flow [14] or immersion [5; 3]. As such, current literature on game experience 
is fragmented. We summarise some recent studies below. Sweetser and Wyeth [14] adapted the flow concept 
[4] into a game context. They propose a model of game design heuristics structured by the concept of 
flow and argue that each element of flow (e.g., concentration, challenge, skills, etc) contributes to 
game enjoyment. They provided tentative evidence for their model by showing that highly rated video games 
scored better in terms of their game-flow characteristics compared to games that had received low ratings. 
Although we agree that flow is an important dimension of game experience, we think Sweetser and Wyeth's 
[14] argument of equating flow to game enjoyment might be limited. First, game enjoyment represents a 
broader set of experiences besides flow. Second, their argument is still tenuous since they did not study 
how and whether players actually experience more flow in highly rated games. Emri and Mäyrä [5] studied 
immersion in the game world as experienced while playing. More concretely, they proposed a model consisting 
of three different components of immersion: sensory, challenge-based and imaginative immersion (SCI­model). 
Sensory immersion refers to the multi-sensory properties of a game the extent to which the surface features 
of a game have a perceptual impact on the user. Challenge-based immersion involves immersion in the cognitive 
and motor aspects of the game that are needed to meet the challenges the game poses. Finally, imaginative 
immersion refers to the immersion within the imaginary fantasy world created through the game, and depends 
on the richness of the narrative structure of the game. Brown and Cairns [3] developed a slightly different 
view on what immersion in a gaming context means. They performed a number of in-depth interviews with 
gamers to find out what they mean when they talk about immersion. They analysed their data using grounded 
theory, and found that to most players, immersion describes the degree of involvement within a game. 
Accordingly, Brown and Cairns [3] describe a progression of three stages of immersion, indicating increasing 
levels of involvement: engagement, engrossment, and total immersion (or presence). The level of immersion 
appears to depend on the path of time and is controlled by barriers that need to be removed before the 
next level of immersion can be experienced. Klimmt [8] proposes that game enjoyment is based on three 
experiential factors: experience of effectance or immediate feedback to the player as a causal agent, 
cyclic feelings of suspense and relief, and the fascination from being drawn in to an alternative reality, 
or a fictional world. Notwithstanding the fact that the studies cited above provide significant input 
when deliberating on a comprehensive categorisation of game experience, they do miss a shared vocabulary 
or common understanding of digital game experience. Moreover, in our opinion, current studies have overlooked 
two critical dimensions of game experience. First, digital gaming often takes place in social contexts 
(e.g., game competitions between friends or online gaming). Previous studies have already suggested that 
the specific nature of a social context may significantly influence players' game experience [2]. We 
think this area needs further exploration. Second, current game experience studies do not devote much 
attention to negative game experiences. However, negative experiences such as in-game frustration [6] 
or tension are presumably essential in order for the overall game experience to work. One of the main 
challenges facing the gaming research community is a lack of a coherent and fine-grained set of methods 
and tools that enable the measurement of entertainment experiences in a sensitive, reliable and valid 
manner. We therefore see the need to develop a self-report measure of game experience, covering the broad 
spectrum of experiences induced by digital games [7]. However, it is impossible to develop such an instrument 
without a comprehensive conceptualisation of game experience that can serve as a framework for formulating 
self­report items. In the present study, we take a qualitative and exploratory approach in investigating 
the full account of digital game experiences. We employ focus group methodology which in itself is an 
innovative approach to study game related behaviour. To the best of our knowledge, within academic gaming 
literature the application of focus group methodology has been limited. We only found two other focus 
group studies [2; 13]. Bracken et al. [2] used focus group methodology to investigate whether online 
gamers experience different types of presence like spatial, social, and co-presence. Their results clearly 
illustrate that all three types of presence sensations are applicable to online gaming. Further, Miller 
et al. [13] applied focus groups to explore female preferences for specific types of game designs. Given 
the diversity of individual differences with respect to play styles [1] or motivations to play games 
[15], focus groups can provide in­depth, contextual, and motivational insights into the specific experiences 
of different types of gamers. The objective of our study was twofold. First, we wanted to get a full 
account of first-hand experiences of gaming. We conducted focus group interviews with different types 
of gamers with the aim of obtaining a wide array of lay-conceptualisations of game experience. Focus 
groups further enabled us to explore differences in game experiences according to player type, game genre, 
and context of play. We addressed both in-game and post­game experience. Second, we aimed at unravelling 
the different dimensions of game experience and develop a categorisation. We discussed theoretical and 
empirical findings in an expert meeting and consolidated these into a categorisation of digital game 
experience. 2. FOCUS GROUPS 2.1 Focus group methodology Focus group methodology is a qualitative research 
tool that is frequently used in social sciences to explore people's meanings, ways of understanding, 
or experiences of a complex phenomenon [11]. In practice, focus group methodology typically involves 
a series of group interviews about a given topic or phenomenon guided by a moderator. One of the major 
strengths of focus group methodology is its exploratory nature. Focus groups enable the researcher to 
get to know their target audience in detail without the need for a priori assumptions or research questions. 
Moreover, focus groups can serve as a source of new ideas and hypotheses [12]. Further, focus groups 
are very useful in providing context and depth. Besides observing experiences and thoughts, the moderator 
can probe in order to acquire relevant background information (e.g., about motivations, contexts) on 
these experiences and thoughts. Related to this, focus group methodology lends itself for interpretation 
of the experiences and thoughts reported by the target audience. As such, it enables researchers to get 
a clearer view on the why of behaviour [11]. 2.2 Procedure We organized four focus groups with gamers. 
The composition of the focus groups differed according to several variables such as game frequency, age, 
and occupational status. Two focus groups (FG1 and FG2) included infrequent gamers (i.e., people who 
game at least once a month), two focus groups (FG3 and FG4) consisted of frequent gamers (i.e., people 
who game at least once a week). Participants' ages ranged from 19 to 37 years. FG1 had five participants 
of which two were female. FG2 consisted of three male participants. FG3 and FG4 both had four male participants. 
With respect to professional status, FG1 and FG2 consisted of undergraduate students, FG3 included both 
undergraduate and graduate students, FG4 was composed of working people over 30 years of age. Each focus 
group took about 90 minutes and participants were rewarded 10 for their participation. The focus groups 
were structured in the following way: Introductory round: First, the moderator and the assistant moderator 
presented themselves and gave a brief description of the main goal of the focus groups. More concretely, 
they explained that the focus group was about game experience and participants could freely talk about 
how they experienced digital gaming. Then, participants presented themselves, giving their name, game 
frequency, and the type of games they usually played. Individual task: We asked each participant to 
reflect for five minutes on what they considered to be the most prominent game experiences for themselves. 
Participants had to write down these experiences on Post-It notes. We also asked them to indicate their 
most favourite game and the game they had played last. After this, all Post-It s were pasted in the middle 
of the table to serve as a starting point and inspiration source for the next stage, the group discussion. 
Group discussion: The group discussion was the most crucial part of our focus groups. In these group 
discussions participants could freely talk and interact with each other about their game experiences. 
The discussion was clustered around three core questions by means of a semi-structured questionnaire. 
Accordingly, the three core question were fixed but additional questions could be posed, probing for 
clarification or more in­depth insights. The three core questions were: (1) On what occasions do you 
typically start gaming?, (2) What do you experience or feel while gaming? (i.e., in-game experiences), 
(3) What do you experience or how do you feel after gaming? (i.e., post-game experiences) The moderator 
further probed the experiences that were reported by each participant individually. Additional Post-It 
s were used when new experiences were mentioned. Group task: At the end of the group discussion participants 
were asked to cluster and rank all game experiences that were reported on the Post It notes depending 
on how central they are to gaming in general (i.e., across games). They wrote down all experiences on 
a large sheet of paper with the most prominent experiences in the centre of the sheet and the less relevant 
experiences closer to the margins of the sheet. As such, sheets from the different focus groups could 
be compared and aided us in structuring the diversity of experiences mentioned by the participants. All 
focus group interviews were recorded and transcribed.  2.3 Results The results section is structured 
according to the three core questions that were posed in the group discussion. 2.3.1.1.1 Question 1: 
On what occasions do you typically start gaming? The occasions in which participants typically start 
gaming varied considerably. A substantial amount of them reported that they started playing a game as 
a pastime to overcome boredom. ....when I am feeling bored or when I don't feel like studying... (Female 
participant, FG1, 21 years)1 1 All citations were translated from Dutch. I game when I feel like gaming, 
when I don't feel like doing anything else... (Male participant, FG2, 24 years) Related to this, participants 
said that they often started gaming upon coming home after a stressful day, mostly school or work related. 
Playing games helped them divert their thoughts away from school or work. If I come home after a busy 
day and I don't want to do anything else yet, I often play a couple of quick games before I continue 
with something else (male participant, FG1, 20 years) ...I start playing a game to de-stress, no duties 
anymore, I can do what I choose and what I like... (male participant, FG4, 31 years) Another occasion 
that they put forward was more social in nature. Some of the participants reported that they often played 
games when they were with friends, for example, before or after going out. I rarely game on my own. When 
I game it is a social event where we sit on the couch, with beer and chips. This usually happens the 
hours before we go out. (Male participant, FG2, 22 years) One female participant reported a combination 
of the social and the boredom occasion. When we are together with friends and we have a break or when 
we do not really know what to do, we sometimes play a game together. (Female participant, FG1, 21 years) 
 Some of the more frequent gamers reported that they played games in a coordinated way, making appointments 
with friends, and competing with them in a team. For those gamers, the type of game they played differed 
with each occasion. More concretely, they play short games when feeling bored or after a busy day. In 
contrast, long games are scheduled and played in teams. I play FPS games if I have nothing else to do, 
or World Worms Party. When I play Massive Multi-player Online Role Playing Games (MMORPG) it happens 
in a much more coordinated way, you really need to make appointments beforehand. (Male participant, FG3, 
23 years) I game if I want to do something completely different, for example if I come home after work. 
Most of the time I play a couple of short First Person Shooter (FPS) games, those games you can play 
at any moment, against anyone. In the evenings, I play longer Real Time Strategy (RTS) games. (Male participant, 
FG3, 28 years) Other more frequent gamers did not report participating in official game competitions, 
but they mentioned organising competitions between friends. These activities are planned weeks beforehand. 
A couple of times a year, we organise ''game nights'' in which we gather with four friends. We then start 
up our own game competition using various games. We game all night long and our aim is to find who's 
the best all­round gamer. (Male participant, FG4, 31 years)  2.3.1.1.2 Question 2: What do you experience 
or feel while gaming? Almost all participants mentioned fun, amusement, and relaxation as most prominent 
game experiences. Playing games is fun, it relaxes me, it's my hobby. (Male participant, FG4, 31 years). 
 Experiences of fun were often related to game immersion. This means, the participants mentioned experiences 
like loosing connection with the outside world , forgetting everything around you , and being fully occupied 
with the game . Feeling happy is linked with loosing connection with the outside world. You get yourself 
fully drawn in. (male participant, FG1, 22 years) You get into a different world, you can be there for 
hours without other things on your mind, without realising what happens outside that world. (Male participant, 
FG4, 34 years) Other experiences were more closely linked to imaginative immersion. For example, being 
creative , exploring the game world . One of the female participants linked these experiences to the 
fun factor: I like it when you get more creative in a game. It is funny when you discover something new, 
something you did not expect. When you find out something that you were looking for, you feel glad. (Female 
participant, FG1, 21 years) It is like making your own movie. (Male participant, FG4, 37 years) When 
the more frequent gamers reported on the experience of immersion, they distinguished between different 
types of games. FPS games are about beating the opponent and are very demanding. As such, the atmosphere 
and graphics are less important. With MMORPG it is all about the atmosphere and the beautiful scenes. 
You get yourself fully drawn in. (Male participant, FG3, 29 years) Some participants reported that they 
were not interested in being immersed in a fantasy world, but they said they enjoyed the freedom to explore 
a game world, without specific goals or tasks, or pre-set scripts. Instead of improving my skills, I 
often enjoy wandering around in the game world, for example simply driving through all the streets in 
the game. (Male participant, FG4, 34 years) Further, concentration and tension were mentioned as in-game 
experiences. Participants reported that these experiences were often related to challenge and difficulty 
of the game. Most participants agreed that concentration was needed in order to perform well in games. 
Interestingly, some frequent gamers mentioned 'being in the zone' as a state of full concentration in 
which performance and competence are at their best. These descriptions bear clear resemblance to the 
concept of flow. ''The zone'' happens when you are fully in the game. A bomb may explode, you don't notice 
it. The bell may ring a hundred times, you don't hear it. You may be hungry, you don't feel it...You 
always hope to get into the zone as quickly as possible. Everything works out at that moment, you cannot 
loose: I'm there and you die. (Male participant, FG4, 31 years) Especially for the more frequent gamers, 
the experience of challenge and tension can turn into negative experiences such as, irritation , disappointment 
, frustration , and even anger . They explicitly reported that frustration and irritation often occur 
when there is a mismatch between challenge and skills (i.e., if the game is either too easy or too hard). 
If a game gets too complicated I am often inclined to turn it off, to quit gaming. There has to be some 
challenge in the game; I don't like it if it is too easy, but if it is too complex I don't like it either. 
I get irritated if something doesn't work, I sometimes even get angry. (Male participant, FG3, 23 years) 
I often play RTS games against the same person, if we set a high difficulty setting, it gets more challenging. 
Of course you feel disappointed if it doesn't work and satisfaction if it does work out. I think disappointment 
relates to the effort you put into the game. (Male participant, FG3, 28 years) Conversely, some participants 
reported that negative experiences turn into very positive game experiences. The frustration you have 
during game play can have a positive ending. For example, if you have to try a hundred of times in order 
to cross a very small beam and suddenly you succeed, feelings are extremely positive, you really get 
euphoric. (Male participant, FG4, 37 years) Notably, frequent gamers who participate in game competitions 
often distinguished between experiences playing games purely for fun and experiences playing competition 
games with their team. Particularly, immersion and concentration seemed to differ between those two types 
of game play. Interestingly, these gamers reported that they played console games when playing for fun 
and PC games when competing in serious game competitions. With MMORPG and FPS you need to sit close to 
the screen, they are very exacting. If you meet with friends to have some fun together, it's much nicer 
to lean back on the couch, the game triggers the fun, but it's also about other things then. We have 
a drink and we chat. The game play is purely for fun. When we play games on the PC it is much more serious, 
you need to be very concentrated then, and strictly focused on the game. (Male participant, FG3, 29 years) 
 Also, negative experiences are stronger if the game play gets more serious. Game competitions are dead 
serious, as serious as a soccer game Holland-Germany. You can really feel aggression, or anger. When 
you play for fun, it is more informal, having fun is the dominant experience. (Male participants, FG3, 
29 years) A substantial part of the reported game experiences related to gaming in a social context. 
Experiences that are typically mentioned in this context are competition and enjoyment with others. 
Participants reported that competition instigated feelings of tension , nervousness , and teasing one 
another , while at the same time, they perceived competition as fun , having a laugh , and being connected 
with others . It is always a lot of fun! For example when we play Mario Cart with four friends, there 
s a lot of friendly banter. It is very funny if one player gets picked on by three others. That enhances 
the enjoyment you have with others. (Male participant, FG2, 22 years) Emotions evoked through competition 
with co-located people were reported as much stronger than emotions through competition with the computer, 
or through competition with online people. Also, participants reported that they put more effort in the 
game when they play against co-located friends. Moreover, they said that they experienced more tendencies 
to take revenge . This was attributed to their physical presence, enabling non­verbal and verbal communication 
and physical contact. Playing against the computer is totally different from playing against a friend 
who sits next to you. You can nudge him, give comments... (Male participant, FG2, 28 years) When you 
play with strangers on the Internet, you miss a part of the communication. You cannot figure out whether 
they play for fun or not. You cannot tease them. (Male participant, FG2, 24 years) Social experience 
and connectedness between players is extremely important for frequent players who cooperate in a team. 
Additional experiences that emerge in this specific type and context of game play are besides the more 
general experiences of fun and immersion power, control, thrill, and satisfaction. It is nice to play 
in a team; we often make a lot of jokes and fun together. The urge to build something evokes pleasure. 
The feeling of getting more and more power and more control on your environment is also part of the fun; 
and also that you get more status within your environment. (Male participant, FG3, 29 years) It is important 
that you feel that you are one team. For me realism is important so you can fully imagine yourself in 
the game. It causes more of a thrill. If I experience that I am really someone in the game and for my 
team, it gives me a feeling of satisfaction. (Male participant, FG3, 26 years) 2.3.1.1.3 Question 3: 
What do you experience after gaming? With regard to experiences after gaming, results were mixed. Most 
of the participants said that time had gone by faster than expected . I often start gaming on Saturday, 
right after I wake up, around 10 in the morning. It often happens that my wife gets back from work at 
six in the evening and that I am still there in my boxer shorts, without having eaten anything during 
that day. For me, it feels like only half an hour has passed. (Male participant, FG4, 34 years) When 
probing whether this led to feelings of regret or satisfaction, the answers varied according to personal 
and situational factors. Frequent gamers were quite unanimous with respect to their experiences after 
game play. In general, they did not see it as a waste of time and often had the feeling of having done 
something really useful. Only in very specific situations they reported the experience of disappointment 
or regret. If I play online games I never experience it as a waste of time. When you are cooperating 
in a team and one member gives up, it is a pity. Then I feel disappointed. (Male participant, FG3, 23 
years) Gaming is never a waste of time. Watching TV is much more a waste of time, because it is more 
passive, you are not involved in what happens. (Male participant, FG3, 28 years) ....Only if you have 
been gaming for quite a long time and you did not achieve anything, I often regret having spent so much 
time on it. Especially when I have more urgent things to do. (Male participant, FG3, 29 years) For less 
frequent gamers, regret depended on the situation in which they played the game. More concretely, regret 
or bad feelings were greater if the game play had restrained them from doing more urgent or more useful 
activities. I often feel bad if I wasted my time with playing a game. However, if it is a lazy Saturday 
afternoon and you have nothing better to do it doesn't matter. Then I even find it useful to play a game. 
(Female participant, FG1, 21 years) Sometimes when you are studying and you take a short break, you forget 
the time and then you feel bad that you have wasted your precious time at playing stupid games. (Female 
participant, FG1, 21 years) If the weather is nice, then I regret that I didn't spend my time outside. 
I find it a pity then. However, I did have fun, so it is not that bad after all. (Male participant, FG2, 
28 years) Some participants reported that they anticipated those negative experiences. For example, 
one participant explicitly stated that he only quit gaming when he was in a favourable position. This 
way, he reported, he always has a good feeling after gaming. Another participant said he would not start 
gaming when he had more urgent things to do. Yet another mentioned only playing short games in order 
to prevent that he would spend his whole evening playing games.  3. TOWARDS A COMPREHENSIVE CATEGORISATION 
OF DIGITAL GAME EXPERIENCE After the focus groups we organised an expert meeting that was aimed at combining 
knowledge and insights gathered from both theoretical findings and focus group explorations, and consolidating 
these into a tentative model of game experience. Five game researchers participated in this meeting. 
These included psychologists and experts on measurement development as well as the state of the art in 
theories of game experience (two females, three males). Two of them are very frequent gamers themselves, 
the remaining three should be labelled infrequent gamers. This provided a solid base for determining 
the tentative core dimensions of digital game experience. The expert meeting started with an individual 
and personal reflection of each researcher on what they saw as important game experiences (both in-game 
and post-game experiences). Similar to the procedure of the focus groups, the experts wrote these down 
on Post-Its. Subsequently, memos were added based on theoretical considerations and the results from 
the focus group meetings. We then engaged in an interactive and iterative session, organising all Post-Its 
on a whiteboard, according to centrality and similarity, thus creating a comprehensive categorisation 
of game experience dimensions. Our final categorisation is presented in the table below. Table 1. A comprehensive 
categorisation of digital game experience Dimension In-game experiences Post-game experiences ENJOYMENT 
fun, amusement, pleasure, relaxation energised, satisfaction, relaxation FLOW concentration, absorption, 
detachment jetlag, lost track of time, alienation IMAGINATIVE IMMERSION absorbed in the story, empathy, 
identification returning to the real world SENSORY IMMERSION presence returning to the real world SUSPENSE 
challenge, tension, pressure, hope, anxiety, thrill release, relief, exhausted, euphoria COMPETENCE pride, 
euphoria, accomplishment pride, euphoria, accomplishment, satisfaction NEGATIVE AFFECT frustration, disappointment, 
irritation, anger regret, guilt, disappointment, anger, revenge CONTROL autonomy, power, freedom power, 
status SOCIAL PRESENCE enjoyment with others, being connected with others, empathy, cooperation accomplishment 
in a team, bonding Aiming to stay as close as possible to gamers first-hand experiences, we distilled 
most dimensions directly from the focus groups, except for suspense. The word suspense itself was not 
used by the gamers in our focus groups. However, suspense is studied in current game literature as an 
important component of game enjoyment [9]. Moreover, experiences typically involving suspense (e.g., 
tension, pressure, relief, etc.) were often mentioned. Hence, we choose the term Suspense for these experiences. 
We distinguished between imaginative and sensory immersion. Although sensory immersion was not explicitly 
reported in our focus groups, it did surface in earlier interviews with gamers [2; 5], and does appear 
to be different from the experiences reported under imaginative immersion. Since our goal was to arrive 
at a comprehensive categorisation, it was decided to add this component. 4. DISCUSSION AND CONCLUSION 
We presented a study on digital game experience in which we combined theoretical considerations with 
game experiences surfaced through focus groups. This qualitative and exploratory approach has several 
advantages. We were able to hear and study first-hand game experiences, expressed by the gamers themselves. 
This provided us with a rich and varied set of experiences which enabled us to get a full account of 
game experience and the dimensions it consists of. In contrast to existing, fragmented literature, this 
study presented a more complete overview of how it feels to play digital games. Moreover, we summarised 
our findings into a tentative but comprehensive categorisation. We are fully aware that our categorisation 
is still tentative and limited in the sense that it only describes dimensions of game experience and 
does not show how these are interconnected. Further research is needed to corroborate correlational and 
even causal relationships between the different game experience dimensions. Also, future investigations 
should focus on the interplay between game experiences and different game genres, player types and player 
motivations. Ultimately, a comprehensive model of digital game experience including all game experiences 
and moderating variables can be developed. Nevertheless, the categorisation as it stands now bears relevance 
for both game theorists and game developers. Concretely, we are currently employing this categorisation 
as a frame of reference in the development of a self-report measures of game experiences, comprising 
the Game Experience Questionnaire (GEQ) [7], and the Social Presence in Gaming Questionnaire [10]. Additionally, 
we envision applications of this categorisation in experimental game experience studies. For example, 
if specific dimensions need to be manipulated, our categorisation can aid in determining which concrete 
experiences or feelings must be focused upon. This categorisation can also serve as a starting point 
or inspiration source in developing a shared understanding and vocabulary of different game experience 
dimensions. As we discussed earlier, current gaming literature still lacks a common conceptualisation 
of game experience. We call for further research and cooperation among game researchers, since a shared 
definition of basic concepts is essential in order for a scientific field to progress. Game developers 
can rely on this categorisation as a tool or a checklist to design games that are able to evoke a rich 
spectrum of game experiences. The verbalisations of gamers, cited in our result section, can provide 
game developers with interesting insights in how and when gamers feel and experience certain emotions 
as they engage in playing games. An ultimate application for game developers would be to design games 
in which the game content can be dynamically changed depending on the player's experiences. This could 
lead to an exiting new genre of experientially adaptive games. To summarise, digital game experience 
is a multi-dimensional and multi-layered concept. Actual game experiences range from very broad positive 
and negative emotions to experiences that are more specifically related to play or to fantasy and alternative 
realities. First-hand feelings, as we explored in this paper, enabled us to make a categorisation of 
dimensions of digital game experience which form the heart of playing digital games.  5. ACKNOWLEDGEMENTS 
 We gratefully acknowledge financial support from the European Commission s Framework 6 IST programme. 
In particular, the work reported here has been supported by the FUGA project (part of the IST New and 
Emerging Science and Technology programme) and the Games@Large project (part of the IST Networked Audio-Visual 
Systems and Home Platforms programme). We thank Brian Gajadhar for his assistance in running part of 
the focus groups. 6. REFERENCES [1] Bartle, R.A. (1996). Hearts, clubs, diamonds and spades: players 
who suit MUDs. http://www.mud.co.uk/richard/hcds.html. [2] Bracken, C.C., Lange, R.L., and Denny. J. 
(2005). Online video games and gamers' sensations of spatial, social, and co­presence. Proceedings of 
the annual FuturePlay conference [3] Brown, E. and Cairns, P. (2004). A grounded investigation of game 
immersion. ACM CHI 2004, 1297-1300. [4] Csikszentmihalyi, M. (1990). Flow. The Psychology of Optimal 
Experience. New York: Harper &#38; Row. [5] Ermi, L. and Mäyrä, F. (2005). Fundamental components of 
the gameplay experience: Analysing immersion. In: S. de Castell &#38; J. Jenson (eds.), Changing Views: 
Worlds in Play. Selected papers of the 2005 Digital Games Research Association s Second International 
Conference. [6] Gilleade, K.M. and Dix, A. (2004). Using frustration in the design of adaptive videogames. 
ACM ACE 2004, 228-232. [7} IJsselsteijn, W.A., de Kort, Y.A.W., &#38; Poels, K. (in preparation). Development 
of the Game Experience Questionnaire (GEQ). [8] Klimmt, C. (2003). Dimensions and determinants of the 
enjoyment of playing digital games: a three-level model. In: Copier, M., and Raessens, J. (Eds.), Level 
up: Digital games research conference. Utrecht University, Faculty of Arts. [9] Klimmt, C. ., Rizzo, 
A.S., Vorderer, P., Koch, J., and FIscher, T. (2007). Suspense as dimension of video game enjoyment. 
Paper presented to the Game Studies special interest group at the annual conference of the International 
Communication Association, San Francisco, CA.  [10] De Kort, Y.A.W., IJsselsteijn, W.A., &#38; Poels, 
K. (submitted). Digital Gaming Devices as Social Presence Technology: Development of the Social Presence 
in Gaming Questionnaire (SPGQ). [11] Lunt, P. &#38; Livingstone, S. (1996). Rethinking the focus group 
in media and communications research. Journal of Communication, 46(2), 79-98. [12] Merton, R.K. (1987). 
The focused interview and focus groups: continuities and discontinuities. Public Opinion Quarterly, 51, 
550-556. [13] Miller, L. et al. (1996). Female participants' Preferences in Software Design: Insights 
from a Focus Group. Interpersonal Computing and Technology, 4(2), 27-36. [14] Sweetser, P &#38; Wyeth, 
P. (2005). GameFlow: A model for evaluating player enjoyment in games. ACM Computers in Entertainment, 
3 (3), 1-24. [15] Yee, N. (2002). Facets: 5 motivation factors for why people play MMORPG's. http://www.nickyee.com/facets/home.html. 
  
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2007</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>1328219</article_id>
		<sort_key>170</sort_key>
		<display_label>Pages</display_label>
		<pages>7</pages>
		<article_publication_date>11-14-2007</article_publication_date>
		<seq_no>3</seq_no>
		<title><![CDATA[While the ball in the digital soccer is rolling, where the non-player characters should go in a defensive situation?]]></title>
		<page_from>90</page_from>
		<page_to>96</page_to>
		<doi_number>10.1145/1328202.1328219</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1328219</url>
		<abstract>
			<par><![CDATA[<p>The non-player characters (NPCs), i.e. the artificial characters that are not under direct control by the user, are essential part of many digital games. Achieving the realistic behavior by NPCs in digital sports games such as the simulated soccer is challenging. Here we limit our scope to the defensive situation, i.e. when the ball is controlled by the opponents, and propose a systematic method for optimal NPC positioning. So far the methods for automatically finding defensive positions by the intelligent robotic soccer players have been investigated by some scholars within RoboCup, an international research and educational initiative in Artificial Intelligence and robotics. Although simulated soccer teams using these methods have proved to be reasonably good, the collaboration issue in defensive situations has been overlooked. In this paper we propose a systematic approach based on solving a multi-criteria assignment problem. This allows gracefully balancing the costs and rewards involved in defensive positioning to achieve better results.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[RoboCup]]></kw>
			<kw><![CDATA[multi-criteria assignment problem]]></kw>
			<kw><![CDATA[player collaboration]]></kw>
			<kw><![CDATA[player positioning]]></kw>
			<kw><![CDATA[simulated soccer]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.6.5</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010341.10010342</concept_id>
				<concept_desc>CCS->Computing methodologies->Modeling and simulation->Model development and analysis</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010341.10010342</concept_id>
				<concept_desc>CCS->Computing methodologies->Modeling and simulation->Model development and analysis</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Experimentation</gt>
			<gt>Management</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P925272</person_id>
				<author_profile_id><![CDATA[81342501295]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Vadim]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kyrylov]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Rogers State University, Claremore, OK]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P925231</person_id>
				<author_profile_id><![CDATA[81342497915]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Eddie]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Hou]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Simon Fraser University, Surrey, British Columbia, Canada]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>1328219</ref_obj_id>
				<ref_obj_pid>1328202</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Razykov, S; Kyrylov, V. (2006). <i>While the Ball in the Digital Soccer Is Rolling, Where the Non-Player Characters Should Go If the Team is Attacking?</i> In: Proceedings of the Future Play, London, ON, October 2006. http://www.futureplay.org/docs/papers/2006/paper-339.pdf]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Beim, G. (1977). <i>Principles of Modern Soccer.</i> Boston, MA: Houghton Mifflin Company.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Bangsbo, J.; Peitersen B. (2002). Defensive Soccer Tactics. Human Kinetics: Champaign, IL.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Reis, L. P.; Lau, N. (2001). <i>FC Portugal Team Description.</i> In: RoboCup 2000 Simulation League Champion. In: Stone, P.; Balch, T., and Kraetzschmar, G. (eds.): RoboCup 2000, LNAI 2019. Springer: Berlin, Heidelberg, New York, pp 29--40]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>696853</ref_obj_id>
				<ref_obj_pid>646586</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Kok, J.; de Boer, R.; Vlassis, N.; and Groen, F. (2002). <i>UvA Trilearn 2002 Team Description.</i> In: G. Kaminka, P. Lima, and R. Rojas, editors, RoboCup 2002: Robot Soccer World Cup VI, Fukuoka, Japan. Springer-Verlag, p 549.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1121619</ref_obj_id>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Kocay, W. and Kremer, D. (2006). <i>Graphs, Algorithms, and Optimization.</i> Chapman &amp; Hall/CRC Press: Boca Raton, FL]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Hunter, M.; Kostiadis, K.; Hu, H. (2000). A Behaviour-based Approach to Position Selection for Simulated Soccer Agents. <i>"1 st European Workshop on RoboCup, Amsterdam, 28 May - 2 June 2000"</i>
]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Larichev, O. I. and Kozhukharov A. N. (1979). Multiple Criteria Assignment problem: Combinibg the Collective Criterion with Individual Preferences. <i>Matematiques et Sciences Humaines</i>, 68, pp 63--77]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Wilamowsky, Y.; Epstein, S.; and Dickman, B. (1994). Multicriteria assignment problems with preemptive priorities. <i>Mid-Atlantic Journal of Business</i>, 30, No. 1, pp. 113--120]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Scarelli, A. and Narula, S. C. (2003). A Multicriteria Assignment Problem. <i>Journal of Multi-Criteria Decision Analysis</i>, 11, Issue 2, pp. 65--74]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Zhan, Yu. (2007). <i>The Tao of Soccer:</i> An Open Source project. https://sourceforge.net/projects/soccer/]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 While the Ball in the Digital Soccer Is Rolling, Where the Non-Player Characters Should Go in a Defensive 
Situation? Vadim Kyrylov Rogers State University Claremore, OK, 74017 USA 1-918-343-7953 vkyrylov@rsu.edu 
ABSTRACT The non-player characters (NPCs), i.e. the artificial characters that are not under direct control 
by the user, are essential part of many digital games. Achieving the realistic behavior by NPCs in digital 
sports games such as the simulated soccer is challenging. Here we limit our scope to the defensive situation, 
i.e. when the ball is controlled by the opponents, and propose a systematic method for optimal NPC positioning. 
So far the methods for automatically finding defensive positions by the intelligent robotic soccer players 
have been investigated by some scholars within RoboCup, an international research and educational initiative 
in Artificial Intelligence and robotics. Although simulated soccer teams using these methods have proved 
to be reasonably good, the collaboration issue in defensive situations has been overlooked. In this paper 
we propose a systematic approach based on solving a multi-criteria assignment problem. This allows gracefully 
balancing the costs and rewards involved in defensive positioning to achieve better results. Categories 
and Subject Descriptors I.6.5 [Simulation and Modeling]: Model Development General Terms Algorithms, 
Management, Performance, Design, Experimentation. Keywords Multi-criteria assignment problem, simulated 
soccer, RoboCup, player positioning, player collaboration. 1. INTRODUCTION. MODELING PLAYER POSITIONING 
IN THE SOCCER GAME Artificial Intelligence (AI) is a way to bring more realism in digital games. This 
paper continues our early AI study [1] on optimized player positioning in sports games with a ball. Permission 
to make digital/hard copy of part of this work for personal or classroom use is granted without fee provided 
that the copies are not made or distributed for profit or commercial advantage, the copyright notice, 
the title of the publication, and its date of appear, and notice is given that copying is by permission 
of the ACM, Inc. To copy otherwise, to republish, to post on servers, or to redistribute to lists, requires 
prior specific permission and/or a fee. FuturePlay 2007, November 15-17, 2007, Toronto, Canada. Copyright 
2007 ACM 978-1-59593-943-2/07/0011...$5.00 Eddie Hou Simon Fraser University -Surrey Surrey, British 
Columbia V3T 0A3 Canada 1-778-782-5000 ehou@sfu.ca In such games, simulated agents that are not directly 
controlled by the human player are referred to as non­player characters (NPCs). Because these agents 
comprise an essential part of the gaming environment, behaving in a rational, human-like way is a standard 
requirement. However, methods for modeling such behavior have not been studied in depth. Like in our 
previous paper [1], we want to derive a model of the intelligent behavior of an NPC without the ball. 
It can be shown that the average NPC spends less than 10 percent of the time intercepting or handling 
the ball; the remaining more than 90 percent accounts for moving somewhere without the ball while not 
trying to intercept it. This implies the crucial importance of addressing rational positioning without 
the ball; any improvement in the NPC behavior would likely have great impact on the whole game. Noteworthy 
that NPC behavior without the ball strongly depends on whether its team is attacking or fending off the 
attack launched by the opponent team. In the previous paper, we have proposed the model for the situation 
when our team is in attack; now we concentrate on defense. In particular, we propose a method for finding 
a reasonably good position by the NPC without the ball in the defensive situation. Thus we want to provide 
a complete solution to the rational positioning problem for NPCs in digital games like soccer. Real-life 
soccer provides some clues for the digital version of this game. The major purpose of soccer player positioning 
in defense is repelling the attack and creating conditions for launching the attack. However, this requires 
coordinated effort because the opponent team also coordinates its own actions. Normally the fastest player 
to the ball from the defending team is trying to approach the opponent player who controls the ball, 
thus forcing him prematurely trying to score a goal or to consider passing the ball to some teammate. 
The objective of the rest players on the defending side is either to block the path of the ball to own 
goal or to prevent the opponent players from receiving a pass, or create difficulties for further handling 
of the ball if such pass had occurred. This is accomplished by finding a suitable position on the field 
near the opponent player by the defender; in soccer terms, this is referred to as  ³PDUNLQJ´ DQG ³FRYHULQJ´ 
> @ &#38;RRUGLQDWLRQ LV QHFHVVDU\ to guarantee that each potentially dangerous opponent is taken care 
of and none of the opponents is marked by two or more players because of the limited team size. We want 
to implement similar rational behavior of NPCs in the digital soccer game. So far we have not found any 
academic publications in the digital game research community on how this problem could be approached 
systematically. However, some insights are provided within RoboCup, an international research and educational 
initiative whose main objective is to advance robotics and Artificial Intelligence using the soccer game 
as a standard testing environment. Here we are reporting our findings made while working on research 
projects associated with the RoboCup Simulation League. We believe that many studies within this league 
are applicable for advancing the digital gaming technology. The RoboCup scholars have developed some 
methods for player positioning. One of major requirements is that player behavior must be persistent 
over several simulation cycles; players are not supposed abruptly changing their minds during each cycle, 
anyway. This implies that the true intelligent NPC should keep some aspired position in mind that it 
persistently should be moving to. This position changes substantially if only the situation in the game 
also significantly changes. Using a two-layer control structure is the mainstream idea for calculating 
this desired position. Because we have explained it in our previous paper [1], here we give just an outline. 
On the higher level, such details of current situation as the location of opponent players are ignored. 
The team formation prescribes a specific home position on the field for each player which is reflecting 
the players' role (e.g. right-wing attacker, central defender, and so on). At any time, the default player 
position is determined by its fixed µKRPH¶ SRVLWLRQ E\ WKH FXUUHQW ORFDWLRQ RI WKH EDOO DQG E\ which 
side is currently controlling the ball. With some variations, these ideas have been reported in two team 
descriptions [4, 5]; both teams had won top places in the world RoboCup competitions. Assuming that both 
goals are lying on x-coordinate axis, the precise method for calculating the default position (xi, yi) 
of the player is given by the formulas: xi = w*xhomei + (1-w)[EDOO .[i, (1) yi = w*xhomei + (1-w)*yball, 
where w is the weight (0<w<1), (xhomei, yhomei) is the IL[HG µKRPH¶ SRVLWLRQ RI WKH SOD\HU xball, yball) 
is the current ball position; .[i is the fixed individual adjustment of x-coordinate whose sign and value 
is different for the offensive and defensive situations. So the default position is changing over time 
with the ball while maintaining relative locations of the players in the formation thus implementing 
the team strategy. This resembles what the human soccer players are doing, especially if the ball is 
rather far away; they just move towards the default position. Persistence of player positioning is accomplished 
by the weight w that translates the ball movement with a reduced impact on the default position; these 
changes are continuous over time, anyway. Abrupt changes of the default position occur only when the 
situation changes from attack to defense. The decision about whether the current situation is attacking 
or defensive could be made when the ball is rolling freely. Each player determines when and where the 
ball will be intercepted by some player. If this player is the teammate, we have an offensive situation; 
this case was addressed in [1] earlier. If the ball is going to be intercepted by the opponent, the situation 
becomes defensive; this is exactly the case we discuss here. On the lower level of control in the defensive 
situation, the individual soccer player is constantly fine tuning his position in the vicinity of the 
default position. In doing so, the player is taking into account the local situation trying to determine 
the best position that would most likely lead to preventing the nearby opponent from receiving the ball 
passed to him by the teammate or shoot at the goal. Because reaching this optimal position takes some 
time, persistent actions by the defender are required over several simulation cycles. Obviously, we are 
interested in making sure that the aspired position is optimal not now, but at the future time when it 
would be reached by this player. This raises the critical issue of predicting the situation on the field 
and choosing the prediction time horizon T. In this paper, we refer to the set of all positions currently 
reachable by player in time T as the feasible set. As the player changes its own position, this feasible 
set is changing accordingly. The decision to be made by the player about where to go is finding the best 
position in this set. Time horizon T certainly cannot be too large, as we do not know exactly how the 
opponent team is going to act. On the other hand, too small T makes little sense, as only positions that 
are very close to the current location of the defender would be deemed feasible; this may result in the 
lack of persistence of player behavior. Thus we need to use the greatest possible value of T that still 
maintains reasonable accuracy of prediction. In our previous paper [1], we have proposed a method for 
determining the time horizon T. It is based on the idea that while the ball is rolling freely, the situation 
on the soccer field could be predicted with reasonably high precision. The two fastest players to the 
ball from the two teams would be trying to intercept it. The rest of the players would tend to move to 
their default positions determined by their role in the team formation and the location of the ball interception 
point. The experience from real-life soccer proves that unless players do so, their team would be at 
disadvantage. Thus we have rather solid grounds for predicting the situation while the ball is rolling 
freely (hence the title of this paper). Therefore, the time horizon T for planning player actions regarding 
its positioning is done in the time remaining until the ball will be intercepted by some player. Note 
that in an average soccer game the ball is rolling about 90 per cent of the time; so we can make good 
predictions a majority of the time.  Thus on the second layer of control details of the situation such 
as the location of reach player are taken into account. The default positions of defenders obtained on 
the first layer are adjusted to better fend off the attack. Without such adjustment, default positions 
create FRQGLWLRQV IRU VXFFHVVIXOO\ GLVUXSWLQJ WKH RSSRQHQW¶V DWWDFN only incidentally. Individual adjusting 
can make this happen more frequently, thus contributing to the success of the team. We want to implement 
these behaviors in the NPCs populating the digital soccer game. individually without taking into account 
the decisions made by their teammates, i.e. without collaboration. Thus each defender chooses to mark 
the nearest opponent. Yellow midfielders #6 and #7 are moving towards their default positions waiting 
for the outcome of the attack. What happens next is shown in Figure 2. Red player #10 is left unattended 
and is going to receive a pass from red #11 before yellow #4 interferes. Once red #10 receives the pass, 
it would be able to score the goal or pass the ball to red #9 whose scoring position would be even better. 
Thus the red team almost certainly wins in this situation. Figure 2. After about 1 second, red #11 passes 
the ball to the unattended red #10 before yellow #4 interferes. The red team is likely to score a goal. 
Player positioning in defense substantially differs from positioning during attack by the critical importance 
of player collaboration. To further explain this feature, consider Figure 1. It shows a situation when 
the red team is about to shoot the ball in the yellow team¶s goal. Arrows in magenta show the intentions 
by the yellow team defenders to place themselves to fend off the attack. Figure 1. The red team is attacking. 
The ball is rolling up the field and could be reached by red #11. Yellow defenders are individually marking 
the closest opponents; thus red #10 is left unattended The ball is rolling up the field and is about 
to be reached by red #11. The fastest to the ball yellow #4 is also going to intercept it. The yellow 
defenders #2, #3, and #5 are trying to mark the attackers. They are making these decisions The attack 
by the red team could be more likely fended off if the defenders collaborated instead of making individual 
decisions about marking the opponents. Thus each defender must take into account the alternative options 
of the whole team and find a solution that would balance some global optimality criteria. Note that in 
Figure 3 yellow #2 is going to mark red #10 even though this is not the closest opponent. Yellow midfielder 
#6 joins the defenders by going to mark red #9 thus contributing to the team effort. The critical condition 
is that each defending NPC must be anticipating that its teammates are going to act in the best interest 
of the whole team. Collaboration is essential.  We want NPCs in a digital soccer game to exhibit this 
intelligent collaborative behavior in the defensive situations. So far we have not found any suggestions 
in the digital game research community on how the collaboration problem could be approached systematically. 
Nor have we found in the RoboCup community any academic publications that propose a systematic solution 
to this issue. The objective of this paper is to improve defensive NPC positioning in simulated soccer 
and to measure this improvement. Our method boils down to the adjustment of WKH µGHIDXOW¶ SRVLWLRQ FDOFXODWHG 
DV  DQG LV EDVHG RQ WZR ideas. First, we propose that this adjustment should be made ZLWK VRPH SUHGLFWHG 
VLWXDWLRQ RQ WKH ILHOG LQ WKH 13&#38;¶V µPLQG¶ )RU WKLV SXUSRVH ZH extend the concept of the prediction 
time horizon T from our earlier work [1]. This is the time remaining until the freely rolling ball is 
reached by the opponent player plus optional .7 whose meaning we will explain later. Second, given the 
time T+ .7, we want to optimize the individual movements of NPCs with respect to the global criteria 
that reflect the team success rather than individual performance of the NPCs. In doing so, we propose 
a set of optimalty criteria and develop an algorithm for finding near-optimal solution. We also measure 
the performance gain from the proposed methods. 2. THE OUTLINE OF THE DEFENSIVE POSITIONING METHOD To 
contain the complexity of the collaborative defensive positioning problem, we split it into two sub problems: 
(1) making a collaborative decision for a group of defenders and (2) making the decision about the point 
to move to by an individual NPC based on this group decision. The collaborative decision making concerns 
optimization of the assignment of n defenders to cover m attackers. This problem is formulated, as follows: 
Let Dij be a Boolean decision variable whose value is 1 if i-th defender is assigned to mark j-WK RSSRQHQW 
 .i.n; .j.m) and 0 if otherwise: Dij {0,1} . (2) Thus there are total of n*m such unknown variables. 
Also let uij be the anticipated µXWLOLW\¶ UHVXOWLQJ IURP WKH assignment ilj. By varying the set {D }, 
we want to gain the maximal total ij utility of the collaborative action by n defenders: nm U({D }) ¦¦D 
u . (3) ij ijij i 1 j 1 In doing so, besides (2), the following two constraints must be observed: n ¦Dij 
d1 , (4) i 1 m ¦Dij d1. (5) j 1 Constraints (4) and (5) mean that each defender must be assigned to mark 
no more than one opponent and each opponent must be marked by no more than one defender. This problem 
is referred to as the Linear Assignment Problem; its solution is delivered by the so-called Hunga­rian 
algorithm, whose complexity is O((max(m,n))4). [6]. In the context of our study, however, it is difficult 
to measure the defender assignment utility with just one criterion. Actually, we must be balancing rewards 
and risks; this implies several criteria functions that yet to be specified. In what follows, we resolve 
this by deriving the criteria functions from soccer tactics and offering an algorithm that would provide 
an optimal solution of the multi-criteria assignment problem (MCAP). Decision making by the individual 
NPC is based on the assignment to take care of the specific attacking opponent. The defending NPC must 
find the optimal point to move to by balancing the risks and rewards incurred with such movement. The 
end point also must be reachable within the time horizon, i.e. before the situation becomes hardly predictable. 
In this paper, we propose an improved method for finding the optimal point with respect to the available 
limited time. 3. IDENTIFYING THE FEASIBLE OPTIONS While the ball is rolling freely, a NPC can determine 
the time horizon T when the ball will be intercepted and predict the situation rather precisely. The 
example in Figure 4 shows the two main constraints for the yellow NPC #3. The yellow circle is the reachable 
area in time T+.7, where the meaning of .7 will be explained later. The magenta circle is the responsibility 
area where this NPC must keep positioning itself to maintain team formation. The center of this area 
is given by (1). The overlap of these two circles represents the set of feasible positions. Early studies 
[3, 5, 7] have shown that, for any given predicted locations of the ball interception point and the opponent 
player without the ball, it is possible to determine the best location for the defender to mark or cover 
this opponent. However, the limitation factor of the available time T+.7 in these studies was neglected. 
We have found position of the opponent and the center of the yellow goal out that, depending on time 
balance, there are two main (Figure 6). Instead of marking the opponent, we get what is cases. FDOOHG 
µFRYHULQJ¶ > @   Figure 4. The feasible alternative positions for the yellow NPC #3 (shaded area). 
The ball is rolling freely towards red #8 who is going to intercept it in A. Case 1: Marking. If the 
defender NPC can reach the best marking position before the ball could be sent to the opponent being 
covered, the recommended marking position, C, lies on the line between the ball interception point A 
and the predicted location B of the opponent attacker at time T (Figure 5). In this case, .7 is the time 
necessary for the ball to reach C after it had been passed by red #8 to red #9. Thus the defender himself 
must reach C in time T +.7 or less. Therefore, the shaded feasible area must be also determined for this 
extended time horizon. Distance BC must be large enough to exclude the interference by red #9 after intercepting 
the ball by yellow NPC #3. Figure 6. This situation differs from Figure 5 in that the time balance would 
not permit yellow NPC #3 to reach the position from where it could block red #9. Point C allows for covering 
red #9 from the direction of the yellow goal thus making it difficult to shoot if #9 receives a pass. 
In this case, .7 is time necessary for the ball to reach B after it was passed by red #8 to red #9. While 
planning collaborative defensive positioning, the recommended point Cij is calculated for each pair of 
i-th defender and j-th opponent. Distance BC must be small enough for yellow NPC #3 to prevent red #9 
from freely handling the ball. The latter requirement cannot be satisfied if the opponent¶V time advantage 
is too large. If this is the case for ik-th defender and js-th opponent, pair (ik, js) is just eliminated 
from the set of feasible assignments {ilj}. 4. CRITERIA FOR COLLABORATIVE DECISION MAKING AND THE OPTIMIZATION 
ALGORITHM The utility of assigning n defenders on m attackers is difficult to express it terms of single 
criterion because there are several conflicting factors. We consider two: gain and cost. Gain could be 
measured in terms of the threat prevented by taking care of an opponent player. Cost is the required 
time to implement this action. We want to maximize total gain and minimize total cost simultaneously. 
We measure the threat imposed by j-th attacking player by taking into account three factors: (1) the 
angular size E(x , y ) RI RZQ JRDO IURP WKH RSSRQHQW¶V ORFDWLRQ jj (x , y )  GLVWDQFH IURP WKH RSSRQHQW¶V 
ORFDWLRQ WR RZQ jj goal dgoal (xj , y ) ; and (3) distance between the ball and j WKH RSSRQHQW¶V ORFDWLRQ 
d (x , y ) . The threat ball j j  increases with the first factor and decreases with the other two. 
The distance to the goal contributes to threat more than the distance to the ball. Thus we get a heuristic 
function: E(xj , yj ) (6) Threat jd (x , y ) d (x , y ) goalj j ball j j The second criterion, cost 
is measured by the time Tij necessary for i-th defender to reach the recommended point Cij; if this point 
is infeasible, this time is set to infinity. So we want to maximize the total prevented threat: THREAT 
({D }) ¦ m Threat j ¦ n D , (7) ij ij j 1 i 1 while also simultaneously minimizing the total time expenditure: 
nm TIME ({Dij}) ¦¦DijTij . (8) i 1 j 1 Unfortunately, it looks like an algorithm to solve this problem 
precisely has not been developed as yet; all methods that we have found in the literature so far have 
dealt with particular cases only [8, 9, 10]. Thus, assuming the preemptive priorities of our criteria, 
we can use one of these methods [9]. By following this approach, we assume that threat is preemptive 
over time. So we select the opponents one at a time in the order of the anticipated prevented threat. 
For each unassigned opponent, we find the choice of this application was governed by that it is simpler 
and has fewer ambiguous factors than the RoboCup simulated soccer. This reduces the required number of 
games to gather sufficient statistical data. Like in our previous paper [1], the sole purpose of this 
experiment was to demonstrate that using smart defensive positioning is in principle better that using 
just default positions calculated as in (1). Precise measurements of performance, however, are only possible 
with a full set of advanced features implemented in the artificial players. In the experiments we have 
been using two almost identical teams whose players have rather basic skills. Of advanced skills, they 
had reasonably good ball passing and goal scoring algorithms. The only difference was that the experimental 
team was adjusting player positions as described in this paper, while players without the ball in the 
control team were moving to their default positions without any fine tuning. So in the control team, 
opponent marking or covering was occurring as a matter of chance and in the improved team NPCs were doing 
this on purpose. The team performance was measured by the score difference. Figure 7 shows the histogram 
based on 100 games each 10 minutes long. Score Difference Frequency 25 20 Frequency 15 defender with 
the minimal time Tij to mark or cover it. The process ends when all treatening opponents are marked or 
covered or all available teammates are allocated. Thus the defeat shown in Figure 2 would have never 
happened. If NPCs have complete and precise information about the world, as it is normally the case in 
commercial video games, by solving the described MCAP, each NPC would have the same results. Implementing 
this decision is all that is left up to each NPC. If the knowledge of the situation is imperfect, the 
collaboration decisions made by different defenders would not necessarily match, thus disrupting the 
collaboration itself. This issue could be resolved by organizing communication between NPCs, which is 
more applicable to the RoboCup simulated soccer. So once the assignment ilj is decided, i-th defending 
NPC would move straight towards the recommended point Cij. 5. EXPERIMENTAL RESULTS AND CONCLUSION To 
measure the performance gain achieved by using the new algorithm for optimizing defensive player positioning, 
we have run a set of experiments using the open source digital soccer game known as the Tao of Soccer 
[11]. The 10 5 0 -2-101 2 34 5 Score Difference Figure 7. A histogram of the score difference in 100 
games. The experimental team has a higher average score by 1.63; however, this difference has too low 
of a statistical significance, as with only 100 games, the distribution appears to have too long tails. 
A little more cautious claim about the score difference, however, is significant. Indeed, at 95% confidence 
level, the experimental team with advanced defensive positioning scores on average at least 1.3 extra 
goals per game. This difference is indeed worthy of trying to achieve. Because the defensive situations 
in which our improvements kicked in happen rather infrequently, we also created two custom-designed scenarios 
in that marking and covering opponents is critical for the defending team. Figure 8 shows two situations 
where defenders are outnumbered by attackers who are about to score a goal. In these experiments, no 
goalie was at the goal line for the defending team; the ball was randomly placed in front of an attacker, 
with randomly positioned attackers. The situation, whose duration was 200 simulation cycles (10 s), was 
repeated 500 times. In the end of each repetition the statistics on the number of goals scored was gathered. 
 3 defenders, 4 attackers 2 defenders, 3 attackers Figure 8. Two custom-designed scenarios with defenders 
outnumbered by attackers The results for the control and experimental team are shown in Table 1. Table 
1. Experimental results with special scenarios Defending team Average goals scored Standard deviation 
Scenario: 3 defenders, 4 attackers Control 0.400 0.015 Experimental 0.304 0.015 Scenario: 2 defenders, 
3 attackers Control 0.568 0.016 Experimental 0.280 0.014 These results indicate that there is statistically 
significant (at more than 99% confidence) improvement in the team performance. Indeed, the modifications 
made to the experimental team reduced the probability of scoring a goal by the attackers 1.3-2.0 times. 
Best results are achieved when the numerical superiority of attackers is greater. This proves the viability 
of the proposed method for defensive positioning of non-player characters.  6. REFERENCES [1] Razykov, 
S; Kyrylov, V. (2006). While the Ball in the Digital Soccer Is Rolling, Where the Non-Player Characters 
Should Go If the Team is Attacking? In: Proceedings of the Future Play, London, ON, October 2006. http://www.futureplay.org/docs/papers/2006/paper-339.pdf 
[2] Beim, G. (1977). Principles of Modern Soccer. Boston, MA: Houghton Mifflin Company. [3] Bangsbo, 
J.; Peitersen B. (2002). Defensive Soccer Tactics. Human Kinetics: Champaign, IL. [4] Reis, L. P.; Lau, 
N. (2001). FC Portugal Team Description. In: RoboCup 2000 Simulation League Champion. In: Stone, P.; 
Balch, T., and Kraetzschmar, G. (eds.): RoboCup 2000, LNAI 2019. Springer: Berlin, Heidelberg, New York, 
pp 29­40 [5] Kok, J.; de Boer, R.; Vlassis, N.; and Groen, F. (2002). UvA Trilearn 2002 Team Description. 
In: G. Kaminka, P. Lima, and R. Rojas, editors, RoboCup 2002: Robot Soccer World Cup VI, Fukuoka, Japan. 
Springer-Verlag, p 549. [6] Kocay, W. and Kremer, D. (2006). Graphs, Algorithms, and Optimization. Chapman 
&#38; Hall/CRC Press: Boca Raton, FL [7] Hunter, M.; Kostiadis, K.; Hu, H. (2000). A Behaviour-based 
Approach to Position Selection for Simulated Soccer Agents. ³1 st European Workshop on RoboCup, Amsterdam, 
28 May -2 June 2000" [8] Larichev, O.I. and Kozhukharov A.N. (1979). Multiple Criteria Assignment problem: 
Combinibg the Collective Criterion with Individual Preferences. Matematiques et Sciences Humaines, 68, 
pp 63-77 [9] Wilamowsky, Y.; Epstein, S.; and Dickman, B. (1994). Multicriteria assignment problems with 
preemptive priorities. Mid-Atlantic Journal of Business, 30, No. 1, pp. 113-120 [10] Scarelli, A. and 
Narula, S.C. (2003). A Multicriteria Assignment Problem. Journal of Multi-Criteria Decision Analysis, 
11, Issue 2, pp. 65-74 [11] Zhan, Yu. (2007). The Tao of Soccer: An Open Source project. https://sourceforge.net/projects/soccer/ 
Eddie Hou has just completed his studies towards a PDVWHUV¶ GHJUHH LQ WKH 6FKRRO RI ,QWHUDFWLYH $UWV 
DQG Technology at Simon Fraser University. Dr. Vadim Kyrylov while conducting this research was a faculty 
member in the same school. Now he is Associate Professor in the Department of Applied Technology at Rogers 
State University.  
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2007</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>1328220</article_id>
		<sort_key>180</sort_key>
		<display_label>Pages</display_label>
		<pages>8</pages>
		<article_publication_date>11-14-2007</article_publication_date>
		<seq_no>4</seq_no>
		<title><![CDATA[Cognitive dimensions of a game scripting tool]]></title>
		<page_from>97</page_from>
		<page_to>104</page_to>
		<doi_number>10.1145/1328202.1328220</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1328220</url>
		<abstract>
			<par><![CDATA[<p>In this paper we show how a heuristic evaluation can be applied to a game scripting tool, using the Cognitive Dimensions of Notations framework. We introduce an end-user development toolset that allows users to create custom modules and content for the popular Neverwinter Nights computer role-playing game. The use of the Cognitive Dimensions of Notations as a discussion aid is illustrated through the examination of the toolset using a select set of dimensions. We comment on the findings, and on the usefulness of this approach to study of game development.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[cognitive dimensions of notations]]></kw>
			<kw><![CDATA[game development]]></kw>
			<kw><![CDATA[heuristic evaluation]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>K.8.0</cat_node>
				<descriptor>Games</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.7.2</cat_node>
				<descriptor>Hypertext/hypermedia</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.7.2</cat_node>
				<descriptor>Scripting languages</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010405.10010497.10010510.10011689</concept_id>
				<concept_desc>CCS->Applied computing->Document management and text processing->Document preparation->Document scripting languages</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010497.10010510.10010920</concept_id>
				<concept_desc>CCS->Applied computing->Document management and text processing->Document preparation->Hypertext / hypermedia creation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010476.10011187.10011190</concept_id>
				<concept_desc>CCS->Applied computing->Computers in other domains->Personal computers and PC applications->Computer games</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10011007.10010940.10010941.10010969.10010970</concept_id>
				<concept_desc>CCS->Software and its engineering->Software organization and properties->Contextual software domains->Virtual worlds software->Interactive games</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003251.10003258</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Multimedia information systems->Massively multiplayer online games</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Experimentation</gt>
			<gt>Human Factors</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P925259</person_id>
				<author_profile_id><![CDATA[81342499846]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Marty]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kauhanen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Carleton University, Ottawa, Canada]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P244169</person_id>
				<author_profile_id><![CDATA[81100135223]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Robert]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Biddle]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Carleton University, Ottawa, Canada]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[BioWare Corporation. Neverwinter Nights community site. http://nwn.bioware.com/.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>727492</ref_obj_id>
				<ref_obj_pid>647492</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[A. Blackwell. Cognitive dimensions of notations: Design tools for cognitive technology. Lecture Notes in Computer Science, 2117, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[S. DeRose, editor. <i>XML Linking Language (XLink)</i> Version 1.0. W3C, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>93015</ref_obj_id>
				<ref_obj_pid>92968</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[T. Green. <i>Cognitive dimensions of notations.</i> In A. Sutcliffe and L. Macaulay (Eds.) People and Computers V. Cambridge, UK: Cambridge University Press, 1989.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[T. Green and A. F. Blackwell. Cognitive <i>dimensions of information artefacts: a tutorial.</i> Version1.2. http://www.ndirect.co.uk/thomas.green/workStuff/Papers/, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[T. Green and M. Petre. Usability analysis of visual programming environments: A 'cognitive dimensions' framework. Journal of Visual Languages and Computing, 7(2), 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[D. Moar. BioWare <i>Aurora Neverwinter Nights Toolset Module Construction Tutorial.</i> BioWare Corporation, 2006.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[J. Nielsen. Ten usability heuristics. http://www.useit.com/papers/heuristic/heuristiclist.html.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[J. Nielsen. How to conduct a heuristic evaluation. 1994. http://useit.com/papers/heuristic/heuristicevaluation.html,]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[J. Watamaniuk. <i>Introduction to the Aurora Neverwinter Toolset.</i> BioWare Corporation, 2006.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Yee, N. (2007). <i>Motivations of Play in Online Games.</i> CyberPsychology and Behavior, 9, 772--775.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[M. Kauhanen, C. Eaket, R. Biddle. <i>Patterns for story authoring tools.</i> To appear in 12th European Conference on Pattern Languages of Programs. Hillside Group, 2007.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[C. Dormann, J. P. Fiset, S. Caquard, B. Woods, A. Hadziomerovic, E. Whitworth, A. Hayes and R. Biddle. <i>Repurposing a computer role playing game for engaging learning.</i> In Proceedings Ed-Media: World Conference on Educational Multimedia, Hypermedia, and Telecommunications, pages 4430--4435, Montreal, Canada, 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Cognitive Dimensions of a Game Scripting Tool Marty Kauhanen Human-Oriented Technology Lab Carleton 
University Ottawa, Canada mkauhanen@gmail.com ABSTRACT In this paper we show how a heuristic evaluation 
can be applied to a game scripting tool, using the Cognitive Dimensions of Notations framework. We introduce 
an end-user development toolset that allows users to create custom modules and content for the popular 
Neverwinter Nights computer role -playing game. The use of the Cognitive Dimensions of Notations as a 
discussion aid is illustrated through the examination of the toolset using a select set of dimensions. 
We comment on the findings, and on the usefulness of this approach to study of game development. Categories 
and Subject Descriptors K.8.0 [Personal Computing ]: games I.7.2 [Document Preparation]: hypertext/hypermedia, 
scripting languages  General Terms Design, Experimentation, Human Factors  Keywords cognitive dimensions 
of notations, game development, heuristic evaluation 1. INTRODUCTION This paper explores the use of 
a powerful analytical framework, the Cognitive Dimensions of Notation, for evaluation of a tool for end­user 
scripting of a commercial game. The cognitive dimensions approach is in some ways similar to the more 
well-known approach of heuristic evaluation, and in fact we use aspects of that approach in applying 
the cognitive dimensions framework. Our more general goal is to study the tools that are used to make 
games, both to understand the activity of game creation and learn how it might influence game design, 
and to understand how the process might be changed. We first introduce heuristic evaluation and then 
the principles of the cognitive dimensions framework. We then use the cognitive dimensions of notations 
framework for an examination of an end­user development toolset for the Neverwinter Nights computer role 
­playing game, called the Aurora Toolset. While not intended as a complete cognitive dimensions analysis 
of the toolset, we do highlight the potential findings of the approach with regard to some particular 
dimensions of analysis. Permission to make digital or hard copies of all or part of this work for personal 
or classroom use is granted without fee provided that copies are not made or distributed for profit or 
commercial advantage and that copies bear this notice and the full citation on the first page. To copy 
otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission 
and/or a fee. FuturePlay 2007, November 15-17, 2007, Toronto, Ontario. Copyright 2007 ACM 978-1-59593-943-2/07/0011...$5.00 
Robert Biddle Human-Oriented Technology Lab Carleton University Ottawa, Canada robert_biddle@carleton.ca 
 2. HEURISTIC EVALUATION Nielson and Molich suggested the method of heuristic evaluation as a usability 
engineering method for finding usability problems in a user interface design [9]. The heuristic evaluation 
method is performed by having a small number of evaluators examine a user interface independently, at 
first, and then comparing their notes in a collaborative session. While examining the interface, each 
evaluator uses a standard set of phrases that are recognized usability principles [9] or rules of thumb 
[8], called heuristics. The result of the evaluation is a list of usability problems found in the user 
interface, with each problem referencing a particular heuristic. The approach takes advantage of the 
many heuristics for good design that have been identified, and the general method does not prescribe 
which heuristics to evaluate. They do, however, offer a reasonable general set, which had been widely 
used [8]: Visibility of system status  Match between system and the real world  User control and freedom 
 Consistency and standards  Error prevention  Recognition rather than recall  Flexibility and efficiency 
of use  Aesthetic and minimalist design  Help users recognize, diagnose, and recover from errors  
Help and documentation Nielsen explains that an evaluator uses these heuristics as reference points for 
explaining the short-comings of a system [9]. A reference point is useful because it grounds the evaluator 
s observations in the perspective of accepted and recognized usability principles. Normally the heuristics 
above are each accompanied by a short description. For example, Nielsen presents the first three heuristics 
as follows [8]: Visibility of system status: The system should always keep users informed about what 
is going on, through appropriate feedback within reasonable time.  Match between system and the real 
world: The system should speak the users language, with words, phrases and concepts familiar to the user, 
rather than system­oriented terms. Follow real-world conventions, making information appear in a natural 
and logical order.   User control and freedom: Users often choose system functions by mistake and will 
need a clearly marked emergency exit to leave the unwanted state without having to go through an extended 
dialogue. Support undo and redo. While it is not necessary for the purpose of this paper to include all 
the descriptions of the heuristics, the three examples above were included to show how the descriptions 
do help clarify the heuristic, and that the descriptions are most likely not necessary beyond first reading. 
This is due to the succinct and operational nature of the heuristic phrases. Heuristic evaluation differs 
from prior observational user testing methods, with the main advantage being that it can save time by 
leveraging inspection. The full method recommended involves several expert evaluators working first independently 
and then together. The evaluators would normally be given background information, such a list of tasks, 
organized into use cases, or scenarios, that represent how the system is to be used. Our idea is to take 
this general kind of approach and apply it as a method of study about game development tools. The heuristics 
typically used in heuristic evaluation seem too general, and so we looked elsewhere for guidance.  3. 
COGNITIVE DIMENSIONS Cognitive Dimensions of Notations is a broad-brush, discussion tool for non-HCI 
specialists [5]. Blackwell defines the Cognitive Dimensions of Notations as a framework for describing 
the usability of notational systems . . . and information artifacts [2]. Examples of notational systems 
include spreadsheet processors, end-user development tools like the Aurora Toolset and various domain-specific 
systems. Examples of information artifacts include cell phones, mp3 players and the controls for air 
conditioner and are essentially self-contained notational systems [2]. Like heuristic evaluation, the 
Cognitive Dimensions of Notations approach seeks to identify and provide a list of usability problems. 
In addition, Cognitive Dimensions of Notations provides a vocabulary that is used by designers to discuss 
the implications of their design decisions [2] with respect to the usability of those designs. The implications 
are expressed as trade -offs, as a change in the degree of one dimension may have effects upon the other 
dimensions of a notation or artifact [6, 2, 4, 5]. In 1989, Green introduced Cognitive Dimensions of 
Notations stating that the cognitive dimensions method makes it easier to compare interfaces and languages, 
even if they are dissimilar [4]. Later, Green and Petre compare three very different visual programming 
environments (Basic, LabVIEW and Prograph) using the cognitive dimensions framework [6]. Green and Blackwell 
also provide detailed descriptions and illustrations of the dimensions in an online tutorial [5]. In 
2001, Blackwell gives a state of the nation view of the ongoing cognitive dimensions activities and research 
that includes an introduction to the framework, a summary of the dimensions, and criteria for the dimensions 
themselves [2]. 3.1 Dimensions and Activities The proposed cognitive dimensions are as follows [2]: 
 Viscosity: Resistance to Change  Visibility: Ability to View Components Easily  Premature Commitment: 
Constraints in the Order of Doing Things  Hidden Dependencies: Important Links between Entities Are 
Not Visible  Role-Expressiveness: The Purpose of an Entity Is Readily Inferred  Error-Proneness: The 
Notation Invites Mistakes and the System Give Little Protection  Abstraction: Types and Availability 
of Abstraction Mechanisms  Secondary Notation: Extra Information in Means Other Than Formal Syntax 
 Closeness of Mapping: Closeness of Representation to Domain  Consistency: Similar Semantics Are Expressed 
in Similar Syntactic Forms  Diffuseness: Verbosity of Language  Hard Mental Operations: High Demand 
on Cognitive Resources  Provisionality: Degree of Commitment to Actions or Marks  Progressive Evaluation: 
Work-to-Date Can Be Checked at Any Time Blackwell summarizes how dimensions are used and that the dimensions 
are neither used in a vacuum nor are they necessarily good or bad [2, 5]. The designer (or evaluator) 
makes notes on the dimensional characteristics of a notation system while considering the commonly performed 
activities of the user and the structure of the notation. Blackwell and Green also state that the accompanying 
tools that the environment provides are also included in the evaluation. In their online tutorial, Green 
and Blackwell distinguish the four main types of activities, providing the following definitions and 
examples [5]: incrementation adding further informa tion without altering the structure in any way adding 
a new card to a card-file; adding a formula to a spreadsheet transcription copying content from one structure 
to another structure copying book details to an index card; converting a formula into spreadsheet terms 
modification changing an existing structure, possibly without adding new content changing the index terms 
in a library catalogue; changing the layout of a spreadsheet modifying the spreadsheet to compute a different 
problem  only does the method provide a designer with a checklist of usability design exploratory combining 
typographic design; problems, it also provides helpful information on how to deal with modification, 
with incrementation and sketching; such problems and a clear advantage over heuristic evaluation. the 
further programming on the fly Still, for all its detail, there still are some minor drawbacks. First, 
characteristic that ( hacking ) some of the dimensions do not seem to play by the rules. Consider the 
desired end the following question: if premature commitment is almost always state is not known harmful, 
then is this not breaking the previously mentioned criteria: in advance dimensions are neither good nor 
bad? Perhaps this is due to the long list of criteria for a dimension, as listed by Blackwell et al. 
[2], in Green and Blackwell discuss the cognitive relevance of the main that to satisfy some criteria, 
the polarity characteristic was affected. activities with respect to some of the dimensions, giving the 
Some of the more important criteria for a good dimension include desirable profiles for each. orthogonality 
(making sure that two dimensions do not describe the To illustrate the relationships between the dimensions, 
we now same phenomenon), polarity (neither good nor bad), granularity consider two dimensions: premature 
commitment and hidden (tackle phenomena at a similar scale) and naming convention (a few dependencies, 
and their respective activity profiles. Hidden words at most; neutral; technical and accessible). Blackwell 
admits dependencies is additionally defined as Important Links between that coming up with good names 
for a dimension is difficult [2]. Entities Are Not Visible [2]. A more detailed definition of the Another 
possible explanation for the dimension, premature dimension offers: a hidden dependency is a relationship 
between commitment, to seemingly break the rules involves the lack of two components such that one of 
them is dependent on the other, examples where premature commitment is actually desired. One but the 
dependency is not fully visible [5]. Examples of hidden only needs to think of a safety-critical system 
or device that may dependencies include: HTML links and cells in spreadsheets. only be used safely in 
a particular order, thus calling for its controls Blackwell and Green conclude that hidden dependencies 
do not to be stringent and only allow operations in a particular order. While have an effect upon incrementation 
and transcription activities, Blackwell and Green do not provide such examples, they do mention except 
when mistakes are transcribed. Modification to structure, that the cost of premature commitment may be 
offset by decreasing however, has harmful effects when considering hidden the viscosity of the system, 
thereby allowing mistakes to be easily dependencies. For example, a user may not fully realize the undone 
or corrected [5]. ramifications of changing a formula in a spreadsheet because the Another possible weakness 
of the method lies with the names of the formulas and dataflow of a spreadsheet remain mostly hidden 
from dimensions. With so many constraints upon the names, they seem the user. less accessible than the 
operational terms in heuristic evaluation. Notice that hidden dependencies, while not desired in some 
Still, as previously discussed, the operationalization of terms is seen situations, are still acceptable 
in certain situations. While the as a valuable effort [2]. workarounds to hidden dependencies include 
adding cues to the Green and Petre provide, for each dimension, helpful questions that notation, highlighting 
different information and providing additional make the dimensions more operational [6, 2]. For example, 
tools, such workarounds may not be needed for all applications: the premature commitment and hidden dependencies 
are presented as nature of the activity, design costs and trade-offs with other follows [6]: dimensions 
may lead a designer to permit a certain degree of hidden dependencies [5]. For example, most web programmers 
still use the Hidden Dependencies: Is every dependency overtly simple unidirectional hyperlinks of HTML 
and rely upon additional indicated in both directions? Is the indication perceptual or tools, such as 
services provided by search engines, to get the only symbolic? numbers of backlinks to their sites. This 
is despite the advent of XML Linking Language (XLink) which makes multidirectional links Premature commitment: 
Do programmers have to make between resources possible [3]. decisions before they have the information 
they need? Premature commitment is a constraint on the order of doing things. Blackwell claims that this 
is one of the more self-explanatory These thumbnail descriptions are more practical as they seed the 
dimensions [2], yet it is more aptly defined in the tutorial as analysis [2] and are more accessible 
because they are in the form constraints on the order of doing things force the user to make of a question. 
Evaluators now have ready-made questions to ask decisions before the proper information is available 
[5]. In the about the notation or artifact, instead of definitions from which theyactivity profile, Green 
and Blackwell claim that premature must construct their own questions. commitment is harmful with respect 
to all four activities and explain Green and Petre also introduce the notion of straw tests for some 
that, in addition to order constraints, this is also the case when the of the dimensions, most notably 
for viscosity [6, 2]. For this user is forced to look ahead in a way that is cognitively expensive dimension, 
the straw test is measure the time it takes to do certain [5]. They continue to explain that a common 
cause of premature modifications, allowing for quick and inexpensive comparison commitment is when the 
designer s idea of the natural sequence is between the three visual programming languages [6]. at odds 
with the order in which the user will take [5]. In the examination of these two dimensions and their 
activity  4. APPLYING COGNITIVE DIMENSIONS profiles, we see the strengths of the Cognitive Dimensions 
of Before beginning to use the Cognitive Dimensions framework and Notations method. The activities have 
been classified and defined discussing the findings, one should first become familiar with the tool but 
also examined with respect to the dimensions. The work of to be analyzed and the domain to which it belongs. 
Green and Blackwell provide illustrations, examples, work-arounds, remedies and trade-offs for most of 
the dimensions [5]. In short, not  4.1 Neverwinter Nights and Aurora Toolset Developed by BioWARE and 
released in 2002, Neverwinter Nights (NWN) is a computer role -playing game (RPG) [1]. It is a fantasy­themed 
game set in a popular Dungeons and Dragons campaign world called the Forgotten Realms. The game mechanic 
of the game is based on the d20 System. A game mechanic is a set of rules used to determine the outcomes 
of actions in the game, where skills and abilities of the characters and their opponents along with environmental 
factors influence the probabilistic outcome. More importantly, the game comes with a toolset, called 
the Neverwinter Nights Aurora Toolset (Aurora), allowing users to construct their own custom game worlds. 
The game also allows for a user to act as the story-teller, or dungeon-master (DM), altering elements 
of game-play while other players play the game. Combined with the ability to play online with up to 64 
people and to set up persistent worlds on servers has no doubt contributed to NWN s success. The end 
result is essentially a multi-player online role-playing game. The success of the game can be reflected 
by the amount of supplementary material released by BioWare. Since 2002, BioWare has released six premium 
modules, two expansion packs and a number of editions of NWN. 4.2 Selecting Dimensions Cognitive Dimensions 
of Notations is versatile, as the selection of a limited set of dimensions is permitted. It allows evaluators 
to spend time on the dimensions of interest, resulting in a more streamlined usability profile of the 
notation or artifact [2]. The Aurora toolset will be examined using a subset of cognitive dimensions. 
The reasons for selecting each dimension will be detailed in this section. As previously examined, premature 
commitment is harmful under most actions. It would be prudent to see if the designers of the toolset 
took this into consideration. As noted by Green and Petre, with respect to programming the order of working 
should be left to the programmer, not prescribed by the environment [6]. That is, with respect to level 
of abstraction and the textual order in which they write, programmers frequently change while writing. 
This is no different with module builders. Because the tool is essentially a world-builder, it is valid 
to assume that modification would be a common activity. With tha t in mind, it would be prudent to select 
several dimensions that rank modification as harmful or important. Both viscosity and hidden dependencies 
fit both ends of the spectrum. In addition, viscosity would be a useful dimension to consider, especially 
considering that the tool acts as an editor. Hidden dependencies is worth considering, as there are many 
obvious links between game elements as seen during game-play. The dimension visibility seems closely 
related to other dimensions, like premature commitment and hidden dependencies, and therefore will be 
discussed throughout. Because adventures can be long and modules quite large, it would be prudent to 
consider the progressive evaluation in order to see whether or not work-to-date can be checked at any 
time [2] by executing partially complete modules [5]. The limitations of the facility to progressively 
evaluate, if any, should also be investigated. The designers of the toolset write [10]: The idea behind 
the creation of the Toolset is to allow one of the most important aspects of pen and paper Dungeons and 
Dragons to come to life on your computer module building. This suggests that closeness of mapping would 
make a suitable dimension to consider. Or as Green and Petre would pose what programming tricks need 
to be learned? [6]. Would-be builders of adventures and modules are not necessarily programmers, thus 
any element of the tool that relies upon complicated programming may constitute a usability problem. 
While we did examine the toolset with respect to closeness of mapping and identified many programming 
tricks required to learn, the results are not presented here. 4.3 The Scenarios Taking a page from Nielsen 
s Heuristic Evaluation, a number of scenarios will be used to represent typical use. Moar s online tutorial 
on module construction will serve as the scenarios. The result is a playable module, with the three areas: 
a town called Fern, an inn and the Fernesk Mines. The tutorial is divided into nine sub­tutorials and 
is summarized by Moar as follows [7]: Tutorial 1: introduces the New Module and New Area wizards and 
explains how to paint terrain. Tutorial 2: expands on the terrain painting skills learned in the previous 
tutorial and introduces new area manipulation commands. Painting and editing game objects is also covered. 
Tutorial 3: in addition to introducing doors, this tutorial completes the terrain painting lessons by 
explaining how to link areas together. Tutorial 4: describes the difference between the standard and 
custom palettes and demonstrates the different ways to create custom blueprints. Tutorial 5: explains 
Factions and introduces the Faction Editor in the Toolset. In addition, two new factions and a new creature 
blueprint will be created. Tutorial 6: introduces the Journal and Conversation Editors. Tutorial 7: discusses 
item creation and merchants. Tutorial 8: introduces ways to manipulate area lighting and sound settings. 
Tutorial 9: introduces the NWScript language and the Toolset s Script Editor. We have used the Aurora 
Toolset in our research group for development of serious games mods to Neverwinter Nights [13]. However, 
we felt it was important to consider the toolset in general. Accordingly, we worked through these tutorials 
as a way to inform our application of the cognitive dimensions framework. The specific tasks in each 
of the sub-tutorials will be described as required in the analysis.   5. COGNITIVE DIMENSIONS ANALYSIS 
Our analysis will begin with a brief look at the toolset, introducing its parts for reference. On startup, 
the Aurora Toolset gives the option of opening an existing module or creating a new one. A module is 
basically a container for all areas, items, locations, creatures and encounters for an adventure. Selecting 
a new module launches The Module Creation Wizard and the Area Wizard. Watamaniuk provides the picture 
in figure 1, showing the four areas of the toolset [10]. The areas identified are as follows:  A Toolbar 
Commands, preferences and menus.  B Palette Contains hierarchies of content that ma y be added to the 
module, including tile patterns, creatures, objects, doors and other special objects. In parts of the 
tutorial, items listed here are called blue -prints.  C Module Content: This is a hierarchical listing 
of content that has been placed into the module. At the highest level, it is organized by Areas, Conversations 
and Scripts.  D Area Display: This part of the toolset displays the currently selected area. It is the 
place where objects from the palette are added. In the subsections that follow, we will take a number 
of the cognitive dimensions in turn, and offering considerations of the support for that dimension apparent 
in the toolset.  Figure 1. The four areas of the Aurora toolset 5.1 Premature Commitment Constraints 
on the Order of Doing Things [2] Do programmers have to make decisions before they have the information 
they need? [6] In this section, several problems with respect to premature commitment are identified 
and discussed. It is also interesting to note how the discussion of the first problem leads naturally 
into the discussion of related problems with respect to other dimensions, in this case visibility, viscosity 
and consistency. It is a conscious decision to keep the discussions of related problems grouped together, 
rather than break them under appropriate dimension­related headings. The reason for this grouping is 
threefold: first, to reveal the evaluator s train-of-thought, second, to illustrate that problems in 
one dimension may be related to problems in other dimensions and, finally, to show that design patterns 
may become evident [12]. With this dimension in mind, it is easy to see envision designer s view about 
the natural order of use for the toolset: one creates a module, creates an area and then populates it. 
The designer has taken the liberty of making helpful wizards (which are not really optional if you are 
starting from scratch) to facilitate module and area creation in that order. The only other way to start 
the application is to open an existing module. Otherwise all the commands, buttons and menus of the toolset 
are grayed out. It does not take much imagination to envision other ways in which a user may want to 
use the toolset. For example, a builder may have an idea for a custom encounter or a custom magical item 
but may not know up front where it will be used. The builder must open an existing module or create a 
dummy module in order to create the resource. This problem is then compounded by, or perhaps due to, 
the fact that there is no universal palette that keeps track of custom resources. The design decision 
(to have custom resources be module-specific) seems to stem from the way a module is stored: in a single 
file. Each of the custom resources is contained within the module that it was created 20 under and each 
module is stored in a single .mod file. The custom resource must be exported to its own file and then 
imported into the modules as desired. This is strange, given that there is a common listing (or library) 
of blueprints located in the palette. Notice how the high degree of premature commitment and the implication 
of the aforementioned design decision can lead to the discussion to other dimensions, namely the viscosity 
of the import/export tasks, the visibility of the resources to be imported/exported. A bit of exploration 
reveals that the import/export functionality gets rather complicated. For example, if you export an area 
then only the instances of custom creatures placed or painted in the area are exported, unless you specifically 
add the blueprints of those custom creatures into the same export file. One can imagine after many imports 
and exports, a builder can easily lose track of his blueprints. This can be attributed to a low visibility 
of resources in both files and in other modules and the high viscosity when adding custom resources from 
other modules. The designer admits that the import/export is complicated by providing an export note 
dialogue box in which notes about the export file can be made. The notes are then displayed as the resource 
file is imported. The problem is complicated further by the fact that scripts and custom creatures in 
one module may have the same names as in other modules. Importing and exporting can quickly become a 
nightmare. After examining the implications of the above design decisions, one may conclude that the 
ability to operate at one level higher, that is to be able to see and manipulate all the modules at the 
highest level of the hierarchy, in addition to the ability to add custom resources to the library and 
the ability to use the toolset without opening a specific module, would all increase usability. Premature 
commitment would be lessened. Visibility of the custom resources would be increased as would the ease 
of transferring said resources between modules. It would also relegate the import/export functionality 
to transferring specific resources between computers and reduce the amount of time spent dealing with 
low level concepts like files, thus increasing consistency in how resources are shared and accessed. 
Importing and exporting would become a less frequent task, as most designers tend to work from the same 
machine or networked environment. One might complain that having all the modules available may place 
a burden upon system resources. A quick look reveals that the sizes of the exported files are as follows: 
the creature blueprint of the goblin from the tutorial is about 5KB, the inn area is 16 KB and the village 
area of Fern is about 88KB whereas the size of the chapters, or game modules, of the NWN game range from 
6000KB to 31000KB. While it clearly would be undesirable to have all the modules open at once, this is 
not the behaviour of Aurora. For example, when an area is highlighted in the Module Content pane, Aurora 
takes a brief moment to load the area. It would not be a stretch to have all modules and their contents 
listed in an explorer-like window. A library of custom blueprints would also save a nominal amount of 
disk space. With respect to premature commitment, several additional problems become evident when working 
through the Aurora tutorial. Two involve the handling of areas. The first discusses an implication of 
a design while the second targets a more specific usability problem with regards to resizing an area. 
Recall that an area represents a specific place in a module, such as an inn or a mine, represented by 
a map. It is in areas that the players will explore, battle monsters and overcome obstacles during game-play. 
It is the job of the builder to populate the areas with terrain, buildings, creatures, encounters and 
everything that the player will interact with. It is interesting to revisit the fact that the designer 
s of Aurora have placed a great focus upon areas, as discussed earlier in this section, in that an area 
must be created before work on a module may begin. The designer s importance placed upon areas is clear, 
but it does have the implication that exploration becomes a major focus of the game. Yee categorizes 
the motivations of MMORPG players into the following three categories and ten sub-categories [11]: Advancement 
 advancement mechanics competition, Achievement socializing relationship teamwork and Immersion 
 discovery role-play customization escapism. Exploration is a sub-component of discovery, albeit an 
important one. Discovery, in turn, is a sub-category of immersion. The Aurora toolset assumes that the 
builder wishes to include exploration as a part of his module. It is perfectly acceptable in RPGs, however, 
to develop adventures that do not involve exploring maps, instead concentrating on elements like interactive 
narratives, role -playing scenarios and social interaction. Another problem lies with a rather common 
modification activity, namely resizing the area map. The area, as it appears in the Area Display, cannot 
be resized using the mouse. Instead, to resize an area, the command must be called up from the Edit menu. 
The following dialogue box allows the builder to modify number of tiles in each row and column of the 
area. Notice that there is no indication as to how the area will be resized. Thankfully, the section 
in the Aurora tutorial called Advanced Area Manipulation warns the builder [7]:  Warning: The Toolset 
adds to and removes from the top row and right column of the area when it is being resized. This normally 
isn t an issue if the area is enlarged but if the area is reduced, objects on the top rows and right 
columns tiles will be automatically deleted. Tip: The Resize Area command can be undone using [Ctrl] 
+ Z or the Undo command. But what if one wants to add to or trim the area on bottom row and/or left column? 
If this is the case, the builder is burdened with a series of tasks that make resizing the area more 
viscous. In the case of adding space to the bottom and/or left side of the area, the user may be tempted 
to shift components around, that is until the user realizes where the tiles are added and uses the Rotate 
Area command, also found under the Edit menu. For example, to add a row to the bottom of an area, the 
builder must do the following: 1) Re-orient the camera (a button located in the Tool-bar, nowhere near 
the camera control buttons) so that it matches the orientation of the area and the builder knows which 
side is the top. 2) Edit Rotate Area Clockwise 180 (the user is also given the option of a CounterClockwise 
180 rotation, which is the same thing.) 3) Edit Resize Area Increase Row Size by 1 4) Edit Rotate 
Area Clockwise 180 (presumably if the orientation of the map is meaningful in the context of the adventure). 
5) Trim the impassable terrain at the edge. Note that the Rotate Area command is different than the 
Rotate Camera arrows provided at the bottom of the Area Display. The new squares are still only added 
to top and right side of the area with respect the original orientation of the area, regardless of the 
camera rotation. After enlarging an area, the builder must trim back any impassable terrain tiles (like 
cliff tiles or dense tree tiles) because the new tiles are not empty; the new tiles contain the same 
terrain as the tiles to which they are now adjacent. This adds to the chore, and viscosity, of resizing 
an area, especially if a lot of work has already gone into the area. If the steps prove too troublesome, 
an alternative would be to create an entirely new area and then link the areas together using a transition 
point. This may not be desirable as a transition to a new area during game-play often implies new objectives 
and may confuse players by interrupting the flow of the game. With the case of reducing the size of an 
area, the system provides a warning that some objects may be deleted and kindly mentions that if the 
change is desirable, the undo functionality is available. There is neither a cancel button nor any indication 
of which tiles and objects are being deleted. After learning this behaviour, presumably by trial-and-error 
or by heeding the warning in the Aurora tutorial, the builder hopefully realizes the following: make 
sure to choose the right size for an area at the start, preferably, or early on in an area s development 
as altering the size may become costly; do not place important items near the borders (top and right) 
as they will disappear if you make size of the area smaller; use Rotate Area in conjunction with Resize 
Area command to add tiles to the desired side. These realizations indicate a high level of premature 
commitment.  5.2 Consistency Similar Semantics Are Expressed in Similar Syntactic Forms [2] When some 
of the language has been learnt, how much of the rest can be inferred? [5] Besides the low consistency 
between how common resources and custom resources are shared between modules, other problems in Aurora 
are evident. The most glaring is the inconsistent behaviour of the Undo command. For instance, undo works 
well when pa inting features tiles, items or creatures upon an area. As already discussed, undo also 
reverses the effects of resizing areas. The undo command is not available after importing, however. Given 
the low visibility of resources located in the export files and the possibility of existing resources 
being copied over by those in an import, a functioning undo would be greatly appreciated. The lack of 
consistency in the behaviour of the undo command may lead to irreparable mistakes, a lot of second-guessing 
and is frustrating in the least. Another problem lies in the low consistency of the behaviour of the 
eraser tool. The eraser tool is found under Terrain grouping in the Palette, yet it erases Features and 
most of the Terrain tiles. For other terrain tiles, like grass tiles, the eraser tool merely toggles 
the look of the terrain tile. Some terrain tiles, like trees, leave artifacts that cannot be erased using 
the eraser tool; they instead must be painted over with another terrain tile, like grass tiles for instance. 
Even the area that the eraser tool highlights acts more like a Feature tile than a Terrain tile, as seen 
in the following screenshot. And finally, in an attempt to handle two similar concepts (a blueprint and 
an instance of a blueprint) in a similar fashion, the designer made a mistake by not identifying that 
the two are indeed different. Perhaps it is more a visibility problem, but it was noticed when looking 
for examples of consistency. The problem is illustrated in the screens used to edit an instance of a 
creature and to edit a blueprint of a creature; they appear almost identical. The only indication that 
the second screen belongs to a blueprint is it has a field for category. Another indication may be inferred 
from buttons found under the Advanced Tab. The implication is one may begin editing a blueprint when 
they meant to edit an instance or vice versa.  5.3 Progressive Evaluation Work-to-Date Can Be Checked 
at Any Time [2] Can a partially-complete program be executed to obtain feedback on How am I doing ? [5] 
 Aurora provides the ability to build the module like a compiler, flagging and notifying the builder 
of any errors. Builders may also test their module, effectively allowing them to execute their module 
and experience the module as the players would. This can also be done with incomplete modules. The only 
drawback to the way that the test functionality is implemented is that builders must play the module 
from the beginning. Given that modules may include many areas and multiple quests, it would be highly 
desirable to be able choose the point at which they wish to test. Unfortunately, in Aurora this is not 
the case, making testing long or complex modules a time-consuming task. This is largely due to the fact 
that there is a very weak concept of state within a module. The state is handled haphazardly, using a 
combination of local variables and scripts that check to see if certain events have occurred. Sometimes 
scripts make reference to local variables and other times they do not. For instance, in the Aurora tutorial, 
a local variable called nFirstTimeTalked is created inside the Conversation Editor using the Script Wizard 
[7]. The local variable will be used to store data that represents whether or not the player has already 
talked to a particular creature, called Falstadd. The local variable is then employed by a script, that 
is in turn attached to the Falstadd s conversation resource (a container for simple branching conversations), 
to determine which conversation to use. When first spoken to, Falstadd greets the player and bestows 
a quest. The next time he is spoken to, he asks about the status of the quest. It must be stressed that 
the variable is local to Falstadd s conversations only. There are no local variables for modules. A third 
conversation is created; a conversation that Falstadd has with the player if the player has completed 
the quest. In this final conversation, the concept of state is handled differently. The quest that the 
player performs for Falstadd involves the recovery of a particular ring . The item is created and given 
a specific and unique identifier called a tag. The final conversation is available only when the ring 
is in the player s inventory. A conversation script is used to check whether or not the ring is in the 
inventory, but no local variable is used. A module script updates the journal upon the player s acquisition 
of the ring, instructing the player to return to Falstadd. The in-game journal is periodically updated, 
showing the progress attained in each quest. Moar writes in general, the state of a plot or quest is 
measured by its journal entries but is driven by the dialogue spoken by its participants [7]. More precisely, 
the journal updates are driven by the scripts and any local variables they may use. Here lies a hidden 
dependency: from the journal editor, one does not know which local variables or scripts trigger each 
journal update or state of the plot [7]. Thus, without a clear view of all local variables and no concept 
of global variables, it is not possible to test from a certain state of the plot. 5.4 Visibility Ability 
to View Components Easily [2] Systems that bury information in encapsulation reduce visibility [2] Is 
every part of the code simultaneously visible (assuming a large enough display), or is it at least possible 
to juxtapose any two parts side-by-side at will? If the code is dispersed, is it at least possible to 
know in what order to read it? [5] Visibility has been discussed throughout the other sections. Here 
a checklist of the visibility-related issues identified is provided, including those already covered. 
 unable to view resources in an export file  unable to view resources in other modules from the module 
under design  not easy to visibly differentiate between the edit screens of an instance and a blueprint 
(should this be under consistency or hidden dependencies?)  variables are not readily visible or accessible 
from the main program; they are created inside the script wizard that is in turn accessible in the conversation 
editor  script preview pane in the conversation editor is very small (6 lines) and cannot be expanded 
through normal window manipulation   5.5 Viscosity Resistance to Change [2] How much effort is required 
to perform a single change? [5] Here is a checklist of problems with respect to viscosity: Many tasks 
are required to export a custom resource and import it into another module.  Many tasks are required 
to resize a map area. As previously discussed, this task is not as simple as it should be.  5.6 Hidden 
Dependency Important Links between Entities Are Not Visible [2] Are there places where the user needs 
to resort to fingers or penciled annotation to keep track of what s happening? [5] Here is a checklist 
of some problems with high hidden dependencies: The links between scripts and journal entries are unidirectional; 
the scripts are not seen by the elements in the Journal Editor.  Scripts listed in the Module Content 
Pane are linked to conversation branches, yet there is no indication from the Module Content Pane as 
to which conversations they belong. Editing the script directly does not indicate where it is used. One 
must open and edit the conversation resource and select each conversation branch to see the particular 
script that is attached. Builders must rely upon their own naming convention for scripts, notes or memory. 
 When a builder edits an instance of a creature, there is no indication that the instance now no longer 
follows the blueprint for the creature. Conceivably, a builder could then edit a blueprint and update 
all instances accordingly, destroying the first edits to the instance.  When dealing with custom resources 
that exist in multiple modules, there is no way of seeing which resource is newer or how they differ. 
Builders must keep track of differences between custom resources across modules themselves, or run the 
risk of copying over newer ones during import. It is up to the user to make detailed notes during export 
in the dialogue box provided.   6. CONCLUSIONS In this paper we explored using the heuristic evaluation 
of a game scripting tool, using cognitive dimensions. We reviewed the nature of heuristic evaluation 
and outlined the cognitive dimensions framework. We then conducted an exploratory evaluation of the Aurora 
Toolset, using a tutorial sequence as a source of common uses. We concentrated our discussion of the 
Aurora Toolset on the cognitive dimensions of viscosity, visibility, premature commitment, consistency, 
hidden dependencies and progressive evaluation. The dimensions were chosen at first for a variety of 
reasons, including their implications with respect to the modification activity and the fact that many 
seemed related to one another. We later found it difficult to keep the discussion of one dimensional 
characteristic separate from one another, as many of the usability problems were related to other problems 
in other dimensions. In particular, visibility seems to go hand-in-hand with many dimensions, including 
hidden dependencies (are the links visible?) and premature commitment (what information if made visible 
would then alleviate the cost of the constraints?). We found the dimensions seemed less operational than 
Nielsen s heuristics. In particular, the abundance of criteria that a dimension must seems to the dimension 
names and descriptions to be more complex, less obvious and less accessible. We feel that more attention 
is needed in three areas: the first is to work on making the dimensions more accessible and operational, 
second is to re-examine the relationships between the dimensions as some are very closely related, third, 
to examine the role that cognitive dimensions may play in suggesting associations with well­known solutions 
to design problems. Our eventual goal is to use this method as a way to reflect on the game design process, 
as well as on the tools that support it. From our experience reported herein, our reflection is on how 
closely these issues may be related. A common thread that unifies our findings using the cognitive dimensions 
framework to look at the Aurora Toolset is that the toolset seems to support some ways of designing and 
building a game more fluidly than others. In other words, there is an underlying script about how one 
should script a game.  7. REFERENCES [1] BioWare Corporation. Neverwinter Nights community site. http://nwn.bioware.com/. 
[2] A. Blackwell. Cognitive dimensions of notations: Design tools for cognitive technology. Lecture Notes 
in Computer Science, 2117, 2001. [3] S. DeRose, editor. XML Linking Language (XLink) Version 1.0. W3C, 
2001. [4] T. Green. Cognitive dimensions of notations. In A. Sutcliffe and L. Macaulay (Eds.) People 
and Computers V. Cambridge, UK: Cambridge University Press, 1989. [5] T. Green and A. F. Blackwell. Cognitive 
dimensions of information artefacts: a tutorial. Version1.2. http://www.ndirect.co.uk/thomas.green/ workStuff/Papers/ 
, 1998. [6] T. Green and M. Petre. Usability analysis of visual programming environments: A cognitive 
dimensions framework. Journal of Visual Languages and Computing, 7(2), 1996. [7] D. Moar. BioWare Aurora 
Neverwinter Nights Toolset Module Construction Tutorial. BioWare Corporation, 2006. [8] J. Nielsen. Ten 
usability heuristics. http://www.useit.com/papers/heuristic/heuristic list.html. [9] J. Nielsen. How 
to conduct a heuristic evaluation. 1994. http://useit.com/papers/heuristic/heuristic evaluation.html, 
[10] J. Watamaniuk. Introduction to the Aurora Neverwinter Toolset. BioWare Corporation, 2006. [11] Yee, 
N. (2007). Motivations of Play in Online Games. CyberPsychology and Behavior, 9, 772-775. [12] M. Kauhanen, 
C. Eaket, R. Biddle. Patterns for story authoring tools. To appear in 12th European Conference on Pattern 
Languages of Programs. Hillside Group, 2007. [13] C. Dormann, J.P. Fiset, S. Caquard, B. Woods, A. Hadziomerovic, 
E. Whitworth, A. Hayes and R. Biddle. Repurposing a computer role playing game for engaging learning. 
In Proceedings Ed-Media: World Conference on Educational Multimedia, Hypermedia, and Telecommunications, 
pages 4430-4435, Montreal, Canada, 2005.   
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2007</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>1328221</article_id>
		<sort_key>190</sort_key>
		<display_label>Pages</display_label>
		<pages>8</pages>
		<article_publication_date>11-14-2007</article_publication_date>
		<seq_no>5</seq_no>
		<title><![CDATA[Casual games discussion]]></title>
		<page_from>105</page_from>
		<page_to>112</page_to>
		<doi_number>10.1145/1328202.1328221</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1328221</url>
		<abstract>
			<par><![CDATA[<p>Digital games have become a remarkable cultural phenomenon in the last ten years. The casual games sector especially has been growing rapidly in the last few years. However, there is no clear view on what is "casual" in games cultures and the area has not previously been rigorously studied. In the discussions on casual games, "casual" is often taken to refer to the player, the game or the playing style, but other factors such as business models and accessibility are also considered as characteristic of "casual" in games. Views on casual vary and confusion over different meanings can lead to paradoxical readings, which is especially the case when "casual gamer" is taken to mean both "someone who plays casual games" and someone who "plays casually". In this article we will analyse the ongoing discussion by providing clarification of the different meanings of casual and a framework for an overall understanding of casual in the level of expanded game experience.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[casual game player]]></kw>
			<kw><![CDATA[casual gamer]]></kw>
			<kw><![CDATA[casual games]]></kw>
			<kw><![CDATA[casual gaming]]></kw>
			<kw><![CDATA[casual playing]]></kw>
			<kw><![CDATA[digital games]]></kw>
			<kw><![CDATA[expanded game experience]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.2.1</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10002951.10003227</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003241.10003243</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Decision support systems->Expert systems</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003241.10003243</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Decision support systems->Expert systems</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Human Factors</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P925252</person_id>
				<author_profile_id><![CDATA[81342501110]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Jussi]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kuittinen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Tampere]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P925218</person_id>
				<author_profile_id><![CDATA[81342501070]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Annakaisa]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kultima]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Tampere]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P925251</person_id>
				<author_profile_id><![CDATA[81342506130]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Johannes]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Niemel&#228;]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Tampere]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P925242</person_id>
				<author_profile_id><![CDATA[81342506587]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Janne]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Paavilainen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Tampere]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[2006 Casual Games Market Highlights. Casual Connect Magazine(Fall 2006), 6--8. Retrieved March 31, 2007, from http://mag.casualconnect.org/fall2006/Fall_2006_Kiev_english.pdf.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Bogost, I. (2004). Asynchronous Multiplay: Futures for Casual Multiplayer Experience. Retrieved March 31, 2007, from http://itu.dk/op/papers/bogost.pdf.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Bogost, I. (2006). Is there a future for casual games on digital cameras? Water Cooler Games. Retrieved March 31, 2007, from http://www.watercoolergames.org/archives/000711.shtml.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Brodie, J. (2007). I'm Mad as H@#%, and I'm Not Going to Take it Anymore! - Gamezebo.com. Retrieved March 31, 2007, from http://tinyurl.com/yrn22j.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Clark, E. Monetization Across the Value Chain - An Interview with Mark Cottam and Paul Jensen of MumboJumbo. Casual Connect Magazine, 10--15. Retrieved March 30, 2007, from http://mag.casualconnect.org/winter2007/CasualConnect_Winter_2007.pdf.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Cybulskie, A. (2004). Casual players *already* complaining about WoW. Retrieved March 31, 2007, from http://tinyurl.com/25w2q7.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Dillon, B. (2005). 2005 Indie Games Conference: Casual Games. Retrieved March 30, 2007, from http://www.gamasutra.com/features/20051018/dillon_01.shtml.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Dillon, B. (2006). Casuality Roving Reporter: Beth Dillon - Gamezebo.com. Gamezebo.com. Retrieved March 31, 2007, from http://tinyurl.com/2x7e2h.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Dobson, J. (2006b). Survey: PopCap Releases Casual Game Findings. Retrieved March 31, 2007, from http://www.gamasutra.com/php-bin/news_index.php?story=10861.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Drucker, S., He, L., Cohen, M., Wong, C., &amp; Gupta, A. (2002). Spectator Games: A New Entertainment Modality For Networked Multiplayer Games. Retrieved March 31, 2007, from http://research.microsoft.com/~sdrucker/papers/spectator.pdf.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Ducheneaut, N., &amp; Moore, R. J. (2004). The social side of gaming: a study of interaction patterns in a massively multiplayer online game. Chicago, Illinois, USA: ACM Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1124834</ref_obj_id>
				<ref_obj_pid>1124772</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Ducheneaut, N., Yee, N., Nickell, E., &amp; Moore, R. (2006). 'Alone together?' Exploring the Social Dynamics of Massively Multiplayer Games. Conference proceedings on human factors in computing systems, 407--416. Retrieved March 31, 2007, from http://tinyurl.com/lsafd.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Entertainment Software Association: Essential Facts About The Computer and Video Game Industry 2006. (2006). Retrieved March 30, 2007, from http://tinyurl.com/gonbv.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Entertainment Software Association: Top 10 Industry Facts. Retrieved March 30, 2007, from http://theesa.com/facts/top_10_facts.php.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Ermi L. &amp; M&#228;&#228;yr&#228; F. (2005). Fundamental components of the gameplay Experience: Analyzing Immersion. Selected Papers Proceedings if DiGRA 2005 Conference: Changing Views -- Worlds in Play, 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Game Research. (2002). Online Gaming Habits. Retrieved March 31, 2007, from http://tinyurl.com/2azeo6.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Gough, D. (2006). Casual Games and Micro Payments. Suttree.com: Casual Games, Social Software. Retrieved March 31, 2007, from http://tinyurl.com/27tu33.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Hattan, J. (2005). Casual Games Summit. Retrieved March 29, 2007, from http://www.gamedev.net/columns/events/coverage/feature.asp?feature_id=17.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Higgins, T. (2005). Go Casual! - Austin Game Conference Report. Retrieved March 30, 2007, from http://weblogs.macromedia.com/thiggins/archives/2005/11/go_casual_-_aus.cfm.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Hyman, P. (2004). 'Casual' video games are serious business. Retrieved March 31, 2007, from http://www.hollywoodreporter.com/hr/search/article_display.jsp?vnu_content_id=1000535245.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Jakobsson, M., &amp; Taylor, T. (2003). The Sopranos meets Everquest - social networking in massively multiuser networking games. Retrieved March 31, 2007, from http://tinyurl.com/ytktcf.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Jeffries, M. (2001). Casual gamers Vs True gamers&#8230; Retrieved March 31, 2007, from http://tinyurl.com/2a7glz.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[Macrovision Corporation. (2006). Survey Reveals Casual Gamers Are Not So Casual. Retrieved March 31, 2007, from http://tinyurl.com/mnj36.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[Millis, G., &amp; Robbins, B. (Eds.). (2005). IGDA 2005 CasualGames White Paper. Retrieved March 30, 2007, from http://www.igda.org/casual/IGDA_CasualGames_Whitepaper_2005.pdf.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[Olson, R. (2006). Casual Gamers Anything But. Retrieved March 30, 2007, from http://www.redherring.com/Article.aspx?a=17429&hed=Casual+Gamers+Anything+But.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[PopCap Games. (2006). Survey: Casual Computer Games as TV Replacement? Players Average 48 Years of Age, Seek Relaxation and Mental Exercise from Games; Largest-Ever Survey of Casual Game Players Yields Surprising Data. Retrieved March 29, 2007, from http://tinyurl.com/yrhjhp.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[RealNetworks, Inc. (2006). Research Reveals Casual Games Provide Mental Balance, Stress Relief and Relaxation. Retrieved March 31, 2007, from http://tinyurl.com/2aeqca.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[Seay, A. F., Jerome, W. J., Lee, K. S., &amp; Kraut, R. E. (2004). Project massive: a study of online gaming communities. Vienna, Austria: ACM Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[Sisson, B. (2004). Casual players *already* complaining about WoW. Retrieved March 31, 2007, from http://tinyurl.com/2glyhh.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>30</ref_seq_no>
				<ref_text><![CDATA[Spencer, H. (2001). Casual gamers Vs True gamers&#8230; Retrieved March 31, 2007, from http://tinyurl.com/2zdd9j.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>31</ref_seq_no>
				<ref_text><![CDATA[Stuart, K. (2005). Casual gaming: the new hardcore from Guardian Unlimited: Gamesblog. Guardian Unlimited: Gamesblog. Retrieved March 31, 2007, from http://tinyurl.com/2ee3av.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>32</ref_seq_no>
				<ref_text><![CDATA[Tams, J. (2006). Online Casual Games Q&A. Minna Magazine(Summer 2006), 2--5. Retrieved March 29, 2007, from http://mag.casualconnect.org/MinnaMagazine_Summer2006. pdf.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>33</ref_seq_no>
				<ref_text><![CDATA[Tinney, W. (2005). Postcard from the Casual Games Conference. Retrieved March 31, 2007, from http://www.gamasutra.com/features/20050803/tinney_01.shtml.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>34</ref_seq_no>
				<ref_text><![CDATA[Twist, J. (2005). Casual gaming to 'take off in 2005'. Retrieved March 30, 2007, from http://news.bbc.co.uk/1/hi/technology/4151431.stm.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>35</ref_seq_no>
				<ref_text><![CDATA[Wallace, M., &amp; Robbins, B. (Eds.). (2006). IGDA 2006 Casual Games White Paper. Retrieved March 29, 2007, from http://www.igda.org/casual/IGDA_CasualGames_Whitepaper_2006.pdf.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>36</ref_seq_no>
				<ref_text><![CDATA[Wallis, A. (2006). Q&A: Cai Looks Beyond 'Hardcore Vs. Casual'. Retrieved April 1, 2007, from http://www.gamasutra.com/php-bin/news_index.php?story=10704.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>37</ref_seq_no>
				<ref_text><![CDATA[Waugh, E. (2006). GDC: Casual Games Summit 2006: An Introduction to Casual Games. Retrieved March 30, 2007, from http://www.gamasutra.com/features/20060322/waugh_01.shtml.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>38</ref_seq_no>
				<ref_text><![CDATA[Wen, H. (2006). Analyze This: Will 'Casual' Games Dominate the Future of the Industry? Retrieved March 31, 2007, from http://www.gamasutra.com/features/20060803/wen_01.shtml.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>39</ref_seq_no>
				<ref_text><![CDATA[Whitney, C. (2004). Casual players *already* complaining about WoW. Retrieved March 31, 2007, from http://tinyurl.com/yw2jb9]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>40</ref_seq_no>
				<ref_text><![CDATA[WORLD OF WARCRAFT&#174; SURPASSES 8 MILLION. (2007). Retrieved March 31, 2007, from http://www.blizzard.com/press/070111.shtml.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>41</ref_seq_no>
				<ref_text><![CDATA[Zimmerman, E. (2007). Discussions with Eric Zimmerman on the Games &amp; Storytelling workshop in Helsinki, Finland.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Casual Games Discussion Jussi Kuittinen University of Tampere Kanslerinrinne 1 FIN-33014 University 
of Tampere +358 405 820 925 jussi.kuittinen@uta.fi Annakaisa Kultima University of Tampere Kanslerinrinne 
1 FIN-33014 University of Tampere +358 504 437 258 annakaisa.kultima@uta.fi ABSTRACT Digital games have 
become a remarkable cultural phenomenon in the last ten years. The casual games sector especially has 
been growing rapidly in the last few years. However, there is no clear view on what is casual in games 
cultures and the area has not previously been rigorously studied. In the discussions on casual games, 
casual is often taken to refer to the player, the game or the playing style, but other factors such as 
business models and accessibility are also considered as characteristic of casual in games. Views on 
casual vary and confusion over different meanings can lead to paradoxical readings, which is especially 
the case when casual gamer is taken to mean both someone who plays casual games and someone who plays 
casually . In this article we will analyse the ongoing discussion by providing clarification of the different 
meanings of casual and a framework for an overall understanding of casual in the level of expanded game 
experience. Categories and Subject Descriptors I.2.1 [Applications and Expert Systems]: Games  General 
Terms Human Factors,  Keywords Digital games, casual games, casual gamer, casual game player, casual 
gaming, casual playing, expanded game experience 1. INTRODUCTION Digital games have become a multibillion 
dollar business [14] and the casual games sector is one of the fastest growing segments within the industry. 
Casual games have been described as games that generally involve less complicated game controls and overall 
complexity in terms of gameplay or investment required to get through the game [35]. Industry experts 
have estimated that in Permission to make digital/hard copy of part of this work for personal or classroom 
use is granted without fee provided that the copies are not made or distributed for profit or commercial 
advantage, the copyright notice, the title of the publication, and its date of appear, and notice is 
given that copying is by permission of the ACM, Inc. To copy otherwise, to republish, to post on servers, 
or to redistribute to lists, requires prior specific permission and/or a fee. FuturePlay 2007, November 
15-17, 2007, Toronto, Canada. Copyright 2007 ACM 978-1-59593-943-2/07/0011...$5.00 Johannes Niemelä Janne 
Paavilainen University of Tampere University of Tampere Kanslerinrinne 1 Kanslerinrinne 1 FIN-33014 University 
of FIN-33014 University of Tampere Tampere +358 504 437 257 +358 400 473 650 johannes.niemela@uta.fi 
janne.paavilainen@uta.fi 2008, the market for casual games will exceed $2 billion dollars in the U.S 
alone and it is reported that half of all gamers in the U.S are playing casual games [13]. Casual games 
can be played on various platforms such as PC, consoles, mobile phones and other hand held devices. Widest 
possible target group, easy online distribution and world wide markets are seen as strengths of casual 
games [18, 35]. The discussion on casual games has not been studied before and there is no valid framework 
available to understand the casual in casual games. The term casual is seen as ill-fitting by the industry 
[7, 25, 35, 41] and there are even suggestions about rejecting the term [8, 25, 36]. It appears that 
there is no consensus as to what casual exactly means when people are talking about games that are labelled 
as somehow casual . Although some acknowledge the problem [19], generally the term is used as if there 
were general consensus over its meaning. Without a clear understanding of the casual in games and games 
culture, these discussions are confusing and difficult to understand. The purpose of this article is 
to describe and analyse the casual games discussion. The goal is to provide clarification of the terms 
used and to provide an early model for understanding the wider sense of casual games in the light of 
expanded game experience. This article is part of the GameSpace project, which studies the design and 
evaluation methods for casual mobile multiplayer games.  2. METHODOLOGICAL APPROACH AND DISPOSITION 
In order to build the tentative terminology for the casual in games and to gain a more profound understanding 
of the phenomenon, we examined the issue by going through several different sources. To reach the widest 
possible domain of the use of casual we went through the various views of game professionals, game journalists, 
gamers, white papers and reported surveys to name a few. Our sources were mainly retrieved from the web 
and additionally the topic was discussed with Finnish game professionals in GameSpace workshops on casual 
games organised in autumn 2006 and winter 2007. Our understanding was taken further by personal game 
experiences of researchers playing over 60 different games that were from casual games portals or games 
that had features that were mentioned in casual games discussions. This paper introduces different sides 
of the discussion and serves as a starting point for further research and discussion. The methodological 
approach can be defined as loose qualitative content analysis or conceptual analysis.  3. THE CASUAL 
GAMES DISCUSSION: GAMES, PLAYERS AND PLAYING The casual game discussion often approaches the phenomenon 
from the perspective of games by looking at their properties. There are various definitions available 
from different organizations (e.g. IGDA, CGA, GDC) or spokespersons for industry on what is a casual 
game (i.e. [32, 35, 37]). The definitions mainly focus on defining a casual game as one that is easy 
to learn, simple to play and offers quick rewards with forgiving gameplay, which all turns into a fun 
experience. Sometimes casual games are connected with non-violent content and it is also reported that 
casual games are affiliated with advergames, web games and downloadable games [35]. There are also contradictions 
in the discussion. For example, multitasking might be considered as an ill-favoured feature for a casual 
game, yet many successful casual games, like Zuma or Diner Dash, require multitasking [37]. A genre-based 
approach is also common in the casual game discussion, with puzzle, card and board games often mentioned 
[25, 27]. Sometimes casual games are considered as a genre of their own with various sub-genres like 
puzzle, Mah-Jong, word, casual-action and card &#38; board games [35]. Genres are also present when companies 
publish survey results. Some casual games fit into many genres, like Zuma, which could be considered 
to be an arcade, puzzle, action or even shoot em up game. Discussions also refer to the casual gamer 
or player. The loose casual games term is partly used because it refers to a casual consumer who can 
pick up and play casual games easily without great effort [24]. It is also said that the casual games 
are aimed at the casual players [34]. Usually casual gamers are contrasted against hardcore gamers so 
as to make a clear distinction between the two groups. A casual gamer is someone who is not a hardcore 
gamer and casual games are non-hardcore games. IGDA also defines a third group, core gamers, who are 
between the casual and the hardcore gamers. These groups are not meant to be mutually exclusive definitions, 
but rather examples of how the game industry usually sees the different audience segments. The IGDA characterisation 
is defined by the competitiveness and amount of involvement required in the games preferred in these 
groups. Hardcore gamers play games that are extremely competitive [and] require greater degree of involvement 
and casual gamers play games with gentle learning curves that do not require much involvement. The core 
gamer is in the middle. [35]. New user demographics are commonly emphasised in the casual gamer discussions. 
Casual games are said to attract new gamer demographics such as females, non-gamers, thirty/forty­somethings, 
and lapsed gamers [37]. The specific information on gamer demographics comes mainly from the press releases 
of casual game developers and publishers. One notion which is highlighted in these press releases is 
that the majority of casual gamers are women and that the majority of these women are middle-aged and 
older [9, 20, 27]. In the discussion around these studies, it is also pointed out that women really [buy 
the] games for themselves [25] and use them e.g. as ways to rejuvenate [25], thereby underlining the 
idea that casual games have truly reached women as gamers in a positive way. However, even if the casual 
games are heralded as games appealing to women and especially to older women, it is also emphasised in 
some discussions that it does not mean that they are games only for women. Instead, the design intention 
is usually characterised as games for all [33, 34, 35]. This can be also called games for the mass audiences 
[20] or broadest amount of gamers [7]. One viewpoint is that the term casual gamer is almost a misnomer. 
Hardcore or core gamers sometimes use the term to distinguish between the true gamers and the mass [22, 
31, 30] so that the casual gamer is not really a gamer at all. Similarly it is said that the casual gamers 
apparently do not view themselves as gamers [7, 34] even though according to the surveys they play quite 
a lot and also at hours which could be seen as non-casual. The term casual gamer does not necessarily 
refer to someone who just plays casual games, but it can also be used to refer to players of a game otherwise 
perceived as hardcore. For example, in a discussion on the casual gamers in World of Warcraft, some see 
casual gamers as someone who simply plays for fun with a laid back attitude when it suits them [39]. 
For some, casual gamers are simply hardcore gamers who cannot find the time to really commit themselves 
to gaming as a hobby [6] or even as someone who use the lack of time as an excuse for not being willing 
to spend the effort [29]. Thus, the term gamer is also used diversely in the casual discussions. Casual 
games are considered to be something easy and quick to pick up and drop. Mobile platforms emphasise especially 
the anytime, anywhere gaming attitude. It all seems fairly logical, when we look at the general properties 
of games that are labelled as casual. However, surveys conducted by Macrovision and PopCap Games reveal 
that casual gamers play quite a lot more than expected [23, 26]. Loren Hillberg, executive vice president 
and general manager of commerce at Macrovision, stated in their survey press release that Our survey 
has determined that mainstream audiences dedicate a substantial amount of time to gameplay -not just 
in 15-minute increments as previously thought. [23]. Surveys by PopCap Games and Harris Interactive (for 
RealNetworks) state that the motivations for playing casual games are fairly instrumental, meaning that 
casual games are played for example for stress relief, keeping one s mind sharp or as a distraction from 
chronic pain and/or fatigue [26, 27]. The majority of parents think that casual games are beneficial 
for their children in an educational sense [27]. In the discussions the motivational factors are sometimes 
pointed out as distinctive features of both the casual and the hardcore gamers. The surveys are somewhat 
skewed in favour of the hardcore end of casual gamers. Macrovision reports that 70 % of those who answered 
in their survey have bought a game after trying it and 30 % have downloaded more than 21 games in the 
last year [23]. The PopCap Games survey was based on those who have bought at least one game from their 
website [26]. The conversion rate in casual games is said to be around 1 to 2 % [5, 35], meaning that 
of 100 people who try a casual game, only one or two actually buy it. Casual games are often marketed 
with the try before you buy model , which means the option to download the demo version free of charge 
but obtaining the full version entails purchasing the whole product [35]. This means that the surveys 
may well not reach the freeloaders, who might make up to 98% of all the casual gamer population. Freeloaders 
try but do not buy. Selecting survey respondents from a customer database or website does not give accurate 
data on casual gaming phenomena. It is also possible that freeloaders have a low effort threshold, so 
they do not participate in surveys which makes them unreachable [16]. Current survey results make casual 
seem like something paradoxical, emphasising the commitment of a casual gamer and assuming that they 
are slightly more hardcore than previously thought. Although the freeloaders may be uninteresting from 
the business point of view, they are a very important group to study from the perspective of academic 
research.  4. MAKING DISTINCTIONS: DIFFERENT MEANINGS OF CASUAL Although the discussion is about casual 
games , one word does not seem to be enough. The discussion concerns gamers, players, gaming and playing 
being somehow casual in addition to games that meet all these requirements and restrictions ending up 
labelled as casual. In the next refinement of casual , the casual games, those who play them; playing 
style and attitudes and the non-gamers as casual gamers are separated in the level of meaning. Even though 
these terms are interrelated, they constitute a more refined terminology for the phenomenon of casual 
in games cultures. Casual in games cultures. The phenomenon of the casual aspects Casual game. Certain 
properties of games are called casual, e.g. game has generally appealing content, simple controls, easy-to­learn 
gameplay, fast rewards, or support for short play sessions. These properties can vary depending on the 
game and the term should be treated more or less ostensibly (referring to these games here ). Casual 
gaming. The aspects of the present game cultures are characterised as casual: the attitude towards gaming 
may be casual, e.g. playing games may be perceived as just one leisure activity among others (e.g. TV, 
movies, sports) or present clearly instrumental motives other than leisure for the playing activity. 
Casual playing. The way a game is used or played is characterised as casual, e.g. a game is played in 
small time bursts or in a low cognitive state. This refers more to the play session than to the general 
attitude towards games. Casual gamer. A person who plays games in a casual manner, not necessarily casual 
games, (casual playing) or who has a casual attitude towards gaming (casual gaming). Casual game player. 
A person who plays games that are called or labelled as casual (not necessarily playing casually). Studies 
show that the demography covers almost everybody (from teens to older people, from newbies to lapsed 
gamers) and the largest group seems to be women over 35 .  Figure 1. Relations of the meanings of casual 
in games cultures. It is quite obvious how in many cases these terms can be confused. The ways different 
actors, such as developers, Casual game players are often portrayed as the antithesis of publishers or 
gamers use casual , needs clarification. Currently hardcore players. The perception is that their focus 
on puzzles casual gamer is very often used synonymously with casual like Bejeweled or games like MahJong 
is limited to small game player which may be a source of some confusion for the chunks of time. While 
research has confirmed some speakers themselves. For instance, here are two quotes from the perceptions 
of these gamers, a new survey is challenging other article discussing Macrovision s survey results: long-held 
beliefs. For example, it turns out many casual game fans spend copious amounts of time with their favorite 
titles. These are by no means casual game players, said Alex Torrubia, vice president of business development 
at Macrovision s Trymedia Games, the organization behind the survey [25] And: Casual gamers are playing 
often, and for long sessions. According to the survey, 37 percent play nine or more game sessions each 
week. Sixty-six percent say each session lasts for at least one hour, while 31 percent play for more 
than two hours at a time. [25] (Bold face added for clarification) The authors use the terms casual gamers 
and casual game players at the same time to refer to a group of people who play Macrovision s casual 
games and then state that these are by no means casual game players referring to the attitudes and devotion 
level of a player. We feel that although casual can be confusing, there is no real need to replace the 
term. Since the casual phenomenon seems to be more complex and more extensive than previously understood, 
a more accurate understanding of the phenomenon may yield more fertile results in game design and research. 
 5. MORE TO THE DISCUSSION: BUSINESS MODELS, ACCESSIBILITY, PRODUCTION AND THE FUTURE OF CASUAL GAMES 
Although the definition of casual in games has mainly been explored by scrutinizing the properties of 
a game, players or playing styles, the discussion does not end there. Other frequently discussed topics 
are business models, accessibility, production and the future prospects of casual games such as social 
aspects of games. Apart from the game properties, distribution and business models are sometimes seen 
as distinctive features of casual . The most common business models are listed as: try and buy downloadables, 
advertising sponsored, subscription based and skill-based gaming [1, 32, 37]. These models are not seen 
as the only options; there is talk about in-game micro-payments [37], new advertising sponsored models 
[25] and emphasis on experimentation with business models in the future. The discussion on business models 
can be reduced to general talk about the accessibility of casual games. IGDA lists three primary points 
of access: downloadable games to play offline, online play and other platforms such as mobiles and consoles. 
Other platforms include set-top boxes, toys and electronic devices, which have some sort of game pre-installed, 
embedded or have the ability to load games [35]. Retail packaged casual games are also emerging [1, 35]. 
The need for different distribution models is well characterized by Duncan Magee from RealArcade: wherever 
you find these customers is where we need to put our games [33]. Conversion rates of casual games are 
also one common topic. The conversion rate in casual games is said to hover around 1 to 2 % [5, 35], 
and in web downloadable games around 0.5 to 2.5 % [36] so paying for casual games is only the tip of 
the iceberg, as mentioned before. However, there seem to be no clear data of players who play embedded, 
bundled or pre-installed games like Windows Solitaire, Minesweeper or Nokia mobile phone s Snake. Conversion 
rates are taken as an indication of potential consumers but it has also been conjectured that the casual 
game mass markets are much harder to reach and can be very much here today, gone tomorrow [38]. For example 
Michael Pachter of Wedbush Morgan Securities thinks that the casual games market has a larger audience 
but it is still smaller in dollars spent compared to core games. According to him, casual games will 
be a big part of the overall growth but they will not dominate the future. David Cole of DFC Intelligence 
thinks that the key to the industry is being able to diversify. A single casual game will not reach the 
whole audience but a large number of different games will. [38]. While targeting the widest possible 
audience, knowledge of player demographics is considered important. There are already suggestions that 
the demographics should have finer nuances instead of the black and white setup of core gamers vs. hardcore 
gamers [16, 36]. For example, a survey conducted by Parks Associates suggests that there are at least 
six different gamer groups; power, social, leisure, incidental, dormant, and occasional gamers, all of 
whom should be taken into account [36]. It has also been suggested that there is a normal shift from 
one group to another: casual gamers evolve and become more demanding [20, 37, 38]. Social aspects and 
gaming communities have recently been studied with great interest (e.g. [11, 12, 21, 28]). Researchers 
have been concentrating especially on the massive multiplayer online games (MMOGs). Currently the most 
popular MMOG in the world is the World of Warcraft with over 8 million subscribers [40]. Although WoW 
is not considered to be a casual game, there is talk of casual players in WoW societies [37]. It is also 
thought that communities and social aspects will have a significant role in casual games [8, 34]. This 
could, for example, be an alone together [12] type of experience that some MMO gamers enjoy, spectator 
experiences [10] or asynchronous casual multiplayer experiences [2]. There are also contradictory views 
on the social aspects of casual games. For example, Richard Krueger of Boonty and Duncan Magee of RealArcade 
have stated that casual gaming is a solo based independent experience and there is no room for competition 
in casual games which is usually a result of a strong community [33]. There is also speculation about 
a convergence of casual and hardcore markets [20]. This is already a reality with new consoles like Xbox 
360, Playstation 3 and Nintendo Wii. Casual games are shifting from the web-based PC world to other platforms. 
They have already entered the console markets and are expected to do well [5]. For example, conversion 
rates in Xbox Live Arcade service vary around 10-20 % [17]. In some instances, mobile gaming has already 
been labelled as casual gaming [32] and spokespersons for industry have agreed that it is a promising 
mix. Devices like digital cameras, which are not intended for gaming, could also provide a possible platform 
to host casual games in the future [3]. This implies that casual games could be affiliated with many 
different devices. The characteristics of casual games and the different expectations of casual gamers 
call for different kinds of production strategies. This is apparent in the discussions related to the 
production of casual games. Casual games are said to be developed at a faster pace with smaller teams 
and lower development budgets compared to retail PC and console games. Dave Rohrl of PopCap Games reports 
that team size is three to five persons, development time is six to twelve months and it costs roughly 
100,000-250,000 dollars to develop a typical downloadable casual game [37]. The risks are lower with 
small budgets and a hit game can provide a big return on investment. Low risk could also lead to more 
experimentation [37] and this is eagerly taken as a potential for game innovations, which is also one 
common topic [31] in casual games discussions. Low investments in development are conducive to innovation 
in big companies. Start-up companies also have to be innovative to break into the market in the first 
place. Yet there are huge numbers of cloned and slightly altered games in the market. Joel Brodie of 
GameZebo thinks that the industry is stagnating although he thinks that the casual games industry is 
still more innovative than the retail video game industry [4]. However, within the innovation topic, 
some are concerned that casual games are confused with indie games [7].  As stated earlier, the current 
casual gamers are becoming more demanding and are looking for more content and versatile game mechanics. 
This is probably true if by casual gamer we mean players who enjoy titles like Zuma, Bejeweled and Diner 
Dash, playing them several hours per week. This probably does not tell the whole story, since those who 
enjoy such casual games as online chess, poker and other parlour games, may not be looking for more [20]. 
This underlines the important aspect that casual cannot be contemplated from only one perspective. When 
one game is casual in one way, another game may be casual in some other way. Instead of interpreting 
the discussion concerning completely separate issues, the fragemented views could be treated as an indication 
that the phenomenon should be examined in a broader context.  6. THE CASUAL GAME EXPERIENCE AND THE 
MODEL FOR EXPANDED GAME EXPERIENCE (EGE) Even though casual in games cultures is approached differently 
while talking about the properties of games, attitudes of players, different playing styles and distribution 
models, they are all interrelated. When the talk is about players, there is the matter of attitudes, 
motives, skills and behaviour that may be characterised as casual and then supported as casual features 
of games. Certain attitudes and skill levels then again can lead to situations requiring new approaches 
to the ways to distribute and sell games If we think about games as experiential products, we need to 
understand the different possibilities that games can provide. Traditionally game experience models concentrate 
on explaining the gameplay experience [e.g. 15] and while working well as guidelines for designing and 
understanding different aspects of intensive play sessions, they may be powerless in front of the diverse 
experiential space of games cultures, as the game experiences are not limited game sessions, nor are 
they only born within these. At least the issues addressed within casual games discussions seem to indicate 
that relevant experiential factors for gaming may also exist outside the play sessions, such as the accessibility 
of a game. It could be speculated that failure to seeing them as a part of the game experience design 
may lead to failure to deliver a successful product. Yet again, this may have implications for more holistic 
design processes. An overall understanding of the different aspects of casual in games cultures and of 
designing new types of casual games may benefit from the perspective of casual as an expanded game experience, 
where the experience should be seen as a continuum from accessing the game to the gameplay itself.  
Figure 2. Model for Expanded Game Experience (EGE). We have tried to sketch an early version of the 
model to help to understand the expanded experiences to do with casual games. The model may also help 
in understanding hardcore game experiences, but while hardcore experiences may be rather gameplay concentrated, 
other models may elucidate these better. In this early version of EGE model (see Figure 2) three different 
phases of game experience have been identified. For every phase of the experience there are different 
relevant outer impacts and inner processes representing the contextual and personal factors. Due to the 
simplified model, the experience may be seen to form in the interaction of these two. Just as outer impacts 
may vary according to situations and games played, every phase may also have different relevant processes 
from the player s side. This approach provides opportunities to understand players more diversely than 
only within the approximations of being casual , hardcore or other [36] segmentations. Casual games may 
have the most heterogeneious audience, where motivations, relevant skills and resources such as time 
vary even according to the phases of the game experience. For example, for one player understanding chess 
is not difficult, but complicated game hardware may drive him away from online chess in the pursuit of 
casual leisure. Somebody else may find that online chess is casual fun if s/he is talented in gameplay 
and in understanding the hardware. Then again somebody else may not succeed in finding casual fun in 
online chess at all due to lacking the skills of the game. In other words while skill level in outer 
game experiences may concern general computer skills, in gameplay experiences this may concern special 
skills in games (e.g. knowing that smashing boxes may give you an advantage in the game). Motivation 
and resources can be seen to be similarly varied. While for someone the casual experience of games may 
mean not being identified as a gamer even though they play games (outer game experiences), for some it 
may mean fast access to the game experience (game related experience) and for some short sessions in 
gameplay and instrumental values of games (gameplay experiences). In the design of casual games there 
can be different approaches to support these casual aspects of the game experience concentrating on what 
outer impacts they may be able to affect. In this sense the different aspects of casual games discussions 
may be thought of as being different approaches in casual game experience design.  7. FUTURE WORK We 
will continue to develop the model for expanded game experience (EGE) to get a clearer view of the potential 
of casual games and this way to see what is absent from the discussions. This will be then further developed 
into a method for designing and evaluating casual games.  8. CONCLUSIONS The casual games discussion 
is diverse. Discussions cover the properties of a game, gamers and gaming; factors of production and 
marketing. Confusion in the discussion may occur when there is no clear conception of what is meant by 
casual . However, the discussion is an indication of an extensive phenomenon that could be called casual 
in games cultures. This includes the topics of play behaviours, attitudes toward games and the widest 
possible target audience as well as all the implications from these for the design process. Casual is 
so far best defined by the easiness of the game experience in its expanded sense, covering the whole 
experience from the accessing of a game to playing it. This in no sense make things less complicated: 
different and even conflicting features may support the casual experience in different design solutions. 
That is: casual in games may manifest itself differently in different games. In this article we have 
tried to shed light on the discussion around casual games by defining some of the key terms used. We 
think that it is important to understand the difference between playing casual games and playing games 
casually. It is also important to realise that casual itself is not only a property of the game but relates 
to many other things such as player attitude or availability of the game. The casual game discussion 
is also heavily biased towards certain kinds of casual games such as Zuma or Diner Dash, which represent 
the high-end products of casual game business. Advergames, pre-installed games and Flash games can be 
also seen as part of the casual games phenomenon, especially when the casual is not explained only through 
the game s properties. Casual games phenomena have revealed that gaming should be studied from a wider 
perspective than just scrutinizing the relationship between the gamer and the game in the gaming situation. 
Future versions of the EGE model may give a wider perspective on the design and evaluation of casual 
games. 9. ACKNOWLEDGEMENTS We would like to thank Professor Frans Mäyrä and the whole staff at the Game 
Research Lab for their support and comments on the paper, especially Eetu Paloheimo, for the co-operation 
in developing the EGE model. We would also like thank our industry partners from Nokia, TeliaSonera, 
Veikkaus, Sulake and Sumea/Digital Chocolate. Special thanks go to Eric Zimmerman for interesting discussions 
on casual games during the Games &#38; Storytelling Workshop 2007 in Helsinki. 10. REFERENCES [1] 2006 
Casual Games Market Highlights. Casual Connect Magazine(Fall 2006), 6-8. Retrieved March 31, 2007, from 
http://mag.casualconnect.org/fall2006/Fall_2006_Kiev_engli sh.pdf. [2] Bogost, I. (2004). Asynchronous 
Multiplay: Futures for Casual Multiplayer Experience. Retrieved March 31, 2007, from http://itu.dk/op/papers/bogost.pdf. 
[3] Bogost, I. (2006). Is there a future for casual games on digital cameras? Water Cooler Games. Retrieved 
March 31, 2007, from http://www.watercoolergames.org/archives/000711.shtml. [4] Brodie, J. (2007). I 
m Mad as H@#%, and I m Not Going to Take it Anymore! - Gamezebo.com. Retrieved March 31, 2007, from http://tinyurl.com/yrn22j. 
 [5] Clark, E. Monetization Across the Value Chain - An Interview with Mark Cottam and Paul Jensen of 
MumboJumbo. Casual Connect Magazine, 10-15. Retrieved March 30, 2007, from http://mag.casualconnect.org/winter2007/CasualConnect_Wi 
nter_2007.pdf. [6] Cybulskie, A. (2004). Casual players *already* complaining about WoW. Retrieved March 
31, 2007, from http://tinyurl.com/25w2q7. [7] Dillon, B. (2005). 2005 Indie Games Conference: Casual 
Games. Retrieved March 30, 2007, from http://www.gamasutra.com/features/20051018/dillon_01.sht ml. [8] 
Dillon, B. (2006). Casuality Roving Reporter: Beth Dillon - Gamezebo.com. Gamezebo.com. Retrieved March 
31, 2007, from http://tinyurl.com/2x7e2h. [9] Dobson, J. (2006b). Survey: PopCap Releases Casual Game 
Findings. Retrieved March 31, 2007, from http://www.gamasutra.com/php­bin/news_index.php?story=10861. 
[10] Drucker, S., He, L., Cohen, M., Wong, C., &#38; Gupta, A. (2002). Spectator Games: A New Entertainment 
Modality For Networked Multiplayer Games. Retrieved March 31, 2007, from http://research.microsoft.com/~sdrucker/papers/spectator.pdf. 
[11] Ducheneaut, N., &#38; Moore, R.J. (2004). The social side of gaming: a study of interaction patterns 
in a massively multiplayer online game. Chicago, Illinois, USA : ACM Press. [12] Ducheneaut, N., Yee, 
N., Nickell, E., &#38; Moore, R. (2006). Alone together? Exploring the Social Dynamics of Massively Multiplayer 
Games. Conference proceedings on human factors in computing systems, 407-416. Retrieved March 31, 2007, 
from http://tinyurl.com/lsafd. [13] Entertainment Software Association: Essential Facts About The Computer 
and Video Game Industry 2006. (2006). Retrieved March 30, 2007, from http://tinyurl.com/gonbv. [14] Entertainment 
Software Association: Top 10 Industry Facts. Retrieved March 30, 2007, from http://theesa.com/facts/top_10_facts.php. 
[15] Ermi L. &#38; Mäyrä F. (2005). Fundamental components of the gameplay Experience: Analyzing Immersion. 
Selected Papers Proceedings if DiGRA 2005 Conference: Changing Views Worlds in Play, 2005. [16] Game 
Research. (2002). Online Gaming Habits. Retrieved March 31, 2007, from http://tinyurl.com/2azeo6. [17] 
Gough, D. (2006). Casual Games and Micro Payments. Suttree.com: Casual Games, Social Software. Retrieved 
March 31, 2007, from http://tinyurl.com/27tu33. [18] Hattan, J. (2005). Casual Games Summit. Retrieved 
March 29, 2007, from http://www.gamedev.net/columns/events/coverage/feature.as p?feature_id=17. [19] 
Higgins, T. (2005). Go Casual! - Austin Game Conference Report. Retrieved March 30, 2007, from http://weblogs.macromedia.com/thiggins/archives/2005/11/g 
o_casual_-_aus.cfm. [20] Hyman, P. (2004). Casual video games are serious business. Retrieved March 
31, 2007, from http://www.hollywoodreporter.com/hr/search/article_display. jsp?vnu_content_id=1000535245. 
[21] Jakobsson, M., &#38; Taylor, T. (2003). The Sopranos meets Everquest - social networking in massively 
multiuser networking games. Retrieved March 31, 2007, from http://tinyurl.com/ytktcf. [22] Jeffries, 
M. (2001). Casual gamers Vs True gamers..... Retrieved March 31, 2007, from http://tinyurl.com/2a7glz. 
[23] Macrovision Corporation. (2006). Survey Reveals Casual Gamers Are Not So Casual. Retrieved March 
31, 2007, from http://tinyurl.com/mnj36. [24] Millis, G., &#38; Robbins, B. (Eds.). (2005). IGDA 2005 
Casua lGames White Paper. Retrieved March 30, 2007, from http://www.igda.org/casual/IGDA_CasualGames_Whitepape 
r_2005.pdf. [25] Olson, R. (2006). Casual Gamers Anything But. Retrieved March 30, 2007, from http://www.redherring.com/Article.aspx?a=17429&#38;hed=Cas 
ual+Gamers+Anything+But. [26] PopCap Games. (2006). Survey: Casual Computer Games as TV Replacement? 
Players Average 48 Years of Age, Seek Relaxation and Mental Exercise from Games; Largest-Ever Survey 
of Casual Game Players Yields Surprising Data. Retrieved March 29, 2007, from http://tinyurl.com/yrhjhp. 
[27] RealNetworks, Inc. (2006). Research Reveals Casual Games Provide Mental Balance, Stress Relief and 
Relaxation. Retrieved March 31, 2007, from http://tinyurl.com/2aeqca. [28] Seay, A.F., Jerome, W.J., 
Lee, K.S., &#38; Kraut, R.E. (2004). Project massive: a study of online gaming communities. Vienna, Austria 
: ACM Press. [29] Sisson, B. (2004). Casual players *already* complaining about WoW. Retrieved March 
31, 2007, from http://tinyurl.com/2glyhh. [30] Spencer, H. (2001). Casual gamers Vs True gamers..... 
Retrieved March 31, 2007, from http://tinyurl.com/2zdd9j. [31] Stuart, K. (2005). Casual gaming: the 
new hardcore from Guardian Unlimited: Gamesblog. Guardian Unlimited: Gamesblog. Retrieved March 31, 2007, 
from http://tinyurl.com/2ee3av.  [32] Tams, J. (2006). Online Casual Games Q&#38;A. Minna Magazine(Summer 
2006), 2-5. Retrieved March 29, 2007, from http://mag.casualconnect.org/MinnaMagazine_Summer2006. pdf. 
[33] Tinney, W. (2005). Postcard from the Casual Games Conference. Retrieved March 31, 2007, from http://www.gamasutra.com/features/20050803/tinney_01.sht 
ml. [34] Twist, J. (2005). Casual gaming to take off in 2005 . Retrieved March 30, 2007, from http://news.bbc.co.uk/1/hi/technology/4151431.stm. 
[35] Wallace, M., &#38; Robbins, B. (Eds.). (2006). IGDA 2006 Casual Games White Paper. Retrieved March 
29, 2007, from http://www.igda.org/casual/IGDA_CasualGames_Whitepape r_2006.pdf. [36] Wallis, A. (2006). 
Q&#38;A: Cai Looks Beyond Hardcore Vs. Casual . Retrieved April 1, 2007, from http://www.gamasutra.com/php­bin/news_index.php?story=10704. 
[37] Waugh, E. (2006). GDC: Casual Games Summit 2006: An Introduction to Casual Games. Retrieved March 
30, 2007, from http://www.gamasutra.com/features/20060322/waugh_01.sht ml. [38] Wen, H. (2006). Analyze 
This: Will Casual Games Dominate the Future of the Industry? Retrieved March 31, 2007, from http://www.gamasutra.com/features/20060803/wen_01.shtml 
. [39] Whitney, C. (2004). Casual players *already* complaining about WoW. Retrieved March 31, 2007, 
from http://tinyurl.com/yw2jb9 [40] WORLD OF WARCRAFT® SURPASSES 8 MILLION. (2007). Retrieved March 31, 
2007, from http://www.blizzard.com/press/070111.shtml. [41] Zimmerman, E. (2007). Discussions with Eric 
Zimmerman on the Games &#38; Storytelling workshop in Helsinki, Finland.   
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2007</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	</section>
	<section>
		<section_id>1328222</section_id>
		<sort_key>200</sort_key>
		<section_seq_no>5</section_seq_no>
		<section_type>SESSION</section_type>
		<section_title><![CDATA[Educational games]]></section_title>
		<section_page_from>113</section_page_from>
	<article_rec>
		<article_id>1328223</article_id>
		<sort_key>210</sort_key>
		<display_label>Pages</display_label>
		<pages>8</pages>
		<article_publication_date>11-14-2007</article_publication_date>
		<seq_no>1</seq_no>
		<title><![CDATA[The impact of realism on learning engagement in educational games]]></title>
		<page_from>113</page_from>
		<page_to>120</page_to>
		<doi_number>10.1145/1328202.1328223</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1328223</url>
		<abstract>
			<par><![CDATA[<p>We describe an evidence-based model for improving the quality and outcomes of game-based instructional materials for K-12 and undergraduate science courses. Our educational game models have been able to address critical issues in developing improved learning outcomes, especially in areas of higher order thinking like clinical judgment, understanding what scientists "do" as they engage in the scientific method, and in language training. The current focus of our work is the importance of realism and learning engagement in instructional games and simulations. In this paper, we use educational frameworks from the Federation of American Scientists and the United States National Research Council as a foundation from which to consider how to study the impacts of realism and engagement in educational games. Using this guiding framework, we have developed a methodology for building and evaluating instructional simulations in the sciences and mathematics that meet exacting standards for evidence-based education. In this paper, we explore the impact of realism and engagement in instructional games and simulations within the context of creating an evidence-based framework for teaching, learning, and assessment of learning outcomes.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[educational games]]></kw>
			<kw><![CDATA[engagement]]></kw>
			<kw><![CDATA[realism]]></kw>
			<kw><![CDATA[serious games]]></kw>
			<kw><![CDATA[teaching and learning]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.6.4</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010341.10010342.10010344</concept_id>
				<concept_desc>CCS->Computing methodologies->Modeling and simulation->Model development and analysis->Model verification and validation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010341.10010342</concept_id>
				<concept_desc>CCS->Computing methodologies->Modeling and simulation->Model development and analysis</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010341.10010342.10010344</concept_id>
				<concept_desc>CCS->Computing methodologies->Modeling and simulation->Model development and analysis->Model verification and validation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010341.10010342</concept_id>
				<concept_desc>CCS->Computing methodologies->Modeling and simulation->Model development and analysis</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Human Factors</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P925244</person_id>
				<author_profile_id><![CDATA[81444601456]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Jay]]></first_name>
				<middle_name><![CDATA[Shiro]]></middle_name>
				<last_name><![CDATA[Tashiro]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Ontario, Oshawa, Ontario, Canada]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P925229</person_id>
				<author_profile_id><![CDATA[81537214456]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[David]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Dunlap]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Coccinella Development, Inc., Tucson, Arizona]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Anderson, L., and Krathwohl, D. <i>A taxonomy for learning, teaching, and assessing.</i> Longman, New York, NY, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>557640</ref_obj_id>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Alessi, S. M., and Trollip, S. R. <i>Multimedia for Learning: Methods and Development.</i> Allyn and Bacon, Boston, MA, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[AACN - American Association of Colleges of Nurses. <i>The Role of the Clinical Nurse Leader.</i> American Association of Colleges of Nursing, Washington, DC, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Aronson, E., Brewer, M. and Carlsmith, J. M. Experimentation in social psychology. In, G. Lindzy and E. Aronson (Eds.) <i>Handbook of social psychology, 3&#60;sup&#62;rd&#60;/sup&#62; Edition.</i> Random House, New York, NY. 1985, 441--486.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1214315</ref_obj_id>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Bogost, I. <i>Persuasive Games -- the expressive power of videogames.</i>: MIT Press, Cambridge, MA, 2007]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Cacioppo, J. T., Petty, R. E., and Quintanar, L. R. Individual differences in relative hemispheric alpha abundance and cognitive responses to persuasive communications. <i>Journal of Personality and Social Psychology</i>, 43, 3, (1982), 623--636.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Cacioppo, J. T. Petty, R. E., and Kao, C. F. The efficient assessment of 'need for cognition'. <i>Journal of Personality Assessment. 48</i>, (1984), 306--307.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Cacioppo, J. T., Petty, R. E., Feinstein, J. A., and Jarvis, W. B. G. Dispositional differences in cognitive motivation: The life and times of individuals varying in need for cognition. <i>Psychological Bulletin, 19, 2</i>, (1996), 197--253.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Federation of American Scientists. <i>Summit on Educational Games -- Harnessing the power of video games for learning.</i> Federation of American Scientists, Washington, DC, 2006.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Feingold, C., Calaluce, M., and Kallen, M. Computerized patient model and simulated clinical experiences: Evaluation with baccalaureate nursing students. <i>Journal of Nursing Education, 43, 2</i>, (2004), 156--163.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Fonteyn, J. (1998). <i>Thinking strategies for nursing practice.</i> Lippincott, Philadelphia, PA.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Fulcher, G. <i>Virtual Medical Office for Bonwit-West's Clinical Procedures for Medical Assistants, 6&#60;sup&#62;th&#60;/sup&#62; Edition.</i> Elsevier-Saunders, Philadelphia, PA, 2007.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Fulcher, G. <i>Virtual Medical Office for Kinn's The Administrative Medical Assistant, 6&#60;sup&#62;th&#60;/sup&#62; Edition.</i> Elsevier-Saunders, Philadelphia, PA, 2007.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Fulcher, G. <i>Virtual Medical Office for Kinn's The Medical Assistant, 10&#60;sup&#62;th&#60;/sup&#62; Edition.</i> Elsevier-Saunders, Philadelphia, PA, 2007.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Gardner, H. <i>Intelligence reframed: Multiple intelligences for the 21&#60;sup&#62;st&#60;/sup&#62; century.</i> Basic Books, New York, NY, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Gee, J. P. <i>Good video Games</i> + <i>Good Learning</i> -- <i>Collected essays on video games, leaning, and literacy.</i> Peter Lang, New York 2007.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Gee, J. P. <i>Situated Language and Learning: A critique of traditional schooling.</i> Routledge, London, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>983348</ref_obj_id>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Gee, J. P. <i>What video Games have to Teach Us About Learning and Literacy.</i> Palgrave MacMillan, New York, NY, 2003]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Higuchi, K., and Donald, J. Thinking processes used by nurses in clinical decision making. <i>Journal of Nursing Education, 41, 2</i>, (2002), 145--153.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Institute of Medicine. To err is human -- <i>Building a safer health care system.</i> National Academy Press, Washington, DC, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Institute of Medicine. <i>Crossing the quality chasm: A new health system for the 21&#60;sup&#62;st&#60;/sup&#62; century.</i> National Academy Press, Washington, DC, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Institute of Medicine. <i>Guidance for the National Healthcare Disparities Report.</i> National Academy Press, Washington, DC, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[Institute of Medicine. <i>Health professions education -- A bridge to quality.</i> National Academy Press, Washington, DC, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[Institute of Medicine. <i>Unequal treatment -- Confronting racial and ethnic disparities in healthcare.</i> National Academy Press, Washington, DC, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[Institute for Safe Medication Practices. <i>Medication Errors, 2&#60;sup&#62;nd&#60;/sup&#62; Edition.</i> American Pharmacists Association, Washington, DC, 2007]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[JCAHO. <i>Frontline of defense.</i> Joint Commission on the Accreditation of Healthcare Organizations, Oakbrook Terrace, IL, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1076823</ref_obj_id>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[Juul, J. <i>Half-Real: video games between real rules and fictional worlds.</i> MIT Press, Cambridge, MA, 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[Mathers, D. <i>Virtual clinical Excursions -- for Black and Hawks Medical-Surgical Nursing: Clinical Management for Positive Outcomes, 7&#60;sup&#62;th&#60;/sup&#62; Edition.</i> Elsevier-Saunders, Philadelphia. PA, 2006.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[National Research Council (2000). Bransford, J. D., Brown, A. L., and Cocking, R. R. (Eds.). <i>How people learn: Brain, mind, experience, and school.</i> National Academy Press, Washington, DC, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>30</ref_seq_no>
				<ref_text><![CDATA[National Research Council. <i>Knowing what students know: The science and design of educational assessment.</i> National Academy Press, Washington, DC, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>31</ref_seq_no>
				<ref_text><![CDATA[Sadowski, C. J. and G&#252;l&#246;z, S. Elaborative Processing mediates the Relationship between Need for Cognition and Academic Performance. <i>Journal of Psychology, 130, 3</i>, (1996), 303--307.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>32</ref_seq_no>
				<ref_text><![CDATA[Sternberg, R. J. (1997) <i>Thinking styles.</i> Cambridge University Press, New York, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>33</ref_seq_no>
				<ref_text><![CDATA[Sullins, E. S., Hernandez, D., Fuller, C. and Tashiro, J. S. Predicting who will major in a science discipline: Expectancy-value theory as part of an ecological model for studying academic communities. <i>Journal of Research in Science Teaching, 32, 1</i>, (1995), 99--119.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>34</ref_seq_no>
				<ref_text><![CDATA[Tashiro, J. and Long, G. Moving Toward Evidence-based Nursing Education. Submitted to the <i>Journal of Research in Science Teaching</i>, (2007).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>35</ref_seq_no>
				<ref_text><![CDATA[Tashiro, J. and Rowland, P. McD. What works: Empirical approaches to restructuring courses in biology and environmental sciences. In A. McNeal and C. D'Avanzo (Eds.) <i>Student-active science: Models of innovation in college science teaching.</i> Harcourt Brace and Company, Orlando, FL, 1997, <i>163--187.</i>
]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>36</ref_seq_no>
				<ref_text><![CDATA[Tashiro, J. T., Sullins E. S., Long, G., and Kelly, M. <i>Virtual clinical excursions in medical-surgical nursing: assessment and management of clinical problems.</i> Mosby, St. Louis, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>37</ref_seq_no>
				<ref_text><![CDATA[Tashiro, J. T., Sullins E. S., Long, G., and Kelly, M. <i>Virtual clinical excursions for fundamentals in nursing.</i> Mosby, St. Louis, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>38</ref_seq_no>
				<ref_text><![CDATA[Tashiro, J. T., Sullins, E. S., Long, G., and Kelly, M. <i>Virtual clinical excursions in medical-surgical nursing: Clinical management for positive outcomes.</i> Mosby, St. Louis, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>39</ref_seq_no>
				<ref_text><![CDATA[Tashiro, J. T., Sullins, E. S., Long, G., and Kelly, M. <i>Virtual clinical excursions for basic nursing: essentials for practice.</i> Mosby, St. Louis, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>40</ref_seq_no>
				<ref_text><![CDATA[Tashiro, J. T., Sullins, E. S., and Long, G. <i>Virtual clinical excursions for nursing care of infants and children.</i> Mosby, St. Louis, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>41</ref_seq_no>
				<ref_text><![CDATA[Tashiro, J. T., Sullins, E. S., and Long, G. <i>Virtual clinical excursions for fundamental concepts and skills for nursing.</i> Mosby, St. Louis, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>42</ref_seq_no>
				<ref_text><![CDATA[Welk, D. S. Designing clinical examples to promote pattern recognition: Nursing education-based research and practical applications. <i>Journal of Nursing Education, 41(2)</i>, (2002), 53--60.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 The Impact of Realism on Learning Engagement in Educational Games Jay Shiro Tashiro, PhD, RN University 
of Ontario Institute of Technology Oshawa, Ontario, Canada L1H 7K4 jay.tashiro@uoit.ca ABSTRACT We describe 
an evidence-based model for improving the quality and outcomes of game-based instructional materials 
for K-12 and undergraduate science courses. Our educational game models have been able to address critical 
issues in developing improved learning outcomes, especially in areas of higher order thinking like clinical 
judgment, understanding what scientists do as they engage in the scientific method, and in language training. 
The current focus of our work is the importance of realism and learning engagement in instructional games 
and simulations. In this paper, we use educational frameworks from the Federation of American Scientists 
and the United States National Research Council as a foundation from which to consider how to study the 
impacts of realism and engagement in educational games. Using this guiding framework, we have developed 
a methodology for building and evaluating instructional simulations in the sciences and mathematics that 
meet exacting standards for evidence­based education. In this paper, we explore the impact of realism 
and engagement in instructional games and simulations within the context of creating an evidence­based 
framework for teaching, learning, and assessment of learning outcomes. Categories and Subject Descriptors 
I.6.4 [Computing Methodologies]: Simulation and Modeling Model Validation and Analysis General Terms 
Design, Human Factors  Key Words Teaching and learning, serious games, educational games, realism, engagement 
 1.0 INTRODUCTION A very large and diverse literature converges on the idea that there are educational 
benefits to simulations and gaming technology. These benefits include: involving Permission to make digital/hard 
copy of part of this work for personal or classroom use is granted without fee provided that the copies 
are not made or distributed for profit or commercial advantage, the copyright notice, the title of the 
publication, and its date of appear, and notice is given that copying is by permission of the ACM, Inc. 
To copy otherwise, to republish, to post on servers, or to redistribute to lists, requires prior specific 
permission and/or a fee. FuturePlay 2007, November 15-17, 2007, Toronto, Canada. Copyright 2007 ACM 978-1-59593-943-2/07/0011...$5.00 
David Dunlap Coccinella Development, Inc. Tucson, Arizona, United States 85749 ddunlap@3dlanguage.net 
 students in complex practice skills without risk, improved psychomotor skills, enhanced retention of 
knowledge as well as enhanced decision-making skills, interactive learning, opportunities for replay 
at a particular step in a sequela as well as repeated practice of a sequela, options for immediate feedback, 
and retention of knowledge related to procedures. Some of this literature was nicely presented in the 
report on the recent Summit on Educational Games sponsored by the Federation of American Scientists Federation 
[9], with good syntheses also from Bogost [5] and Gee [16-19]. Work in healthcare has been reviewed by 
Feingold, Calaluce, and Kallen [10], while the United States National Research Council presented summaries 
of research covering topics in the areas of how people learn and the science and design of educational 
assessment [29,30]. These works provided a useful point of departure, but have simplified a very large 
and diverse research literature from artificial intelligence, simulation, education, and psychology. 
More recent work on cognitive taxonomies [1] also holds promise for informing how and why to build educational 
games (but see points of opposition by Sternberg [32] and Gardner [15]). A comprehensive review of literature 
from science education, nursing education, general education, and psychology reveals many different types 
of studies focused on how to help students move from novices to experts or at least from novices to a 
more knowledgeable state. Consistent with major themes within this diverse literature base, the National 
Research Council [30] offers a streamlined list of critical issues in developing expertise. We revise 
this list into questions that we believe any set of instructional materials, including educational games, 
must address: (1) How do instructional materials enhance predisposition to learn? (2) How do the materials 
provide multiple paths for learning? (3) How does an instructional package help students overcome limitations 
of prior knowledge? (4) When and how do the educational materials provide practice and feedback? (5) 
Can the instructional materials help students develop an ability to transfer knowledge acquired by extending 
knowledge and skills beyond the contexts in which they were gained? (6) How will the instructional package 
incorporate the role of social context? (7) How and why will the instructional materials address cultural 
norms and student beliefs? It should be clear that the vast majority of instructional materials, especially 
educational games do not address all of these questions. Key conclusions by the Federation of American 
Scientists [9] also provided us with important insight into building educational games. In a 2005 summit, 
there was interesting convergence on eight conclusions reached by expert working groups:  1. It is clear 
that the modern workforces of technology-oriented countries require the skills that many video games 
require players to master. 2. Attributes of games could be useful in applications in learning (contextual 
bridging, increased time on task, improved motivation and goal orientation, personalization of learning, 
feedback, cues and partial solutions). 3. Games for education differ from games for entertainment. 
4. Rigorous research is required to help translate the art and technologies of gaming into teaching, 
learning, and assessment systems. 5. Video game and educational materials industries are inhibited by 
high development costs and uncertain markets for educational innovations developed as learning games. 
 6. There are a variety of barriers that inhibit markets for educational games, including market fragmentation, 
faculty members and parents negative attitudes about video games, and lack of evidence for efficacy and 
evidence-based learning through gaming. 7. Educational institutions are slow to transform practices 
and organizational systems that take advantage of new technology, including gaming and simulations. 
8. There is no serious evidence-based learning framework that currently exists for implementing large-scale 
evaluations of the outcomes of using educational games.  Through a series of National Science Foundation 
grants, funding from the National Institute of Nursing Research, and contractual work with major publishers 
of educational materials, the authors were able to develop a diverse array of educational games. We stimulated 
this work by challenging the premises of extant development strategies so that we could answer the nested 
questions, What really works in the educational games, for whom when, how, and with what outcomes [33, 
34, 35]. Our simulation models and educational games have been able to address the National Research 
Council s seven critical issues in developing improved learning outcomes, especially in areas of higher 
order thinking like clinical judgment and understanding what scientists do as they engage in the scientific 
method. Over 70 major simulation suites have been released by a major publisher of nursing and medical 
instructional materials (a small sample includes [12-14, 28, 36-41]). In addition, a language immersion 
world is now under construction for an educational publisher that serves K-12 markets in the United States. 
From this foundation of experience, we began to examine how and why to select simulation and gaming attributes 
that could be used in large-scale studies of educational games and that could be developed within an 
evidence-based learning framework. However, as this work progressed we recognized two confounding dimensions 
that are important in creating educational games designed to improve learning outcomes. One of these 
dimensions is the realism of the gaming environment. The other dimension is the level of engagement within 
the environment. We began to study how these dimensions could shape learning and how they interact with 
each other within gaming and learning environments.  2.0 MODELS TO STUDY IMPACTS OF REALISM AND ENGAGEMENT 
In our early work, we used a threshold model for delineating the realism we built into clinical simulations 
for healthcare education. That is, we used panels of experts to help us delineate how realistic a set 
of simulations should be in look and feel in order to engage the end users within an educationally sound 
learning environment. Interestingly, the impact of realism on learning has remained an underdeveloped 
area of the simulation, gaming, and educational literature. We first struggled with this problem when 
trying to study how to reduce the well documented healthcare disparities that negatively impact minority 
populations in the United States [3, 20-25]. We were interested in developing a sound theoretical framework 
for understanding what level of realism must be portrayed in a healthcare simulation in order for effective 
learning and retention of learning to occur. In particular, we wanted to probe what behaviors within 
simulations might provide clues about how students could be engaged in simulations that helped them develop 
patterns of inclusive care. Until recently, this was an area seldom discussed in the educational research 
literature of nursing and medicine. There was an important literature that examined realism of simulations 
outside of nursing and medicine, including areas of psychology, education, multimedia, and simulation 
development. Referred to as experimental and mundane realism in the psychology literature [4] and as 
fidelity in the simulation and educational literature [3], the look and feel of simulations may be extremely 
important to students learning and retaining knowledge and skills. A simple example is that games and 
simulations may be particularly useful for helping nursing students (and practicing nurses) develop reliable 
pattern recognition strategies that will allow them to identify suites of data that fit together [11] 
and differentiate when, how and why data deviate from typical patterns [19, 42]. If we can help healthcare 
students develop reliable pattern recognition strategies they will be better able to discriminate essential 
and nonessential data in extant and emerging patient attributes. Improved pattern recognition, broadly 
defined, should provide a better foundation for improving clinical judgment and ultimately improving 
patient outcomes across all patient groups. However, there is a scant research base that allows us to 
decide how realistic a simulation has to be in order to help students develop sound pattern recognition. 
This is true in nursing and medicine as well as in K-12 and undergraduate sciences and mathematics. 
 Some researchers have hypothesized an interesting relationship between a user s learning and the level 
of realism in a simulation [2]. Their logic was that the relationship between realism (or fidelity) and 
learning during a simulation experience would be complex. These researchers predicted different learning 
curves for simulation users who were novices, had intermediate knowledge of the simulation area, or were 
experts in the subject or skills area being simulated. In brief, a model was developed in which it was 
hypothesized that a novice s initial learning during a gaming or a simulation experience increased as 
realism increased up to a point, after which increases in realism would lead to a decrease in learning. 
A similar pattern was predicted for users with intermediate knowledge in the subject or skills area being 
simulated. The initial learning would be higher than that found among novices, would peak at some level 
of simulation realism, and then would decrease as simulation realism increased but never fall below that 
of a novice at the same level of realism. The expert s learning gains would increase as realism in the 
game or simulation increased and would reach an asymptote as the game or simulation approached reality 
in terms of what could be done during the simulation experience. For the experts, the learning achieved 
would always be higher at every level of fidelity than found for the novice or user of intermediate knowledge. 
Establish New Belief Disposition To Think Cognitive Critically Processing Confirm Extant Belief Internal 
Stimuli External Stimuli The basic premise was that as realism increased the complexity of what was 
portrayed in the simulation or the actions required of the user would reach a point at which the simulation 
became too confusing or stressful for novice or even intermediate users. However, a variety of researchers 
have noted that the user s perception of the fidelity or realism may be different than the actual fidelity. 
In Figure 1, we show a simplistic representation of how affective, conative, and behavioral influences 
shape learning. In this figure, the box labeled environment can be conceptualized as the learning environment. 
The level of realism (realism of graphics and realism of procedures or functionality in the game) will 
be an inherent characteristic of this learning environment within an educational game or simulation. 
You can see in this figure that the learning environment shapes external stimuli as well as stimuli that 
are internal to the individual who is within a learning process. Since it is likely that interactions 
between the individual and the learning environment shape disposition to engage in effortful metacognitive 
endeavor (what some would call critical thinking), we can trace the arrows from the environment to the 
various compartments of dispositional, planning and behavioral influences on the learning and development 
of knowledge within a gaming environment [5, 6-8, 16-19, 31]. Factual &#38; Conceptual Procedural Knowledge 
Metacognitive Disposition PlanningTo Take and Action Committing  Environment Action or Behavior Figure 
1. Simplified schematic representation of how dispositional, planning, and behavioral influences shape 
learning. However, we feel the representation in Figure 1 is too simplistic. Our current work has modified 
this model substantially as we began to look at the impact of engagement, especially learning gains for 
time-on-task within an educational game. You can find evidence in the literature that motivation might 
be split into at least two compartments, intrinsic and extrinsic, with each motivation compartment influenced 
by the technological facets of the learning environment as well as individual users profiles of level 
of technological literacy. The important point is that the transfer of learning is likely to be shaped 
by fidelity, along with multiple other interacting motivational and cognitive processes that shape engagement 
within a game-based learning environment. It seems unreasonable that realism and engagement are likely 
to be orthogonal dimensions. For example, the Alessi and Trollip model [2] described earlier suggests 
that as realism increases then the learning outcomes reach an optimum level but subsequently will drop 
off for individuals who are novices or of intermediate knowledge in the skills or content domain of the 
simulation or educational game. Such a decrease in learning as realism increases could be due to a confounding 
of realism and engagement with less motivation to remain engaged as realism swamps the novice and intermediate 
knowledge users within the simulation or gaming environment. Since the literature is still relatively 
depauperate in the area of interactions between engagement and realism of a learning environment, we 
conducted a series of gedanken experiments. First, we set up three orthogonal axes learning, realism, 
and engagement. Setting the premise that these axes represented continuous variables, we then worked 
through different combinations of variable values and looked at the surface structure within the three-dimensional 
space of the three axes. This allowed us to build the gedanken experiments as what if scenarios. For 
example, what if learning drops off for a novice as realism in an educational game increases and engagement 
also drops off. Or, what if learning drops as realism increases but engagement does not drop or drops 
off more slowly than learning as realism in an educational game increases. Figure 2 shows a simplified 
version of one gedanken experiment in which we explored what is happening in the A-C regions. This kind 
of conceptual looping allowed us to examine what made sense and what made no sense in the context of 
literature on learning, motivation, engagement, and realism in an educational game or simulation that 
had elements of a video game. This approach of exploring the three dimensional space within the axes 
of learning, realism, and engagement led us to think more deeply about differences in individuals who 
might be working within an educational game. Clearly individuals in different developmental stages or 
with different prior knowledge could react differently in the same educational game (e.g., individuals 
in concrete reasoning relative to those with well-developed formal operational reasoning). From the research 
literature, we identified a number of important differentials that might enhance or inhibit students 
usage patterns and learning outcomes in an educational game. These included generalized technology literacy, 
specific prior experience with gaming environments, inclusiveness of the learning game environments (gender, 
socioeconomic status, ethnicity), expectations for success in an educational game and the value placed 
on such success (including influence of familial and broader social networks on expectations and values), 
disposition to engage in effortful cognitive endeavor (i.e., disposition to engage in higher order thinking 
[6-8]), social and cultural context for use of educational games [5, 16-18, 30], and prior knowledge 
of the student involved in a learning game [5, 16]. Indeed, this analysis substantiated the view of the 
National Research Council [30] in its argument that there are seven critical factors that instructional 
materials must address to improve higher order thinking. This analysis also substantiated the foundation 
of The Federation of American Scientists recommendations [9] for studying video games as learning environments 
suitable for educational games.  Figure 2. Three dimensional analysis for gedanken experiments. Region 
A represents the situation of high levels of realism, engagement, and learning. B and C are regions with 
different combinations of learning, realism, and engagement. In particular, to design a learning game 
environment that took into account the differentials described above would require enormous development 
costs, and as the Federation of American Scientists noted the video game and educational materials industries 
are inhibited by high development costs and uncertain markets for educational innovations developed as 
learning games. Furthermore, a variety of barriers inhibit markets for educational games, including market 
fragmentation as well as instructors and parents negative attitudes about video games. There also is 
a quite remarkable lack of evidence for efficacy and evidence-based learning through gaming. Continuing 
with our gedanken experiments, we next argued that the axes are not really orthogonal and are probably 
not even three single dimensions. For example, suppose that engagement in a game was shaped by intrinsic 
and extrinsic motivation and these were shaped by the gaming environment. Using a broad literature base, 
we worked through the difficulty of trying to delineate meaningful variables and variable clusters that 
might contribute to learning, realism, and engagement but then we had to face the enormous complexity 
of the confounding of variables. Finally, we settled on a multivariate approach that reduced the variables 
related to learning, realism, and engagement into suites of vectors and then treated the resultant of 
learning outcome variables as being shaped by the other variables. This type of analysis is much more 
complicated and validates the Federation of American Scientists (FAS) recommendations for a rigorous 
research program and also works on ten specific game attributes for application in learning. These were 
derived from advances in cognitive and learning science [9; see pages 18-20] and FAS argues games should 
provide: 1. Clear learning goals. 2. Broad experiences and practice opportunities that continue to challenge 
the learner and reinforce expertise. 3. Continuous monitoring of progress and use of this information 
to diagnose performance and adjust instruction to a learner s level of mastery (see also research on 
adaptive learning and teaching). 4. Encouragement of inquiry and questions, and response with answers 
that are appropriate to learner and context. 5. Contextual bridging, which is closing the gap between 
what is to be learned and its usefulness to the learner. 6. Engagement leading to an increased time 
on task within a learning game environment. 7. Motivation and strong goal orientation. 8. Scaffolding 
in the form of cues, prompts, hints, and partial solutions to keep learners progressing through the activities 
in a learning game. 9. Personalization that allows tailoring of learning to the individual learner. 
 10. Infinite patience inherent in a game environment that literally does not tire of repetitive actions 
and so provides learners with innumerable opportunities to try an activity over and over.  3.0 PRELIMINARY 
STUDIES Rather than be discouraged by the complexity of the problem of studying learning outcomes within 
educational game environments, we decided to build a modular research platform in which we could nest 
different types of learning environments and establish a system we called EMME to collect data on users 
choices within the environment. EMME is the Electronic Monitoring and Mentoring Engine. It was built 
in its first version to follow students choices within clinical simulations and contrast students choices 
to the choices that would have been made by an expert clinical panel. As a starting point, we studied 
Second Life and built a virtual world similar in level of realism to the Second Life virtual world because 
it has been so well received by many different types of individuals. By level of realism, we mean the 
degree of realism in the graphical skins as well as in the procedural rules of an educational game or 
simulation. For the prototype, we built an outpatient clinic in which different kinds of patients can 
enter and engage with the learner through conversations mediated by voice recognition. We chose to build 
the system for fourth year nursing students in Canada and the United States and are using a multiattribute 
latent class model of learning outcomes assessment to examine students pattern recognition of critical 
suites of patient data that indicate a particular clinical problem, disease, or injury state. To study 
the prototype s usability, we took the system to the Rutgers International Nursing Computer and Technology 
Conference that was held in San Francisco in June 2007. At this conference, we introduced faculty, undergraduate 
students, and publishers representatives to the prototype through informal presentations. These presentations 
allowed us to collect data for a first round of usability analyses on perceptions of usefulness of this 
type of gaming environment for teaching clinical pattern recognition to nursing students. Based on the 
positive and negative feedback we received, our research team is now working on five gaming scenarios 
that will allow undergraduate nursing students to assess a patient walking into an outpatient clinic 
and to make a clinical judgment about the respective patient. We have chosen congestive heart failure, 
chronic obstructive pulmonary disease, asthma, diabetes, and coronary artery disease as patient problems 
with enormous economic and quality of life burdens. As a set of benchmarks for educational design, we 
are using the Federation of American Scientists ten recommendations for game attributes essential to 
applications in learning. The research platform was built so that we would be able to vary levels of 
realism systematically and for each level of realism embed different levels of possible student engagement. 
Again, levels of realism is degree of realism in the graphical skin and procedural rules available to 
the user. Simultaneously, we have embedded EMME to collect data on learning outcomes. The differentials 
we mentioned earlier (level of abstract reasoning, general technological literacy, prior experience in 
gaming environments, and so on) can be measured and used to disaggregate groups of nursing students or 
as covariates in a multivariate statistical analytical framework. Obviously, such a research design is 
complex and requires a large sample size. However, the building of educational games that are also research 
engines is a crucial advance that gaming theorists and developers must take in order to understand what 
really works in educational games, for whom, when, how, and with what outcomes.  4.0 DISCUSSION Despite 
a diverse array of efforts to develop educational games and simulations, few are easily customizable 
to the idiosyncrasies of an academic program or clinical setting. Four major problems in game and simulation 
design impede widespread development of educational games and simulations, especially games that have 
evidence-based usage in academic nursing programs as well as in clinical settings. We must find solutions 
to these four problems: 1. Instructional designers seldom conduct the research necessary to demonstrate 
their products actually improve learning or skills. In healthcare, an empirically-driven approach becomes 
especially critical in the context of the Institute of Medicine s call for broadly based core competencies. 
[3, 20-26] Similar problems exist throughout the educational games and simulations available at the K-12 
and undergraduate levels. 2. With few exceptions, commercially available educational games and simulations 
have not been shown to improve what some call critical thinking (including the important higher levels 
of declarative, procedural, and also metacognitive knowledge) of users while also improving disposition 
to engage in higher order thinking [6-8, 31]. Such simulations have remained elusive, despite many different 
types of simulations that are being evaluated. 3. Few commercially available simulations have been developed 
to mesh sensibly with the strategic needs of K-12 and undergraduate curricula or with professional development, 
continuing education, and training programs. 4. There are no commercially available products related 
to improving learning outcomes or skills competencies that are designed to become part of an evidence-based 
education framework as well as an evidence-based practice framework that improves students' and practitioners' 
learning-training outcomes.  These four basic problems are exacerbated by the complexity of studying 
the impact of realism and engagement on game and simulation design as well as the ultimate impact on 
student learning. However, many of the logistical difficulties of studying multiple, interacting variables 
can be solved with a research-driven educational gaming and simulation design methodology, such as the 
one we have recently developed. The key in evidence-based learning is to create coupled teaching-learning-assessment 
systems that have reliability and validity in measuring the appropriateness of decisions that students 
or other users make in response to an engagement within an educational game or simulation. At the same 
time, such a system must be easily adaptable to the idiosyncrasies of curricular frameworks and individual 
courses within a particular discipline or domain area of an academic or professional education program. 
We can see this fundamental problem in systems that have tried to provide such a coupling of teaching-learning-assessment 
when they are not easily customizable to the idiosyncrasies of a particular educational program or training 
setting. Furthermore, the vast majority of available systems do not have an automatic grading or performance 
rating system that has both reliability and validity. Finally, such teaching­learning-assessment systems 
have not really empirically demonstrated that they can couple the level of realism that optimizes student 
engagement with learning to automated authentic performance assessments. We have made a promising start 
in studying the impact of realism and engagement on learning within videogames, serious games, or educational 
games that are designed to have some educational intent. The research model we propose can contribute 
to a better understanding of how and what a student user could learn within an educational or serious 
game. However, there is a deep structure in videogame development that has not been adequately meshed 
with learning theory, achievement and motivation behavior theory, and cognitive development in order 
to create educational games that really work to improve learning. We now turn from our research model 
to explore critical issues in learning and motivation theory that are relevant to gaming and development 
of educational games. Recent syntheses of research on the expressive power of videogames [5] and their 
potential for teaching and learning [16-19] provide additional insight into relationships between realism, 
engagement, and potential for learning. For example, in none of the earlier sections of this paper did 
we mention a particular educational framework that would define a particular praxis framework for choosing 
instructional materials, like educational games. How might educators utilize the types of analyses we 
presented in Figures 1 and 2 in order to inform their choices about choosing instructional materials? 
Bogost [5] builds an interesting analysis of the complex relationships between the surface representation 
or graphical skin of a game (or simulation) and the procedural model of the underlying programming and 
its emergent functionality. Juul [27] would probably refer to this as the fiction and rules of the game 
or simulation. As a hypothetical example, consider an educational simulation we built to train paramedics 
in patient care. In one segment of the game, the patient is in a supine position and you can implement 
a variety of interventions to try to stabilize the person, before and during transport to a hospital. 
The simulation includes all of the interventions that a paramedic might want to implement in patient 
care. A few examples are: clearing the airway, opening the airway, administering oxygen, starting an 
intravenous line and administering IV fluids or medications, putting on bandages, administering a variety 
of pharmacological therapies, and defibrillating the patient. We examined how the same underlying rules 
embedded in the simulation s programming could be expressed in the functionality of tools of torture. 
Instead of a defibrillator, we could layer in the graphic skin of an electric shock device. Instead of 
devices for opening the airway, we could graphically skin in devices that cause choking and gagging. 
Without adding more detail here, we hope readers will get the point. Basically, a life-saving paramedic 
simulation becomes a torture simulation. The goal of interpreting patient physiological and psychosocial 
responses to achieve stabilization of the patient is permuted to the goal of getting the information 
you need from an individual through torture. Different skins or fictions or contexts are layered over 
the same procedural model or rules.  Indeed, a similar and more startling example was described by Bogost 
(see page 242 in [5]) when he outlined how game designer Robert Koster imagined putting a new skin on 
the popular game Tetris. Instead of using the abstract tetrominoes Koster projected using dead bodies 
in different contortions with the playing field becoming a mass grave. Again, he imagined the same procedural 
model or rule base but different skins, contexts, or fiction. The abstract goals of Tetris and a Genocide 
simulator (or our paramedic and torture simulators) are the same, the rules underlying the goals are 
the same, but the fiction is horrifyingly different. Gee [16-18] has provided a perspective of embodied 
experiences as semiotic domains that are sets of practices with situated meaning. Gee focuses, in part, 
on how games teach individuals how to play the game. In turn, game mastery may have the potential to 
inculcate transfer of abstract thinking schema to a variety of problems in which the procedural model 
of the game has value in problem solving or interpretation. These ideas are very much consonant with 
the models of experimental and mundane realism described in psychological research [4]. We can now ask 
if Gee and Bogost have provided us with insight into what theoretical perspectives we might use to examine 
the value of gaming in educational instructional methods and materials. Certainly, some faculty members 
might want the well-designed educational game to provide a kind of 1:1 mapping of real world structures 
and processes onto skin and rules of a game (e.g., a clinical procedure for a patient). Then, game users 
would be encouraged to mimic how desired learning outcomes would be achieved in the real world. Realism 
would usually be a very important dimension of games striving for such 1:1 mapping for a learning environment. 
Engagement might suffer if the level of realism in the skin and rules swamped the student. From a different 
perspective, videogames might well be seen as providing environments in which individuals construct their 
own interpretation of the reality portrayed in the game and so of the real world structures and processes 
the game mimics. From this perspective, Bogost [5] argues constructivists would envision videogames as 
providing environments in which game users derive insights into relationships that drive the environment. 
Realism might not be so important in this type of learning environment as long as engagement drove exploration 
sufficiently to construct the learning that a faculty member hoped a student would achieve. From an informed 
faculty perspective, the choice of an environment for learning would be based on the educational goals 
and objectives a faculty member was trying to achieve in use of the environment. Consequently, and again 
from an informed position, a faculty member would want to look carefully at the skin and the rules of 
an educational game and make sensible decisions about the game s abilities to help students achieve the 
instructor s educational goals and objectives. However, a large percentage of faculty at K-12 and undergraduate 
levels know very little about how to analyze the skin-rule interactions that might shape student learning 
or the implications of such interactions in design of educational methods and materials [35]. We therefore 
propose more rigorous studies of the interactions of realism and engagement in different types of learning 
environments. We also propose that such studies be conducted to include a diverse range of faculty perspectives 
and within different theoretical frameworks of educational praxis. This paper reports a small step in 
that direction.  5.0 LITERATURE CITED [1] Anderson, L., and Krathwohl, D. A taxonomy for learning, 
teaching, and assessing. Longman, New York, NY, 2001. [2] Alessi, S. M., and Trollip, S. R. Multimedia 
for Learning: Methods and Development. Allyn and Bacon, Boston, MA, 2001. [3] AACN - American Association 
of Colleges of Nurses. The Role of the Clinical Nurse Leader. American Association of Colleges of Nursing, 
Washington, DC, 2003. [4] Aronson, E., Brewer, M. and Carlsmith, J. M. Experimentation in social psychology. 
In, G. Lindzy and E. Aronson (Eds.) Handbook of social psychology, 3rd Edition. Random House, New York, 
NY. 1985, 441-486. [5] Bogost, I. Persuasive Games the expressive power of videogames.: MIT Press, Cambridge, 
MA, 2007 [6] Cacioppo, J. T., Petty, R. E., and Quintanar, L.R. Individual differences in relative hemispheric 
alpha abundance and cognitive responses to persuasive communications. Journal of Personality and Social 
Psychology, 43, 3, (1982), 623-636. [7] Cacioppo, J. T. Petty, R. E., and Kao, C. F. The efficient assessment 
of need for cognition . Journal of Personality Assessment. 48, (1984), 306-307. [8] Cacioppo, J. T., 
Petty, R. E., Feinstein, J. A., and Jarvis, W. B. G. Dispositional differences in cognitive motivation: 
The life and times of individuals varying in need for cognition. Psychological Bulletin, 19, 2, (1996), 
197-253.  [9] Federation of American Scientists. Summit on Educational Games Harnessing the power 
of video games for learning. Federation of American Scientists, Washington, DC, 2006. [10] Feingold, 
C., Calaluce, M., and Kallen, M. Computerized patient model and simulated clinical experiences: Evaluation 
with baccalaureate nursing students. Journal of Nursing Education, 43, 2, (2004), 156-163. [11] Fonteyn, 
J. (1998). Thinking strategies for nursing practice. Lippincott, Philadelphia, PA. [12] Fulcher, G. Virtual 
Medical Office for Bonwit-West s Clinical Procedures for Medical Assistants, 6th Edition. Elsevier-Saunders, 
Philadelphia, PA, 2007. [13] Fulcher, G. Virtual Medical Office for Kinn s The Administrative Medical 
Assistant, 6th Edition. Elsevier-Saunders, Philadelphia, PA, 2007. [14] Fulcher, G. Virtual Medical Office 
for Kinn s The Medical Assistant, 10th Edition. Elsevier-Saunders, Philadelphia, PA, 2007. [15] Gardner, 
H. Intelligence reframed: Multiple intelligences for the 21st century. Basic Books, New York, NY, 1999. 
[16] Gee, J. P. Good video Games + Good Learning Collected essays on video games, leaning, and literacy. 
Peter Lang, New York 2007. [17] Gee, J. P. Situated Language and Learning: A critique of traditional 
schooling. Routledge, London, 2004. [18] Gee, J. P. What video Games have to Teach Us About Learning 
and Literacy. Palgrave MacMillan, New York, NY, 2003 [19] Higuchi, K., and Donald, J. Thinking processes 
used by nurses in clinical decision making. Journal of Nursing Education, 41, 2, (2002), 145-153. [20] 
 Institute of Medicine. To err is human Building a safer health care system. National Academy Press, 
Washington, DC, 2000. [21] Institute of Medicine. Crossing the quality chasm: A new health system for 
the 21st century. National Academy Press, Washington, DC, 2001. [22] Institute of Medicine. Guidance 
for the National Healthcare Disparities Report. National Academy Press, Washington, DC, 2002. [23] Institute 
of Medicine. Health professions education A bridge to quality. National Academy Press, Washington, DC, 
2003. [24] Institute of Medicine. Unequal treatment Confronting racial and ethnic disparities in healthcare. 
National Academy Press, Washington, DC, 2003. [25] Institute for Safe Medication Practices. Medication 
Errors, 2nd Edition. American Pharmacists Association, Washington, DC, 2007 [26] JCAHO. Frontline of 
defense. Joint Commission on the Accreditation of Healthcare Organizations, Oakbrook Terrace, IL, 2001. 
[27] Juul, J. Half-Real: video games between real rules and fictional worlds. MIT Press, Cambridge, MA, 
2005. [28] Mathers, D. Virtual clinical Excursions for Black and Hawks Medical-Surgical Nursing: Clinical 
Management for Positive Outcomes, 7th Edition. Elsevier-Saunders, Philadelphia. PA, 2006. [29] National 
Research Council (2000). Bransford, J. D., Brown, A. L., and Cocking, R. R. (Eds.). How people learn: 
Brain, mind, experience, and school. National Academy Press, Washington, DC, 2000. [30] National Research 
Council. Knowing what students know: The science and design of educational assessment. National Academy 
Press, Washington, DC, 2001. [31] Sadowski, C. J. and Gülöz, S. Elaborative Processing mediates the 
Relationship between Need for Cognition and Academic Performance. Journal of Psychology, 130,3, (1996), 
303-307. [32] Sternberg, R. J. (1997) Thinking styles. Cambridge University Press, New York, 1997. [33] 
 Sullins, E. S., Hernandez, D., Fuller, C. and Tashiro, J. S. Predicting who will major in a science 
discipline: Expectancy-value theory as part of an ecological model for studying academic communities. 
Journal of Research in Science Teaching, 32, 1, (1995), 99-119. [34] Tashiro, J. and Long, G. Moving 
Toward Evidence­based Nursing Education. Submitted to the Journal of Research in Science Teaching, (2007). 
[35] Tashiro, J. and Rowland, P. McD. What works: Empirical approaches to restructuring courses in biology 
and environmental sciences. In A. McNeal and C. D Avanzo (Eds.) Student-active science: Models of innovation 
in college science teaching. Harcourt Brace and Company, Orlando, FL, 1997, 163-187. [36] Tashiro, J. 
T., Sullins E. S., Long, G., and Kelly, M. Virtual clinical excursions in medical-surgical nursing: assessment 
and management of clinical problems. Mosby, St. Louis, 2001. [37] Tashiro, J. T., Sullins E. S., Long, 
G., and Kelly, M. Virtual clinical excursions for fundamentals in nursing. Mosby, St. Louis, 2001. [38] 
Tashiro, J. T., Sullins, E. S., Long, G., and Kelly, M. Virtual clinical excursions in medical-surgical 
nursing: Clinical management for positive outcomes. Mosby, St. Louis, 2003. [39] Tashiro, J. T., Sullins, 
E. S., Long, G., and Kelly, M. Virtual clinical excursions for basic nursing: essentials for practice. 
Mosby, St. Louis, 2003. [40] Tashiro, J. T., Sullins, E. S., and Long, G. Virtual clinical excursions 
for nursing care of infants and children. Mosby, St. Louis, 2003. [41] Tashiro, J. T., Sullins, E. S., 
and Long, G. Virtual clinical excursions for fundamental concepts and skills for nursing. Mosby, St. 
Louis,, 2003. [42] Welk, D. S. Designing clinical examples to promote pattern recognition: Nursing education-based 
research and practical applications. Journal of Nursing Education, 41(2), (2002), 53-60.   
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2007</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>1328224</article_id>
		<sort_key>220</sort_key>
		<display_label>Pages</display_label>
		<pages>8</pages>
		<article_publication_date>11-14-2007</article_publication_date>
		<seq_no>2</seq_no>
		<title><![CDATA[Instructional ethology]]></title>
		<subtitle><![CDATA[reverse engineering for serious design of educational games]]></subtitle>
		<page_from>121</page_from>
		<page_to>128</page_to>
		<doi_number>10.1145/1328202.1328224</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1328224</url>
		<abstract>
			<par><![CDATA[<p>The effective application and use of games and game technology for education requires examinations of existing artifacts, both in and out of formal educational settings, as well as the development of new theories and models for how to design games intended primarily to educate rather than entertain. One way to facilitate an understanding of how a medium like digital game technology can be used effectively in education is to study that medium's outstanding examples, regardless of their original purpose. This paper describes a methodology for analysing entertainment games that uses a synergy of reverse engineering and ethology, neither of which have been used in this context before. Normally, reverse engineering attempts to recover the original design of a software application, but in this case it will be used to generate an alternate design that can then in turn be used to inform instructional design. Ethology studies the observed behaviour of animals, but here is adapted as a method for the study of games. Through this perspective, it is possible to identify and classify built-in learning objectives and from there to associate the mechanisms and strategies employed to teach them. It is proposed that these strategies can then be used in educational games without compromising the essential qualities that have made digital games the most popular leisure activity in the western world today.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[cognition]]></kw>
			<kw><![CDATA[direct manipulation]]></kw>
			<kw><![CDATA[education]]></kw>
			<kw><![CDATA[human-computer interaction]]></kw>
			<kw><![CDATA[learning]]></kw>
			<kw><![CDATA[learnware]]></kw>
			<kw><![CDATA[reflection]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>D.2.2</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>D.2.7</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>H.5.2</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>K.3</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010405.10010489</concept_id>
				<concept_desc>CCS->Applied computing->Education</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003456.10003457.10003490.10003503.10003505</concept_id>
				<concept_desc>CCS->Social and professional topics->Professional topics->Management of computing and information systems->Software management->Software maintenance</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003456.10003457.10003527</concept_id>
				<concept_desc>CCS->Social and professional topics->Professional topics->Computing education</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10011007.10011074.10011111</concept_id>
				<concept_desc>CCS->Software and its engineering->Software creation and management->Software post-development issues</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003121</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10011007.10011074.10011081</concept_id>
				<concept_desc>CCS->Software and its engineering->Software creation and management->Software development process management</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10011007.10011074.10011075.10011079.10011080</concept_id>
				<concept_desc>CCS->Software and its engineering->Software creation and management->Designing software->Software implementation planning->Software design techniques</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Experimentation</gt>
			<gt>Human Factors</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P158074</person_id>
				<author_profile_id><![CDATA[81100546832]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Katrin]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Becker]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Calgary]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Katamari Damacy {Game}, Namco, 2004, PS2.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Becker, K., Games and Learning Styles. in <i>Special Session on Computer Games for Learning and Teaching, at the The IASTED International Conference on Education and Technology ~ICET 2005~</i>, (Calgary, Alberta, Canada, 2005).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Becker, K. How are Learning Objectives Woven into the Design of a Serious Game? Instructional Design for Serious Games, University of Calgary, 2005 retrieved from: http://pages.cpsc.ucalgary.ca/~becker/Main/PhD/Thesis-Proposal-NTI.pdf]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Becker, K. Pedagogy in Commercial Video Games. in Gibson, D., Aldrich, C. and Prensky, M. eds. <i>Games and Simulations in Online Learning: Research and Development Frameworks</i>, Idea Group Inc, 2006.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Becker, K. Video Game Pedagogy: Good Games = Good Pedagogy. in Miller, C. T. ed. <i>Games: Their Purpose and Potential in Education (in press)</i> Springer Publishing, 2008.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>624902</ref_obj_id>
				<ref_obj_pid>624579</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Chikofsky, E., J. and Cross, J. H., II; Reverse engineering and design recovery: a taxonomy. <i>Software, IEEE, 7</i> (1). 13--17.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Crosbie, W., Instructional Design does not equal Game Design -- Lessons learned in delivering a course in game design and education. in <i>World Conference on Educational Multimedia, Hypermedia and Telecommunications 2005</i>, (Chesapeake, VA, 2005), AACE, 2617--2621.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Dobson, J. Survey: 'Word Of Mouth' Most Important For Game Buyers <i>Gamasutra</i>, 2006 retrieved from: http://www.mi6conference.com/Magid_ MI6.pdf on Nov. 14 2006.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Elliott, J., Adams, L. and Bruckman, A., No Magic Bullet: 3D Video Games in Education. in <i>ICLS 2002</i>, (Seattle, WA, 2002).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Ellis, H., Heppell, S., Kirriemuir, J., Krotoski, A. and McFarlane, A. Unlimited Learning: The role of computer and video games in the learning landscape, 2006 retrieved from: http://www.elspa.com/assets/files/u/unlimitedlearningtheroleofcomputerandvi deogamesint_344.pdf on Dec. 10, 2006.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Elorg (designer). Tetris {Game}, Mirrorsoft Ltd., 1987.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[ESA. Essential Facts About the Computer and Video Game Industry: 2006 Sales, Demographics, and Usage, The Entertainment Software Association, 2006, latest data on Video game industry retrieved from: http://www.theesa.com/archives/files/Essential%20Facts%202006.pdf on Jun 25 2006, 2005]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Fern&#225;ndez-Armesto, F. Teaching vs. Instruction: Strictly speaking, education &amp; instruction are mutually exclusive. You instruct soldiers. You teach students. <i>CAUT Bulletin</i>, 2006]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Freitas, S. d. Learning in Immersive Worlds: a review of game based learning, Joint Information Systems Committee (JISC), London, 2007, 73 retrieved from: http://www.jisc.ac.uk/media/document s/programmes/elearning_innovation/ga ming%20report_v3.3.pdf]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Gagn&#233;, R. M. <i>The conditions of learning and theory of instruction.</i> Holt, Rinehart and Winston, New York, 1985.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Gee, J. P. Learning by Design: Good Video Games as Learning Machines. <i>E-Learning, 2</i> (1).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Gouglas, S., Sinclair, S., Ellefson, O. and Sharplin, S. Neverwinter Nights in Alberta: Conceptions of Narrativity through Fantasy Role-Playing Games in a Graduate Classroom. <i>Innovate, Journal of Online Education, 2</i> (3).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Gunter, G., Kenny, R. and Vick, E., A Case for Formal Design Paradigm for Serious Games. in <i>CODE -- Human Systems; Digital Bodies</i>, (Miami University, Oxford, Ohio, 2006), The International Digital Media and Arts Association and the Miami University Center for Interactive Media Studies]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Hsi, I. Analyzing the conceptual coherence of computing applications through ontological excavation <i>College of Computing</i>, Georgia Institute of Technology, 2004, 162]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>951346</ref_obj_id>
				<ref_obj_pid>950792</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Hsi, I., Potts, C. and Moore, M., Ontological Excavation: Unearthing the core concepts of the application. in <i>Tenth Working Conference on Reverse Engineering 2003 (WCRE'03)</i>, (2003), 345--352.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Kafai, Y. B. Playing and Making Games for Learning: Instructionist and Constructionist Perspectives for Game Studies. <i>Games and Culture, 1</i> (1). 36--40.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Kirriemuir, J. and McFarlane, A. Literature Review in Games and Learning, 2004 retrieved from: http://www.nestafuturelab.org/researc h/reviews/08_01.htm on June 11, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1207478</ref_obj_id>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[Koster, R. <i>Theory of Fun for Game Design.</i> Paraglyph Press, Scottsdale, AZ, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[Meier, S. (designer). Civilization III {Game}, Infogrames, 2001, Windows.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[Molyneux, P. (designer). Black &amp; White {Game}, Electronic Arts, 2001, PC.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[Peters, R. S. Criteria of Education. in <i>Ethics and Education</i>, Allen and Unwin, 1966.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1197653</ref_obj_id>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[Prensky, M. <i>Don't Bother Me Mom I'm Learning!</i> Continuum St. Paul, MN, 2006.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[Rieber, L. Multimedia Learning in Games, Simulations, and Microworlds. in Mayer, R. E. ed. <i>The Cambridge Handbook of Multimedia Learning</i>, Cambridge University Press, 2005, 549--567.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[Rieber, L. P., Davis, J., Matzko, M. and Grant, M., Children as multimedia critics: Middle school students' motivation for and critical analysis of educational multimedia designed by other children. in <i>What We Know and How We Know It</i>, (Seattle, WA, 2001), American Educational Research Association.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>30</ref_seq_no>
				<ref_text><![CDATA[Squire, K. Changing the Game: What Happens When Video Games Enter the Classroom? <i>Innovate, Journal of Online Education, 1</i> (6).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>31</ref_seq_no>
				<ref_text><![CDATA[Squire, K. From Content to Context: Videogames as Designed Experience. <i>Educational Researcher 35</i> (8). 19--29.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>32</ref_seq_no>
				<ref_text><![CDATA[Squire, K. Resuscitating Research in Educational Technology: Using Game-Based Learning Research as a Lens for Looking at Design-Based Research. <i>Educational Technology, 45</i> (1). 8--14.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>33</ref_seq_no>
				<ref_text><![CDATA[Takatalo, J., Hakkinen, J., Kaistinen, J., Komulainen, J., Sarkela, H., Kaistinen, J. and Nyman, G., Adaptation into a Game: Involvement and Presence in Four Different PC- Games. in <i>Future Play, The International Conference on the Future of Game Design and Technology</i>, (The University of Western Ontario, London, Ontario, Canada, 2006).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>34</ref_seq_no>
				<ref_text><![CDATA[Tinbergen, N. On the aims and methods of ethology. <i>Zeitschrift fur Tierpsychologie, 20</i>. 410--463.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>35</ref_seq_no>
				<ref_text><![CDATA[Winn, B. and Heeter, C. Resolving Conflicts in Educational Game Design Through Playtesting. <i>Innovate, Journal of Online Education, 3</i> (2).]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Instructional Ethology: Reverse Engineering for Serious Design of Educational Games Katrin Becker University 
of Calgary becker@minkhollow.ca Abstract The effective application and use of games and game technology 
for education requires examinations of existing artifacts, both in and out of formal educational settings, 
as well as the development of new theories and models for how to design games intended primarily to educate 
rather than entertain. One way to facilitate an understanding of how a medium like digital game technology 
can be used effectively in education is to study that medium's outstanding examples, regardless of their 
original purpose. This paper describes a methodology for analysing entertainment games that uses a synergy 
of reverse engineering and ethology, neither of which have been used in this context before. Normally, 
reverse engineering attempts to recover the original design of a software application, but in this case 
it will be used to generate an alternate design that can then in turn be used to inform instructional 
design. Ethology studies the observed behaviour of animals, but here is adapted as a method for the study 
of games. Through this perspective, it is possible to identify and classify built-in learning objectives 
and from there to associate the mechanisms and strategies employed to teach them. It is proposed that 
these strategies can then be used in educational games without compromising the essential qualities that 
have made digital games the most popular leisure activity in the western world today. Categories and 
Subject Descriptors: D.2.2 [Software Engineering]: User Interfaces; D.2.7 [Distribution, Maintenance, 
and Enhancement] Restructuring, reverse engineering, and reengineering H5.2 [Information Interfaces and 
Presentation]: User Interfaces - User­centered design; Interaction styles; Theory and methods; Permission 
to make digital/hard copy of part of this work for personal or classroom use is granted without fee provided 
that the copies are not made or distributed for profit or commercial advantage, the copyright notice, 
the title of the publication, and its date of appear, and notice is given that copying is by permission 
of the ACM, Inc. To copy otherwise, to republish, to post on servers, or to redistribute to lists, requires 
prior specific permission and/or a fee. FuturePlay 2007, November 15-17, 2007, Toronto, Canada. Copyright 
2007 ACM 978-1-59593-943-2/07/0011...$5.00 K.3 [Computing Milieux]: Computers and Education General Terms: 
Design, Experimentation, Human Factors Keywords: Human-computer interaction, direct manipulation, reflection, 
education, learning, cognition, learnware  1. Introduction As the interest in and the use of digital 
games in education continues to gather momentum, so will the demand for instructional design theories 
and models geared to this medium. Developing a game can be both time consuming and expensive designing 
a game intended to facilitate deliberate learning requires additional consideration. Commercial games, 
being true to their theatrical roots, are designed primarily to entertain and although their designers 
may have intended lessons they wish players to take up, the game will rarely be labelled a failure if 
the players fail to do so. On the other hand, an entertainment game that fails to entertain is a failure. 
The relative ranking of these two elements, namely learning and entertainment are reversed in educational 
games so that an educational game that fails to help players achieve the learning objectives is a failure, 
while one that does not entertain may still be useable. Entertainment is related to engagement though, 
so the importance of entertainment can not be ignored. It seems common sense to include elements of instructional 
design and development when creating educational games, however, how this should be done is still not 
clear. Educators have always appropriated whatever technologies are available to us for use as technologies 
for instruction, and digital games are no exception. This paper is a report on a methodology that has 
been created to examine several top-rated commercial digital games in order to identify the learning 
support mechanisms employed. Some digital games made primarily for entertainment already incorporate 
many if not all of the major components necessary to meet the requirements of effective instruction [4, 
16, 27, 28]. However, since the incorporation of formal pedagogy has not likely been a deliberate game 
design decision, it is unlikely that designers such as Sid Meier or Sir Peter Molyneux would have included 
"implement Gagne's nine events of instruction" as part of their design specifications when creating Civilization 
III [24] or Black and White [25]. Because the embodiment of accepted pedagogy in existing commercial 
games is assumed to be largely coincidental, interviewing or otherwise studying the games designers themselves 
is unlikely to generate insights in a form that can be applied to instructional design directly. Consequently 
uncovering the mechanisms that support learning in digital games must be approached from a different 
angle.  2. Studying the Masters If we were to take a close look at how the different forms of both 
classical and modern communication media (theatre, literature, film, television, etc.) have been used 
for educative purposes and which commercial examples have been appropriated by educators, it becomes 
clear that the majority of the most remarkable and effective lessons taught to us in this way have been 
created by extraordinarily talented writers, playwrights, directors, and producers together with their 
teams (Shakespeare, Hemmingway, Twain, Spielberg, etc.). One other notion stands out. These significant 
creative works have, by and large, not been created by professional educators or instructional designers. 
What does this mean? Should we ignore what instructional design methods and theories have to say? The 
answer is, Of course not . Far from trying to circumvent what educators and instructional designers have 
learned, we should recognize that studying these outstanding examples as educational objects presents 
us with opportunities to learn techniques and strategies we can apply to intentional learning objects, 
even if they weren t produced by professional educators. We should try to characterize what it is about 
them that makes them have the impact they do. Looking at the practice of the masters is an accepted approach 
to education in Fine Arts, the Performing Arts, Literature, and Music as well as a few others. All have 
a long tradition of learning from the masters. In Education, we study the scholars and eagerly try to 
assimilate their theories, and there is also a long-standing tradition of studying master educators. 
As a medium, games are more closely aligned with film and theatre than they are with the more familiar 
teaching formats like textbooks, lectures or even websites. Given that, one could argue that much can 
be learned about how to design games by looking at the masterpieces of this profession (i.e. the best 
games) just as we learn about designing film by looking at film masterpieces. By studying the masters 
, we can progress towards understanding the essential elements of good games and begin to discuss the 
implications this holds for the deliberate design of educational games. There is, however, a caveat: 
knowing why a game is good is not the same as knowing how to make a game good. It is nonetheless an essential 
step in that process.  3. Educational Game Design Effective application and use of games and game technology 
for education requires examinations of existing artifacts, both in and out of formal educational settings, 
as well as the development of new theories and models for how to design games intended primarily to educate 
rather than entertain. A growing body of literature is developing that reports on the use of commercial 
games in the classroom [10, 14, 17, 22, 30, 31], as well as custom-designed games [9, 33, 35], and designing 
games as a means to learning [21, 29]. Other reports have proposed instructional design theories and 
models for educational digital games [18]. Most games that have been examined in this context have either 
been educational games or commercial games being used in educational contexts. Also, most studies involve 
the use of games in formal learning situations like classrooms where the main subjects of the study are 
the learners. In these contexts, design research methodologies are providing useful insights [32], but 
there is evidence to suggest that expertise in instructional design does not necessarily prepare one 
to design engaging educational games [7]. One way to facilitate an understanding of how a new medium 
like digital game technology can be used effectively in education is to study the designs of that medium's 
outstanding examples, regardless of their original purpose. In other words, it is possible to uncover 
instructional design elements by studying the game itself and its behaviour. However, most commercial 
games do not lend themselves especially well to direct analysis as educational learning objects because 
they were never designed as such. The methodology described in the following paragraphs is an approach 
to analyzing the game itself rather than the effect it has on the learners, but does so as if that game 
actually were an educational object. Analyzing an entertainment game as though it were an educational 
one when it was not designed as such necessitates a dissociation of what is learned in the game from 
how society values that which is learned. Doing so creates a common plane on which both educational and 
entertainment games can be assessed. The primary facet of the game that is examined through this perspective 
is its observable behaviour.  The described method for analysis of a commercial game is based on three 
fundamental assumptions: 1) that players must learn and indeed do learn new things while playing the 
game; 2) that successful games are successful at least partially because they facilitate that learning; 
and 3) that it is possible to examine learning in a digital game without associating what is learned 
with value-laden educational aims. All three are necessary conditions that make instructional ethology 
an appropriate methodology in this context.  Learning in Games People learn throughout their lives. 
It s what we do. The notion that people learn during gameplay is no longer controversial. Some have even 
suggested that learning is really what games are all about [23]. Previous work by this author [2-4] has 
focused on connecting commercial video games to accepted pedagogy in a fairly general way. However, while 
cherry picking specific elements from a wide variety of games in order to support an argument is useful 
it also has its limitations. Suppose we wish to examine games in the context of Gagné s Nine Events of 
Instruction [15]. If we show that nine different games each implement one event well, we have still not 
shown that any one game is capable of embodying Gagné s theory. Further we have no evidence that ANY 
single game that was able to incorporate all nine events would still be a popular game. We all remember 
films for example that may have had one or two good moments but are otherwise unremarkable or even bad. 
It is a much more significant feat to look at the whole of a work and see how the various parts fit together. 
Fortunately, there is evidence to suggest that some games do succeed in embodying one or more complete 
pedagogical models [5]. Successful Games Facilitate Learning What makes a game successful? Critical 
and commercial success are both recognizable and accepted (albeit subjective) measures of a game s popularity, 
and popularity in turn gives some indication of that game s perceived quality as judged by players, developers, 
and game critics. While it is acknowledged that commercial success is not a guarantee of quality, inclusion 
in the top ten or twenty games in any given year is a significant achievement. There are thousands of 
titles released each year, and nearly 230 million games were sold in the US in 2005 [12]. That means 
that less than 1% (possibly less than .05%) of these games makes it onto this list. Commercial game buying 
decisions are based heavily on game demos and word of mouth [8] so in one way or another it is the game 
itself that determines its sales, and ultimately its survival. A game that offers too little or too much 
support is likely to be seen as too difficult or insufficiently challenging, which in turn makes it unlikely 
to become popular. In this way, game design is critical to game success. A part of that design unavoidably 
includes supporting the player while they learn what they must learn in order to progress through the 
game.  Learning vs. Education Learning happens all the time and is a natural condition of being human. 
Further, learning always involves some sort of change: change in what we remember, in our skills, our 
attitudes, or behaviours. We can learn things that are useful or useless, life­saving, or dangerous, 
helpful or hurtful. In short, learning has no associated implications of moral, ethical or other value: 
learning is not Education. Education is value-laden. R.S. Peters, in Criteria of Education [26] states 
that it is impossible to consider education without implying some worthwhile and desirable change in 
the person being educated. Education implies learning which occurs over and above what is natural, and 
implies some persuasion (possibly even coercion) that is enacted on the recipient of this education. 
Because most commercial games were probably not designed to be educational, mining commercial games for 
insights into instructional game design requires a distinction between learning as a naturally occurring 
phenomenon, and education, which is deliberate. Thus, learning may be a desirable outcome of education, 
but education is not necessary for learning to occur. Where does teaching fit in? Teaching and instruction 
are terms that are often used interchangeably, yet there are some that would claim they are in fact mutually 
exclusive [13]. The implication is that instruction is more structured, teacher-centered and directed, 
and more closely related to training than is teaching. Teaching includes facilitation of learning through 
constructivism, inquiry-based methods, and so on. Whether commercial games teach or facilitate learning 
is a distinction that is not germane to the current investigation.  4. Methodological Synergy Uncovering 
the teaching or instructional mechanisms in a commercial game requires an examination of the game from 
the perspective of the player but not AS the player, and it requires analysis on two fronts: behavioural 
and structural, for both aspects play important roles in supporting learning in games. All digital games 
are software applications so the structural analysis draws its approach from software engineering, and 
specifically from a recent approach in black-box reverse engineering called ontological excavation [19]. 
Learning that happens while playing games is supported by the form of the application but also and perhaps 
more importantly, by its behaviour and that aspect of the methodology is inspired by methods used in 
the study of animal behaviour. The result is a new approach to analysis, called instructional ethology. 
 Black Box Reverse Engineering Instructional ethology uses a variation on black box reverse engineering 
as used in software engineering, but it is an approach that has not been used in this context before. 
Reverse engineering is the process of analysing a software program or application in order to discover 
how it works, and is referred to as black-box if the process does not examine the original source code 
of the application. Normally, reverse engineering is performed in order to recover the original design 
of a software application for the purposes of renovation or augmentation [6], but in this case it is 
used to generate an alternate, hypothetical design that can then in turn be used to inform instructional 
design of serious games. This alternate design is one that may not have been explicitly formulated by 
the original designers. It focuses on the instructional aspects of the program s behaviour as observed 
through its interface hence the term ethology . Ontological Excavation The described methodology is 
also loosely based on a technique called ontological excavation , developed by Idris Hsi [20]. This is 
a technique for reverse engineering that uses the morphology, or external interface of an application 
to uncover the ontology1 of an application, or the application s theory of the world . In other words, 
the message in the medium includes that a design is not neutral and reflects a 1 In computer science, 
an ontology is a data model that represents a set of concepts within a domain and the relationships between 
those concepts. The domain or universe of discourse, indicates the relevant set of entities that are 
being dealt with by quantifiers. theoretical construct held or imposed by the designers (either intentionally 
or not). For example, a calendar application would embody a theory about how users schedule their time. 
There are five main steps to this process [19]: 1. Model the user interface in a morphological map of 
the application s interactors, displays, and containers. 2. Generate a list of morphological elements. 
 3. For each element, identify the concepts (entity types and attributes) that it invokes. 4. Through 
dynamic interaction with the application, identify the relationships between the concepts. 5. Model 
the concepts and relationships into a semantic network representing the application s ontology.  Since 
the object of this analysis is to yield instructional elements of the application rather than its ontology 
the process has been adapted. Applying this notion to a game then, a comparable theory would have to 
do with how players take up the game and would include how they learn what they need to learn in order 
to win the game. Also in the case of a game, because there is no access to the game s source code this 
ontology must be inferred solely from its morphology. This is accomplished by examining the game as it 
is being played which differs significantly from other studies of learning in games in that this analysis 
focuses on the game and not the player. While there are numerous sophisticated utilities and meta-languages 
for the description of ontological computer data models, most are designed to support code development 
from an object-oriented perspective, whereas instructional ethology examines the learning elements of 
the application which do not necessarily bear any relationship to the structure of the underlying code. 
 Ethology Ethology is the study of animal behaviour from four perspectives: anatomy, physiology, neurobiology 
and phylogenic history. Each has an analogy that can be applied to a digital game: anatomy corresponds 
to the game s structure (which is addressed through ontological excavation adaptations); physiology corresponds 
to its function; neurobiology maps onto the interaction; and the phylogenic history which normally addresses 
the evolutionary relatedness of an animal to others and corresponds to the game s similarity to other 
games, which in turn speaks to notions of genre. In 1963, biologist Nikolaas Tinbergen published a seminal 
paper [34] outlining four fundamental questions of animal behaviour which have become the cornerstones 
of animal behaviour research: causation, function (survival value), development (ontogeny) and evolution. 
 These four fundamental questions form the basis for the study of instructional ethology. The first 
addresses causation: what are the stimuli that elicit the response, and how has it been modified by recent 
learning? For a game the question is one of interaction: what are the prompts that elicit player response, 
and how is it modified by recent changes due to player achievements? The second deals with function: 
how does the behaviour impact on the animal's chances of survival and reproduction? In game terms this 
element is the heart of how games teach and corresponds to learning support: how does the behaviour of 
the game help it to succeed in the goal of helping players get through to the end? It is the only one 
of the four not likely to be described in a gamed design document. The third question asks about development: 
how does the behaviour change with age, and what early experiences are necessary for the behaviour to 
be shown? A game s behaviour develops as well but we usually call it game flow, so the question can be 
adapted to ask how does the game s behaviour change as players advance (as from level to level), and 
what criteria are necessary for that behaviour to be modified? Finally, the fourth question which speaks 
to evolutionary history asks, how does the behaviour compare with similar behaviour in related species, 
and how might it have arisen through the process of phylogeny? Obviously, games are not bound by any 
kind of genetic relationships, or by true evolution, but they are still categorized by genre, which of 
course has its roots in taxonomy. While novel approaches to known genres are possible as well as combinations 
of several genres embodied in a single game, the metaphor is still useful as most games can be classified 
by their primary form, such as a shooter, or a puzzle game. Thus the final question for instructional 
ethology is one of classification: how does the game s behaviour compare with other games in the same 
genre and how is it related to other genres?  These guiding questions form the basis of the behavioural 
analysis which is the framework through which the interactive parts of the game are analyzed, and the 
structural analysis roughly follows the process described for ontological excavation.  5. Analysis As 
an example of this methodology in action let s use Katamari Damacy [1], a well-known, critically acclaimed 
game with a relatively simple goal, which is to roll up objects into a large ball , called a katamari. 
The main premise for this game is that the King of All Cosmos has accidentally destroyed the stars in 
the sky so he charges his son, the Prince with replacing them. This is to be accomplished by going to 
Earth with a sticky ball called a katamari and rolling it over various objects. As the Earth is deemed 
to have a great many items, the Prince is to roll up as many as he can in a given time period and the 
King will launch the resultant ball into the sky to create a new star. There are also constellations 
to be made which include a additional challenge of rolling up specific kinds or objects, such as bears 
to create Ursa Major. Morphology The structure of the game includes the two main characters: the King 
of All Cosmos, and his son, the Prince. The player is the Prince. The game space is divided in to two 
main parts: the Cosmos which contains the game options as well as access to the various play levels, 
and the levels which all exist on Earth. The entities in this game that provide instructional support 
include the game space, which has significant conceptual coherence. All game options and play levels 
are accessible from the Prince s home planet2, and each location on this planet serves a distinct function. 
Conceptual coherence of the visible elements is important to the usability of any software application, 
and games are no exception. Instructionally, conceptual coherence plays an important role in situated 
learning and provides the context for what is to be learned. Thus the aspects of this game s structural 
design that support learning are instructionally sound. 2 There is also a Space Mushroom which contains 
elements necessary for the multi-player mode. Assessment is essential for learning as it provides the 
feedback necessary to allow learners to track their progress and in the structural analysis portion of 
the model this aspect is addressed through the game s displays. In Katamari Damacy, display or feedback 
elements are similarly well integrated into the game space, for example scores for completed levels are 
represented as stars in the Cosmos, but the player may repeat a level at any time. Each accessible level 
is represented as an object on the Prince s home planet, and when a level is repeated, players are given 
the option of replacing the existing star or using the katamari to create stardust. During a course (rolling 
a katamari) the display shows the time remaining as well as a pictorial clock dial, the current diameter 
of the katamari as well as the target size (again, both numerically and pictorially), and each time an 
object is rolled, it is identified and its size is displayed. There are also warnings about potential 
hazards. Here again the game provides both guidance and feedback that is consistent and concise. The 
play levels themselves are all on Earth, and each is a surrealistic but recognizable representation of 
some physical space, such as a house or town. The level of detail visible is directly connected to the 
size of the katamari. The overall structure is relatively minimalist in the sense that virtually all 
items are directly relevant to the game there are few distractions and all items appear to be useable 
in the game.  Ethology This game begins with the back-story, as do many games, which sets the premise 
for the gameplay that follows. It also provides the support for segues between levels. The basic controls 
for each level involve only the left and right analog sticks, which are used to roll the katamari. At 
the start of the game players are led through a tutorial mode, where each distinct move sequence must 
be demonstrated before the player is allowed to progress. Although the game cannot ensure that players 
remember the moves, it can make sure that players have practiced each one. Constantly updated feedback 
in the game is a behaviour that helps the player track the effectiveness of various strategies and thus 
helping the player succeed. The game s behaviour changes both as the player progresses through the levels 
and as the player progresses through each level. The point of view changes from very small to very large, 
which is connected to the size of the katamari. Small items are no longer visible when the katamari is 
large, and objects that acted as obstacles initially become candidates for rolling. As is typical in 
level progression, the requirements increase as the levels do and both the target size of the katamari 
increases as well as a decrease in the relative amount of time allotted to complete the task.  While 
the cultural perspective of the game s design clearly affects the personality of the King, functionally 
it does not impact on the game s behaviour. The King offers little verbal encouragement, even when levels 
are completed well within the limits and provides ample criticism when levels are missed. However, levels 
can be attempted as often as desired with no consequences for failure failure to complete a level does 
not adversely affect other parts of the game. The comments by the king offer little in the way of positive 
reinforcement, but as they do not affect the function of the game, they can be ignored. Thus, from an 
instructional ethology perspective, the king s comments are irrelevant. Classification of this game is 
more of a challenge than most, and the identified genre of this game is often listed as novelty, or miscellaneous. 
In terms of behaviour, it could be classified as a puzzle game, and as such compares to other classics 
like Tetris [11]. When examined in this light, it can be seen that both structurally and behaviourally, 
puzzle games like Katamari Damacy, Tetris, Brain Age and others have much in common.  6. Conclusion 
Katamari Damacy is an example of a highly successful game that facilitates learning what players need 
to succeed in the game through many dimensions. Even though any claims to educational content in this 
game would be a stretch, the overall structure and behaviour could be used as models for games that are 
educational for example, items could include physical characteristics besides size that would affect 
how they were rolled. Lessons learned from this analysis that are more broadly applicable would include 
the importance of conceptual coherence, direct relationships between player action and game behaviour, 
and constant, straightforward, and relevant user feedback. The field of serious games is still a very 
young one and will require new theories and approaches as well as considered adaptations of proven methodologies 
for design, development, and assessment. Instructional Ethology is one such adaptation that can lead 
to new insights about how games and game technology support learning. Integration of the game s behaviour 
with its morphology is essential for effective instructional support.  7. References 1. Katamari Damacy 
[Game], Namco, 2004, PS2. 2. Becker, K., Games and Learning Styles. in Special Session on Computer Games 
for Learning and Teaching, at the The IASTED International Conference on Education and Technology ~ICET 
2005~, (Calgary, Alberta, Canada, 2005). 3. Becker, K. How are Learning Objectives Woven into the Design 
of a Serious Game? Instructional Design for Serious Games, University of Calgary, 2005 retrieved from: 
http://pages.cpsc.ucalgary.ca/~becker/ Main/PhD/Thesis-Proposal-NTI.pdf 4. Becker, K. Pedagogy in Commercial 
Video Games. in Gibson, D., Aldrich, C. and Prensky, M. eds. Games and Simulations in Online Learning: 
Research and Development Frameworks, Idea Group Inc, 2006. 5. Becker, K. Video Game Pedagogy: Good Games 
= Good Pedagogy. in Miller, C.T. ed. Games: Their Purpose and Potential in Education (in press) Springer 
Publishing, 2008. 6. Chikofsky, E., J. and Cross, J.H., II; Reverse engineering and design recovery: 
a taxonomy. Software, IEEE, 7 (1). 13 - 17. 7. Crosbie, W., Instructional Design does not equal Game 
Design - Lessons learned in delivering a course in game design and education. in World Conference on 
Educational Multimedia, Hypermedia and Telecommunications 2005, (Chesapeake, VA, 2005), AACE, 2617-2621. 
 8. Dobson, J. Survey: 'Word Of Mouth' Most Important For Game Buyers Gamasutra, 2006 retrieved from: 
http://www.mi6conference.com/Magid_ MI6.pdf on Nov. 14 2006. 9. Elliott, J., Adams, L. and Bruckman, 
A., No Magic Bullet: 3D Video Games in Education. in ICLS 2002, (Seattle, WA, 2002). 10. Ellis, H., Heppell, 
S., Kirriemuir, J., Krotoski, A. and McFarlane, A. Unlimited Learning: The role of computer and video 
games in the learning landscape, 2006 retrieved from: http://www.elspa.com/assets/files/u/u nlimitedlearningtheroleofcomputerandvi 
deogamesint_344.pdf on Dec. 10, 2006. 11. Elorg (designer). Tetris [Game], Mirrorsoft Ltd., 1987.  12. 
ESA. Essential Facts About the Computer and Video Game Industry: 2006 Sales, Demographics, and Usage, 
The Entertainment Software Association, 2006, latest data on Video game industry retrieved from: http://www.theesa.com/archives/files/ 
Essential%20Facts%202006.pdf on Jun 25 2006, 2005 13. Fernández-Armesto, F. Teaching vs. Instruction: 
Strictly speaking, education &#38; instruction are mutually exclusive. You instruct soldiers. You teach 
students. CAUT Bulletin, 2006 14. Freitas, S.d. Learning in Immersive Worlds: a review of game based 
learning, Joint Information Systems Committee (JISC), London, 2007, 73 retrieved from: http://www.jisc.ac.uk/media/document 
s/programmes/elearning_innovation/ga ming%20report_v3.3.pdf 15. Gagné, R.M. The conditions of learning 
and theory of instruction. Holt, Rinehart and Winston, New York, 1985. 16. Gee, J.P. Learning by Design: 
Good Video Games as Learning Machines. E-Learning, 2 (1). 17. Gouglas, S., Sinclair, S., Ellefson, O. 
and Sharplin, S. Neverwinter Nights in Alberta: Conceptions of Narrativity through Fantasy Role-Playing 
Games in a Graduate Classroom. Innovate, Journal of Online Education, 2 (3). 18. Gunter, G., Kenny, 
R. and Vick, E., A Case for Formal Design Paradigm for Serious Games. in CODE - Human Systems; Digital 
Bodies, (Miami University, Oxford, Ohio, 2006), The International Digital Media and Arts Association 
and the Miami University Center for Interactive Media Studies 19. Hsi, I. Analyzing the conceptual coherence 
of computing applications through ontological excavation College of Computing, Georgia Institute of Technology, 
2004, 162 20. Hsi, I., Potts, C. and Moore, M., Ontological Excavation: Unearthing the core concepts 
of the application. in Tenth Working Conference on Reverse Engineering 2003 (WCRE'03), (2003), 345-352. 
 21. Kafai, Y.B. Playing and Making Games for Learning: Instructionist and Constructionist Perspectives 
for Game Studies. Games and Culture, 1 (1). 36-40. 22. Kirriemuir, J. and McFarlane, A. Literature Review 
in Games and Learning, 2004 retrieved  from: http://www.nestafuturelab.org/researc h/reviews/08_01.htm 
on June 11, 2004. 23. Koster, R. Theory of Fun for Game Design. Paraglyph Press, Scottsdale, AZ, 2004. 
 24. Meier, S. (designer). Civilization III [Game], Infogrames, 2001, Windows. 25. Molyneux, P. (designer). 
Black &#38; White [Game], Electronic Arts, 2001, PC. 26. Peters, R.S. Criteria of Education. in Ethics 
and Education, Allen and Unwin, 1966. 27. Prensky, M. Don't Bother Me Mom I'm Learning! Continuum St. 
Paul, MN, 2006.  28. Rieber, L. Multimedia Learning in Games, Simulations, and Microworlds. in Mayer, 
R.E. ed. The Cambridge Handbook of Multimedia Learning, Cambridge University Press, 2005, 549-567. 29. 
Rieber, L.P., Davis, J., Matzko, M. and Grant, M., Children as multimedia critics: Middle school students' 
motivation for and critical analysis of educational multimedia designed by other children. in What We 
Know and How We Know It, (Seattle, WA, 2001), American Educational Research Association. 30. Squire, 
K. Changing the Game: What Happens When Video Games Enter the Classroom? Innovate, Journal of Online 
Education, 1 (6). 31. Squire, K. From Content to Context: Videogames as Designed Experience. Educational 
Researcher 35 (8). 19-29. 32. Squire, K. Resuscitating Research in Educational Technology: Using Game-Based 
Learning Research as a Lens for Looking at Design-Based Research. Educational Technology, 45 (1). 8-14. 
 33. Takatalo, J., Hakkinen, J., Kaistinen, J., Komulainen, J., Sarkela, H., Kaistinen, J. and Nyman, 
G., Adaptation into a Game: Involvement and Presence in Four Different PC- Games. in Future Play, The 
International Conference on the Future of Game Design and Technology, (The University of Western Ontario, 
London, Ontario, Canada, 2006). 34. Tinbergen, N. On the aims and methods of ethology. Zeitschrift fur 
Tierpsychologie, 20. 410­ 463. 35. Winn, B. and Heeter, C. Resolving Conflicts in Educational Game Design 
Through Playtesting. Innovate, Journal of Online Education, 3 (2).  
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2007</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>1328225</article_id>
		<sort_key>230</sort_key>
		<display_label>Pages</display_label>
		<pages>8</pages>
		<article_publication_date>11-14-2007</article_publication_date>
		<seq_no>3</seq_no>
		<title><![CDATA[A framework for socially communicative faces for game and interactive learning applications]]></title>
		<page_from>129</page_from>
		<page_to>136</page_to>
		<doi_number>10.1145/1328202.1328225</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1328225</url>
		<abstract>
			<par><![CDATA[<p>In this paper, we describe a modular multi-dimensional parameter space for real-time face game-based animation. Faces are our most expressive communication tools. Therefore a synthetic facial creation and animation system should have its own tailored authoring environment rather than using general purpose tools from image, 2D and 3D animation. This environment would take advantage of a knowledge space of faces types, expressions, and behavior, encoding known facial knowledge and meaning into a comprehensive, intuitive facial language and set of user tools. Since faces and face expression work on so many cognitive levels, we propose a multi-dimension parameter space called FaceSpace as the basic face model, and a comprehensive authoring environment based on this model. We describe the underlying mechanisms of our environment, and also demonstrate its early game applications and content process.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[communication systems]]></kw>
			<kw><![CDATA[facial animation]]></kw>
			<kw><![CDATA[gaming]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.6.7</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010226.10010239</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Image and video acquisition->3D imaging</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010341.10010366</concept_id>
				<concept_desc>CCS->Computing methodologies->Modeling and simulation->Simulation support systems</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Experimentation</gt>
			<gt>Human Factors</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP14280521</person_id>
				<author_profile_id><![CDATA[81328488119]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Steve]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[DiPaola]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Simon Fraser University, Vancouver, BC, Canada]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P794413</person_id>
				<author_profile_id><![CDATA[81315487846]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Ali]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Arya]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Carleton University, Ottawa, Ontario, Canada]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Arya A, DiPaola S, 2004 Face as a Multimedia Object, 5th International Workshop on Image Analysis for Multimedia Interactive Services, Portugal.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Arya, A., and Hamidzadeh, B. 2003. ShowFace: A Framework for Personalized Face Animation. In Proceedings of RichMedia-2003, Lausanne, Switzerland, IEEE Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>614937</ref_obj_id>
				<ref_obj_pid>614664</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Battista, S., et al. 1999. MPEG-4: A Multimedia Standard for the Third Millennium, Multimedia, vol. 6, no. 4, IEEE Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Borkenau, P., and Liebler, A., 1992. Trait Inferences: Sources of Validity at Zero Acquaitance. In Journal of Personality and Social Psychology. Vol 62. no 4, pp 645--657.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>545272</ref_obj_id>
				<ref_obj_pid>545261</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Byun, M., and Badler, N. I., 2002. FacEMOTE: Qualitative Parametric Modifiers for Facial Animations. In Proceedings of ACM SIGGRAPH/ Eurographics symposium on Computer Animation, ACM Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>192272</ref_obj_id>
				<ref_obj_pid>192161</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Cassell, J., et al. 1994. Animated Conversation: Rule-based Generation of Facial Expression, Gesture and Spoken Intonation for Multiple Conversational Agents. In Proceedings of ACM SIGGRAPH, ACM Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>383315</ref_obj_id>
				<ref_obj_pid>383259</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Cassell, J., et al. 2001. BEAT: The Behavior Expression Animation Toolkit. In Proceedings of ACM SIGGRAPH, ACM Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>791604</ref_obj_id>
				<ref_obj_pid>791218</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Decarlo, D., et al. 2002. Making Discourse Visible: Coding and Animating Conversational Facial Displays. In Proceedings of Computer Animation Conference, IEEE Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[DiPaola, S. 1991. Extending the Range of Facial Types. Visualization and Computer Animation, 2, 4, 129--131.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[DiPaola, S. 2002. FaceSpace: A Facial Spatial-Domain Toolkit. In Proceedings of InfoViz 2002, 49--55.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[DiPaola S, Arya A, Chan J. 2005. Simulating Face to Face Collaboration for Interactive Learning Systems, Proceeding from E-Learn.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Ekman, P., and FrieSEN, W. V. 1978. Facial Action Coding System, Consulting Psychologists Press Inc.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>791529</ref_obj_id>
				<ref_obj_pid>521641</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Ezzat, T. and Poggio, T. 1999. MikeTalk: A Talking Facial Display Based on Morphing Visemes. In Proceedings of Computer Animation Conference, IEEE Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>311538</ref_obj_id>
				<ref_obj_pid>311535</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Funge, J. et al. 1999. Cognitive Modeling. In Proceedings of ACM SIGGRAPH, ACM Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Gross, J., et al. 2000. The Dissociation of Emotion Expression from Emotion Experience: A Personality Perspective. In Personality and Social Psychology Bulletin, vol 26. no 6. pp 712--726.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>545271</ref_obj_id>
				<ref_obj_pid>545261</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Kahler, K. et al. 2002. Head Shop: Generating Animated Head Models with Anatomical Structure. In Proceedings of ACM SIGGRAPH/ Eurographics symposium on Computer animation, ACM Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Knutson, B. 1996. Facial Expressions of Emotion Influence Interpersonal Trait Inferences, Journal of Nonverbal Behavior, 20, 165--182.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>218407</ref_obj_id>
				<ref_obj_pid>218380</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Lee, Y., Terzopoulos, D., Waters, K., 1995. Realistic Modeling for Facial Animation. In Proceedings of ACM SIGGRAPH, ACM Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>569955</ref_obj_id>
				<ref_obj_pid>800193</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Parke, F. I. 1972. Computer Generated Animation of Faces. In Proceedings of ACM Annual Conference, ACM Press, 451--457.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>249651</ref_obj_id>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Parke, F. I., and Waters, K. 2000. Computer Facial Animation. A. K. Peters.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Pasquariello, D., and Pelachaud, A., 2001. Greta: A Simple Facial Animation Engine. In 6th Online World Conference on Soft Computing in Industrial Applications.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Pelachaud, W. and Bilvi, M. 2003. Computational Model of Believable Conversational Agents. In Communication in MAS: Background, Current Trends and Future.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[Rousseau, D., and Hayes-roth, B. 1997. Interacting with Personality-Rich Characters. Knowledge Systems Laboratory Report No. KSL 97--06, Stanford University.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[Russell, J. A., 1980. A Circumplex Model of Affect. In Journal of Personality and Social Psychology, 39, 1161--1178.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[Smid, K. et al. 2004. Autonomous Speaker Agent. In Proceedings of Computer Animation and Social Agents, Geneva, Switzerland.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>618849</ref_obj_id>
				<ref_obj_pid>616072</ref_obj_pid>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[Tiddeman, B. et al. 2001. Prototyping and Transforming Facial Textures for Perception Research. Computer Graphics and Applications, IEEE Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[Turk, M. J., and Pentland, A. P. 1991. Face Recognition Using Eigenfaces. In Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR-91), IEEE Press, 586--591.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[Valentine, T. 1999. Face-Space Models of Face Recognition. In Computational, geometric, and process perspectives on facial cognition: Contexts and challenges. Wenger, M. J. &amp; Townsend, J. T. (Eds.), Lawrence Erlbaum Associates Inc.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>37405</ref_obj_id>
				<ref_obj_pid>37402</ref_obj_pid>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[Waters, K. 1987. A Muscle Model for Animating 3D Facial Expression. ACM Computer Graphics, ACM Press, 21, 4.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>30</ref_seq_no>
				<ref_text><![CDATA[Wiggins, J. S. et al. 1988. Psychometric and Geometric Characteristics of the Revised Interpersonal Adjective Scale, Multivariate Behavioural Research, 23, 517--530.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 A Framework for Socially Communicative Faces for Game and Interactive Learning Applications Steve DiPaola 
Ali Arya Simon Fraser University Carleton University Vancouver, BC, Canada Ottawa, Ontario, Canada 778-782-6579 
613-875-2792 sdipaola@sfu.ca arya@carleton.ca  Figure 1. Sample animated heads showing expressions, 
talking, and moving, all created from one synergistic system. ABSTRACT In this paper, we describe a 
modular multi-dimensional parameter space for real-time face game-based animation.. Faces are our most 
expressive communication tools. Therefore a synthetic facial creation and animation system should have 
its own tailored authoring environment rather than using general purpose tools from image, 2D and 3D 
animation. This environment would take advantage of a knowledge space of faces types, expressions, and 
behavior, encoding known facial knowledge and meaning into a comprehensive, intuitive facial language 
and set of user tools. Since faces and face expression work on so many cognitive levels, we propose a 
multi-dimension parameter space called FaceSpace as the basic face model, and a comprehensive authoring 
environment based on this model. We describe the underlying mechanisms of our environment, and also demonstrate 
its early game applications and content process. Categories and Subject Descriptors I.6.7 [Simulation 
and Modeling]: Simulation Support Systems. I.3.7 [Computer Graphics]: Three-Dimensional Graphics and 
Realism.  General Terms Algorithms, Design, Experimentation, Human Factors.  Keywords Facial Animation, 
Gaming, Communication Systems. 1. INTRODUCTION The last decade of twentieth century experienced the 
merging of Permissionto make digital/hardcopy of partofthiswork for personalor classroomuse is grantedwithoutfee 
providedthat the copiesarenot made or distributedforprofit or commercialadvantage, the copyright notice, 
the title of the publication,and itsdate of appear, andnotice is giventhat copying is bypermissionoftheACM,Inc.To 
copy otherwise, torepublish,to poston servers, or to redistribute tolists, requires prior specificpermissionand/or 
a fee. FuturePlay 2007, November 15-17, 2007, Toronto, Canada. Copyright 2007 ACM 978-1-59593-943-2/07/0011...$5.00 
some traditionally separate forms of audio-visual art and entertainment. The boundaries between live 
action feature films, animation, and games started to disappear, and the key to the newly forming comprehensive 
medium was interactivity . Advances in computer hardware and software have introduced the Interactive 
Multimedia Presentation as a common base for a variety of audio-visual applications, and computer-generated 
facial animation is a rapidly growing part of such presentations. For instance, although current computer 
games make limited use of facial expressions, next generation game platforms provide hardware capabilities 
for computations involved in having more degrees of freedom in characters. One of the main objectives 
of game designers is to utilize these new platforms to introduce more realistic characters who can change 
expressions more frequently, demonstrate personality traits more clearly, and behave more interactively. 
A virtual customer service representative can be considered another application of such characters. Some 
of the issues facing content and application developers in this regard are: Behaviour. Designing different 
facial actions, expressions, and personality traits usually involve a painstaking and time­consuming 
process where artists create the related animation using conventional 3D software and by defining key 
frames for the movement of each facial feature. This is one of the major difficulties of increasing the 
number of moveable features (and so the realism). Re-usability. Designs for one head model are not generally 
usable on another model. As a result, even a similar action on a new head requires the design process 
to be repeated. Interaction. The need for a detailed design process limits the amount of interactivity 
and dynamic behaviour a character can have at run-time. In other terms, the characters can not be completely 
autonomous. Programmability. There is a serious lack of programmable components that can be re-used in 
new applications to provide facial animation capabilities. Each application has to be developed by implementing 
such functionality from scratch.  Level of Details. The animators, especially when using conventional 
graphics software, have to deal with all the details of a head model to perform actions. An intelligent 
software that is aware of head regions and their function can hide the details unless necessary, by performing 
group actions on all the points that are functionally related. For example, averting the gaze direction 
is a simple action that should involve only a single input as new direction. The rest, i.e. rotating 
eyeball points, should be taken care of by the software. Such a feature is missing in most design and 
runtime environments due to the fact that they are not customized for face animation. In this paper, 
we introduce Interactive Face Animation Comprehensive Environment (iFACE) that provides solutions to 
all of the above problems in a unified face animation framework. iFACE parameter spaces allow animator 
and/or programmer to effectively control facial geometry, perform MPEG-4 compatible facial actions, show 
expressions, and display behaviours based on definable personality types. All of these are encapsulated 
within a Face Multimedia Object (FMO) that can be used in any applications through programming interfaces. 
The framework includes stand-alone graphical design environments and plug-in components for 3D software 
programs such as Maya. iFACE hierarchical geometry arranges parameters in different layers of abstraction 
to allow exposure to proper level of details. The physical points can be pixel or vertex to support 2D 
and 3D models, both with the same control interface. On top of them are the feature points which correspond 
to MPEG-4 Face Animation and Definition Parameters. Using only these parameters almost any facial action 
is possible. Features and component layers are at higher levels and allow grouping of functionally related 
parameters. The parameters and their respective API are independent of the head model, so a set of parameters 
can be applied to any head model, resulting in the same facial actions. Dynamic behaviours in iFACE are 
possible through Knowledge, Mood, and Personality parameter spaces. They allow defining interaction rule 
and scripts written in Face Modeling Language (FML), expressions, and personality types. iFACE personality 
types are based on the state-of-the-art in behavioural psychology. They are defined as a combination 
of Affiliation and Dominance factors and control the way facial actions are performed (e.g. frequency 
of blinking, typical head movements, etc). Using these parameters, an autonomous character can be created 
which interacts properly in a dynamic environment. The parameterized approach with its behavioural extensions 
allow the animators and runtime programmers to use face as a self­supporting object without the need 
for dealing with details, and apply the same parametric design to any head model. iFACE API on the other 
hand, provides a powerful flexible component-based structure to be used in any application that requires 
face animation. The API itself uses a layered architecture to access different functionality. Some related 
works in face animation are briefly reviewed in Section 2. The main concepts of FMO and iFACE framework 
are discussed in Section 3. iFACE architecture and object model are presented in Section 4, and some 
experimental results related to SAGE project are presented in Section 5. Some concluding remarks and 
discussions are the subject of Section 6.  2. RELATED WORK The common practice for face animation is 
to use general-purpose 3D modeling and animation tools such as Alias Maya, Discreet 3DS Max or SoftImage 
XSI. While providing very powerful design environments, these tools lack dedicated face-centric features 
that allow efficient and realistic modeling and animation of facial states and actions [12]. The run-time 
environments, consequently, animate the limited degrees of freedom provided by the authoring tools, and 
do not support any face-specific run-time support (such as dynamic creation of typical behaviours) that 
can simplify application development. Although this situation might be marginally sufficient for current 
level of face animation in games, and match the computational power of existing game consoles, it is 
far less than ideal, especially for next generation games running on much more powerful platforms. One 
of the earliest works on computerized head models for graphics and animation was done by Parke [19]. 
It can be considered as the first parameterized head model which was extended by other researchers [20, 
9] to include more facial features and add more flexibility. Different methods for initializing such 
generic model based on individual (3D or 2D) data have been proposed and successfully implemented 20]. 
Parameters are usually grouped into conformation and expression categories, the former for building a 
particular head and the latter for animating it. The parameterized models are effective ways due to use 
of limited parameters, associated to main facial feature points. Such parameters can be used to calibrate 
a standard model and animate it. Facial Action Coding System (FACS) [12] was an early and still valid 
study of possible facial actions related to such feature points. Although not originally a computer graphics 
technique, FACS has been widely used by researchers in parameterized models and others. This approach 
has been formalized in MPEG-4 standard by introduction of Face Definition Parameters (FAPs) and Face 
Animation Parameters (FAPs) [3]. The former group of parameters defines the important features and the 
latter actions applied to a subset of them (not every FDP can be animated). The primary issue with such 
parameter space is its flatness . All parameters are worked with in a similar way while not every application 
actually needs all of them. A hierarchical grouping of parameters is necessary for efficient management 
of parameter space. Also, the relatively huge amount of parameters (result of extensions to the original 
models) makes application development and authoring hard. A common solution to this issue has been defining 
higher-level parameters and behaviors [5, 6, 8]. For example, smile is an action that involves a few 
features and can be defined at a higher level of abstraction, knowing the combined effect of movements 
in feature points. MPEG-4 FAPs define two groups of such high level parameters for standard facial expressions 
and visemes (visual representation of uttered phonemes). Although such macro parameters make it easier 
to use the underlying model, the simple two-tier model is still not very effective for managing facial 
activities and providing local control over level-of-details. The MPEG-4 standard allows definition of 
parameter groups but it is only a standard to be used by particular models, which are still mainly flat 
. Pasquariello, and Pelachaud [21] (among others) have proposed hierarchical head models that allow a 
more efficient parameter control through grouping and regions. Our approach, as explained later, uses 
this idea and extends it to multiple layers of abstraction on top of actual data points (2D pixels or 
3D vertices) to ensure maximum flexibility and minimum effort when group actions are required. Our head 
model pyramid has a head object on top, and components, features, feature points, and physical points 
are at lower levels.  Physically-based head models form another approach in modeling head and face [29, 
18, 16]. Here the physical and anatomical characteristics of bones, tissues, and skin are simulated to 
provide a realistic appearance (e.g. spring-like elasticity). Such methods can be very powerful for creating 
realism but the complexity of facial structures make them (1) computationally expensive, and (2) almost 
always not enough adequate. Considering the effectiveness of parameterized models for communicative purposes 
(as explained in the next section), it maybe argued that physically-based models are not a very efficient 
choice in many applications. This does not deny the advantages of physically­based models and the fact 
that they can even be used within the context of parameterized models to provide local details when needed. 
Image-based methods have also been used for head and face modeling. In animation, image-based methods 
are mainly based on morphing between given images and applying pre-learned transformations in order to 
create new ones [2, 13, 26]. No need for complicated 3D computation and data, and also image-based photo-realism, 
are major advantages of such methods, but their capability in creating a wide range of facial actions 
is limited due to unavailability of 3D information. A general head model that can utilize both 2D and 
3D data with the same user and programming interface will be very promising, in this regard. The concept 
of facespace as a universal space of all faces that can be created by given parameters (features or image 
templates) has also been studied by researchers such as Valentine [28] and DiPaola [10]. Focusing more 
on face recognition, Valentine considers this space to have dimensions formed by distinctive geometric 
features or Principal Component Analysis (PCA) vectors (i.e. Eigenfaces) [27]. In either case, the space 
is not time­based. DiPaola introduces the behaviors, and effectively extends the facespace to include 
temporal changes. But the nature of these time-based dimensions and their relation to the geometry has 
not been clearly defined. Finally, the behavioral modeling of animated characters has been studied by 
some researchers. Funge et al. [14], for instance, define a hierarchy of parameters. At the base of their 
parameter pyramid is the geometric group. On top of that come kinematic, physical, behavioral, and cognitive 
parameters and models. Although very important for introduction of behavioral and cognitive modeling 
concepts, the model may not be very suitable for face animation purposes due to the interaction of parameter 
groups and the need for emotional parameters as opposed to physically-based ones. Cassell et al. [6,7] 
defined behavioral rules to be used in creating character actions but do not propose a general head model 
integrating geometrical and behavioral aspects. Byun and Badler [5] propose the FacEMOTE system that 
allows four high-level behavioural parameters (Flow, Time, Weight, and Space) to control the expressiveness 
of an input FAP stream. Although it demonstrates how high-level behavioural parameters can control facial 
animation, it does not intend to be a comprehensive face object. On the other hand, three spaces of Knowledge, 
Mood, and Personality (each with their own parameters as explained later) can control the facial behaviour 
in a more explicit way. RUTH system by DeCarlo et al. [8] uses behavioural rules to animate a face when 
a given text is spoken. Smid et al. [25] use a similar approach but associate a considerably larger set 
of facial actions (head, eye, brow movements) to features of a given speech through behavioural rules 
in order to create an autonomous speaker agent. Although these rules can be base for defining personality 
types, the possibility has not been explored by these researchers. Pelachaud and Bilvi [22] propose performative 
dimensions (dominance and orientation) and emotion dimensions (valence and time) as behavioural parameters 
to control facial actions. Published at the same time as original iFACE [10], the systems share common 
concepts but iFACE provides a more comprehensive framework for defining personality types and custom 
expressions, and it is based on studies in behavioural psychology to associate facial actions to these 
personality types and expressions. Also, iFACE allows interactive non-verbal scenarios through an XML-based 
scripting language, MPEG-4 compatibility at lower levels, multimedia streaming, authoring tools, programming 
interfaces, and wrapper applets for form­based applications. Personality space also allows a more general 
mechanism for defining facial personalities.  3. IFACE SYSTEM 3.1 Face Multimedia Object The ability 
to create a multimedia presentation as a combination of parts from different sources (e.g. separate foreground 
object and background scene) has resulted in new multimedia standards such as MPEG-4 [3] that treat the 
presentation not as one piece of data but a collection of objects of different types. The simplest of 
these types can be audio and video. The need for more efficient multimedia authoring and management suggest 
that such object­based approach be extended to more aggregation in multimedia content, i.e. grouping 
of related content elements into higher-level types . For a variety of cases where human figures play 
a key role ( face-centric applications) face is a primary candidate for such a data type. The introduction 
of Face Definition and Animation Parameters (FDPs and FAPs) in MPEG-4 standard was a step toward such 
higher-level of abstraction on top of face­related multimedia content. The authors have proposed Face 
Multimedia Object (FMO) [1] as a more systematic approach to encapsulate face functionality into one 
autonomous but controllable object.  Figure 3. Using Face Multimedia Object To be successful, FMO needs 
to provide means of creating and displaying the desired appearance and behaviours, and also expose proper 
control mechanisms through user interaction or program access. The face appearance depends primarily 
on its geometry. In general this geometry can be 2D or 3D, realistic or stylistic. It includes high-level 
functionality such as resizing a region and low-level ones such as manipulating a point (2D pixel or 
3D vertex). High-level functionality should be independent of the type of geometry we are using (i.e. 
the same programming/control interface for all the faces in Figure 1). This suggests a hierarchical model 
that exposes as much detail as necessary through different layers of abstraction. Facial behaviour on 
the other hand, depends on individual-independent rules of interaction and scenarios and also individual 
characteristics such as short-term moods and long­term personality traits. All of these have to be developed 
in a way to be suitable for interactive and real-time performance. As shown in Figure 3, FMO operates 
as a face engine for design-time and run-time applications. Using FMO, animators and authors can design 
proper geometry and facial actions and pass them to run-time modules only as commands, instead of keyframes 
with information on all moving parameters. At run­time, the application/game only detects the required 
action and asks the engine to replicate the same result. This has the advantages such as: 1- Less information 
saved by design tool and passed to run-time 2- Ease of run-time development due to black-box use of FMO 
3- Possibility of dynamic applications and user-controlled event­driven scenarios without the need of 
a pre-design 3.2 Parameter Spaces For a large group of applications, facial presentations can be considered 
a means of communication. A communicative face relies and focuses on those aspects of facial actions 
and features that help to effectively communicate a message. This may not require very detailed data, 
but efficient use of parameters and their structural patterns. This means that the head/face model has 
to provide local control of level-of-details and high-level to low­level functionality. Rousseau and 
Hayes-Roth [23] consider Personality Traits, Moods, and Attitudes as major parameters in their social­psychological 
avatar model. In a similar but revised way, we believe that the communicative behavior of a face can 
be considered to be determined by the following parameter spaces Geometry: This forms the underlying 
physical appearance of the face. Creating and animating different faces and face-types are done by manipulating 
the geometry that can be defined using 2D and/or 3D data (i.e. pixels and vertices). This geometry is 
based on a hierarchy of facial regions and sub-regions. Figure 4. iFACE Geometry Hierarchical Head Model 
x Knowledge: Behavioral rules, stimulus-response association, and required actions are encapsulated into 
Knowledge. In the simplest case, this can be the sequence of actions that a face animation character 
has to follow. In more complicated cases, knowledge can be all the behavioral rules that an interactive 
character learns and uses (see Funge et al. work on Cognitive Modeling [14]). Knowledge acts through 
an XML-based language that defines scenarios, events, and decision-making logic. x Personality: Different 
characters can learn and have the same knowledge, but their actions, and the way they are performed, 
can still be different depending on individual interests, priorities, and characteristics. Personality 
encapsulates all the long-term modes of behavior and characteristics of an individual [30], 4]. Facial 
personality is parameterized based on typical head movements, blinking, raising eye-brows and similar 
facial actions. x Mood: Certain individual characteristics are transient results of external events and 
physical situation and needs. These emotions (e.g. happiness and sadness) and sensations (e.g. fatigue) 
may not last for a long time, but will have considerable effect on the behavior. Mood of a person can 
even overcome his/her personality for a short period of time. Emotional state can be modeled as point 
in a 2D space where two axes correspond to energy and value [24].  3.3 Face Geometry Geometry Components 
and Regions allow grouping of head data into parts that perform specific actions together (e.g. resizing 
the ears or closing the eye). Features are special lines/areas that lead facial actions, and Feature 
Points (corresponding to MPEG-4 parameters) are control points located on Features. Only the lowest level 
(Physical Point) depends on the actual (2D or 3D) data. iFACE Geometry object model corresponds to this 
hierarchy and exposes proper interfaces and parameters for client programs to access only the required 
details for each action. Facial Regions are shown in Figure 5. iFACE authoring tool (iFaceStudio) allow 
users to select Feature Points and Regions. Each level of Geometry accesses the lower levels internally, 
hiding the details from users and programmers. Eventually, all the facial actions are performed by applying 
MPEG-4 FAPs to the face. Although geometric parameters can change over time, they have a pure spatial 
nature by themselves, and can build a multi­dimensional spatial facespace in Valentine s terms, i.e. 
all geometrically possible faces. Knowledge, Personality, and Mood, on the other hand, have a time-based 
nature since they define the way different geometric states are used and related. Together, these four 
groups of parameters serve as meta-dimensions of a spatio-temporal facespace. Time does not act as an 
explicit dimension in this facespace but it is implied in it. On the other hand, geometry plays a particularly 
different role, as it is possible to create any face by changing only geometric parameters. The other 
meta-dimensions only make these changes meaningful and purposeful. This is illustrated in Figure 2, where 
Geometry acts as the foundation while others interact with it and with each other. Figure 5. Face Regions. 
These are small areas that usually move together and are controlled by Feature Points. iFACE Components 
are related groups of these Regions, e.g. eye area 3.4 Face Modeling Language The behaviour of an iFACE 
character is determined primarily by Knowledge. It provides the scenario that the character has go through 
as an XML-based script. iFACE uses Face Modeling Language (FML) [2] that is specifically designed for 
face animation. FML document can be a simple set of sequential actions such as speaking and moving the 
head, or a complicated scenario involving parallel actions and event-based decision­making similar to 
the following script: <fml> <model> <event name= kbd /> </model> <story> <action> <!--parallel actions--> 
<par> <hdmv type= yaw value="80" begin= 0 end="2000" /> <play file="Audio1.wav" /> </par> <!--exclusive 
actions --> <!--only one of options will run--> <excl ev_name= kbd > <talk ev_value= F1_down >Hello</talk> 
<talk ev_value= F2_down >Bye</talk> </excl> </action> </story> </fml> iFACE Knowledge module exposes 
interfaces to allow opening new scripts or running single FML commands. It also allows defining and raising 
program-controlled events that are base for dynamic and interactive scenarios. 3.5 Mood Although scripts 
can select a new personality or modify the mood, but Knowledge space is generally independent of the 
character . Mood and Personality spaces deal with character-dependent parameters. Mood controls short-term 
emotional state that can affect the way a certain action is animated. For instance actions in a part 
of script can be performed in a happy mood and in another part in a sad one and be visually different. 
In general, moods are represented with a certain facial expression with which any facial action is as 
in Figure 6. iFACE supports two types of moods each with a zero to one activation level: 1) Standard 
emotions (joy, sadness, surprise, anger, fear, disgust) predefined based on previous studies and 2) Custom 
expressions defined by user. It is also possible to select the current mood of character by adjusting 
Energy and Stress values which will result in activation of standard emotions at some level according 
to Russell s Circumplex mood model [24] where horizontal and vertical dimensions are Stress and Energy, 
respectively. 3.6 Face Personality Interpersonal Adjective Scale [30] is a widely accepted personality 
model that links different personality types to two Affiliation and Dominance parameters in a two dimensional 
Circumplex model (Figure 8). Facial actions and expressions are shown to cause perception of certain 
personality traits [4, 17]. The foundation of iFACE personality is associating major facial actions and 
expressions with personality parameters and types, i.e. visual cues for personality. This is done based 
on published works and our own on-going research (described in Section 4 as an iFACE application). When 
the personality parameters are changed or a certain personality type is activated, the associated facial 
 actions are selected to be performed (i.e. visual cues are Sample associations between visual cues 
and perceived presented) in order to make perception of that personality type personality types are shown 
in Table 1. These are the result of an more probable in the viewer. Following personality-related on-going 
study which is the subject of another paper. actions are defined: Expressions, 3D head movements, Nodding, 
Raising/lowering/squeezing eyebrows, Gaze shift, Blinking. Table 1. Visual Cues and Personality Types 
 Visual Cue Perceived Personality Type Happiness and surprise high in dominance and affiliation Anger 
High dominance / low affiliation Sadness and fear low in dominance Averted gaze avoidance (low affiliation) 
Moving away low affiliation Frequent moving high dominance eyebrow raise -1 sided high dominance Tilted 
head low dominance and/or high affiliation Wide-open eyes high affiliation Frequent blinking low affiliation 
/ low dominance Figure 6: Neutral, Talking, and Frowning facial states (left to right) of four different 
characters. For each one of these, strength, duration, and frequency of occurrence are controllable. 
The visual cues can happen randomly, with a pre-defined order, or based on the voice energy when talking. 
Two threshold values are set for speech energy: Impulse and Emphasis. When the energy reaches any on 
of these thresholds, certain visual cues of current personality type are activated, for instance nodding 
when emphasizing on a part of speech. We use ETCodec lip-sync module by OnLive that calculates a speech 
energy for each audio frame of 60mSec. ETCodec also gives values for mouth shape which are translated 
to MPEG-4 FAPs by iFACE. 3.7 Software Architecture iFACE is developed as a set of .NET components written 
with C#. It is possible to access them directly from .NET Managed Code or through .NET/COM Interop from 
Unmanaged Code1. It uses Microsoft Direct3D and DirectSound for graphics and audio purposes. In cases 
where Unmanaged Code was required (for instance using existing ETCodec lip-sync library) a COM object 
is developed to wrap the code and use it in iFACE. Implementation of iFACE FMO on game consoles as a 
possible run-time environment, and iFACE plug-in components for Maya and 3DS-MAX are on-going projects. 
iFACE is designed to work with a variety of client types. Depending on the level of details exposed by 
the components, iFACE objects are grouped into three layers shown in Figure 9.  4. APPLICATIONS WITH 
IFACE 4.1 Face Personality Study Behavioural psychology researchers usually use photographs and less 
commonly video to perform experiments. They can benefit from an interactive environment that can create 
realistic animations with different features (e.g. mood and personality). This can replace actors which 
are hard or expensive to find with software that does not need external setup and can be easily configured. 
iFACE system is being used in such an application which in turn provides information regarding how viewers 
perceive the personality of a subject based on his/her facial actions. Using iFACE the researcher can 
change the personality traits (or any other aspect) of the subject and observe the reaction and 1 Code 
written for .NET framework (e.g. a C# program) is called Managed Code. Normal Windows and Component Object 
Model (COM) code are considered Unmanaged. .NET allows interoperability with COM objects using a mechanism 
called COM Interop.  perception of the viewers. For more information see iFACE web site: http://ivizlab.sfu.ca/arya/Research/FacePersonality 
Streaming Layer Data Layer (Parameter Spaces) Figure 9. iFACE Layered Architecture  4.2 COMPS Collaborative 
Online Multimedia Problem-based Simulation (COMPS) [11] is a system being developed to provide Problem-Based 
Learning (PBL) tools for medical students. PBL works by introducing students to a case (problem), giving 
them some facts, and taking the students through cycles of discussion and hypothesizing until the disease 
is correctly identified. A major part of a PBL-based approach for medical students is to interact with 
patients, especially listening to them describing their symptoms. Bringing patients to a classroom or 
examination room is hard and in some cases impossible. Using actors for this purpose is a common but 
rather expensive alternative. A Social Conversational Agent (SCA) is an ideal replacement. SCA can also 
be a proper for automated instructor or to represent a remote instructor (or patient) when transmitting 
real-time video is not possible but SCA can be animated based on real audio data. Here, we briefly review 
two examples of simulated patient and remote instructor as typical applications of iFACE in COMPS: x 
Simulated Patient: An FML script file is primary animation control file for iFACE. Using iFaceStudio 
authoring tool, a set of keyframe animations are created to represent typical head movements of the patient. 
These are then associated with a new personality type. The script selects the type and then gives the 
face object a text or audio file to speak . During the speech, the typical behaviours (head movements) 
are selected randomly and performed by the animated head, as explained in Section 3. The presentation 
can be more complicated using event processing and decision-making capabilities of FML. Events can be 
associated with user selections (e.g. from pre-defined set of questions) and the animation can go through 
different branches (see script sample of Section 3 and the usage of keyword excl). x Remote Instructor: 
A simpler mechanism for controlling iFACE animation is to provide only the audio data as input. Data 
can come from a local file or a network stream. A remote instructor can use iFACE recording capability 
to send his/her voice data to another (or group of) remote iFACE objects which in turn use the data to 
drive the animation. Again proper personality and mood can be selected.  4.3 Storytelling Masks iFACE 
is used in a museum environment to create animations of native North American artists explaining their 
work and the myths related to them using a game metaphor, as illustrated in Figure 11 where a real artist 
s voice, passion, stories and expression first introduces himself and his work (A), begins to transform 
into his artwork (B), has his work tells it s back story with full voice and expression (C,D) and can 
return to his persona to interactively answer questions or give other educational content (A)  4.4 
Evolving Faces Human migration, as explained in out of Africa theory, is illustrated in this application 
using talking faces of each region/age, as shown in Figure 12 where emotive talking faces describe the 
DNA science of human migration out of Africa, actively morphing facial types accordingly.  application 
programming interface, scripting language, and authoring tools. iFACE use a hierarchical head model that 
hides the modeling details and allows group functions to be performed more efficiently. Multiple layers 
of abstraction on top of actual head data make the client objects and users independent of data type 
(3D or 2D) and provide the similar behaviour regardless of that type.Behavioural extensions in form of 
Knowledge, Personality, and Mood control scenario-based and individual­based temporal appearance of the 
animated character. On the other hand, streaming and wrapper objects make the use of iFACE components 
easier in a variety of applications. iFACE framework is a powerful face engine for character-based online 
services, games, and any other face-centric system. Future research on iFACE will involve comprehensive 
association of all facial actions and expressions to most likely personality type to be perceived, exploring 
the possibility of higher level parameters in face personality (on top of affiliation and dominance) 
in order to define practical character types such as nervous and heroic), and realistic combination of 
current mood and facial actions by using non-linear functions 6. REFERENCES [1] Arya A, DiPaola S, 2004 
Face as a Multimedia Object, 5th International Workshop on Image Analysis for Multimedia Interactive 
Services, Portugal. [2] Arya, A., and Hamidzadeh, B. 2003. ShowFace: A Framework for Personalized Face 
Animation. In Proceedings of RichMedia-2003, Lausanne, Switzerland, IEEE Press. [3] Battista, S., et 
al. 1999. MPEG-4: A Multimedia Standard for the Third Millennium, Multimedia, vol. 6, no. 4, IEEE Press. 
[4] Borkenau, P., and Liebler, A., 1992. Trait Inferences: Sources of Validity at Zero Acquaitance. In 
Journal of Personality and Social Psychology. Vol 62. no 4, pp 645-657. [5] Byun, M., and Badler, N.I., 
2002. FacEMOTE: Qualitative Parametric Modifiers for Facial Animations. In Proceedings of ACM SIGGRAPH/ 
Eurographics symposium on Computer Animation, ACM Press. [6] Cassell, J., et al. 1994. Animated Conversation: 
Rule-based Generation of Facial Expression, Gesture and Spoken Intonation for Multiple Conversational 
Agents.. In Proceedings of ACM SIGGRAPH, ACM Press. [7] Cassell, J., et al. 2001. BEAT: The Behavior 
Expression Animation Toolkit. In Proceedings of ACM SIGGRAPH, ACM Press. [8] Decarlo, D., et al. 2002. 
Making Discourse Visible: Coding and Animating Conversational Facial Displays. In Proceedings of Computer 
Animation Conference, IEEE Press. [9] DiPaola, S. 1991. Extending the Range of Facial Types. Visualization 
and Computer Animation, 2, 4, 129-131. [10] DiPaola, S. 2002. FaceSpace: A Facial Spatial-Domain Toolkit. 
In Proceedings of InfoViz 2002, 49 55. [11] DiPaola S, Arya A, Chan J. 2005. Simulating Face to Face 
Collaboration for Interactive Learning Systems, Proceeding from E-Learn. [12] Ekman, P. , and FrieSEN, 
W. V. 1978. Facial Action Coding System, Consulting Psychologists Press Inc. [13] Ezzat, T. and Poggio, 
T. 1999. MikeTalk: A Talking Facial Display Based on Morphing Visemes. In Proceedings of Computer Animation 
Conference, IEEE Press. [14] Funge, J. et al. 1999. Cognitive Modeling. In Proceedings of ACM SIGGRAPH, 
ACM Press. [15] Gross, J., et al. 2000. The Dissociation of Emotion Expression from Emotion Experience: 
A Personality Perspective. In Personality and Social Psychology Bulletin, vol 26. no 6. pp 712-726. [16] 
Kahler, K. et al. 2002. Head Shop: Generating Animated Head Models with Anatomical Structure. In Proceedings 
of ACM SIGGRAPH/ Eurographics symposium on Computer animation, ACM Press. [17] Knutson, B. 1996. Facial 
Expressions of Emotion Influence Interpersonal Trait Inferences, Journal of Nonverbal Behavior, 20, 165-182. 
[18] Lee, Y., Terzopoulos, D., WATERS, K., 1995. Realistic Modeling for Facial Animation. In Proceedings 
of ACM SIGGRAPH, ACM Press. [19] Parke, F. I. 1972. Computer Generated Animation of Faces. In Proceedings 
of ACM Annual Conference, ACM Press, 451 457. [20] Parke, F. I., and Waters, K. 2000. Computer Facial 
Animation. A. K. Peters. [21] Pasquariello, D., and Pelachaud, A., 2001. Greta: A Simple Facial Animation 
Engine. In 6th Online World Conference on Soft Computing in Industrial Applications. [22] Pelachaud, 
W. and Bilvi, M. 2003. Computational Model of Believable Conversational Agents. In Communication in MAS: 
Background, Current Trends and Future. [23] Rousseau, D., and HAYES-ROTH, B. 1997. Interacting with Personality-Rich 
Characters. Knowledge Systems Laboratory Report No. KSL 97-06, Stanford University. [24] Russell, J.A., 
1980. A Circumplex Model of Affect. In Journal of Personality and Social Psychology, 39, 1161­1178. [25] 
Smid, K. et al. 2004. Autonomous Speaker Agent. In Proceedings of Computer Animation and Social Agents, 
Geneva, Switzerland. [26] Tiddeman, B. et al. 2001. Prototyping and Transforming Facial Textures for 
Perception Research. Computer Graphics and Applications, IEEE Press. [27] Turk, M. J., and Pentland, 
A. P. 1991. Face Recognition Using Eigenfaces. In Proceedings of IEEE Conference on Computer Vision and 
Pattern Recognition (CVPR-91), IEEE Press, 586 591. [28] Valentine, T. 1999. Face-Space Models of Face 
Recognition. In Computational, geometric, and process perspectives on facial cognition: Contexts and 
challenges. Wenger, M. J. &#38; Townsend, J. T. (Eds.), Lawrence Erlbaum Associates Inc. [29] Waters, 
K. 1987. A Muscle Model for Animating 3D Facial Expression. ACM Computer Graphics, ACM Press, 21, 4. 
[30] Wiggins, J.S. et al. 1988. Psychometric and Geometric Characteristics of the Revised Interpersonal 
Adjective Scale, Multivariate Behavioural Research, 23, 517-530.   
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2007</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	</section>
	<section>
		<section_id>1328226</section_id>
		<sort_key>240</sort_key>
		<section_seq_no>6</section_seq_no>
		<section_type>SESSION</section_type>
		<section_title><![CDATA[Storytelling in games]]></section_title>
		<section_page_from>137</section_page_from>
	<article_rec>
		<article_id>1328227</article_id>
		<sort_key>250</sort_key>
		<display_label>Pages</display_label>
		<pages>8</pages>
		<article_publication_date>11-14-2007</article_publication_date>
		<seq_no>1</seq_no>
		<title><![CDATA[DEAL]]></title>
		<subtitle><![CDATA[dialogue management in SCXML for believable game characters]]></subtitle>
		<page_from>137</page_from>
		<page_to>144</page_to>
		<doi_number>10.1145/1328202.1328227</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1328227</url>
		<abstract>
			<par><![CDATA[<p>In order for game characters to be believable, they must appear to possess qualities such as emotions, the ability to learn and adapt as well as being able to communicate in natural language. With this paper we aim to contribute to the development of believable non-player characters (NPCs) in games, by presenting a method for managing NPC dialogues. We have selected the trade scenario as an example setting since it offers a well-known and limited domain common in games that support ownership, such as role-playing games. We have developed a dialogue manager in State Chart XML, a newly introduced W3C standard, as part of DEAL --- a research platform for exploring the challenges and potential benefits of combining elements from computer games, dialogue systems and language learning.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[SCXML]]></kw>
			<kw><![CDATA[game dialogue]]></kw>
			<kw><![CDATA[non-player characters]]></kw>
			<kw><![CDATA[serious games]]></kw>
			<kw><![CDATA[statecharts]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.2.7</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>I.2.11</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010178.10010219</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Distributed artificial intelligence</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010179</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Natural language processing</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Languages</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P925249</person_id>
				<author_profile_id><![CDATA[81342490254]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Jenny]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Brusk]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Gotland University, Sweden]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P499071</person_id>
				<author_profile_id><![CDATA[81100443089]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Torbj&#246;rn]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Lager]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[G&#246;teborg University, Sweden]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P925217</person_id>
				<author_profile_id><![CDATA[81342497369]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Anna]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Hjalmarsson]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Centre for Speech Technology, KTH Stockholm, Sweden]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P925265</person_id>
				<author_profile_id><![CDATA[81342515975]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Preben]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wik]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Centre for Speech Technology, KTH Stockholm, Sweden]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>567365</ref_obj_id>
				<ref_obj_pid>567363</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Allen, J. F., Byron, D. K., Dzikovska, M., Ferguson, G., Galescu, L. &amp; Amanda Stent. (2001) Towards conversational human-computer interaction. <i>AI Magazine, 22(4): 2737.</i>
]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>219079</ref_obj_id>
				<ref_obj_pid>219030</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Aust, H., Oerder, M., Seide, F. &amp; Steinbiss, V. (1995) The phillips automatic train timetable information system. <i>Speech Communication, 17:249_262.</i>
]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>176803</ref_obj_id>
				<ref_obj_pid>176789</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Bates, J. (1994) The role of emotion in believable agents. <i>Communications of the ACM, 37(7): 122125</i>, July.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Bj&#246;rk, S. &amp; Holopainen, J. (2004) <i>Patterns in Game Design.</i> Charles River Media. ISBN1-58450-354-8.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Brusk, J. &amp; Lager, T. (2007) Developing Natural Language Enabled Games in (Extended) SCXML. <i>Proceedings from the International Symposium on Intelligence Techniques in Computer Games and Simulations (Pre-GAMEON-ASIA and Pre-ASTEC)</i>, Shiga, Japan, March 1--3.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Edlund, J., Skantze, G., &amp; Carlson, R. (2004). Higgins --- a spoken dialogue system for investigating error handling techniques. In <i>Proceedings of ICSLP 2004</i>, 229--231.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Egges, A., Zhang, X., Kshirsagar, S. &amp; Magnenat-Thalmann, N. (2003) <i>Emotional communication with virtual humans.</i> &lt;&lt;http://www.miralab.unige.ch/papers/161.pdf&gt;]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1071196</ref_obj_id>
				<ref_obj_pid>1071195</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Egges, A., Kshirsagar, S., &amp; N. Magnenat-Thalmann (2004) Generic personality and emotion simulation for conversational agents. <i>Computer Animation and Virtual World, 15:113</i>, January. &lt;http://www.miralab.unige.ch/papers/81.pdf&gt;]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>630752</ref_obj_id>
				<ref_obj_pid>630325</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Gratch, J., Rickel, J., Andr&#233;, E., Cassell, J., Petajan, E. &amp; Badler, N. (2002) <i>Creating interactive virtual humans: Some assembly required.</i> Technical report, Workshop report, IEEE Intelligent Systems. &lt;http://www.cis.upenn.edu/badler/papers/x4GEW.pdf&gt;]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Gustafson, J. Boye, J., Fredriksson, M., Johanneson, L. &amp; K&#246;&#246;nigsmann, J. (2005) Providing computer game characters with conversational abilities. In <i>Proceedings of Intelligent Virtual Agent (IVA05)</i>, Kos, Greece.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>34886</ref_obj_id>
				<ref_obj_pid>34884</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Harel, David (1987) Statecharts: A Visual Formalism for Complex Systems, <i>In Science of ComputerProgramming 8</i>, North-Holland.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>608623</ref_obj_id>
				<ref_obj_pid>608597</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Hayes-Roth, B. &amp; Doyle, P. (1998) Animate characters. <i>Autonomous Agents and Multi-Agent Systems, 1(2):195230</i>. ISSN 1387--2532. &lt;&lt;http://dx.doi.org/10.1023/A:101001981877&gt;]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1196757</ref_obj_id>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Iuppa, N., &amp; Borst, T. (2007). <i>Story and simulations for serious games : tales from the trenches.</i> Focal Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Jennings, N. R., Faratin, P., Lomuscio, A. R., Parsons, S., Sierra, C. &amp; Wooldridge, M. (2000) Automated Negotiation: Prospects, Methods and Challenges. GDN2000 Keynote Paper. <i>Int. Journal of Group Decision and Negotiation</i>
]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1214993</ref_obj_id>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Jurafsky, D. &amp; Martin, J. H. (2001) <i>Speech and Language Processing.</i> Prentice Hall: Upper Saddle River, New Jersey.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Lankoski, P. &amp; Bj&#246;&#246;rk, S. (2007) Gameplay Design Patterns for Believable Non-Player Characters. In <i>Situated Play, Proceedings of Digra 2007</i>, University of Tokyo, Japan.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Mateas, M. &amp; Stern, A. (2003) <i>Fa&#231;&#231;ade: An Experiment in Building a Fully-Realized Interactive Drama.</i> Game Developers Conference, Game Design track, March.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Skantze, G. (2005) GALATEA: A Discourse Modeller Supporting Concept-level Error Handling in Spoken Dialogue Systems. <i>In Proceedings of SigDial (pp. 178--189).</i> Lisbon, Portugal.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Swartout, W., Gratch, J., Hill, R., Hovy, E., Marsella, S., Rickel, J. &amp; Traum, D. (2004) <i>Toward virtual humans.</i> Working notes of the AAAI Fall symposium on Achieving Human Level Intelligence through Integrated Systems and Research.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Tsang, E. &amp; Gosling, T. (2002) Simple Constrained Bargaining Game. In <i>Proceedings of the First International Joint Conference on Autonomous Agents and Multi-Agent Systems (AAMAS-2002)</i>, Bologna, Italy, July15--19. &lt;http://lia.deis.unibo.it/aamas2002&gt;]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Wik, P., Hjalmarsson, A. &amp; Brusk, J. (2007) DEAL: A Serious Game for CALL Practicing Conversational Skills in the Trade Domain. <i>In Proceedings of SlaTE --- Workshop on Speech and Language Technology in Education</i>, Pennsylvania, USA.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1104477</ref_obj_id>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Zubek, R. (2005) Hierarchial Parallel Markov Models for Interactive Social Agents. PhD Dissertation, Computer Science Department, Northwestern University. Tech Report NWU-CS-05-10. &lt;http://robert.zubek.net/publications/dissertation.pdf&gt;]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 DEAL Dialogue Management in SCXML for Believable Game Characters Jenny Brusk Torbjörn Lager Anna Hjalmarsson 
Preben Wik Dept of Game Design, Narrative Dept of Linguistics Centre for Speech Technology and Time-based 
Media, Göteborg University, Sweden KTH Stockholm, Sweden Gotland University, Sweden lager@ling.gu.se 
{annah, preben}@speech.kth.sejenny.brusk@hgo.se ABSTRACT In order for game characters to be believable, 
they must appear to possess qualities such as emotions, the ability to learn and adapt as well as being 
able to communicate in natural language. With this paper we aim to contribute to the development of believable 
non-player characters (NPCs) in games, by presenting a method for managing NPC dialogues. We have selected 
the trade scenario as an example setting since it offers a well-known and limited domain common in games 
that support ownership, such as role­playing games. We have developed a dialogue manager in State Chart 
XML, a newly introduced W3C standard1, as part of DEAL a research platform for exploring the challenges 
and potential benefits of combining elements from computer games, dialogue systems and language learning. 
 Categories and Subject Descriptors I.2.7 [Artificial Intelligence]: Natural Language Processing discourse, 
language generation, language parsing and understanding, speech recognition and synthesis. I.2.11 [Artificial 
Intelligence]: Distributed Artificial Intelligence coherence and coordination, intelligent agents, languages 
and structures, multiagent systems.  General Terms Algorithms, Design, Languages.  Keywords Game dialogue, 
non-player characters, statecharts, serious games, SCXML. 1. INTRODUCTION As games become more and more 
sophisticated in terms of graphical and technological capabilities, higher demands are also put on the 
content provided by them. With content we mean the Permission to make digital/hard copy of part of this 
work for personal or classroom use is granted without fee provided that the copies are not made or distributed 
for profit or commercial advantage, the copyright notice, the title of the publication, and its date 
of appear, and notice is given that copying is by permission of the ACM, Inc. To copy otherwise, to republish, 
to post on servers, or to redistribute to lists, requires prior specific permission and/or a fee. FuturePlay 
2007, November 15-17, 2007, Toronto, Canada. Copyright 2007 ACM 978-1-59593-943-2/07/0011...$5.00 story, 
characters, dialogue, gameplay, music, sound etc., i.e. everything that is presented to the player through 
the interface. We judge the game and the gaming experience in terms of how well the components in the 
game are composed, how they encourage the player to take certain actions and the extent to which they 
motivate the player to stay in the game, i.e. the level of immersiveness the game provide. Given that 
characters that can be encountered in games offer both possibilities of opposition to players and vehicles 
for narratives, they are a natural focus for improving the content in games. Although not primarily focusing 
on games, a lot of research has been conducted within the field of believable characters, in the sense 
characters that provide the illusion of life [3]. These characters possess qualities such as emotions, 
personality, the ability to communicate in natural language, adaptive behavior and learning capabilities 
[7, 8, 9, 12, 19] qualities usually ascribed to humans. Believable characters tend to appear in animated 
and/or interactive dramas, or as interactive (conversational) agents, but also in simulations such as 
the Mission Rehearsal Exercise project [19]. In games, the characters need interactive abilities, such 
as self­impelled actions, expression of emotions, and self-awareness [16]. It is also important that 
there is an interplay between the different properties of a character as well as between the character 
and the game world (including events and actions caused by the player or other characters): For instance, 
a character that experiences an emotional moment, should be able to express these emotions verbally as 
well as non-verbally, preferably in accordance with her personality. To avoid repetitious responses, 
the character needs to have a range of possible responses to choose from, perhaps based on an emotional 
memory, the interpersonal relationship and the dialogue history. Lankoski &#38; Björk [16] mean that 
in order for the dialogues to be believable the characters must be able to produce contextualized conversational 
responses, i.e. the character needs to take the current game state into account when formulating a response. 
A similar view is presented in [5] saying that designers need to consider dialogue flow a part of the 
game flow, treat dialogue actions on par with other game actions, and think of the current game state 
as comprising also the state(s) of the dialogue(s) taking place at the current point in time. We believe 
that the most successful natural language enabled games will treat natural language dialogue as an integral 
part of the game, rather than something added on as an afterthought. 1 http://www.w3.org/TR/scxml/  
With these views in consideration, we wish to contribute to the creation of a more realistic and immersive 
dialogue with non­player characters (NPCs) in games.  2. DIALOGUE SYSTEMS Dialogue systems are programs 
that can communicate with humans in natural language [15]. The system takes free-form text or speech 
input and transforms it to a representation that can be understood by the system. The system must then 
produce an appropriate response to the input. How this is done depends on the purpose and the complexity 
of the system. Dialogue systems have mainly been designed to collaborate with the user to solve a particular 
task, such as managing bank transactions or handle time-table tasks, such as The Phillips Automatic Train 
Timetable Information System [2], i.e. to handle dialogues that Allen et al [1] refer to as practical. 
These systems usually operate in a specific and simple domain, which enables them to perform robustly. 
The complexity of the system may vary from the simplest finite-state based systems, to the most complex 
agent-based models. (see e.g. [1] for an excellent overview). Game dialogue systems, on the other hand, 
usually refer to the tree-structure that constitutes player (character)-NPC interaction. They appear 
to the player as a dialogue menu displayed in a static interface, as in Grim Fandango2 and Fable3. In 
some games the dialogue system is more like an information retrieval system, such as in The Elder Scrolls 
III: Morrowind4, where questions are posed by clicking hyperlinked key-words connected to a database. 
Game dialogue systems thus rarely allow free-form input from the players, instead they present the different 
available options to the player as a list of phrases or topics. 2.1 Practical Dialogue Systems vs Game 
Dialogue Systems We argue that there are some critical differences between the requirements of a practical 
dialogue system as opposed to a dialogue system designed for games in terms of: Error handling Any system 
must of course be able to handle upcoming errors, such as misunderstanding or non­understandings, but 
the strategies may differ. When a practical dialogue system aims at reaching a level of understanding 
in the dialogue that will lead to a successful completion of the task, a game character in dialogue with 
the player may behave irrationally or emotionally instead. It can pretend to have understood, change 
subject or perhaps just end the dialogue abruptly. Correctness and cooperativeness the information provided 
by the practical dialogue system should be correct and relevant, whereas the outcome of a game dialogue 
may depend on the character providing it, the current situation and the interpersonal relationship. We 
can think of situations where the NPC provide the player with false information or withhold information 
until a 2 Lucas Arts (1998), for PC 3 Lionhead Studios Ltd (2004), Microsoft, for XBox 4 Bethseda Softworks 
(2002), for PC relationship has been established or a certain game state has been reached. Predictability 
and reliability The purpose of interacting with a practical dialogue system is to be provided with a 
certain service. It is therefore important that the system behaves in a consistent manner and has a predictable 
outcome. In games, on the other hand, the believability of the character may clash with the predictability 
of the dialogue system. Motivation The main motivation for using a practical dialogue system is to successfully 
perform a certain task or acquire information from it. In a game, there can be several reasons for the 
player to engage in a dialogue: To socialize, get game hints or quests, or just get entertained. A game 
dialogue system should therefore be designed to handle longer exchanges as well as a variety of relevant 
topics. In the DEAL-project for instance (presented below), one of the goals is to create a game dialogue 
system for language learning. In this case, the talking in itself is the most important goal of the interaction, 
not to complete the task.  3. NATURAL LANGUAGE INTERACTION IN GAMES Many different approaches to introducing 
natural language in games have been applied. One of the first ways natural language was used in games 
was as typed commands meant to serve the same purpose as direct manipulation of a graphical user interface. 
We have seen examples in the old text-based adventure games, such as the Zork-series5, where the user 
could type in text-based commands expressed by words or phrases that could be parsed and understood by 
the system. Today, players can control the game using voice in addition to the mouse and keyboard. The 
new technology use voice-over IP to enable the player to communicate with the game system as well as 
with other players in multiplayer online games. This way, the player can do more tasks simultaneously, 
such as fighting a monster while talking to co-players. Hence, these new possibilities also support socialization, 
coordination and collaboration in multiplayer games. To summarize, there are several ways in which natural 
language (dialogue) may come into play in games. Assuming the commonly made distinction between game 
(G), player (P), player character (PC) and non-player character (NPC), and stretching the notion of dialogue 
somewhat, we may distinguish between: P in dialogue with G: Games may be voice controlled . Instead 
of hitting the pause button in order to pause a game, the player may just say pause .  P in dialogue 
with PC: Player is directing his player character using dialogue.  P in dialogue with P: Player talking 
to player, using (voice­based) chat.  5 Infocom (1980-1982)  NPC in dialogue with NPC: The use of 
natural language for commenting on the states and the events of a game, such as the commentators talking 
to each other in FIFA 200X.  P in dialogue with NPC: For the purpose of letting NPCs provide the player 
with background story, quests and directions for progressing the game, but also in order to uphold social 
relationships with NPCs. Dialogues will thus sometimes be task oriented, sometimes of a more socially 
motivated kind.  Conversations between humans are often of the multimodal kind, and realistic dialogue 
with NPCs should therefore be too. An NPC should be able to nod instead of saying yes , or nod and say 
yes at the same time. Thus, the boundary between controlling the visual appearance and behaviour of an 
NPC how it looks and what it does and its natural language capabilities what it says is not very 
clearcut. Thus, these things should better be controlled and synchronized using one and the same mechanism. 
 4. STATECHART XML (SCXML) SCXML can be described as an attempt to render Harel statecharts [11] in 
XML. Harel developed his statecharts as a graphical notation for specifying reactive systems in great 
detail. In its simplest form, a statechart is just a finite state machine, where state transitions are 
triggered by events appearing in an event queue. Any statechart can be translated into a document written 
in the linear XML-based syntax of SCXML (see [5] for examples). Harel also introduced a number of (at 
the time) novel extensions to finite-state machines, which are also present in SCXML, including: Hierarchy 
 a state may contain another statechart down to an arbitrary depth. Hence reducing the number of states. 
 History a memory of which state the superstate was in when it was left for another state.  Concurrency 
 several statecharts may be run in parallel which basically means that that their parent statechart is 
in two or more states at the same time. This is an important mechanism for introducing independency and 
orthogonality into a design. Concurrency may for example be useful when the NPCs their states-of-mind, 
states-of-body, as well as their (verbal and non-verbal) behaviours are modelled in the hope that a 
good game will emerge from the interaction between different NPCs and between NPCs and human players. 
In such cases it makes sense to model each NPC as a separate statechart, running in parallel with each 
other, and running in parallel with the game world.  Broadcast communication a statechart may send 
an event to the global event queue that will trigger a transition in a concurrent statechart. This way, 
two characters in the game modelled as concurrent statecharts can communicate with each other.  Datamodel 
(a.k.a. extended state variables ) within a statechart we can use datamodels to store and update (XML) 
data. In the trade example, explained below (see figure 1), we store the data retrieved from the database 
search in a  datamodel associated with the shopkeeper's statechart, allowing us to access and manipulate 
the data in any state. Important to note is that SCXML is not intended to interact with a user directly. 
Rather, it needs a presentation layer, which may support different types of modalities.  5. DEAL The 
work (in progress) presented here is part of DEAL, a project investigating the possibilities to create 
a language learning system for conversational training that uses gameplay elements to create an immersive 
learning environment. We are talking about a serious game, i.e. a game that has a purpose other than 
to solely entertain, such as teaching, training or advertising [13]. DEAL sets the scene of a flea market 
where a talking animated agent (a non-player character) is the owner of a shop where used objects are 
sold. The objects sold at a flea market can be a diverse set of items which can be tailored to suit the 
vocabulary mastered by a language learning student. The flea market is also a place where it is acceptable 
to negotiate the price. DEAL is implemented by using components from the Higgins project (see e.g. [18]): 
an off-the-shelf automated speech recognition (ASR) system, a dialogue manager developed for DEAL purposes 
and a GUI with an embodied conversational agent (ECA). The game dialogue manager (DM) in DEAL presented 
in this paper is implemented using SCXML for the following reasons: -It is coupled with the visual statechart 
representation (makes the system easy to manage and overview) -It is finite-state based (Most games are 
finite-state based) -It support concurrency and hierarchy -It is XML-based (many game engines communicate 
with XML data) -It can invoke different presentation layers (chat, voice, multimodal) depending on the 
task. 5.1 Implementation The SCXML application has been implemented and tested in the SCXML Web Laboratory6, 
a web-based interface for SCXML­applications written in Oz, developed by Torbjörn Lager at the Department 
of Linguistics at Göteborg University. The Higgins project aims at developing a collaborative dialogue 
system in which error handling can be tested empirically [6]. Higgins is a module-based system consisting 
of an interpreter, Pickering, that takes the result from the ASR as input and creates a semantic representation 
of the user's communicative act (CA). The CA is then sent to the discourse modeller, Galatea. The output 
from Galatea constitutes the input to an action manager, in this case tailored for the DEAL domain [18, 
21]. The SCXML dialogue manager described in this paper has been developed separately, there is no real 
connection between Galatea and the DM, instead we have made minor adjustments of 6 <http://www.ling.gu.se/~lager/Labs/SCXML-Lab/> 
 the output from Galatea to fit the syntax of the eventdata as formalised in the SCXML Web Lab. We regard 
a communicative act produced by the user as an incoming event after which the system sends a response 
in the form of a new communicative act, that (in this case) is hypothetically passed to the generator 
in Higgins and then back to Galatea again.  6. TRADE As a tool for describing games and gameplay features, 
Björk &#38; Holopainen [4] have introduced the concept of gameplay design patterns, defined as semiformal 
interdependent descriptions of commonly reoccurring parts of the design of a game that concern gameplay 
. The idea is that games that feature a certain gameplay design pattern most likely (or perhaps should) 
feature other related patterns as well. Trade is here described as Players exchange some kind of Resource, 
be it information, actions, or game elements, between each other or the game system and is related to 
patterns such as Resources, Ownership and Social Interaction. A shopkeeper in a game is typically represented 
by an NPC, and a trade dialogue between the shopkeeper and a player may be both practical (to successfully 
complete a transaction) as well as socially oriented, involving elements such as negotiation. Trade is 
thus a good candidate for exemplifying how natural language dialogue can be used in a game setting. There 
are also other reasons why we chose trade for the DEAL project: -it involves explicit and well-known 
roles of the participants -a trading situation is a fairly restricted and universally well­known domain. 
It is something everyone is conceptually familiar with, regardless of cultural and linguistic background. 
-trade is interesting from a language acquisition point of view -trade may involve bargaining. The negotiation 
process is in itself an interesting research area due to its complexity containing both rational and 
emotional elements. The aim is to create a believable interaction involving elements of freedom for the 
player combined with an unpredictable outcome associated with a negotiation process.  7. TRADE IN SCXML 
A trade can be modelled as consisting of three phases: An opening phase, in which the participants acknowledge 
each other, a middle phase, when the actual transaction takes place including an optional bargaining 
phase, and finally an end phase, in which the deal is closed and the participants exit the interaction. 
We have used this structure as a starting point when modelling the statechart. The trade statechart (see 
figure 1.) consists of a top-level state (shop_keeper), which represents the shopkeeper's statechart 
of the dialogue. The dialogue state then consists of three substates, representing each phase in the 
interaction: opening, tradingand ending. An example of a trade dialogue can be as follows (where P represents 
the player and S the shopkeeper) : P1: Hi! I would like to buy a clock S1: A clock. S2: What colour 
did you have in mind? P2: Do you have any green ones? S3: Sure, what size? P3: A small one please. S4: 
How about this clock? P4: How much is it? S5: It costs 250 P5: That is too expensive. I can pay 125 S6: 
How about 225? P6: 150 ... S7: You can get it for 200, no less. P7: Ok, that is a fair price, I'll take 
it. S8: Fine, 200 then. (The user hands over the money, the shopkeeper hands over the object.) S9: Thank 
you and welcome back! When the player utters P1, the shopkeeper's active state is greeting. After greeting 
the shopkeeper, the player immediately expresses a request, triggering a transition to search_object. 
On entering this state, the shopkeeper searches the inventory and finds several matches, causing him 
to ask for additional information (S2 and S3), thus triggering a transition to the subsequent superstate 
get_info. When the shopkeeper retrieves one unique match in the database, the state present_object is 
activated, in which the shopkeeper presents the item to the player (S4). Having agreed upon the item 
to trade, a negotiation process may begin, in this case initiated by the player in P5. When this happens, 
a transition to the state negotiation is taking place. After a period of offers and counteroffers, the 
two participants come to an agreement (S7 followed by P7) causing a transition to resolve_exchange. The 
price is confirmed by the shopkeeper (S8), who then waits until he has received the money from the player. 
 Compared to how trade is usually conducted in games, the NPC in this example is able to take a more 
active part in the interaction, allowing the player to take initiative (as in the initial request), but 
also taking the initiative when there is a need for it (in this case when more information is required). 
The NPC can also start to negotiate when the player gives a counteroffer. The outcome of the situation 
becomes uncertain when we introduce the bargaining process the price is under negotiation and neither 
participant knows what the final bid will be. In this particular case the participants came to an agreement 
leading to a completion of the trade, but situations will occur when the player changes a request, the 
shopkeeper doesn't supply the requested item or the trade is cancelled as a whole. With statecharts 
we can easily add transitions for new types of events, as well as add states for new situations that 
may occur. The complexity of the given example lies in the negotiation  process, where a variety of 
parameters determines the outcome, but also in the way initiative is handled. Below, we will give a detailed 
description of the different states, what they do and how they work. 7.1 Opening Either participant may 
initiate the dialogue, by for instance a greeting event, but the player may also choose to immediately 
send out a request , which is an event that will trigger a transition to the trading state. If the player 
is passive ( no-input ), the system may attempt to receive an input by offering assistance (a transition 
triggered by a time-out event). The system may also fail to recognize or understand the input, which 
will result in a no-match event. 7.2 Trading As expected, the actual trading phase is the non-trivial 
part of the dialogue. The complex state trading contains three substates: define_ooi, negotiation and 
resolve_exchange, all of which are complex states themselves. A trade can only be conducted if the shopkeeper 
owns a specific item that the buyer is interested in purchasing and if the buyer has something to trade 
in return (in this case money). Define object of interest. Before anything else, the shopkeeper must 
find out what the buyer wants to purchase. This complex state define_ooi includes states for gathering 
information about the requested object (get_info), searching for objects in the database (search_object) 
and a state for presenting an object when there is a match in the database (present_object). We have 
used inspiration from form­based dialogue systems, such as VoiceXML7, in collecting the necessary information 
from the player, i.e. when the system retrieves too many matches in a search, it tries to narrow down 
the search space by asking the player to specify the missing properties one by one until a match is found 
(get_info). A more sophisticated system would of course try to ask only relevant questions, i.e. questions 
of distinctive features. The substate search_object does the actual database search based upon the information 
retrieved in get_info. Negotiation. Negotiation is a complex process involving elements of social psychology 
and game theory and can also include emotional elements and lies. Our implementation so far handles offers 
and counteroffers. The next step will be to attempt to add complexity in terms of argumentation-based 
negotiation. Negotiation can be viewed as a distributed search through a space of potential agreements 
[14, p6]. The aim is to reach a point in the agreement space that will optimise the outcome which at 
the same time is accepted by the other agent. The agents present offers or counteroffers based on parameters 
such as cost/utility and time. The shopkeeper's strategy used in this example has been inspired by the 
Zeuthen strategy, described in [14] and the automated bargaining game presented in [20]. In effect, the 
shopkeeper will give an offer based on his last offer (which has 7 <http://www.w3.org/TR/voicexml20/> 
become the current price), the cost (minimum acceptable price), and time, corresponding to the number 
of rounds the shopkeeper has left to conclude the deal (see SCXML code in appendix I). The buyer will 
also make offers according to those parameters, but the number of rounds will most likely be different, 
since the number of rounds is randomly selected for each agent. Neither agent has information about the 
other's time and cost/utility. For each round, the agents will increase their eagerness to conclude the 
deal, we assume neither of them is interested in reaching a breakdown. The shopkeeper may for instance 
accept any price that exceeds the cost when running out of rounds. A breakdown may however occur when 
the shopkeeper has no more than one turn left and the latest bid from the buyer is below the cost or 
lower than her previous bid. Resolve exchange. When the shopkeeper and the buyer have reached an agreement, 
the next step is to conclude the deal. In the complex state resolve_exchange, the shopkeeper starts by 
confirming the agreed price (confirm_price), after which the buyer is expected to hand over the money 
(triggering event). When the shopkeeper has received the requested amount of money, the state money_transaction 
is entered. The shopkeeper thanks the buyer and hands over the goods and when the buyer takes the goods, 
the dialogue reaches the end. Ending. When the transaction is concluded or the trade has been cancelled, 
the application reaches the end phase, where the agents say goodbye to each other and exit the interaction. 
  8. RELATED WORK Initially, we discussed our work in relation to the research on believable characters 
and practical dialogue systems. Another area that is highly relevant in the context is the ongoing research 
around interactive stories, such as Façade8, further described in [17] and The Interactive Story Project9 
(IS). The idea with these projects is to allow the user to influence how the story progresses by intervening 
the play using text (in Façade) or voice (IS). In Façade the player is playing a role in the drama, whereas 
in IS, the user is regarded as an active spectator . Other research projects have used games as environment, 
for instance The NICE Fairy-tale Game System [10], where the player manipulates the game world through 
the helper character Cloddy Hans using voice. Similarly, Zubek [22] presents two examples of game dialogues; 
one where the player interacts with a shopkeeper, and one simulating a break-up of a relationship between 
the player and a virtual character. 9. DISCUSSION A believable character has been described as being 
lifelike , possessing human qualities such as emotions, a visual appearance and the ability to use natural 
language. One way to look at it is to say that a believable character needs a range of different traits 
expressed by different means and that these traits and expressions in fact are separate from each other, 
but yet interacting and combined in a multitude of ways. Statecharts allow us to model these traits independently 
and the behaviour of the character will 8 <http://www.interactivestory.net> 9 < http://www-scm.tees.ac.uk/users/f.charles/> 
 then be determined by the combination of the active states representing the traits. Hence, this method 
can be used to create characters with emergent behaviour. We have in this paper given an example of how 
statecharts can be used to model the dialogue manager for an NPC in a game. The example is derived from 
games designed with the patterns associated with ownership, as described by Björk &#38; Holopainen [4], 
where shops can be used as an arena for trading objects. The NPC has been given the role of a shopkeeper 
capable of presenting objects of interest as well as negotiating the price. The dialogue allows mixed-initiative 
interaction, meaning that either participant can initiate and control the dialogue. This is a work-in­progress, 
we have not yet used statecharts and SCXML to its full potential. The next step will therefore be to 
add the ability to use emotional elements in the interaction and add argumentation­based negotiation, 
which we hope will contribute to a believable and immersive gaming experience. Important to note, however, 
we are not claiming that all dialogues should be conducted using natural language or that NPCs in general 
need to be modelled according to the principles associated with believable characters. We are here presenting 
one of many possible ways to deal with dialogues to invoke a certain type of gaming experience, where 
it enhances gameplay, it is not aimed to be a general principle for designing game dialogues. 10. ACKNOWLEDGEMENT 
This work has been conducted within The Graduate School of Language Technology. The authors would like 
to thank Rolf Carlsson, Jens Edlund, Gabriel Skantze, Staffan Björk and Mirjam P. Eladhari. 11. REFERENCES 
[1] Allen, J. F., Byron, D. K., Dzikovska, M., Ferguson, G., Galescu, L. &#38; Amanda Stent. (2001) Towards 
conversational human-computer interaction. AI Magazine, 22(4): 2737. [2] Aust, H., Oerder, M., Seide, 
F. &#38; Steinbiss, V. (1995) The phillips automatic train timetable information system. Speech Communication, 
17:249_262. [3] Bates, J. (1994) The role of emotion in believable agents. Communications of the ACM, 
37(7): 122125, July. [4] Björk, S. &#38; Holopainen, J. (2004) Patterns in Game Design. Charles River 
Media. ISBN1-58450-354-8. [5] Brusk, J. &#38; Lager, T. (2007) Developing Natural Language Enabled Games 
in (Extended) SCXML. Proceedings from the International Symposium on Intelligence Techniques in Computer 
Games and Simulations (Pre-GAMEON-ASIA and Pre-ASTEC), Shiga, Japan, March 1-3. [6] Edlund, J., Skantze, 
G., &#38; Carlson, R. (2004).Higgins a spoken dialogue system for investigating error handling techniques. 
In Proceedings of ICSLP 2004, 229-231. [7] Egges, A., Zhang, X., Kshirsagar, S. &#38; Magnenat-Thalmann, 
N. (2003) Emotional communication with virtual humans. <http://www.miralab.unige.ch/papers/161.pdf> [8] 
Egges, A., Kshirsagar, S., &#38; N. Magnenat-Thalmann (2004) Generic personality and emotion simulation 
for conversational agents. Computer Animation and Virtual World, 15:113, January. <http://www.miralab.unige.ch/papers/81.pdf> 
 [9] Gratch, J., Rickel, J., André, E., Cassell, J., Petajan, E. &#38; Badler, N. (2002) Creating interactive 
virtual humans: Some assembly required. Technical report, Workshop report, IEEE Intelligent Systems. 
<http://www.cis.upenn.edu/badler/papers/x4GEW.pdf> [10] Gustafson, J. Boye, J., Fredriksson, M., Johanneson, 
L. &#38; Königsmann, J. (2005) Providing computer game characters with conversational abilities. In Proceedings 
of Intelligent Virtual Agent (IVA05), Kos, Greece. [11] Harel, David (1987) Statecharts: A Visual Formalism 
 for Complex Systems, In Science of ComputerProgramming 8, North-Holland. [12] Hayes-Roth, B. &#38; Doyle, 
P. (1998) Animate characters. Autonomous Agents and Multi-Agent Systems, 1(2):195230. ISSN 1387-2532. 
<http://dx.doi.org/10.1023/A:101001981877> [13] Iuppa, N., &#38; Borst, T. (2007). Story and simulations 
for serious games : tales from the trenches. Focal Press. [14] Jennings, N. R., Faratin, P., Lomuscio, 
A. R., Parsons, S., Sierra, C. &#38; Wooldridge, M. (2000) Automated Negotiation: Prospects, Methods 
and Challenges. GDN2000 Keynote Paper. Int. Journal of Group Decision and Negotiation [15] Jurafsky, 
D. &#38; Martin, J. H. (2001) Speech and Language Processing. Prentice Hall: Upper Saddle River, New 
Jersey. [16] Lankoski, P. &#38; Björk, S. (2007) Gameplay Design Patterns for Believable Non-Player Characters. 
In Situated Play, Proceedings of Digra 2007, University of Tokyo, Japan. [17] Mateas, M. &#38; Stern, 
A. (2003) Façade: An Experiment in Building a Fully-Realized Interactive Drama. Game Developers Conference, 
Game Design track, March. [18] Skantze, G. (2005) GALATEA: A Discourse Modeller Supporting Concept-level 
Error Handling in Spoken Dialogue Systems. In Proceedings of SigDial (pp. 178-189). Lisbon, Portugal. 
[19] Swartout, W., Gratch, J., Hill, R., Hovy, E.,Marsella, S., Rickel, J. &#38; Traum, D. (2004) Toward 
virtual humans. Working notes of the AAAI Fall symposium on Achieving Human Level Intelligence through 
Integrated Systems and Research. [20] Tsang, E. &#38; Gosling, T. (2002) Simple Constrained Bargaining 
Game. In Proceedings of the First International Joint Conference on Autonomous Agents and Multi-Agent 
Systems (AAMAS-2002), Bologna, Italy, July15-19. <http://lia.deis.unibo.it/aamas2002> [21] Wik, P., Hjalmarsson, 
A. &#38; Brusk, J. (2007) DEAL: A Serious Game for CALL Practicing Conversational Skills in the Trade 
Domain. In Proceedings of SlaTE Workshop on Speech and Language Technology in Education , Pennsylvania, 
USA. [22] Zubek, R. (2005) Hierarchial Parallel Markov Models for Interactive Social Agents. PhD Dissertation, 
Computer Science Department, Northwestern University. Tech Report NWU-CS-05-10. <http://robert.zubek.net/publications/dissertation.pdf> 
  Figure 1. Trade statechart APPENDIX I SCXML code example smart seller in negotiation state <state 
id="smart_seller" target="smartoffer"><onentry><assign name="RoundsLeft"expr="{Rounds Price}"/><assign 
name="Interval"expr="(Price-Minprice) div RoundsLeft"/><assign name="Price" expr="Price-Interval"/> </onentry> 
<state id="smartoffer"> <onentry> <send target="Self" event="sysoffer" expr="o(agent:system price:Price)"/> 
 </onentry> <transition event="ca" cond="Eventdata.ca_type==counteroffer andthen PreviousBid >= Eventdata.offer"target="smartoffer"> 
<log label="Eventdata.agent" expr="Eventdata.string#' '#PreviousBid#' kronor'"/><log expr="'user offers 
same or lower bid than previous'"/><assign name="RoundsLeft" expr="RoundsLeft-1"/> </transition> <transition 
event="ca" cond="Eventdata.ca_type==counteroffer andthen 1>=RoundsLeft andthen Eventdata.offer>PreviousBid 
andthen Eventdata.offer>=Minprice" target="accept_transaction"><log label="Eventdata.agent" expr="Eventdata.string#' 
'#Eventdata.offer#' kronor'"/><assign name="Price" expr="Eventdata.offer"/><log label="system" expr="'System 
accepts price: '#Price"/> </transition> <transition event="ca" cond="Eventdata.ca_type==counteroffer 
andthen Eventdata.offer>=Price-Interval"target="accept_transaction"> <log label="Eventdata.agent" expr="Eventdata.string#' 
'#Eventdata.offer#' kronor'"/> <assign name="Price" expr="Eventdata.offer"/> <log label="system" expr="'System 
accepts price: '#Price"/> </transition> <transition event="ca" cond="Eventdata.ca_type==counteroffer 
andthen 1>=RoundsLeft andthen Minprice>Eventdata.offer" target="reject_transaction"> <log label="Eventdata.agent" 
expr="Eventdata.string#' '#PreviousBid#' kronor'"/> </transition> <transition event="ca" cond="Eventdata.ca_type==counteroffer 
andthen ((Price-Interval)>Eventdata.offer orelse Minprice>Eventdata.offer)" target="smartoffer"><assign 
name="PreviousBid" expr="Eventdata.offer"/><log label="Eventdata.agent" expr="Eventdata.string#' '#PreviousBid#' 
kronor'"/><assign name="Price" expr="{NextOffer Price PreviousBid RoundsLeft Interval}"/><assign name="RoundsLeft" 
expr="RoundsLeft-1"/> </transition></state></state>    
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2007</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>1328228</article_id>
		<sort_key>260</sort_key>
		<display_label>Pages</display_label>
		<pages>7</pages>
		<article_publication_date>11-14-2007</article_publication_date>
		<seq_no>2</seq_no>
		<title><![CDATA[True story]]></title>
		<subtitle><![CDATA[dynamically generated, contextually linked quests in persistent systems]]></subtitle>
		<page_from>145</page_from>
		<page_to>151</page_to>
		<doi_number>10.1145/1328202.1328228</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1328228</url>
		<abstract>
			<par><![CDATA[<p>Massively Multiplayer Online Role-Playing Games (MMORPGs) typically use a handful of static conventions for involving players in stories, such as predefined quest or story paths (a quest or story path is one in which the user experiences a sequence of related quests that must be accomplished in a particular order). Beyond the work done in MMORPGs there has been strong research in designing adaptive approaches to interactive fiction/drama that dynamically author content for users of the interactions [10] [18]. The system architecture presented in this paper, TRUE STORY, is designed to address issues concerning dynamically generated quest or story paths in persistent worlds, such as MMORPGs, for users to engage in more enhanced, interactive and personal experiences. TRUE STORY empowers persistent world designers by offering a truly modular approach for dynamically generating and presenting compelling content that results in user experiences worth telling a story about. The current implementation is set in a game model to demonstrate a dynamic quest generation system built to present users with unique and compelling experiences linked by context to past quests and/or experiences. This is achieved by utilizing history and relationships developed through interaction between world objects and actions.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[MMORPG]]></kw>
			<kw><![CDATA[contextually linked goals]]></kw>
			<kw><![CDATA[dynamic quest generation]]></kw>
			<kw><![CDATA[game AI]]></kw>
			<kw><![CDATA[interactive narrative]]></kw>
			<kw><![CDATA[multiplayer games]]></kw>
			<kw><![CDATA[story generation]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.2.1</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10002951.10003227</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003241.10003243</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Decision support systems->Expert systems</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003241.10003243</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Decision support systems->Expert systems</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Experimentation</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P925241</person_id>
				<author_profile_id><![CDATA[81342507441]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[James]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Pita]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Southern California, Los Angeles, CA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P925222</person_id>
				<author_profile_id><![CDATA[81327490117]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Brian]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Magerko]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Michigan State University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P925268</person_id>
				<author_profile_id><![CDATA[81536874256]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Scott]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Brodie]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Microsoft Corporation, Redmond, WA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Barber, H. 2006. Adaptive Generation of Dilemma-based Interactive Narratives. The Ninth International Conference on the Simulation of Adaptive Behavior.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Campbell, J. September 2003. The Hero's Journey: Joseph Campbell on His Life and Work. New World Library; 1&#60;sup&#62;st&#60;/sup&#62; New Wo edition.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1202754</ref_obj_id>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Crawford, C. 2004. Chris Crawford on Interactive Storytelling. New Riders Games.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Fairclough, C. and P. Cunningham. 2004. A Multiplayer O.P.I.A.T.E. Int. J. Intell. Games &amp; Simulation 3(2): 54--61.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>861425</ref_obj_id>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Freeman, D. September 15, 2003. Creating Emotion in Games: The Craft and Art of Emotioneering. New Riders Games; 1&#60;sup&#62;st&#60;/sup&#62; edition.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Johnstone, K. June 1999. Impro for Storytellers. A Theatre Arts Book; 1&#60;sup&#62;st&#60;/sup&#62; edition.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1207478</ref_obj_id>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Koster, R. November 6, 2004. Theory of Fun for Game Design. Paraglyph; 1&#60;sup&#62;st&#60;/sup&#62; edition.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Lebowitz, M. 1984. Creating Characters in a Story-Telling Universe. Poetics 13; 171--194]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Magerko, B. 2007. A Comparative Analysis of Story Representations for Interactive Narrative Systems. Artificial Intelligence and Interactive Digital Entertainment Conference.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Mateas, M. and A. Stern. 2003. Fa&#231;ade: An Experiment in Building a Fully-Realized Interactive Drama. Game Developers Conference.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Meehan, J. 1981. Tale Spin. In Inside Computer Understanding, edited by R. Schank and CK Riesbeck. New Jersey: Lawrence Erlbaum Associates.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Perlin, K. and A. Goldberg. 1996. Improv: A System for Scripting Interactive Actors in Virtual Worlds. The Improv System Technical Report NYU Department of Computer Science.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Propp, V. 1969. Morphology of the Folktale. Trans. Laurence Scott. Ed. Louis A. Wagner. 2&#60;sup&#62;nd&#60;/sup&#62; edition. Univ. of Texas Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2175739</ref_obj_id>
				<ref_obj_pid>2175737</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Riedl, M. and A. Stern. 2006. Believable Agents and Intelligent Story Adaptation for Interactive Storytelling. 3&#60;sup&#62;rd&#60;/sup&#62; International Conference on Technologies for Interactive Digital Storytelling and Entertainment, Darmstadt, DE.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Rizzo, P., M. V. Veloso, M. Miceli, and A. Cesta. 1999. Goal-Based Personalities and Social Behaviors in Believable Agents. Applied Artificial Intelligence, 13:239--271.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Roberts, D. L., A. S. Cantino, C. L. Isbell. 2007. Player Autonomy versus Designer Intent: A Case Study of Interactive Tour Guides. Artificial Intelligence and Interactive Digital Entertainment Conference.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Sharma, M., S. Onta&#241;&#243;n, C. Strong, M. Mehta, and A. Ram. 2007. Towards Player Preference Modeling for Drama Management in Interactive Stories. Twentieth International Florida Artificial Intelligence Research Society Conference.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Thue, D., V. Bulitko, M. Spetch, E. Wasylishen. 2007. Interactive Storytelling: A Player Modeling Approach. Artificial Intelligence and Interactive Digital Entertainment Conference.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>925491</ref_obj_id>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Weyhrauch, P. 1997. Guiding Interactive Drama. Ph.D. thesis, Tech report CMU-CS-97-109, Carnegie Mellon University.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Young, R. M., M. Riedl, M. Branly, A. Jhala, R. J. Martin and C. J. Saretto. 2004. An Architecture for Integrating Plan-based Behavior Generation with Interactive Game Environments. Journal of Game Development 1(1): 51--70.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 TRUE STORY: Dynamically Generated, Contextually Linked Quests in Persistent Systems James Pita Brian 
Magerko Scott Brodie TEAMCORE Research Group Games for Entertainment and Microsoft (Carbonated Games) 
University of Southern California Learning Lab Microsoft Corporation Los Angeles, CA 90089 417 Communication 
Arts Bldg One Microsoft Way 307.371.2139 Michigan State University Redmond, WA 98052-6399 jpita@usc.edu 
magerko@msu.edu sbrodie@microsoft.com ABSTRACT Massively Multiplayer Online Role-Playing Games (MMORPGs) 
typically use a handful of static conventions for involving players in stories, such as predefined quest 
or story paths (a quest or story path is one in which the user experiences a sequence of related quests 
that must be accomplished in a particular order). Beyond the work done in MMORPGs there has been strong 
research in designing adaptive approaches to interactive fiction/drama that dynamically author content 
for users of the interactions [10] [18]. The system architecture presented in this paper, TRUE STORY, 
is designed to address issues concerning dynamically generated quest or story paths in persistent worlds, 
such as MMORPGs, for users to engage in more enhanced, interactive and personal experiences. TRUE STORY 
empowers persistent world designers by offering a truly modular approach for dynamically generating and 
presenting compelling content that results in user experiences worth telling a story about. The current 
implementation is set in a game model to demonstrate a dynamic quest generation system built to present 
users with unique and compelling experiences linked by context to past quests and/or experiences. This 
is achieved by utilizing history and relationships developed through interaction between world objects 
and actions. Categories and Subject Descriptors I.2.1 [Applications and Expert Systems]: Games  General 
Terms Design and Experimentation  Keywords Multiplayer Games, MMORPG, Interactive Narrative, Contextually 
Linked Goals, Dynamic Quest Generation, Story Generation, Game AI Permission to make digital/hard copy 
of part of this work for personal or classroom use is granted without fee provided that the copies are 
not made or distributed for profit or commercial advantage, the copyright notice, the title of the publication, 
and its date of appear, and notice is given that copying is by permission of the ACM, Inc. To copy otherwise, 
to republish, to post on servers, or to redistribute to lists, requires prior specific permission and/or 
a fee. FuturePlay 2007, November 15-17, 2007, Toronto, Canada. Copyright 2007 ACM 978-1-59593-943-2/07/0011...$5.00 
 1. INTRODUCTION Persistent game worlds, such as World of Warcraft, have inherited a number of conventions 
established in standalone games that have prevented users from enjoying the unique experience that persistent 
systems have the potential to offer. The most notable conventions are leveling, a reward system that 
presents quantified status points to players for completing tasks, and questing, the act of receiving 
and completing designer defined goals in return for level rewards. Combined with the desire for a narrative 
component in persistent game worlds these conventions force designers to offer their users a finite set 
of scripted quests that all users experience in a similar fashion. Although these conventions allow for 
an enjoyable experience they prevent the user from truly molding their quest or story paths into a unique 
and personal one that they can identify with. A potentially better approach then, would be to determine 
possible quests for a user and then select the most relevant quests to what the user has done in the 
past [18]. In turn this will help drive a user s unique quest experience over their character s lifeline. 
Noting the lack of unique quest experience inherent in persistent game worlds such as World of Warcraft, 
we have designed an open-ended framework that more naturally utilizes the interactive and persistent 
properties of MMO systems. This aids in producing an interactive impact similar to dynamically authored 
interactive systems that most designers of persistent worlds have failed to capture properly in practice. 
In an effort to create a framework that is capable of dynamically generating contextually linked and 
meaningful quests there were some key design principles that had to be addressed. As actions and interactions 
occur between users and the persistent world they must be tracked and the system must be updated accordingly 
so the quest generation system can create quests that are unique to the current state of the world. While 
examining these interactions and actions, the system must be capable of generating quests that are both 
relevant and meaningful to a user s experience. This must be achieved without any long-term quest paths 
or end goals as a constraint because the framework is meant for persistent worlds. This does not infer 
that quest paths cannot end up achieving a meaningful end state, however, they should not be driven by 
such a goal. It is also important that the information tracked by the system is properly managed so that 
it does not grow to large to handle, which in turn could slow the system down with meaningless searches 
for relevant information. Our framework, TRUE STORY, attempts to address these design principles and 
the related work section below describes how the framework was influenced, formulated, and modified to 
scope beyond just MMO games.  2. Related Work The problem of dynamically authoring narrative into an 
interactive experience is nothing new. Numerous games and academic papers have been dedicated to exploring 
and discussing the topic [10] [1] [9] [14] [20] [3] [18]. While the seed for the concept of TRUE STORY 
came directly from analyzing the attempts made by numerous games in the MMORPG genre, the majority of 
the initial design was informed from research in the Interactive Drama (ID) domain. The recent establishment 
of Interactive Drama as a new medium has generated a number of academic papers and example implementations 
related to the combination (or separation) of interactivity and storytelling. 2.1 Conditions and Contextualization 
The unifying characteristic between the examined systems was an underlying driving force, or planner, 
that progresses the storyline or interactions of the system. It became apparent, however, that there 
had been little work to incorporate these ideas into a dynamic quest generation system and less yet towards 
dynamic quests in persistent worlds based on player interaction. By utilizing the principles learned 
from reviewed work we were able to design an open-ended framework capable of creating unique quest experiences 
for users in persistent systems. In order to achieve a generalized and open-ended quest generator it 
was important that we developed a framework that could incorporate any form of quest experience. Quests 
are limited to those defined for a particular system, but there is not limit on how many types of quests 
can be defined in a system utilizing our framework. Incorporating the defined quests and the principles 
of dynamically authoring narrative the framework is then capable of presenting a player with a unique 
questing experience and quest paths, one where each consecutive experience relates to previous interaction 
within the system. Quests that are generated are not driven by a specific story arc or plot focus, which 
is different from the work done in interactive drama. Some approaches to interactive drama direct users 
and story content by evaluating previous actions and deciding what plot line appears logical at the moment 
[10] [1] [18] [16] [19], however, since questing experiences are very different from dramatic experiences 
users should be capable of directing their own experience if presented with the proper opportunity space. 
This opportunity space is created by generating quests that are related to past experiences so a user 
can pursue a path that expands their knowledge of a previous experience. 2.2 Open-Ended Design Impro 
[6] in particular influenced our design through its initial defense of designing stories without knowing 
what the end goal is, thus speaking to how an interesting experience could arise within an interactive 
experience. A quote from an excerpted Johnstone conversation explains one of the major dilemmas faced 
with persistent worlds: I have to write a story and I m supposed to map out everything that s going to 
happen so that my teacher can mark it. She says it will stop me [from] writing the wrong things. Although 
this has been a traditional method of story generation the problem that arises is when a user experiences 
interactive drama from themselves, especially in real time and in a persistent, digital world, a designer 
cannot possibly predict what actions or choices that user may make. The only way to make such a prediction 
is by limiting the user s options and thereby limiting their experience. Some attempts have been made 
at modeling user preferences and generating story content based on such models [17] [9] [18], however, 
in a questing system this would limit the questing options being presented to a user. Users may want 
to change their questing preferences on a regular basis. TALE-SPIN s [11] focus was also beneficial in 
realizing how the use of attribute variables for characters could be used to add depth to the contextual 
links we developed in our implementation. Attributes help define how difficult a quest will be for a 
user to complete and can help narrow the quest space being presented to users. They also add an extra 
component for MMORPGs by giving users an incentive to increase attributes in order to achieve more complex 
quests, which is different than the traditional method of receiving more complex quests to increase attributes. 
 2.3 Layer Relationships Interestingly enough, an important trait that can help guide dynamic quest generation 
and is often overlooked involves neither of the aforementioned topics, but a third involving modeling 
relationships between characters. David Freeman, in his book Creating Emotion in Games, states a screen-writing 
tool used for mapping relationships between characters from film. He describes how he models basic relationships 
such as protective or jealous between the main characters in his game. Depending on which traits other 
characters are aware of then dictates how a character might react. Behaviors such as these relate to 
the overall believability of synthetic characters [15]. Adapting this trait layer technique to model 
relationships that can dynamically adapt based upon previous and current actions is at the heart of what 
makes TRUE STORY tick. TRUE STORY achieves this by maintaining relationship states between characters 
as well as mapping an individual s knowledge of how other characters are related to each other. Over 
time as a user continues to interact with characters in the system they naturally gain knowledge of these 
characters nuances, but in turn within the system the characters gain knowledge of the user s behaviors 
as well as other characters behaviors. Freeman also states clearly what separates good and bad stories 
Interesting, but also deep . This quote relates to any object or plot point, and it relates to the TRUE 
STORY framework as well. TRUE STORY s success comes from checking for possibilities that may present 
a user with an interesting and deep quest based on interactions that have occurred within the system. 
  3. TRUE STORY Framework TRUE STORY is a dynamic goal generation architecture for use in persistent 
systems where multiple users directly interact. The current implementation takes place within a text-based, 
medieval, persistent world implemented by us that makes use of traditional medieval roles. The following 
examples occurred at a state when the world consisted of roughly thirty rooms and twelve characters. 
 The purpose of TRUE STORY then is to systematically assign unique quests, such as a quest to avenge 
your brother s murderer, to users and objects continually, based upon some specified set of constraints. 
Constraints are predefined rules or preconditions that are required to be met for a quest to be presented 
to a user. The constraints used for TRUE STORY include the relationship between two characters, a character 
s past experiences (quests), performable actions such as attack, proximity to information and attributes 
such as thievery skill. These help dictate what a character is capable of accomplishing so the users 
are not assigned impossible tasks and by utilizing a user s memories as a constraint we are able to keep 
quests within a relevant quest path. As a user completes quests their memories and attributes are updated 
according to the task performed, which in turn opens up new quest opportunities. For example, if a user 
has brought numerous petty criminals to justice then the city guard may send that user on a quest to 
catch a more serious criminal since the user has proven their merit. While designers have the ability 
to define different constraints than those mentioned, constraints generally come in the following forms: 
 Memories: past quests in which a role has been played (either as protagonist, party member, or passive 
participant). For instance, in an example taken from our implementation user character A (please note 
that in our framework both user characters and non-playable characters are identical in function and 
form so all following examples can be created by a user character interacting with either another user 
character or non­playable character) has chosen to take the role of a thief and has stolen an object 
from character B, both characters within the system have now created a different memory of the account. 
Character A maintains a full memory of how the action took place and what was stolen while B, who in 
this particular instance did not catch A in the act, creates a memory of the item being stolen, but his 
memory does not include A as the thief in question. These memories are now stored and will help spark 
quests in the future. If character C now comes in contact with B, assuming user character C is a reputed 
lawman and is well known to be so by B, character B will dynamically generate a unique quest for C to 
find and bring the thief to justice. This quest will not be generated for other characters that are well 
known to be lawbreakers. It was necessary for A to maintain a memory of the account in order for the 
system to recognize when C has successfully completed the quest since A is the only character who holds 
an account of who actually stole the object. Since memories could be created at alarming speeds in a 
persistent world it is important that an appropriate method for memory management is designed. A persistent 
world must be capable of eliminating memories that are not useful and tracking those that are.  Attributes: 
designer defined object properties (ex: affinity, thievery, importance, health, damage, etc). These are 
used to see if a character has the capability to complete a quest. A character with no fighting history 
or qualifications will not be asked to take on an evil dragon until they have improved their merits. 
  Actions: designer specified actions that correspond to the types of quests characters could accept, 
offer, or earn memories from. Within the context of our system these involve talking with other characters 
to gain information, stealing, attacking, and examining the world around them. Using the current running 
example with character A, B, and C taken from the current system, C s actual assigned quest would either 
be to steal the item back or kill the culprit (character A) depending on the importance of the original 
item stolen. To recognize that this was a form of justice and not villainy the quest s reward is a positive 
affinity gain plus whatever B is offering as a reward. In order to accomplish this C would have to examine 
other characters until he discovered a character with the stolen item, which in our case this character 
would automatically be labeled as the thief. Given a more robust implementation there may be methods 
for extracting information to find the real thief if A has since dispersed of the item. Please note 
in a larger system there may be a different quest type to discover the culprit s identity and turn that 
character into the law, which would make more sense in this example.  Layers: relationships established 
between objects and/or their properties based upon context. Influenced by quest roles and/or relationships 
with other objects [5]. As players interact with others, relationships begin to develop. If character 
A continually steals from character B and give the items to character D then B will begin to develop 
a negative relationship with A while D develops a positive one. As an additional clarification, relationships 
can be established between characters and non-character objects if designers so choose, as they all derive 
from the same base class (our system implementation does not demonstrate this directly).  Proximity: 
designer defined area of affect to access memory information from game characters or objects. This is 
also a constraint that considers the networked environment and the need for search limitations in practice 
(typically a radius around each object, in our implementation information can only be gained from the 
objects in the current room). This allows for efficient memory searches in a reasonable time. As a user 
interacts with objects within the system they will maintain a memory of that interaction for use in future 
situations, but they cannot draw on information they have not previously learned or are not in proximity 
of.  In many cases quests cannot be generated until specific types of memories, attributes, or layers 
have been established. Using the running example we ll assume there is a non-playable character E who 
was designed as a thief lord who gives thieving quests to characters who are known thieves. Before E 
will actually generate a quest for A, A must have proven to be a strong thief. The current implementation 
recognizes A s capability based not only on their thievery attribute but also by A s memories of their 
successful thieving attempts. If A has performed numerous thieveries than E will search their memories 
of known important items and create a quest for A to steal one of these items.  Related to the concepts 
of constraints is the concept of relevancy. While constraints serve to limit the amount of information 
the system has to search, relevancy performs a qualitative check on the data that falls within that constraint 
space. What determines the relevancy of a quest is strictly up to the system designers. In TRUE STORY, 
a quest is relevant if it has some connection of memory producing capacity that ties into the users current 
memories and layers. Currently this check is primitive and does not actually score which quests are more 
relevant, however, within the context of the framework it can be developed to score relevancy based on 
designer specified constraints. For instance given our implementation, lets assume character A and E 
have formed a strong affinity with each other and character E is assassinated by an unknown assailant. 
As character A wanders the world looking for quests they may come across a character F who is able to 
generate a quest for A that involves the unknown assailant. Although this information is not conveyed 
directly, by involving A in a quest that includes the assailant, A has a higher probability of fulfilling 
their quest to kill E s murderer. This makes what may otherwise be a trivial quest far more relevant 
than others may be. By scoring relevancy to past actions it helps drive users to meaningful quest paths. 
Although other quests will be offered to a user at the same time, the most relevant quests can be offered 
first. The user does not see first hand the relevance of the quest, but is will begin to understand that 
these quests will help them discover important information. The approach to generate quests is twofold: 
first determine possible quests to generate, then select the most relevant (i.e. the most in context) 
quests to what the user has done in the past. The hypothesis, then, is that because the relevancy check 
ensures a user receives quests that are within context of previous quests/actions their character has 
taken, the resulting chain of events is interesting at worst, but compelling at best. The justification 
is that as a user progresses their character s lifeline they should naturally follow story lines that 
interest them by choosing quests with relevance to a particular story arc. This returns to the concept 
of allowing users to create their own dramatic situations through interaction. Additionally, the fact 
that the quests offered are unique to a character s situation, along with the character s actions having 
lasting effects on the persistent world, might suggest that the user will feel a greater sense of agency 
within the world they are essentially helping to craft (or at least by contrast to the previously scripted 
quest chains users were accustomed to).  4. User Interaction TRUE STORY can be thought of as a set of 
small systems interacting to produce emergent results (unique quests). In practice, quests are presented 
in a traditional manner, much like that of World of Warcraft. A user chooses to speak with other characters 
and those characters will in turn offer up information and quests (see Figure 1). The bulk of the underlying 
calculations of TRUE STORY are purposely made transparent to the user. The difference between TRUE STORY 
and a system like World of Warcraft is that the quests being presented to each individual character are 
unique, with a constantly changing world creating an avenue for new quests as the user seeds a character 
with new quest experiences and interactions. Each time a user completes a quest for another character 
in our system that quest memory is stored for all concerned parties. If character A is charged with stealing 
an item from character B by character E and successfully completes the quest then all characters will 
maintain a unique memory of the action. A will become more proficient in his thievery skill, B will now 
have a memory of having lost an item dynamically creating a quest to discover where the item has gone, 
and E will create a memory that A has helped them in the past thus granting A higher affinity with E. 
Although in the system s current state the information tracked is minimalistic with all changes to the 
world being similar to the one above in nature, the framework itself can provide for more comprehensive 
information tracking if the system is designed properly. Figure 1: General Quest Request As Figure 1 
illustrates, there are two similar ways a character becomes associated with a generated quest. The most 
typical interaction is for the character to ask (a.k.a. request) for quests from another character. Characters 
that have been requested for quests will run an offer routine that searches through the constraint space 
involving the two characters. For instance, character A has just asked character E for any quests they 
may have to offer. The system is now granted full access to A and E s memories, attributes, and layers. 
We ll assume A and E are as described before and that A and E have formed a trusting relationship because 
A has already done numerous thefts for E. Recently E has learned about an item of low importance and 
an item of high importance. Due to the nature of the items, E can now offer two separate quests to A. 
The first quest might be to obtain the item of low importance by any means possible and the second quest 
may be to obtain the item of greater importance while also eliminating any evidence of the crime. This 
may include assassinating any witnesses. The offering character will then present the asking character 
with this finite set of the most relevant quests that can be accepted. Quests that may not be offered 
may include stealing an item of no importance of simply gathering information about other items of low 
importance. The second method of becoming associated with generated quests is through generic quests 
that are automatically offered to other characters. For example, in the implementation we developed to 
demonstrate TRUE STORY, a generic Steal quest for an item of arbitrary value can be offered to any player 
that has a high enough theft attribute regardless of their relationship with the offering character. 
This allows characters to continually work on their skills by accepting generic quests to help build 
them up for more interesting assignments. Beyond the user-based characters, non-playable characters (NPCs) 
are also treated within the system with the same logic that user characters are. They are introduced 
into the world as normal users with heavily pre-seeded memories and as the world adjusts their memories 
and attributes in turn adjust along with the world. Their adjustment along with the world is critical 
to the system so that users may carve a name for themselves in their new interactive realm. As character 
A begins to accomplish larger feats, NPCs in the realm will begin to gain memories of the user s character 
and may even recognize them on sight if they gain enough fame. This may also help NPCs to create quests 
against or for a user s character. If a user has become a well-known justice seeker the villains in the 
interactive realm may want the user eliminated while other justice seekers may actively search for the 
user for aid. With enough space allocated for memories, this underlying social network could produce 
some impressive quests based upon long-term memories. Character A may find that the NPC they saved at 
the beginning of their career has grown into a king or perhaps even a thief lord. Character A may then 
be called on during a much later date in their interactive career to perform a new deed or perhaps be 
saved from certain death by such an NPC.  Finally, it is worth noting again that the key component of 
TRUE STORY revolves around the fact that the system does not use any long-term quest paths as a constraint. 
As rationalized in many of the above sections, a long-term goal would add an end state that is undesirable 
inside of a persistent game system. The purpose of TRUE STORY is to subvert the need for an end state 
entirely by keeping the player consistently engaged by discovering the unique path they are choosing 
to follow. A user could begin a quest path to discover the murderer of a well-known friend and, once 
the assailant is found, bring them to justice. All the while the user has completed numerous quests along 
their journey, which in turn has opened up new quest paths for them to explore. Although no dialogue 
has been implemented into our system a user is still capable of following meaningful quest paths that 
have a strong story element to them. Infusing meaningful dialogue into the system could only make it 
stronger, but for the sake of dynamic quest generation and quest path generation is not necessary. Although 
such a quest path as defined above is possible within our current implementation, one place our implementation 
currently falls short is rating how relevant quests are to a specific quest path. Currently the system 
only decides whether a quest is relevant to the character seeking quests. In the future it will be necessary 
to explore assigning quests relevancy weights. As relevancy builds the character can pursue a meaningful 
story that models a real life experience and although the story may come to a conclusion or the user 
may feel the story they are following is complete, there was no real objective in mind outside of a meaningful 
interactive experience. However, the Future Work section describes some potential uses of this system 
in conjunction with end-state allowable implementations.  5. Implementation For the implementation of 
TRUE STORY a simple text based persistent world is used. The environment consists of a series of rooms 
interconnected in a two dimensional plane. All other objects in the world reside either in a room or 
within another object including characters. Rooms are themselves an individual class. Rooms are the boundaries 
of the world and can contain any number of objects. A room can also be linked to up to four other rooms 
in the directions north, south, east, and/or west. Within the boundaries of the world, all interactions 
occur between characters and equipment. Both of these were grouped higher into an all­encompassing class 
called object , which is the base class for all interactions. Categorizing all physical things in the 
world as objects makes it easy for all interactions to occur through objects and allows the model to 
be easily extendable. Even if new object types were created such as food they would be subject to the 
same interactions as characters and equipment with a few new interactions specific for food. Methods 
have been created to add rooms, items, characters, and features to the world as the programmer sees fit. 
In order to add something to the world it was necessary that the object be seeded with the correct information 
(armor has specific defense values, characters have to be given attributes and characteristics, etc.). 
The interactions between objects used in TRUE STORY were earlier defined as quests. The quests chosen 
for this implementation were: Kill: an interaction where an object in the world is trying to eliminate 
another object within the world.  Steal: an interaction where an object (in our model a derived character 
object), is trying to take a different object from a third object, another character.  Discover: occurs 
when an object is dropped or has been stolen in the world and the initial owner would like to discover 
where that object is now.  Retrieve: occurs when an object would like to retrieve a separate object 
in the world, but does not demand that the desired object is necessarily stolen or retrieved in a particular 
fashion.  The system will have more quest options to choose from as more quest types are created and 
a user will be given a wider variety of quest paths. A designer can limit the dilemma of the system creating 
too many quest paths by only allowing the user to choose from a smaller subset of the most relevant quests 
or by limiting the number of quests that can be given. Although the interactions themselves are important 
to the system as a whole, the main feature of our implementation is how these interactions are chosen 
and executed between objects. Although a user may engage in any action at any time of their own accord, 
each object also contains a set of memories, which in this case are actions that a character has either 
participated in actively, or been a part of passively. The driving example as been if character A steals 
from character B, but B does not catch A in the act. These memories are important for establishing the 
context in which future events happen. At any time a character may perform a steal or kill action, which 
is then translated into a self-given quest, but doing so will directly affect their interactions with 
other characters. Each object also contains a set of attributes. For this implementation the attributes 
chosen were health, damage, thievery skill and affinity. The affinity variable chosen is essentially 
a relationship value (negative meaning dislike, positive meaning like) between a user an all other characters 
in the world as well as a user to the world around (just because character B strongly dislikes character 
A does not mean A is negatively perceived in the world because A may have performed far more positive 
deeds than negative ones). Based on the values of these attributes interactions are further conditioned 
to react accordingly.  It is important that a method for obtaining quests is defined beyond the interactions 
and attributes of characters. For TRUE STORY each character is capable of asking any other character 
within the same room (the proximity limitation) for quest options. After a request has been made, the 
character asked will scan through their memories and the asking character s memories to find any relevant 
ties. Each character has two sets of memory, which includes a long-term memory and short-term memory. 
This was designed for the future implementation of memory decay. Long-term memories are events that will 
always remain important to the world. An example of a long-term memory would be if character A assassinated 
the current king of the land. Character A would maintain a long-term memory of accomplishing the act 
and everyone who heard of the assassination would maintain a long-term memory that someone had assassinated 
the king. Short-term memories on the other hand are trivial memories that should only matter for the 
moment. Such a memory might include if character A stole a loaf of bread from character B. Both characters 
should only maintain the memory for a short period of time. Once memory has been properly searched, the 
character asked (B) would have knowledge of any interactions they have had with the requesting character 
(A) or any interactions they have learned that the requesting character has taken over time. If A makes 
a request to B, even if B has not personally interacted with A they may have prior knowledge of A ever 
trying to steal something or trying to kill someone that B is close to then B may be inclined to end 
all voluntary interaction with A depending on the circumstances. Vice versa, if A tried to steal or murder 
from a mutual enemy of B then B may be more inclined to help A out. Now that memory has been addressed, 
if A has made no prior transgressions against B, the attribute values would be checked. For instance, 
if B has any steal quests that could be created or that were already created they would only be offered 
if A has attained a sufficient level in their thievery attribute. B might also offer specific kill quests 
on a third character if A had enough health and a weapon that was capable of doing sufficient damage. 
This shapes interaction because B may offer a kill quest to character A, but not to character C based 
on their current attributes. This also helps in driving game play much like World of Warcraft uses levels 
to decide whether a player is capable of completing a quest. It is clearly shown that all interactions 
done within the system could have a direct result on future interactions. If a character A steals from 
a character B they may soon become a victim of another steal interaction that character B requests of 
character C. In order to clearly demonstrate these results the main user is allowed to control all characters 
within the system. This is to simulate a multi-user environment within a single user environment as no 
networking code has been implemented. The user can switch between characters using a simple command (switch) 
and then observe the memories and attributes of that specific character. Certain characters are also 
seeded with pre­scripted memories as to simulate non-playable characters that might exist within a multi-user 
environment. These seeded characters are used to drive the initial interactions before actual users have 
created more memories. As stated previously, these characters are treated like normal characters because 
they will interact with the world in similar ways through memories and interactions. This is why the 
user is also allowed to control these characters. A full scale MMORPG would play out the exact same way 
with the caveat that it would have much more information to handle. Characters would still be able to 
interact in the exact same ways. A full scale MMORPG may also have implemented more meaningful interactions, 
which would still come in the form of a quest class since all interactions are required to be of a quest 
form, and have better defined social roles. It may also include more attribute values. 5.1 Program The 
program itself was implemented in a Linux environment using only C++ and a text-based world. All actions 
are performed through a text prompt where commands are input. Only the room the user is currently in 
is displayed to the user with its current exits. The user can also see what other objects exist in the 
room beside themselves. All the commands a user can issue are documented and can be seen using a help 
command. After beginning the simulation it is up to the user to create interactions and see how they 
develop the world around them. The user is also capable of creating specific interactions at any point 
in time so they can manipulate the world as desired and view the affects.  6. Discussion TRUE STORY 
has been a positive step towards the dynamic generation of contextually linked quests. Its implementation 
demonstrates that designers of persistent worlds can provide unique content to all of its users by utilizing 
the constraints set forth by our framework, however there remains a lot more to be explored, implemented 
and expanded upon. The current design of the TRUE STORY framework incorporates some important design 
principles that have proved invaluable to the framework. The first principle addressed is that the framework 
is providing a method to track information in persistent worlds to generate unique and interesting quests. 
This is accomplished by utilizing history, relationships and other constraints set forth by the implementer 
of the framework. Although the current implementation only accomplishes this on a rudimentary level it 
does successfully show that unique quests can be generated solely based on user interactions with the 
persistent world they are taking part in. The second principle addressed is that the framework does not 
utilize any long-term goals or conclusions to generate contextually linked quest paths. Rather it utilizes 
previous experiences to try and drive future experiences in a meaningful way. In this way the user can 
create an endless chain of experiences and quests that they are able to accomplish over time. The current 
implementation drives unique experiences based on memories and relationships; however, it does not yet 
drive quest paths in a meaningful way. Currently it falls on the user to choose which quests they feel 
are most relevant to their character s past experiences. Regardless, the current implementation does 
provide for unique questing experiences even if they are not yet tied together through relevancy. Having 
a quest generation tool like this is the next step to creating unique persistent worlds that utilize 
a questing system. Based on the components of the framework (memories, attributes, actions, layers, and 
proximity) it may be possible to adjust the framework to suit an interactive drama setting as well. One 
example would be to adjust constraints so that the quests presented were forced to model a story arc 
like the Hero s Journey [2]. This has not been tested; however, the design is done in such a fashion 
that if constraints are properly implemented it can accommodate almost any form of quest path generation. 
By expanding the actions possible for characters and modifying the constraint space we will be able to 
test how our framework adjusts to more structured settings.  Although the current implementation demonstrates 
some important aspect to dynamic quest generation there are some important aspects that need to addressed 
for a larger setting. It is clear that a multi-user environment will not affect the performance of the 
system since the current implementation can be seen as a multi-user environment. Although only one character 
is able to act at a time they are all treated by the system in the exact same manner so with multiple 
users the system would simply be handling more actions at a time, not new actions however. This is already 
accomplished in MMORPGs and therefore should not pose a problem. The biggest scalability issue comes 
from memory management. As more users are infused into the system more memories and quests will be created 
at a rapid rate. It is important that the designer chooses a device for deciding whether a quest should 
be stored in memory or simply discarded. By choosing important memories this memory space can be kept 
manageable. Different forms of memory decay could also be implemented to discard old memories that are 
no longer applicable to the world. Although this may shrink the possibility space for dynamically generated 
quests with high relevancy it would not prevent the system from generating random quests for the sake 
of continuity. These random quests could help produce attributes and possibly provide important interactions 
to help generate future quests.  7. Future Work The first component we would like to address in the 
future is the lack of an online or networked version of our implementation. Proving that this program 
could run efficiently on a networked setting would be a strong step. Additionally, in the future it would 
benefit the usability to add a graphical component to the system. A graphical component is not crucial 
though. On the simulation side, the main goal is to expand the current implementation with more actions/quest 
types, to demonstrate the richness of emergence that can occur through the interactions between a simple 
set of quests. Also, we need to look into creating a memory decay function for eliminating memories. 
We ve already implemented an importance attribute that will help decide whether events are important 
enough to move to long-term memory and how long a memory will remain in short-term memory before decay. 
We need to incorporate this to see how it affects the believability of characters that forget past actions. 
 8. REFERENCES [1] Barber, H. 2006. Adaptive Generation of Dilemma-based Interactive Narratives. The 
Ninth International Conference on the Simulation of Adaptive Behavior. [2] Campbell, J. September 2003. 
The Hero s Journey: Joseph Campbell on His Life and Work. New World Library; 1st New Wo edition. [3] 
Crawford, C. 2004. Chris Crawford on Interactive Storytelling. New Riders Games. [4] Fairclough, C. and 
P. Cunningham. 2004. A Multiplayer O.P.I.A.T.E. Int. J. Intell. Games &#38; Simulation 3(2): 54-61. [5] 
Freeman, D. September 15, 2003. Creating Emotion in Games: The Craft and Art of Emotioneering. New Riders 
Games; 1st edition. [6] Johnstone, K. June 1999. Impro for Storytellers. A Theatre Arts Book; 1st edition. 
[7] Koster, R. November 6, 2004. Theory of Fun for Game Design. Paraglyph; 1st edition. [8] Lebowitz, 
M. 1984. Creating Characters in a Story-Telling Universe. Poetics 13; 171-194 [9] Magerko, B. 2007. A 
Comparative Analysis of Story Representations for Interactive Narrative Systems. Artificial Intelligence 
and Interactive Digital Entertainment Conference. [10] Mateas, M. and A. Stern. 2003. Façade: An Experiment 
in Building a Fully-Realized Interactive Drama. Game Developers Conference. [11] Meehan, J. 1981. Tale 
Spin. In Inside Computer Understanding, edited by R. Schank and CK Riesbeck. New Jersey: Lawrence Erlbaum 
Associates. [12] Perlin, K. and A. Goldberg. 1996. Improv: A System for Scripting Interactive Actors 
in Virtual Worlds. The Improv System Technical Report NYU Department of Computer Science. [13] Propp, 
V. 1969. Morphology of the Folktale. Trans. Laurence Scott. Ed. Louis A. Wagner. 2nd edition. Univ. of 
Texas Press. [14] Riedl, M. and A. Stern. 2006. Believable Agents and Intelligent Story Adaptation for 
Interactive Storytelling. 3rd International Conference on Technologies for Interactive Digital Storytelling 
and Entertainment, Darmstadt, DE. [15] Rizzo, P., M. V. Veloso, M. Miceli, and A. Cesta. 1999. Goal-Based 
Personalities and Social Behaviors in Believable Agents. Applied Artificial Intelligence, 13:239-271. 
[16] Roberts, D. L., A. S. Cantino, C. L. Isbell. 2007. Player Autonomy versus Designer Intent: A Case 
Study of Interactive Tour Guides. Artificial Intelligence and Interactive Digital Entertainment Conference. 
[17] Sharma, M., S. Ontañón, C. Strong, M. Mehta, and A. Ram. 2007. Towards Player Preference Modeling 
for Drama Management in Interactive Stories. Twentieth International Florida Artificial Intelligence 
Research Society Conference. [18] Thue, D., V. Bulitko, M. Spetch, E. Wasylishen. 2007. Interactive 
Storytelling: A Player Modeling Approach. Artificial Intelligence and Interactive Digital Entertainment 
Conference. [19] Weyhrauch, P. 1997. Guiding Interactive Drama. Ph.D. thesis, Tech report CMU-CS-97-109, 
Carnegie Mellon University. [20] Young, R. M., M. Riedl, M. Branly, A. Jhala, R. J. Martin and C. J. 
Saretto. 2004. An Architecture for Integrating Plan-based Behavior Generation with Interactive Game Environments. 
Journal of Game Development 1(1): 51-70.   
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2007</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>1328229</article_id>
		<sort_key>270</sort_key>
		<display_label>Pages</display_label>
		<pages>8</pages>
		<article_publication_date>11-14-2007</article_publication_date>
		<seq_no>3</seq_no>
		<title><![CDATA[Story scripting for automating cinematics and cut-scenes in video games]]></title>
		<page_from>152</page_from>
		<page_to>159</page_to>
		<doi_number>10.1145/1328202.1328229</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1328229</url>
		<abstract>
			<par><![CDATA[<p>Storytelling can play a very important role in the success of modern video games. Unfortunately, it can be quite difficult for writers to directly create and integrate story content into games on their own, and they must instead rely upon programmers and others on the development team to implement their stories. This needlessly complicates the game development process, leading to increased costs, more strain on developer time, and loss of creative control and, potentially, story quality as a result. Consequently, tools and supports are necessary to enable writers to generate story content for games directly, with minimal programming or programmer assistance required, if any.</p> <p>This paper examines the use of specialized story scripting elements to automate the production of cinematics and cut-scenes for video games. These elements allow writers to specify their stories in a well-defined, structured format that can be acted out automatically by software. This paper discusses these story scripting elements in depth, along with a prototype software engine capable of using these elements for cinematic and cut-scene automation. This paper also presents experiences with using this engine to recreate cinematics and cut-scenes from existing commercial video games.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[automation]]></kw>
			<kw><![CDATA[cinematics]]></kw>
			<kw><![CDATA[cut-scenes]]></kw>
			<kw><![CDATA[story scripting]]></kw>
			<kw><![CDATA[storytelling]]></kw>
			<kw><![CDATA[video games]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>H.5.1</cat_node>
				<descriptor>Artificial, augmented, and virtual realities</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>K.8.0</cat_node>
				<descriptor>Games</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010405.10010476.10011187.10011190</concept_id>
				<concept_desc>CCS->Applied computing->Computers in other domains->Personal computers and PC applications->Computer games</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10011007.10010940.10010941.10010969.10010970</concept_id>
				<concept_desc>CCS->Software and its engineering->Software organization and properties->Contextual software domains->Virtual worlds software->Interactive games</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003251.10003258</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Multimedia information systems->Massively multiplayer online games</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387.10010866</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces->Virtual reality</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003121.10003124.10010392</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)->Interaction paradigms->Mixed / augmented reality</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003121.10003124.10010866</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)->Interaction paradigms->Virtual reality</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Human Factors</gt>
			<gt>Languages</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP43145568</person_id>
				<author_profile_id><![CDATA[81342517239]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[W.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zhang]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The University of Western Ontario, London, Ontario, Canada]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P925257</person_id>
				<author_profile_id><![CDATA[81342504101]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[M.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[McLaughlin]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The University of Western Ontario, London, Ontario, Canada]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP43140343</person_id>
				<author_profile_id><![CDATA[81100424432]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[M.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Katchabaw]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The University of Western Ontario, London, Ontario, Canada]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Atlus. <i>Trauma Center: Second Opinion.</i> Published by Atlus, 2006.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1208681</ref_obj_id>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Bateman, C. <i>Game Writing: Narrative Skills for Videogames. Charles</i> River Media. 2007.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>383315</ref_obj_id>
				<ref_obj_pid>383259</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Cassell, J., Vilhjalmsson, H. and Bickmore, T. BEAT: The Behavior Expression Animation Toolkit. <i>SIGGRAPH 2001 Conference</i>. Los Angeles, California, August 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1214319</ref_obj_id>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Chandler, R. <i>Game Writing Handbook.</i> Charles River Media. 2007.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Cunningham, D., McMahon, H. and O'Neill, B. "Bubble Dialogue: A New Tool for Instruction and Assessment", <i>Educational Technology Research and Development, Volume 40, Number 2.</i> 1992.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1265866</ref_obj_id>
				<ref_obj_pid>1265616</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Cutumisu, M., Onuczko, C., McNaughton, M., Roy, T., Schaeffer, J., Schumacher, A., Siegel, J., Szafron, D., Waugh, K., Carbonaro, M., Duff, H. and Gillis, S. "ScriptEase: A Generative/Adaptive Programming Paradigm for Game Scripting". <i>Science of Computer Programming, Volume: 67, Issue: 1.</i> June, 2007.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1203951</ref_obj_id>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Davies, M. <i>Designing Character-Based Console Games</i>. Charles River Media. 2007.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[El-Nasr, M. Interaction, Narrative, and Drama Creating an Adaptive Interactive Narrative using Performance Arts Theories. <i>Interaction Studies, Volume 8, Number 2</i>, 2007.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>975094</ref_obj_id>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Glassner, A. <i>Interactive Storytelling: Techniques for 21&#60;sup&#62;st&#60;/sup&#62; Century Fiction.</i> A K Peters Limited. 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Goldman, W. <i>The Princess Bride.</i> 20&#60;sup&#62;th&#60;/sup&#62; Century Fox. September 1987.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1597334</ref_obj_id>
				<ref_obj_pid>1597321</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Gordon, A., van Lent, M., van Velsen, M., Carpenter, M. and Jhala, A. Branching Storylines in Virtual Reality Environments for Leadership Development. \ <i>Sixteenth Innovative Applications of Artificial Intelligence Conference (IAAI-04)</i>, San Jose, California, July 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1076618</ref_obj_id>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Krawczyk, M. and Novak, J. <i>Game Development Essentials: Game Story and Character Development</i>. Thomson Delmar Learning. 2006.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Lionhead Studios. <i>The Movies.</i> Activision. 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Magerko, B. A Comparative Analysis of Story Representations for Interactive Narrative Systems. <i>Third Annual Artificial Intelligence for Interactive Digital Entertainment Conference.</i> Marina del Rey, California. 2007.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Mateas, M. and Stern, A. Facade: An Experiment in Building a Fully-Realized Interactive Drama. <i>Game Developer's Conference</i>, San Francisco, California, March 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[McLaughlin, M. and Katchabaw, M. "A Reusable Scripting Engine for Automating Cinematics and Cut-Scenes in Video Games". <i>Loading &#8230; The Journal of the Canadian Game Studies Association, Vol. 1, No. 1</i>, May 2007.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1265861</ref_obj_id>
				<ref_obj_pid>1265616</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Moreno-Gera, P., Sierra, J., Mart&#237;nez-Ortizb, I. and Fern&#225;ndez-Manj&#243;na, B. "A Documental Approach to Adventure Game Development". <i>Science of Computer Programming, Vol. 67, Issue 1.</i> June, 2007.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Sperberg-McQueen, C. and Burnard, C., (eds). <i>Guidelines for Text Encoding and Interchange: XML-compatible Edition.</i> Published for the TEI Consortium by the Humanities Computing Unit, University of Oxford. 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Stern, D. "Duffless." <i>The Simpsons Episode 9F14.</i> 20th Century Fox Broadcasting Company. February 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[The TEI Consortium. "TEI Software". <i>Available at: http://www.tei-c.org/Software.</i> Last accessed July 2007.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Zhang, W. "Reusable Storytelling Engine". <i>MSc. Directed Study Report, The Department of Computer Science, The University of Western Ontario.</i> June 2007.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Story Scripting for Automating Cinematics and Cut-Scenes in Video Games W. Zhang, M. McLaughlin, and 
M. Katchabaw Department of Computer Science The University of Western Ontario London, Ontario, Canada 
N6A 5B7 wzhang95@csd.uwo.ca, mmclaug3@uwo.ca, katchab@csd.uwo.ca ABSTRACT Storytelling can play a very 
important role in the success of modern video games. Unfortunately, it can be quite difficult for writers 
to directly create and integrate story content into games on their own, and they must instead rely upon 
programmers and others on the development team to implement their stories. This needlessly complicates 
the game development process, leading to increased costs, more strain on developer time, and loss of 
creative control and, potentially, story quality as a result. Consequently, tools and supports are necessary 
to enable writers to generate story content for games directly, with minimal programming or programmer 
assistance required, if any. This paper examines the use of specialized story scripting elements to automate 
the production of cinematics and cut-scenes for video games. These elements allow writers to specify 
their stories in a well-defined, structured format that can be acted out automatically by software. This 
paper discusses these story scripting elements in depth, along with a prototype software engine capable 
of using these elements for cinematic and cut­scene automation. This paper also presents experiences 
with using this engine to recreate cinematics and cut-scenes from existing commercial video games. Categories 
and Subject Descriptors H.5.1 [Information Interfaces and Presentation]: Multimedia Information Systems 
 animations, artificial, augmented, and virtual realities; K.8.0 [Personal Computing]: General games 
 General Terms Design, Human Factors, Languages. Keywords Storytelling, automation, story scripting, 
cut-scenes, cinematics, video games Permission to make digital/hard copy of part of this work for personal 
or classroom use is granted without fee provided that the copies are not made or distributed for profit 
or commercial advantage, the copyright notice, the title of the publication, and its date of appear, 
and notice is given that copying is by permission of the ACM, Inc. To copy otherwise, to republish, to 
post on servers, or to redistribute to lists, requires prior specific permission and/or a fee. FuturePlay 
2007, November 15-17, 2007, Toronto, Canada. Copyright 2007 ACM 978-1-59593-943-2/07/0011...$5.00 1. 
INTRODUCTION Storytelling is widely recognized as an important element of modern video games [2,9,12], 
and in some cases is regarded as one of their most defining aspects [7]. Some predict that storytelling 
in games will continue to grow in prominence as new hardware and technologies create more opportunities 
for stories in games, and shifts in player audiences increase the demand for the inclusion of quality 
stories in games [4]. Delivering story in games, unfortunately, can be a challenging task. While story 
creation is naturally the responsibility of writers on the development team [2,17], these writers traditionally 
must work with programmers and others on the team to integrate story content into the game being developed 
due to the complexity involved and programming expertise required. This, however, can be expensive in 
terms of budget and scheduling resources [6], which is problematic considering the limitations often 
in place in creating story content for games [2]. Furthermore, this introduces a gap between storyteller 
and story [6], which can impact the creative process and overall story quality as a result. Consequently, 
a simpler, more streamlined story creation process for games is necessary a need recognized for some 
time by industry practitioners [2,6]. Automating storytelling can alleviate these issues by allowing 
writers to tell their stories in games with minimal programming or programmer support required, if any. 
Following this approach, tools and supports would allow writers to convey their stories in natural language, 
graphically, or in some other simple form, while automation prepares this story content for use with 
little or no human intervention required. Unfortunately, work in this area is relatively scarce, as discussed 
in Section 2 of this paper, and many outstanding problems remain unresolved as a result. Aside from in-game 
storytelling embedded in gameplay, cinematics and cut-scenes are two of the more common techniques for 
storytelling in games, conveying story through visuals and audio, typically presented much like a dramatic 
piece [12]. Our current work is a continuation of our earlier work in this area towards the development 
of a Reusable Scripting Engine designed specifically for automating cinematics and cut-scenes in games 
[16]. Our earlier work primarily focused on the core elements of the Reusable Scripting Engine, establishing 
an architecture and workflow that took story content from authoring tools through to presentation. While 
this allowed basic cinematics and cut-scenes, this did not enable robust presentations with the high 
level of production values necessary for most modern video games. Consequently, our current work has 
focused on providing enriched story scripting elements, giving writers considerably more power, flexibility 
and expressiveness in story creation than our earlier work. This paper introduces and discusses the 
details of our enhanced story scripting elements for video games, as well as their integration into our 
Reusable Scripting Engine platform. This paper also describes our experiences through using these enhanced 
elements to replicate cinematics and cut-scenes from commercial games, thereby demonstrating their effectiveness 
and suitability in automating the story creation process for video games. The remainder of this paper 
is organized as follows. Section 2 presents related work in this area, both from research and industrial 
perspectives. Section 3 discusses story scripting for video games in general, and describes the scripting 
elements and approach taken in our current work. Section 4 presents the design and implementation of 
our proof of concept system, the Reusable Scripting Engine. Section 5 discusses our experiences from 
using this prototype, in particular presenting a case study in replicating cinematics and cut-scenes 
from commercial video games. Finally, in Section 6, we conclude this paper with a summary and a discussion 
of directions for future work. 2. RELATED WORK This section discusses relevant related work, both from 
research and industrial perspectives. As mentioned in the previous section, however, work towards automation 
to directly support writers in their storytelling and story creation efforts for video games is relatively 
scarce. Nevertheless, progress is being made, and related work has many lessons to teach us, even if 
direct support for writers is not being offered. One notable work is ScriptEase [6], an innovative pattern 
and template-driven approach, primarily aimed at in-game storytelling and behaviour control of non-player 
characters. In theory, the same framework could be extended to support cinematic and cut­scene generation, 
but this has not been done to date. Work towards the <e-Game> engine [17] is also very promising. While 
primarily targeted at the development of adventure games, the XML-based <e-Game> language could be used 
to assist in the creation of cinematics and cut-scenes. The language, however, is geared towards game 
creation, and was not specifically designed with cinematic and cut-scene creation in mind. (In fact, 
it would appear from [17] that cinematics and cut-scenes are intended to be handled using pre-rendered 
movies instead of being specified and acted out by the engine itself.) Interesting work also comes in 
the form of Bubble Dialogue [5], developed primarily as a tool to investigate communication and social 
skills, particularly in educational settings. Bubble Dialogue, however, is intended to be a stand-alone 
tool not suitable for embedded use in video games, and it is questionable whether its interface, designed 
for novices to easily construct stories, would be expressive, flexible, and powerful enough for professional 
game writers. The Behavior Expression Animation Toolkit (BEAT) [3] is also relevant to story automation 
for games. Text is input to the system to be spoken by an animated character. As output, speech is generated, 
along with synchronized nonverbal behaviours that appropriately match the text according to rules based 
on human conversational patterns. This system is quite powerful and flexible, but as noted in [3], lacks 
many of the elements necessary to provide a complete performance on its own. It is designed, however, 
to plug into other systems for this purpose, and so could rely upon our own Reusable Scripting Engine 
for this support. Likewise, our system could benefit by having interesting and appropriate behavioral 
animations that are made possible by BEAT, and not available in our current prototype. The work is quite 
complementary. Work towards interactive storytelling in games, such as the work in [8,11,15] and other 
examples discussed in [14], is also related, in that it involves story automation and story representation. 
In this case, automation tends to involve the synthesis of story emerging from the interactions between 
player and non-player characters in the game, with artificial intelligence controlling the non-player 
characters, according to authored constraints on behaviour. Our work, on the other hand, does not deal 
with interactivity, and so storytelling is driven entirely by the originally authored story. As a result, 
story representation for interactive stories can be significantly more complex, as additional elements 
are required to support and specify interactivity. This makes the process of story creation for interactive 
stories more like programming and, consequently, less friendly to writers with little or no programming 
experience. Our approach, on the other hand, avoids this complexity and burden on writers for cut-scenes 
and cinematics, where interactivity in the story is not required. Other related work can be found in 
an interesting commercial video game entitled The Movies [13]. While this game allows players to construct 
their own stories for their own films, the general approach and interface might not be the most productive 
or easiest one for writers to use in crafting stories for use in other games. From an industrial perspective, 
as noted in [6,17], the video games industry has adopted a variety of standard and custom languages to 
be used in the development of games. These languages are used for many purposes, including the scripting 
of cinematics and cut-scenes. Unfortunately, while these languages improve and simplify matters somewhat, 
they are still rather complex and technical in nature. Consequently, writers still must rely upon at 
least some programming talent to integrate their stories into games [6]. In the end, much work is still 
required to assist writers in the story creation process for video games. 3. STORY SCRIPTING FOR VIDEO 
GAMES Stories must be properly scripted to be automatically presented within a video game. This scripting 
identifies characters, dialogue, stage directions, setting, and other elements common to traditional 
dramatic pieces. Fortunately, writers must already define these elements for cinematics and cut-scenes 
constructed according to traditional story creation processes [2], so the need for this information is 
not a new imposition created by automation. For automation to be effective, however, stories must be 
scripted in a precise and formal manner to avoid potential ambiguity and confusion over the interpretation 
of the script by the software automating its presentation. Consequently, there is a need to provide a 
structured and standardized approach to scripting for storytelling within video games for automation 
efforts to be successful. 3.1. Encoding of Dramatic Pieces As mentioned above, story scripts for games 
contain largely the same elements that can be commonly found in traditional dramatic pieces. Consequently, 
instead of developing our own custom language for specifying stories for games, as is frequently done 
in the literature in this area, we turn to efforts towards the standardization of encoding dramatic pieces, 
led by the Text Encoding Initiative (TEI). These efforts have led to the development of an XML-based 
specification for marking up various kinds of texts, including dramatic pieces [18]. TEI guidelines provide 
an extensive set of tags for structuring dramatic pieces and identifying all of the elements listed above 
that must be defined for cinematics and cut­scenes in video games. Consequently, the TEI guidelines for 
dramatic pieces provide an excellent starting point for adding precision and formality to script specifications 
for automated presentation in video games. XML, however, is not the most natural or convenient method 
of expression for writers to use in creating their stories. Requiring writers to produce stories with 
manually embedded TEI tags needlessly complicates the process, and could be a barrier to story creation. 
To assist in the process of working with TEI tags, there are numerous software packages available that 
adhere to TEI guidelines for importing existing works or writing them from scratch [20]. Several of these 
packages plug into existing word processing or office productivity software, or otherwise work with this 
software, to ensure that writers can work with familiar tools and still take advantage of the TEI guidelines. 
This can greatly facilitate the story creation process, particularly when it comes to automation. In 
the end, however, we could not completely follow TEI guidelines in our current work, and instead had 
to derive slightly tailored guidelines for automation purposes, with some modifications and extensions 
to the existing TEI guidelines. This was necessary for several reasons: x TEI guidelines require information 
that does not quite make sense or fit well within the realm of cinematics or cut-scenes for video games. 
 x Many elements in the TEI guidelines are not formal or precise enough for our purposes. For example, 
stage directions in the TEI guidelines are too open and too flexible; additional structure and formality 
needed to be applied to ensure these directions could be followed automatically. x Additional elements 
were required to link game content and assets into story scripts. For example, character models, scenery, 
and other art assets must be identified and linked with corresponding elements within scripts, as well 
as audio assets for music, voice-overs, and so on. x Other new elements were necessary to make managing 
story content within a game easier. For example, dialogue elements needed to be in manageable units that 
could be displayed on­screen and linked with voice-overs as necessary. 3.2. Story Scripting Elements 
The final collection of story scripting elements used in our current work was derived from two sources. 
The first source, naturally, was the TEI guidelines themselves. Since these guidelines were developed 
based on the collaboration of experts in dramatic writing, they provide a reasonable set of elements 
with which to begin. The second source was an examination of cinematics and cut-scenes from several commercial 
video games of various genres from multiple platforms. This second source validated the elements from 
the first source, and identified refinements and other elements necessary, as discussed in the previous 
section. The primary story scripting elements defined in our current work are depicted in Figure 1, showing 
the overall structure to our scripting schema. The main elements of this schema are briefly discussed 
in the subsections that follow. A full XML specification of this schema and a complete discussion of 
all of the story scripting elements defined within the schema can be found in [21]. 3.2.1. The Performance 
The Performance element is the top-level element for a cinematic or cut-scene. It identifies the name 
of the performance, as well as its place in the game. Its main purpose is to contain the Front Matter 
and Body for the cinematic or cut-scene, which provide the actual specification for the performance. 
 3.2.2. Front Matter Front Matter is used to contain definitions of all of the elements to be used when 
the performance is acted out according to specifications in the Body, as described below. This includes 
the cast list for the performance, as well as a list of set materials, overlays, dialogue elements, sound 
effects, music, and voice­overs. This also includes a media element specifying, among other things, where 
media files for the various elements can be found. The cast list defines every character that makes an 
appearance during the performance, as well as narrator characters that are heard but not necessarily 
seen. Each character may have multiple models, allowing them to appear in multiple costumes or multiple 
poses during the performance. The set list defines backdrops for the scenes of the performance. Overlays 
are essentially set elements that can be placed within a scene to create depth as characters can move 
both in front of and behind them. Dialogue  Figure 1. Schema Structure for Specifying Story Elements 
for Cinematics and Cut-Scenes. Elements consist of dialogue areas into which text is rendered, definitions 
of fonts used to render text, and various options defining how and where this is done on-screen. The 
sound effect list identifies sounds that can be queued at any point throughout a performance. The music 
list defines background music that can be played or looped during a performance. Lastly, the voice-over 
list specifies speech effects that can be linked to lines of dialogue that appear in the Body of the 
performance. 3.2.3. The Body The Body of a performance is used to specify the sequence of actual activities 
that constitute the performance using the elements defined in the Front Matter. The Body essentially 
consists of one or more scenes, based on the sets defined in the Front Matter. Scenes, in turn are composed 
of collections of dialogue elements and stage directions. Dialogue elements are used to specify the narration 
and conversational elements in the performance. Each dialogue element is tied to a particular speaker 
(either an on-screen character or narrator), and consists of lines. Lines contain text, references to 
voice-overs to contain the narration or conversation of the dialogue, or both. Each dialogue element 
also carries with it a tone, allowing dialogue to be linked to changes in characters or dialogue areas 
to indicate the emotional context of the dialogue. Stage directions are used to define all of the non-dialogue 
activities that occur during the performance of a cinematic or cut­scene. Movement directions bring characters 
on-screen, move them while on-screen, and move them off-screen when their part in the performance is 
done. Costume changes substitute the active character models in use for the characters in the performance. 
These can be used to make costume changes, as the name implies, or can be used for other purposes, such 
as changing the tone used by a character in dialogue. Set and overlay changes switch the current backdrop 
for the scene or alter the presence or positioning of items in the scene. Lighting changes adjust the 
lighting on scenery objects, characters, or both by increasing or decreasing light intensity, or by changing 
the colour of the lighting that is applied. Music and sound playback elements are used to control the 
playback of music and sound effects respectively. There are also a variety of effects elements that are 
capable of providing a variety of miscellaneous effects during a performance. These include atmospheric 
effects (such as fog or smoke), transformation effects (such as flipping or rotating objects), and various 
special effects (like object transparency). Lastly, interactivity elements are used to enable various 
types of interactions with the player of the game as they watch the cinematic or cut-scene in question. 
This includes pausing the performance for a period of time, waiting for user input (such as a key press 
or mouse button to indicate that the performance should proceed), and allowing the user to cancel the 
performance before it has ended.  4. PROOF OF CONCEPT Having defined the story scripting elements of 
our current work in the previous section, in this section we examine the design and implementation of 
a proof of concept software engine capable of processing these elements and presenting a cinematic or 
cut-scene automatically as a result. This software engine is called the Reusable Scripting Engine. 4.1. 
Engine Design To illustrate our design, we present the architecture of our engine in Figure 2, and then 
proceed to discuss the major modules of this architecture in the subsections below.  Figure 2. Reusable 
Scripting Engine Architecture. 4.1.1. Director The primary role of the Director in the engine is to manage 
the Script Reader and Stage Manager modules to oversee the entire production and presentation of the 
cinematic or cut-scene. As such, it handles internal object management and communication tasks as required 
for the engine. The Director module is also responsible for managing any interactions with the user of 
the engine, which, depending on the context, could either be the player of the game in question or the 
game itself. These interactions could include interactivity control to regulate the flow of the cinematic 
or cut-scene, as well as any other access required to the engine. 4.1.2. Script Reader As the name implies, 
the Script Reader module reads in the story script, crafted by a writer using an appropriate authoring 
tool, and processes it to prepare it for use in the engine. This requires the module to parse the XML 
representation of the script to find the elements of the story, verify the correctness and completeness 
of the script, and fill in any missing or assumed elements of the story where possible. When the script 
is deemed ready for performance, the Script Reader generates a collection of actions from the script, 
creating a performance, and passes this performance on to the Director module to have the performance 
executed. 4.1.3. Stage Manager The Stage Manager module is responsible for generating the actual on-screen 
performance of the story script read in by the Script Reader module. This module receives its direction 
on what to do, how to do it, and when to do it from the Director module, which is basing its directions 
on the collection of actions generated by the Script Reader. The Stage Manager also reports back to the 
Director on the status of the production as it progresses. Any commands or directions received from the 
Director are executed immediately, to provide the Director a good measure of control over how the story 
is presented. 4.2. Engine Implementation Based on the architecture discussed in the previous section, 
we have implemented a prototype engine for Microsoft Windows XP, written in C# using Microsoft Visual 
Studio 2005 Professional Edition. To enable script processing, Microsoft s XML Software Development Kit 
was used, as it provides easy to use and robust XML processing and handling facilities when working in 
this environment. For graphics and audio support, Microsoft DirectX was used. This provided us with clean, 
standard, and efficient support for both 2D and 3D graphics, as well as audio support, all in a single 
package. This also resolved outstanding issues from our earlier prototype [16] that primarily arose from 
our choice of rendering engine at the time. Consequently, this engine prototype is significantly more 
robust, efficient, and feature-rich than its predecessor. Our engine implementation provides both a standalone 
processor that can generate cinematics and cut-scenes on its own, and a module that can be linked in 
with other code. These options provide developers with flexibility in how they integrate the engine into 
an existing game project. Our implementation choices are also compatible with Microsoft s XNA Game Studio 
Express, meaning that we can target both the Windows platform and the Xbox 360 with our engine. While 
we have primarily carried out development on the Windows platform thus far, Xbox 360 support is currently 
under investigation as well. <scene id="standardProcedure" setID="consultationRoom" initialLightingLevel="0"> 
<stageDirection> <musicPlayback id="bgMusic" loop="on"/><lightingChange level="100" subject="scenery" 
duration="1"/><pause duration="2"/></stageDirection> <dialogue speaker="narrator"> <line>- Hope Hospital,Consultation 
Room -</line> </dialogue> <stageDirection> <waitFor event="anyInput"/><soundPlayback id="beep" /><movement 
castID="mary" type="enterHorizontal" startLocation="offRight" endLocation="onRight" speed="1000" /></stageDirection> 
<dialogue speaker="mary"> <line>The patient has beenmoved to \nthe pre-oparea.</line> </dialogue> <stageDirection> 
<waitFor event="anyInput"/><soundPlayback id="beep" /><lightingChange level="25" subject="scenery" duration="1"/><pause 
duration="1"/></stageDirection> <dialogue speaker="narrator"> <line>Mary Fulton, age 39: HopeHospital's 
\nveteransurgical assistant.</line> </dialogue> <stageDirection> <waitFor event="anyInput"/><soundPlayback 
id="beep" /></stageDirection> <dialogue speaker="narrator"> <line>She's kind and well-liked, so nobody\nmentions 
she tends to ramble too much.</line> </dialogue>   5. EXPERIENCES TO DATE Initial experimentation with 
our Reusable Scripting Engine involved recreating scenes from movies and television shows such as the 
Princess Bride [10] and The Simpsons [19], as discussed in [16]. While this experimentation demonstrated 
that our engine could create cinematics and cut-scenes, it did not necessarily validate its suitability 
for use in video games. To do so, we selected a game from the set of games with cinematics and cut-scenes 
initially examined as discussed in Section 3.2, and replicated some of its scenes. The game selected 
for our current work was Trauma Center: Second Opinion [1], developed by Atlus for the Nintendo Wii platform. 
This game was chosen as it would require a robust and rich set of story scripting elements to be adequately 
replicated, and consequently provided a suitable test of our engine s capabilities. Figure 3 presents 
an excerpt from the scripting that was used in replicating the Standard Procedure cut-scene that appears 
before the first operation in the game. Figure 4 contains screenshots illustrating how this script would 
appear when performed. This portion of the cut-scene is performed as follows: 1. The scene begins by 
preparing the set for the cut-scene, the consultation room. Initially, lighting is set to a level of 
0%, indicating that the set will be dark to begin with. Stage directions then begin playback of background 
music, set to loop indefinitely. A lighting change occurs, to raise set lighting to a level of 100%, 
to fully illuminate the set. This is done over a period of 1 second. This is followed by a pause of 2 
seconds before the performance continues. This results in the scene as depicted in Figure 4 (a). 2. 
Dialogue then begins, with the narrator introducing the scene, resulting in what appears in Figure 4 
(b), with dialogue text appearing in a shaded area at the bottom of the screen. 3. Stage directions 
have the performance pause to wait for input from the player, to ensure they have had the chance to read 
the dialogue. Any input is acceptable to continue the scene. A beep sound effect is then played to acknowledge 
the input, as was done in the original game. Mary is then directed to quickly enter from stage right 
and stay on the right half of the scene, resulting in what is depicted in Figure 4 (c). 4. Mary then 
says her line in her default tone, since no tone was specified. Since no voice-overs occurred in the 
original game, none were included with this line of dialogue either. This results in what appears in 
Figure 4 (d). 5. At this point, the scene pauses as discussed in Step 3, and a lighting change occurs 
to dim scenery lighting to 25%. The lighting on Mary, however, is preserved, causing her to stand out 
while the narrator introduces her in the next line of dialogue, as shown in Figure 4 (e). 6. The scene 
pauses once again as discussed above, and the narrator completes the introduction of Mary, as depicted 
in Figure 4 (f). After this, lighting is restored to normal levels,  Figure 3. Scripting Used to Replicate 
Standard Procedure and the scene continues appropriately. Scene from Trauma Center: Second Opinion. 
 Figure 4. Screenshots from Replication of Standard Procedure Scene from Trauma Center: Second Opinion. 
 In the end, our Reusable Scripting Engine allowed us to faithfully, accurately, and easily replicate 
scenes from the original game. The story script was authored using the XML editing facilities in Visual 
Studio 2005 Professional Edition. Even though this package has meager XML editing capabilities in comparison 
to other packages, it took very little time and effort to construct the scripts. All in all, our experiences 
with our Reusable Scripting Engine prototype have been very positive, and it demonstrates tremendous 
possibilities for its use in the future. 6. CONCLUSIONS AND FUTURE WORK Storytelling is an important 
aspect of modern video games, and plays a central role both in drawing in players initially and in keeping 
them playing over the long term. With the success or failure of games depending on their story elements, 
it is becoming increasingly important to provide tools and supports to allow writers to directly produce 
story content for games, without requiring programming background and expertise. This allows stories 
for games to be crafted more efficiently and more effectively, easing the development process and potentially 
increasing the quality of the games as a result. Our current work in this area addresses this need for 
tools and supports by providing story scripting elements and a software engine capable of using these 
elements to automatically produce cinematics and cut-scenes for video games. By feeding authored story 
content directly into our Reusable Scripting Engine, writers no longer need to depend upon programming 
talent to have their stories acted out, which can have significant benefits. Results from using our prototype 
engine to date have been quite positive and show great potential for the future. Possible directions 
for continued work in this area include the following. Replicating cinematics and cut-scenes from other 
video games is an important next step. This will not only provide further validation of our approach 
and engine, but it will also help to uncover additional stage directions, effects, or other elements 
that should be supported in our work. Support for animated characters, set elements, and effects is also 
important. Static characters with little or no animation are still in use in many games today (such as 
Trauma Center: Second Opinion), but our engine must support more than that in the future. Support for 
3D cinematics and cut-scenes is also necessary, and is fortunately possible through our use of DirectX. 
This will require the addition or refinement of stage directions to enable our scripting to work in a 
truly 3D space. There is currently considerable interest in dynamic story elements in video games that 
allow the flow of story to change depending on in-game events. Our engine can and should be extended 
to support these efforts. Our Reusable Scripting Engine should be ported through XNA to the Xbox 360. 
This platform is attractive to academic, independent, and hobbyist developers, and so providing automated 
storytelling support would be very beneficial to development efforts in this area. 7. REFERENCES [1] 
Atlus. Trauma Center: Second Opinion. Published by Atlus, 2006. [2] Bateman, C. Game Writing: Narrative 
Skills for Videogames. Charles River Media. 2007. [3] Cassell, J., Vilhjalmsson, H. and Bickmore, T. 
BEAT: The Behavior Expression Animation Toolkit. SIGGRAPH 2001 Conference. Los Angeles, California, August 
2001. [4] Chandler, R. Game Writing Handbook. Charles River Media. 2007. [5] Cunningham, D., McMahon, 
H. and O Neill, B. Bubble Dialogue: A New Tool for Instruction and Assessment , Educational Technology 
Research and Development, Volume 40, Number 2. 1992. [6] Cutumisu, M., Onuczko, C., McNaughton, M., Roy, 
T., Schaeffer, J., Schumacher, A., Siegel, J., Szafron, D., Waugh, K., Carbonaro, M., Duff, H. and Gillis, 
S. ScriptEase: A Generative/Adaptive Programming Paradigm for Game Scripting . Science of Computer Programming, 
Volume: 67, Issue: 1. June, 2007. [7] Davies, M.. Designing Character-Based Console Games. Charles River 
Media. 2007. [8] El-Nasr, M. Interaction, Narrative, and Drama Creating an Adaptive Interactive Narrative 
using Performance Arts Theories. Interaction Studies, Volume 8, Number 2, 2007. [9] Glassner, A. Interactive 
Storytelling: Techniques for 21st Century Fiction. A K Peters Limited. 2004. [10] Goldman, W. The Princess 
Bride. 20th Century Fox. September 1987. [11] Gordon, A., van Lent, M., van Velsen, M., Carpenter, M. 
and Jhala, A. Branching Storylines in Virtual Reality Environments for Leadership Development. \ Sixteenth 
Innovative Applications of Artificial Intelligence Conference (IAAI-04), San Jose, California, July 2004. 
[12] Krawczyk, M. and Novak, J. Game Development Essentials: Game Story and Character Development. Thomson 
Delmar Learning. 2006. [13] Lionhead Studios. The Movies. Activision. 2005. [14] Magerko, B. A Comparative 
Analysis of Story Representations for Interactive Narrative Systems. Third Annual Artificial Intelligence 
for Interactive Digital Entertainment Conference. Marina del Rey, California. 2007. [15] Mateas, M. and 
Stern, A. Facade: An Experiment in Building a Fully-Realized Interactive Drama. Game Developer's Conference, 
San Francisco, California, March 2003. [16] McLaughlin, M. and Katchabaw, M. A Reusable Scripting Engine 
for Automating Cinematics and Cut-Scenes in Video Games . Loading ... The Journal of the Canadian Game 
Studies Association, Vol. 1, No. 1, May 2007. [17] Moreno-Gera, P., Sierra, J., Martínez-Ortizb, I. and 
Fernández-Manjóna, B. A Documental Approach to Adventure Game Development . Science of Computer Programming, 
Vol. 67, Issue 1. June, 2007. [18] Sperberg-McQueen, C. and Burnard, C., (eds). Guidelines for Text Encoding 
and Interchange: XML-compatible Edition. Published for the TEI Consortium by the Humanities Computing 
Unit, University of Oxford. 2004. [19] Stern, D. Duffless. The Simpsons Episode 9F14. 20th Century Fox 
Broadcasting Company. February1993. [20] The TEI Consortium. TEI Software . Available at: http://www.tei-c.org/Software. 
Last accessed July 2007. [21] Zhang, W. Reusable Storytelling Engine . MSc. Directed Study Report, The 
Department of Computer Science, The University of Western Ontario. June 2007.  
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2007</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	</section>
	<section>
		<section_id>1328230</section_id>
		<sort_key>280</sort_key>
		<section_seq_no>7</section_seq_no>
		<section_type>SESSION</section_type>
		<section_title><![CDATA[Physical games]]></section_title>
		<section_page_from>160</section_page_from>
	<article_rec>
		<article_id>1328231</article_id>
		<sort_key>290</sort_key>
		<display_label>Pages</display_label>
		<pages>6</pages>
		<article_publication_date>11-14-2007</article_publication_date>
		<seq_no>1</seq_no>
		<title><![CDATA[Save 'Em]]></title>
		<subtitle><![CDATA[physical gameplay using augmented reality techniques]]></subtitle>
		<page_from>160</page_from>
		<page_to>165</page_to>
		<doi_number>10.1145/1328202.1328231</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1328231</url>
		<abstract>
			<par><![CDATA[<p>We present <i>Save 'Em</i>, an augmented reality-based computer game designed to explore the challenge of making computer games more immersive and engaging by moving gameplay to the physical environment.</p> <p>As in the classic computer game, <i>Lemmings, Save 'Em</i> is based on maneuvering a group of slow-witted characters called Dudes through a treacherous maze. Using augmented reality techniques, <i>Save 'Em</i> places virtual game entities directly within the player's physical environment; gameplay takes place on a real game board rather than on a computer screen, and the Dudes' fate is tied directly to the player's physical actions.</p> <p>In this paper we discuss our <i>Save 'Em</i> game implementation and use our current findings to explain how moving game interaction from the virtual domain into the physical world using augmented reality can affect both gameplay and the players' overall experience.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[augmented reality]]></kw>
			<kw><![CDATA[computer games]]></kw>
			<kw><![CDATA[control methods]]></kw>
			<kw><![CDATA[gaming]]></kw>
			<kw><![CDATA[immersion]]></kw>
			<kw><![CDATA[interfaces]]></kw>
			<kw><![CDATA[mixed reality]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>H.5.1</cat_node>
				<descriptor>Artificial, augmented, and virtual realities</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>K.8.0</cat_node>
				<descriptor>Games</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.5.2</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10011007.10010940.10010941.10010969.10010970</concept_id>
				<concept_desc>CCS->Software and its engineering->Software organization and properties->Contextual software domains->Virtual worlds software->Interactive games</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003251.10003258</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Multimedia information systems->Massively multiplayer online games</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010476.10011187.10011190</concept_id>
				<concept_desc>CCS->Applied computing->Computers in other domains->Personal computers and PC applications->Computer games</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003121</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003121.10003124.10010866</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)->Interaction paradigms->Virtual reality</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387.10010866</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces->Virtual reality</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003121.10003124.10010392</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)->Interaction paradigms->Mixed / augmented reality</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P925226</person_id>
				<author_profile_id><![CDATA[81413593640]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Cody]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Watts]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Calgary, Calgary, Alberta, Canada]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP43136380</person_id>
				<author_profile_id><![CDATA[81339528031]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Ehud]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Sharlin]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Calgary, Calgary, Alberta, Canada]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[ARToolkitPlus, online: http://studierstube.icg.tu-graz.ac.at/handheld_ar/artoolkitplus.php]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>992041</ref_obj_id>
				<ref_obj_pid>992039</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Cheok, A. D., Goh K. H., Liu, W., Farbiz, F., Fong, S. W., Teo, S. L., Li, Y., Yang, X., "Human Pacman: a mobile, wide-area entertainment system based on physical, social, and ubiquitous computing". Personal and Ubiquitous Computing, vol. 8, no. 2, pp. 71--81, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Dance Dance Revolution, online: http://en.wikipedia.org/wiki/Dance_Dance_Revolution]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Duck Hunt, online: http://en.wikipedia.org/wiki/Duck_Hunt]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Guitar Hero, online: http://en.wikipedia.org/wiki/Guitar_Hero]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Lemmings, online: http://en.wikipedia.org/wiki/Lemmings_(video_game)]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1217738</ref_obj_id>
				<ref_obj_pid>1217728</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Marshall, D., T. Ward, McLoone, S., "From Chasing Dots To Reading Minds: The Past Present And Future Of Video Game Interaction". ACM Crossroads, 12.5, Fall, 2006.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Milgram, P. and Kishino, F., "A Taxonomy of Mixed Reality Visual Displays", IEICE Transactions on Information Systems, vol. E77-D (12), Dec. 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[NES Zapper, online: http://en.wikipedia.org/wiki/NES_Zapper]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1023818</ref_obj_id>
				<ref_obj_pid>1023813</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Sharlin, E., Watson, B., Kitamura, Y., Kishino F., Itoh, Y., "On tangible user interfaces, humans and spatiality", Personal and Ubiquitous Computing, 8 (5). 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>594104</ref_obj_id>
				<ref_obj_pid>594096</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Thomas, B., Close, B., Donoghue, J., Squires, J., De Bondi, P. and Piekarski, W., "First person indoor/outdoor augmented reality application: ARQuake". Personal and Ubiquitous Computing, vol. 6, no. 1, pp. 75--86, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Ullmer B., Ishii H., "Emerging frameworks for tangible user interfaces". In: Carroll JM (ed) Human--computer interaction in the new millennium. Addison--Wesley, Reading, Massachusetts, pp 579--601., 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Wii, online: http://en.wikipedia.org/wiki/Wii]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Save Em: Physical Gameplay using Augmented Reality Techniques Cody Watts Ehud Sharlin Interactions 
Lab Department of Computer Science University of Calgary 2500 University Drive NW Calgary, Alberta, Canada, 
T2N 4A8 {wattsc, ehud}@cpsc.ucalgary.ca ABSTRACT We present Save Em, an augmented reality-based computer 
game designed to explore the challenge of making computer games more immersive and engaging by moving 
gameplay to the physical environment. As in the classic computer game, Lemmings, Save Em is based on 
maneuvering a group of slow-witted characters called Dudes through a treacherous maze. Using augmented 
reality techniques, Save Em places virtual game entities directly within the player s physical environment; 
gameplay takes place on a real game board rather than on a computer screen, and the Dudes fate is tied 
directly to the player s physical actions. In this paper we discuss our Save Em game implementation and 
use our current findings to explain how moving game interaction from the virtual domain into the physical 
world using augmented reality can affect both gameplay and the players overall experience.  Categories 
and Subject Descriptors H.5.1 [Information Interfaces and Presentation]: Multimedia Information Systems 
 Artificial, augmented and virtual realities. H.5.2 [Information Interfaces and Presentation]: User Interfaces 
 Input devices and strategies, interaction styles. K.8.0 [Personal Computing]: General games.  General 
Terms Design.  Keywords Computer games, gaming, interfaces, augmented reality, mixed reality, immersion, 
control methods. Permission to make digital/hard copy of part of this work for personal or classroom 
use is granted without fee provided that the copies are not made or distributed for profit or commercial 
advantage, the copyright notice, the title of the publication, and its date of appear, and notice is 
given that copying is by permission of the ACM, Inc. To copy otherwise, to republish, to post on servers, 
or to redistribute to lists, requires prior specific permission and/or a fee. FuturePlay 2007, November 
15-17, 2007, Toronto, Canada. Copyright 2007 ACM 978-1-59593-943-2/07/0011...$5.00 1. INTRODUCTION There 
are a number of reasons why people play computer games, but personal enjoyment or fun is arguably the 
most common. A fun game means different things to different people on the surface, fun is highly subjective. 
But we believe that there exists a group of core concepts inherent in all games which contribute to 
all players enjoyment, regardless of their personal preferences. One of these concepts is immersion: 
the process by which a player dedicates his or her focus to the game, and becomes emotionally involved 
in its progression. Immersion is valuable to computer gaming because it facilitates escapism; it eases 
players into to leaving their day-to-day concerns behind and allows them to engage exclusively on the 
tasks before them. What s more, this intense focus can amplify feelings of accomplishment as players 
complete tasks within the game. If we assume that immersive games are more enjoyable, then a question 
naturally arises: How can games be designed to foster the immersion of their players? Historically, game 
developers have sought to immerse players through enhanced realism. This has typically been achieved 
through graphical improvements, although improvements to physics engines, artificial intelligence algorithms 
and sound systems have also played their part. However, in recent years the focus has shifted, and immersion 
is increasingly being cultivated through the use of novel game interfaces, particularly novel control 
devices [7]. Many game developers are eschewing traditional, generic input devices such as keyboards 
and gamepads and creating specialized controllers, designed specifically for a single game. By using 
controllers which create a simple, intuitive mapping between the player s actions and their effects, 
a significant barrier to immersion is removed. A good interface can reduce the player s need to memorize 
complicated and often arbitrary key mappings in order to accomplish their goals. Rather, it can allow 
the player to act naturally, translating physical actions into appropriate outcomes in the game environment. 
In this paper, we present Save Em (Figure 1), an augmented reality game played with a simple, intuitive 
control device: a handheld wand . We argue that augmented reality techniques, such as the ones we used 
in Save Em, can harnesses the power of nontraditional control and display interfaces to create gameplay 
which is accessible, immersive and most importantly, fun.  Figure 1: The World of Save 'Em. 2. RELATED 
WORK Within the last decade, novel control interfaces for computer games which enable new ways to play 
have become increasingly common, occasionally even serving as the catalyst for a brand new genre. Consider 
the rhythm games which achieved widespread recognition in North America following the release of Dance 
Dance Revolution [3] in 1998. Rhythm games are part of a genre which challenges players to perform to 
a musical beat by dancing, playing bongos, or strumming a guitar. The hallmark of these games is their 
elaborate controllers which seek to mimic real-life analogues. For example, the guitar-shaped controller 
that comes packaged with the 2005 release Guitar Hero [5] is in fact a ¾ scale model of a Gibson SG guitar. 
Despite their recent success, the use of game-specific controllers which enable new ways of playing is 
not a new development; light-gun peripherals have been a staple of shooting games for more than thirty 
years. The most recognizable example of a light­gun peripheral is likely the Nintendo Zapper [9], which 
was released alongside Duck Hunt [4] in 1985. However, many arcade cabinets with built-in gun peripherals 
predate Duck Hunt, including Desert Gun which was released by Midway in 1977 and Triple Hunt, released 
by Atari in the same year. Since their inception, light-guns have survived and even thrived and shooting 
games complete with light-gun peripherals are now ubiquitous in arcades. Of course, one cannot discuss 
revolutionary control devices without mentioning the Nintendo Wii [13]. Nintendo has never shied away 
from innovation; they were the first to popularize new concepts like force-feedback and touch screens 
in the North American console market. However, despite Nintendo s reputation as a proven innovator, many 
felt that the company risked alienating gamers when it was announced that the Wii would abandon the traditional 
two-handed gamepad in favor of a one-handed remote containing an embedded accelerometer. The long-term 
repercussions of this move remain to be seen, but one thing is for certain: Nintendo s unconventional 
approach to interaction has paid off nearly nine months after its North American release, the demand 
for Wii consoles continues to exceed supply. Though the Wii has set a new standard for physical interaction 
in the console market, researchers are still exploring methods to give players the freedom to physically 
interact with their games. One of these methods is augmented reality (AR); a display technique which 
seeks to integrate synthetic, virtual content with the user s physical environment through the use of 
head-mounted displays (HMDs), projectors or similar display devices [8]. Already, AR interfaces are finding 
applications in a wide variety of areas, including computer games. One of the best-known uses of AR in 
gaming is ARQuake [11], an augmented reality adaptation of id Software s first-person shooter, Quake. 
ARQuake takes the enemies from Quake and with the aid of an HMD superimposes them over the player s 
normal vision, putting her in the role of Quake s protagonist. In contrast to Quake where players move 
using a keyboard, ARQuake players are given free reign to walk (or run) through a real physical location 
as they gun down monsters.  Much as ARQuake draws inspiration from Quake, the Human Pacman project [2] 
is an augmented reality adaptation of Namco s 1980 classic, Pac-man. In Human Pacman, it is the goal 
of the player to collect a series of virtual pellets strewn across a physical arena. As players move, 
their movements are tracked using GPS monitors, and they can see the virtual pellets floating before 
them on their head-mounted displays. To collect pellets, players need merely to walk through them. Human 
Pacman also allows players to join the game as ghosts , whose objective is to hunt down Pacman by chasing 
him through the arena and eventually coming close enough to touch him. Augmented reality interfaces have 
remarkable potential for gaming, giving designers the power to place players directly in the center of 
the game, with action happening above, below and all around them. More importantly, by moving gameplay 
away from a monitor, augmented reality interfaces also tacitly encourages designers to break away from 
generic control peripherals such as the keyboard and embrace new, physically­based interaction techniques. 
Save Em embraces the human-computer interaction theme of tangible interaction. Tangible user interfaces 
(TUIs) exploit our innate physical abilities by providing physical materialization of digital information 
and functions [12]. One key feature of TUIs is I/O unification (input/output unification, [10]). Usually, 
computer interfaces force us to shift our attention between a separated action space and perception space 
(for example, a mouse interface and a separate desktop display). TUIs, like any regular physical object, 
can couple users action space with their perception space, allowing them to focus attention at one spatial 
location. In Save Em, I/O unification is achieved through the use of augmented reality techniques.  
3. DESIGN Our design goal in Save Em was to explore how current augmented reality techniques could be 
used to transfer gameplay to the physical environment. Our aim was to create a casual game in the tradition 
of Tetris: an experience which is accessible and still highly engaging; a game that could easily be picked 
up and intuitively played, providing immediate enjoyment for its players. Of course, in order to meet 
these goals, the game would have to be simple in both concept and control. For these reasons, we sought 
to integrate physical control devices as the cornerstone of Save Em s design. It was our hope that a 
well-designed physical control scheme could leverage players existing knowledge to provide easy-to-learn, 
intuitive gameplay. Our design for Save Em centers on a board game concept where a flat, rectangular 
physical area is designated as a playing surface, and all player interaction would happen on, above, 
or nearby this board. Inspiration for Save Em s gameplay came from Psygnosis's 1991 computer game, Lemmings 
[6]. In Lemmings, a group of ambling, mindless creatures are let lose in an arena filled with a series 
of deadly obstacles including fatal drops, pits of lava, and spring­loaded traps. It is the goal of the 
player to guide the lemmings safely past these hazards and into the arena s exit. This simple task is 
complicated by the fact that the player has no direct control over the lemmings themselves. In fact, 
all the player can do is assign behaviors (such as digging, or climbing) to the lemmings, who are otherwise 
free to walk to their inevitable death. The task of coordinating virtual entities within a danger-filled 
arena seemed tailor-made for our board game concept, but the multi-behavioral controls of Lemmings were 
too complex to translate cleanly into the simple, accessible control interface we desired for Save Em. 
Ultimately, we opted for a similar but distinct concept. In Save Em, the player is tasked with herding 
a group of dim-witted virtual characters (who we affectionately refer to as Dudes ) through a danger-filled 
maze. As in Lemmings, the player is forced to complete this task without ever controlling the Dudes directly. 
Instead, the player must lure the Dudes by holding a physical object a control wand and moving it over 
the surface of the playing area. As the player moves the wand, any nearby Dudes will run directly toward 
its tip, allowing a strategic player to group Dudes and direct them past enemies and around traps, much 
as one might entice a mule to move using a carrot on a stick (Figures 2 to 4). A successful player will 
be able to keep casualties to a minimum as she moves the Dudes towards the maze s exit. As the player 
physically acts, her actions cause an immediate reaction in the virtual game board. This feedback creates 
a tight bond between the real and the virtual that makes the player feel as though the game world is 
very much a part of her own.  4. IMPLEMENTATION The implementation of an augmented reality interface 
requires two key systems: a display system which allows the simultaneous display of both physical and 
digital entities, and a tracking system which gathers information about the player and the world around 
her. We selected an HMD as our display system in Save Em for two significant reasons. Firstly, the use 
of HMDs fosters immersion; by placing the display directly in front of the players eyes peripheral distractions 
are blocked, allowing players to focus solely on the game. Further, an HMD is a hands-free display, which 
is necessary for compatibility with the handheld control wand we had decided upon for Save Em. Save Em 
was implemented using the eMagin Z800 3D Visor HMD. We selected the Z800 over competing models based 
on its compelling feature set. The Z800 is one of the few commercially­available HMDs whose display resolution 
is 800 x 600 rather than the more common 640 x 480. Obviously, a higher resolution supports more attractive, 
more compelling graphics, which are important for creating believable virtual entities. The other novel 
feature offered by the Z800 is its built-in head-tracking. Although this feature was not used in Save 
Em, we felt that it could be valuable to future projects. The Z800 also includes a set of earpieces which 
allow players to hear Save Em s music and sound effects. The Z800 rests on the player s forehead, placing 
a small organic light-emitting diode (OLED) screen over each eye. Each display can be moved laterally 
to adjust the interpupilary distance, allowing wearers to focus the display to their liking. Because 
the Z800 s OLED screens are opaque, it was necessary to attach a webcam to the front of the visor, roughly 
between the player s eyes. The video feed from this camera is augmented with graphical content provided 
by the Save Em game engine, then  Figure 2: While jets of fire erupt from the wall, the player holds 
the wand still, and the Dudes cluster around it. Figure 3: As soon as the fire disappears, the player 
moves the wand to the other side of the board. The Dudes run to catch up. Figure 4: By the time the 
fire has reappeared, the Dudes are safely on the other side. Figure 5: Save Em s physical game board 
is overlaid with a vibrant virtual world.  routed to the screens of the HMD, allowing the wearer to 
effectively see through the display. For tracking, Save Em employs the marker-based visual tracking provided 
by ARToolkitPlus [1]. Flat, high-contrast tracking markers have been affixed to the surface of the playing 
board (which is simply a poster board measuring 720 by 658 centimeters) as well the head of the control 
wand. Using computer-vision algorithms, ARToolkitPlus can identify the distance, position and orientation 
of these markers relative to the camera within any frame of video. By tracking the frames coming from 
the webcam affixed to our player s HMD it is possible to display virtual entities that retain their position 
and orientation in 3D space, regardless of the player s viewpoint. The primary use of the visually-based 
tracking is to determine the position of the tracking markers in relation to the camera. However, by 
inverting the transformation matrix created by the tracking algorithm, the position of the camera in 
relation to the tracking markers can also be calculated. We ve used this information in Save Em to create 
3D positional audio, which changes as the player moves. By tracking the position of the player s head-mounted 
camera, we can effectively determine the distance between the player s head and the surface of the game 
board. By scaling a sound s volume based on the player s distance from the source, we ve created an effect 
where, as the player moves his or her head closer to the board, sounds (such as the roar of a flame jet, 
or the moan of a zombie) get louder and louder, seeming to emanate from the virtual entities themselves. 
As the player moves her head away these ambient sounds once again fall silent, enhancing the illusion 
that the virtual entities of Save Em have a real, physical presence and are part of the player s world. 
Marker-based tracking relies on having an unobstructed image of the tracking markers to provide adequate 
detection. Since the physical game board is overlaid with a virtual game environment, the player is not 
aware of the markers when playing the game (Figure 5). This could have been a problem in Save Em where 
players will often reach across the board, unknowingly obscuring markers with their arm. To solve this 
problem, Save Em s playing surface has been covered with twenty evenly-spaced markers to provide redundancy. 
Since the relative position of each marker has been measured beforehand, the entire board can be effectively 
tracked based on the information provided by a single visible marker. Save Em s game engine was written 
in C++. We selected C++ for several reasons; not only is C++ well-established as a desirable language 
for developing games and other graphics applications, but more significantly, it is also the only language 
for which ARToolkitPlus libraries are immediately available. Save Em s graphical rendering was written 
in OpenGL, using an engine of our own design. All animated 3D models that appear in Save Em (particularly, 
the Dudes and the zombies) are freely­available .md2 (the Quake II model format) files, downloaded from 
the internet.  5. PRELIMINARY FINDINGS Although a formal user study has yet to be conducted, a large 
number of players have already played the game in unstructured settings such as demonstration sessions 
and lab visits. Thus far, our observations of these players have been very encouraging in suggesting 
that the physical gameplay techniques we implemented accomplished our stated goals of creating an accessible, 
immersive and fun experience, effectively using augmented reality techniques to move gameplay to the 
player s immediate physical surroundings. Although players seldom manage to save the Dudes on their first 
attempt, a significant majority of them will eagerly request to try again, whereupon they usually fare 
much better. In fact, many players (even those who do not typically play video games) manage to save 
most Dudes on their second or third try.  Perhaps the most encouraging sign of Save Em s potential is 
that when the game is left running unattended, people have been observed to wander over and begin playing 
without invitation. We feel that this demonstrates Save Em s general appeal, and further solidifies the 
notion that Save Em is an accessible, approachable game which people are eager to try. Why does Save 
Em appeal to players, even those without backgrounds in video gaming? We believe it is due to the game 
s easy-to-use controls which unify a player s actions with their effects in an intuitive way. Physically 
moving a wand with your hand is so natural that the game s learning curve is almost nonexistent. In fact, 
new players can usually begin playing straightaway after watching another player, even without explicit 
instructions on how to play. By using a simple pointing device as an interface for controlling Save Em, 
we ve created a game that allows players to utilize their preexisting knowledge while playing. Anyone 
that has ever issued directions to a friend by pointing on a map will feel right at home guiding the 
Dudes through a maze by pointing with their control wand.  6. FUTURE WORK As of this writing, Save Em 
exists as playable single-level demonstration, designed as a prototype to gauge the effectiveness of 
our proposed design. Based on the positive feedback we have received so far, a sensible avenue for future 
work would be to extend the scope of the game by adding new, more challenging levels which introduce 
new enemies, traps, and puzzle elements. Following this, we also hope to conduct a more formal user study 
to evaluate the effectiveness of our interface. One possible study would entail re-implementing Save 
Em for a standard computer gaming platform, using a game controller or the traditional mouse-and-monitor 
interface. It would then be possible to perform a comparative user study to examine the relative appeal 
of each interface. We are also working to extend our goal of promoting enjoyable gameplay through augmented 
reality techniques and simple, innovative control mechanisms with an altogether new augmented reality 
game entitled Photogeist. In Photogeist, players are placed in an augmented reality environment filled 
with virtual ghosts. The player s goal is to take as many pictures of the ghosts as possible using a 
handheld camera. The player is free to move around the augmented reality environment which integrates 
her physical surroundings with the virtual ghost entities. Photogeist makes use of the camera-tracking 
described in this paper, allowing for ghosts which move and react to the player s presence during gameplay. 
In order not to scare the ghosts, players will have to physically stalk and sneak behind them before 
taking a photograph. We believe that Photogeist will further demonstrate how augmented reality techniques 
can be used to enhance the flexibility and richness of physical game interaction. 7. CONCLUSION Save 
Em is a preliminary exploration of how relatively simple augmented reality techniques can be used to 
move gameplay to the physical world and how this move influences a player s enjoyment. Save Em allows 
us to explore this by immersing the player in an augmented reality environment, facing her with a virtual 
task unfolding on a real game board. Gameplay is controlled using the movement of a handheld wand, which 
is directly mapped to the actions of entities in the virtual game environment, unifying input and output 
in one space. Save Em also integrates an awareness of the player s physical location, enhancing the exploration 
of the game through sound effects that change dynamically according to relative distance and orientation 
between the player and the virtual entities of the game. Based on a series of informal games, preliminary 
findings suggest that the Save Em augmented reality experience affords intuitive and highly entertaining 
gameplay.  8. REFERENCES [1] ARToolkitPlus, online: http://studierstube.icg.tu­graz.ac.at/handheld_ar/artoolkitplus.php 
[2] Cheok, A. D., Goh K. H., Liu, W., Farbiz, F., Fong, S. W., Teo, S. L., Li, Y., Yang, X., Human Pacman: 
a mobile, wide-area entertainment system based on physical, social, and ubiquitous computing . Personal 
and Ubiquitous Computing, vol. 8, no. 2, pp. 71-81, 2004. [3] Dance Dance Revolution, online: http://en.wikipedia.org/wiki/Dance_Dance_Revolution 
[4] Duck Hunt, online: http://en.wikipedia.org/wiki/Duck_Hunt [5] Guitar Hero, online: http://en.wikipedia.org/wiki/Guitar_Hero 
[6] Lemmings, online: http://en.wikipedia.org/wiki/Lemmings_(video_game) [7] Marshall, D., T. Ward, McLoone, 
S., From Chasing Dots To Reading Minds: The Past Present And Future Of Video Game Interaction . ACM Crossroads, 
12.5, Fall, 2006. [8] Milgram, P. and Kishino, F., A Taxonomy of Mixed Reality Visual Displays , IEICE 
Transactions on Information Systems, vol. E77-D (12), Dec. 1994. [9] NES Zapper, online: http://en.wikipedia.org/wiki/NES_Zapper 
[10] Sharlin, E., Watson, B., Kitamura, Y., Kishino F., Itoh, Y., On tangible user interfaces, humans 
and spatiality , Personal and Ubiquitous Computing, 8 (5). 2004. [11] Thomas, B., Close, B., Donoghue, 
J., Squires, J., De Bondi, P. and Piekarski, W., First person indoor/outdoor augmented reality application: 
ARQuake . Personal and Ubiquitous Computing, vol. 6, no. 1, pp. 75-86, 2002. [12] Ullmer B., Ishii H., 
Emerging frameworks for tangible user interfaces . In: Carroll JM (ed) Human computer interaction in 
the new millennium. Addison Wesley, Reading, Massachusetts, pp 579 601., 2001. [13] Wii, online: http://en.wikipedia.org/wiki/Wii 
  
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2007</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>1328232</article_id>
		<sort_key>300</sort_key>
		<display_label>Pages</display_label>
		<pages>8</pages>
		<article_publication_date>11-14-2007</article_publication_date>
		<seq_no>2</seq_no>
		<title><![CDATA[Using games to increase exercise motivation]]></title>
		<page_from>166</page_from>
		<page_to>173</page_to>
		<doi_number>10.1145/1328202.1328232</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1328232</url>
		<abstract>
			<par><![CDATA[<p>In recent years, there has been significant work in integrating physical activity into video games. One goal of this work has been to help motivate sedentary people to be more physically active. Konami's Dance Dance Revolution and Nintendo's Wii Sports have shown that exercise games can be both fun and commercially successful.</p> <p>To date, however, there has been little attempt to investigate what properties of exercise games will help motivate sedentary people to start and continue exercise programs. This paper reviews the literature on exercise motivation and derives from it requirements for computer-aided exercise games. The paper then introduces the new Life is a Village exercise game, and uses it to illustrate how these requirements can be met.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[computer-aided exercise]]></kw>
			<kw><![CDATA[computer-supported cooperative work]]></kw>
			<kw><![CDATA[exertion interfaces]]></kw>
			<kw><![CDATA[video game design]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>H.5.2</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10003120.10003121</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003121</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Human Factors</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P925246</person_id>
				<author_profile_id><![CDATA[81342516861]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Jeffrey]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Yim]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Queen's University, Kingston, ON, Canada]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP43123987</person_id>
				<author_profile_id><![CDATA[81392599672]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[T.]]></first_name>
				<middle_name><![CDATA[C. Nicholas]]></middle_name>
				<last_name><![CDATA[Graham]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Queen's University, Kingston, ON, Canada]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Bandura, A. Health Promotion by Social Cognitive Means. <i>Health Education &amp; Behavior.</i> 31 (2004), 143--164.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Boutcher, J., and Trenske, M. The effects of sensory deprivation and music on perceived exertion and affect during exercise. <i>Journal of Sport and Exercise Psychology.</i> 12 (1990), 167--176.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Callero, P. Role-identity salience. <i>Social Psychology Quarterly.</i> 48, 3 (1985), 203--215.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Cheok, A. D., Fong, S. W., Goh, K. H., Yang, X., Liu, W., Farzbiz, F., and Li. Y. Human Pacman: a Mobile Entertainment. <i>Mobile HCI</i> (2003), 209--243.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Curry, T., and Weaner, J. Sport identity salience, commitment, and the involvement of self in role: measurement issues. <i>Sociology of Sport Journal.</i> 4 (1987), 280--288.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[H&#228;m&#228;l&#228;inen, P., Ilmonen, T., H&#246;ysniemi, J., Lindholm, M., and Nyk&#228;nen, A. Martial Arts in Artificial Reality. <i>Enhancing Virtual Spaces and Large Displays</i>, 2 Apr. 2005. Portland: ACM, 2005. 781--790.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Hagger, M. S., Chatzisarantis, N. L. D., Biddle, S. J. H. A Meta-Analytic Review of the Theories of Reasoned Action and Planned Behavior in Physical Activity: Predictive Validity and the Contribution of Additional Variables. <i>Journal of Sports &amp; Exercise Psychology.</i> 24 (2002), 3--32.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Heumer, G., Carlson, D., Kaligiri, S. H., Maheshwari, S., Hasan, W., Jung, B., and Schrader, A. Paranoia Syndrome - a Pervasive Multiplayer Game. <i>International Symposium on Pervasive Gaming Applications</i>, (May 2006). http://tinyurl.com/ywplrk.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Hohepa, M., Schofield, G., and Kolt, G. S. Physical Activity: What Do High School Students Think? <i>Journal of Adolescent Health.</i> 39 (2006), 328--336.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1125503</ref_obj_id>
				<ref_obj_pid>1125451</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Khoo, E. T., Lee, S. P., Cheok, A. D., Kodagoda, S., Zhou, Y., Toh, G. S. Age Invaders: social and physical inter-generational family entertainment. <i>Conference on Human Factors in Computing Systems.</i> (2006), 243--247.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Lee, K. P. The effects of musical tempos on psychophysical responding during sub-maximal treadmill running. Master's thesis, Pennsylvania State University, 1987.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Mitchell, C., and Stuart, R. B. Effect of Self-Efficacy on Dropout From Obesity Treatment. Journal of Consulting and Clinical Psychology. 52, 6 (1984), 1100--1101.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1297132</ref_obj_id>
				<ref_obj_pid>1297126</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Mueller, F., Gunner, S., Thorogood, A., O'Brien, S., and Wulf, V. Sports over a Distance. <i>Personal and Ubiquitous Computing</i>, 2007. http://tinyurl.com/2yansu.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>958729</ref_obj_id>
				<ref_obj_pid>958720</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Mokka, S., V&#228;&#228;t&#228;nen, A., Heinil&#228;, J., and V&#228;ikkynen, P. Fitness Computer Game with a Bodily User Interface. <i>Second International Conference on Entertainment Computing.</i> (2003), 1--3.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Parker, J. R. Human Motion as Input and Control in Kinetic Games, <i>FuturePlay</i>, London, Ontario, Canada. October 10--12, 2006.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Parker, J. R. Games for Physical Activity: A Preliminary Examination of the Nintendo Wii, <i>6th International Symposium on Computer Science in Sport</i>, Calgary. June 3--6, 2007.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>778724</ref_obj_id>
				<ref_obj_pid>778712</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Str&#246;mberg, H., V&#228;&#228;t&#228;nen, A., R&#228;ty, V., A group game played in interactive virtual space, <i>Design of Interactive Systems</i> (2002), 56--63.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Steptoe, A., and Cox, S. Acute effects of aerobic exercise on mood. <i>Health Psychology.</i> 7, 4 (1988), 329--340.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Wales, D. N. The effects of tempo and disposition in music on perceived exertion, brain waves, and mood during aerobic exercise (Master's thesis, Pennsylvania State University, 1985).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Westcott, W. Role-model instructors. <i>Fitness Management.</i> (March 1991), 48--50.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Wininger, S. R., and Pargman, D. Assessment of Factors Associated with Exercise Enjoyment. <i>Journal of Music Therapy.</i> 40 (2003), 57--73.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Using Games to Increase Exercise Motivation Jeffrey Yim and T.C. Nicholas Graham School of Computing 
Queen s University Kingston, ON, Canada K7L 3N6 {yim,graham}@cs.queensu.ca ABSTRACT In recent years, 
there has been significant work in integrating physical activity into video games. One goal of this work 
has been to help motivate sedentary people to be more physically active. Konami s Dance Dance Revolution 
and Nintendo s Wii Sports have shown that exercise games can be both fun and commercially successful. 
To date, however, there has been little attempt to investigate what properties of exercise games will 
help motivate sedentary people to start and continue exercise programs. This paper reviews the literature 
on exercise motivation and derives from it requirements for computer-aided exercise games. The paper 
then introduces the new Life is a Village exercise game, and uses it to illustrate how these requirements 
can be met. Categories and Subject Descriptors H.5.2 [Information Interfaces and Presentation]: User 
Interfaces evaluation/methodology, input devices and strategies, user-centered design. General Terms 
Human Factors.  Keywords Computer-aided exercise, exertion interfaces, video game design, computer-supported 
cooperative work. 1. INTRODUCTION Recent years have seen the development of numerous games that require 
players to engage in physical activity such as cycling, dancing or swinging a virtual tennis racket. 
Some of these games were created for purely entertainment purposes, using physical actions as a novel 
form of interaction. Other games are intended to help motivate people with sedentary lifestyles to become 
physically active. Permission to make digital/hard copy of part of this work for personal or classroom 
use is granted without fee provided that the copies are not made or distributed for profit or commercial 
advantage, the copyright notice, the title of the publication, and its date of appear, and notice is 
given that copying is by permission of the ACM, Inc. To copy otherwise, to republish, to post on servers, 
or to redistribute to lists, requires prior specific permission and/or a fee. FuturePlay 2007, November 
15-17, 2007, Toronto, Canada. Copyright 2007 ACM 978-1-59593-943-2/07/0011...$5.00 As evidenced by the 
commercial success of games such as Dance Dance Revolution (Konami Corporation) and Wii Sports [16], 
it is possible to create fun games that contain an exercise component. However, there has been as yet 
little attempt to understand the link between what motivates people to perform exercise and the design 
of exercise games. This raises the question of how to move towards a deeper understanding of what game 
features will contribute to or detract from players' motivation to perform exercise. In the sports psychology 
field, there has been extensive work attempting to understand how to motivate people to start and maintain 
exercise programs. In this paper, we draw requirements from this exercise motivation literature, and 
show how these requirements can help in the design of exercise games. Key findings from this literature 
include the linkage of low compliance to exercise programs to poor self-efficacy, poor exercise self­image, 
and lack of peers to exercise with. Features from traditional games can help address these barriers to 
exercise, although naïve design can exacerbate these problems. In order to illustrate these requirements 
and the tradeoffs inherent in applying them, we introduce our Life is a Village computer-aided exercise 
game. Life is a Village contains several novel features, including an innovative approach to cooperative 
game play. The paper is structured as follows. We first survey existing exercise games in order to show 
the broad range of game styles that have been produced to date, both in the commercial and academic fields. 
We then present requirements for exercise games, drawn from the exercise motivation literature. Finally, 
we show how some of these requirements are addressed in the Life is a Village game.  2. GAMES WITH A 
PHYSICAL COMPONENT Exercise games (or more broadly, games with kinetic interfaces [15]) are a fertile 
area for game design. Examples of games requiring physical input include a hang-gliding game [13], a 
game where players use their bodies to control a virtual diving bell [17] and a game where players kick, 
jump and punch to control kung­fu moves of their avatar [6]. There are many ways in which physical interfaces 
can be added to games. Table 1 presents a taxonomy of these approaches. The first axis captures the style 
of user interaction of the game,  Table 1. Taxonomy of exercise games categorized by user interface 
and game world User Interface vs Game World Free motion interface Equipment based physical interface 
Traditional Electronic Interface Virtual World Kick ass Kung fu, Nautilus, EyeToy, Paranoia Syndrome, 
Breakout for Two, Wii Sports, Dance Dance Revolution Life is a Village, FlyGuy, Push N Pull, GameBike, 
PowerGrid Fitness Human Pacman (helper), Age Invaders (helper/opponent) Augmented Reality Human Pacman, 
Age Invaders, Laser Tag Open for research Open for research Reality Soccer Cycling Radio Controlled Cars 
 ranging from free motion (as in traditional sports such as soccer) to equipment-based exercise (as in 
traditional cycling or weight­training exercise.) The mouse/keyboard/gamepad input techniques of traditional 
computer games are presented for comparison. The second axis captures the style of world in which players 
interact. Virtual worlds are typical of computer games, in which players see a representation of themselves 
in a synthetic world presented on a display device. Augmented reality overlays digital information onto 
the real world. And of course, reality represents the real world unadorned by virtual information. 2.1 
REALITY BASED GAMES Games involving physical exercise have existed for thousands of years. Soccer is 
an example of a free-motion interface, where players move their entire body to interact with the ball 
and with other players. Players are free to carry out actions such as running, jumping and kicking. Other 
games are intimately bound to equipment which enhances and constrains the players motions. In a cycling 
or sailing race, competitors enjoy a cybernetic connection to their bicycle or boat, sensing through 
it the road, wind or water. Reality-based games enter the digital world when an electronic interface 
is used to control a real-world entity, such as with RC car racing, where competitors use a controller 
to navigate a radio-controlled car around a track.  2.2 VIRTUAL WORLD GAMES Many exercise games allow 
players to interact with a virtual world (as with traditional computer games) while the game controls 
require physical movement. As with the reality games discussed in the last section, virtual world games 
may involve free-motion or equipment-based interfaces. Kick Ass Kung-Fu [6] is a martial arts game where 
players must defeat virtual opponents. Users play in a large open space with two screens on opposing 
sides. The game is projected on to these screens while a real-time image of the player is captured by 
the camera and placed in to the game. Due to this one-to-one mapping of the player to their digital representation, 
every action performed in the real world is transferred in to the virtual world. Physically walking, 
jumping, kicking and punching are all directly translated in to the game. Another example of a free-motion 
game is Nautilus [17], a cooperative game where players free a trapped dolphin by navigating a diving 
bell to the bottom of a lake (figure 1). Players control the diving bell by physically walking around 
a room. Players group can raise the bell by stamping their feet or flapping their arms. They may also 
lower the bell by standing still or crouching. This detection is possible through the use of floor sensors 
which can sense varying degrees of pressure. The virtual world is projected on to a large wall, while 
lighting and aquatic sounds were added to increase the sense of immersion. Other free-motion, virtual 
world interfaces include Breakout for Two [13], where two players in different locations kick a physical 
soccer ball at a virtual set of blocks (figure 2), Wii Sports [16], where a six degree of freedom accelerometer 
is used to allow players to mimic the actions required to play sports such as tennis and baseball, EyeToy 
(Sony Corp), where a video camera captures body movements as input, and Dance Dance Revolution (Konami 
Corp), a dancing game that requires the player to step on pressure sensitive tiles in time with music. 
There are many examples of games in which exercise equipment is used to control activities in a virtual 
world.   Figure 3. FlyGuy: players fly in a virtual world using a physical hang glider [13] FlyGuy 
[13] is a hang gliding simulator used to foster social interaction (figure 3). Participants are placed 
into a harness from a hanging aluminum frame. From this position, they twist and turn their body using 
the frame as a support to navigate their avatar. GameBike (CatEye Corp) is a stationary bike that controls 
racing games on the PlayStation 2 console. The GameBike uses the bicycle s speed and handle bars as speed 
and steering controls. Virku [14] is a research project where users pedal through a virtual environment 
using a stationary bicycle. The virtual environment is generated with map information, and affects pedaling 
effort. Resistance increases or decreases depending on the slope of the hill. Push N Pull [13] is a resistance 
training game that requires two players to exert synchronized actions on a PowerGridFitness joystick 
(Interaction Laboratories Inc.) Players communicate with one another over a videoconference system. The 
goal is to move a shared virtual object to capture a number of particles. To do this, players must push 
and pull their respective input devices in the same direction. From these examples, we see that there 
are many ways that games allow players to physically interact with a virtual world, based on both free 
motion interfaces and exercise equipment.  2.3 AUGMENTED REALITY GAMES Augmented reality systems overlay 
virtual information onto the physical world. A number of exercise games have taken this approach, allowing 
players to play compute games within a real­world setting. Laser Tag is an early augmented reality game 
with a free motion interface. Players can move freely within an enclosed environment. Reality is augmented 
by virtual laser blasts which lead to LEDs indicating that a player has been hit. Age Invaders [10] is 
both a competitive and cooperative game. The goal of the game is to eliminate opponents by shooting rockets. 
Players may physically walk on a grid embedded with LEDs, or play using a traditional desktop computer. 
The LEDs light up to represent varying objects and actions in the game such as rockets, barriers, and 
hits. Paranoia Syndrome [8] is a cooperative game where players physically walk around a number of rooms. 
Using a PDA, users can view invisible aliens that reside in the physical world around them. Vital information 
such as the health and location of your team mates is displayed on this screen. Additionally, physical 
objects with RFID tags are scanned using the PDA. In Human Pacman [4], players take on the role of Pacman 
and the ghosts. The goal for Pacman is to collect a series of pellets scattered throughout the environment. 
The ghosts in turn attempt to stop Pacman from completing his task. Therefore moving around in the physical 
world directly translates to moving Pacman in the virtual world. Virtual artifacts overlay the physical 
world; e.g., Pacman s power pellets are represented as spheres floating in space. Ghosts are similarly 
represented by other people walking around in the real world. There are currently no augmented reality 
games that are based on equipment interfaces, but it is easy to imagine possibilities such as a game 
based on cycling outdoors. Summing up, we see that there are many different ways in which physical activity 
can be integrated into games. Video game design has stagnated in recent years, with safe releases of 
sequels and remakes. Games with kinetic interfaces offer a new and exciting arena for highly immersive 
games.  3. EXERCISE MOTIVATION One of the underlying goals of games with kinetic interfaces is to help 
motivate people to do exercise. The promise is that if we combine the fun of video games with physical 
activity, people will be more likely to exercise. It is clear from the broad success of commercial games 
such as DDR and Wii Sports that this can be true for some games and some people. However, there has to 
date been little attempt to analyze what makes a successful exercise game. Is it enough to simply bolt 
a kinetic interface onto current mass-market games? How should we design such games to help motivate 
people who are currently sedentary to try them out? What game features will help motivate people to continue 
an exercise program once begun? Fortunately, there is a breadth of literature on exercise motivation. 
We have reviewed this literature, and have drawn from it requirements for exercise games. To our knowledge, 
this is the first attempt to tie the exercise motivation literature to the design of exercise games. 
As will be shown in section four, we have applied some of these requirements in the Life is a Village 
exercise game. We now review these requirements.  3.1 Requirement 1: Integrate Music Wininger et al. 
performed a study of three factors influencing enjoyment of exercise: music, satisfaction with the instructor, 
and exercise role-identity [21]. The study concluded that music was the most important of the three. 
This is consistent with the great success of DDR, a game fundamentally centred around music. Wales found 
that upbeat music significantly decreased feelings of anger, fatigue and depression compared to slower 
music [19]. Corroborating these results, by examining the effects of musical tempo on treadmill running, 
Lee determined that exercising to upbeat music led to higher positive mood states compared to slower 
music [11]. Separate experiments by Steptoe and Cox and Boutcher and Trenske discovered that people report 
a lower level of physical exertion when exercising to music versus exercising to a metronome [18] or 
to no music at all [2]. This shows that the presence of music can reduce peoples perception of how hard 
they are exercising. Boutcher and Trenske explain that these results occur because of two factors. First 
is that music may act as a distracter to physical discomfort. The second is music may lead to positive 
states due to its content or because of its association with past experiences. To summarize, music increases 
exercise enjoyment by increasing positive mood states and reducing feelings of physical discomfort, anger, 
fatigue, and depression. This would suggest that to enhance enjoyment, an exercise game should have music 
that is upbeat. However such music may not be appropriate for all games. For instance in FlyGuy, it may 
not be appropriate to play techno music while players calmly fly through the skies. Therefore it appears 
that music must fit within the context of the game. As found by Boutcher and Trenske, music chosen by 
the game player may have the most positive effects. 3.2 Requirement 2: Facilitate leadership for novice 
players Starting an exercise program can be intimidating, and so people cite the importance of instructors 
in their enjoyment of their programs. Wininger et al. found that the instructor is the second most important 
factor in peoples enjoyment of aerobics classes [21], both for their knowledge of physical fitness and 
their encouragement of the participants. Westcott [20] conducted a study where health club members were 
asked to rank characteristics of exercise instructors. The most important characteristic cited is the 
instructor s knowledge of physical fitness. The next most important factors are the instructor s teaching 
skill, enthusiasm, and amount of personal attention they gave to participants. Games therefore should 
facilitate leadership of players, and particularly of novices. This leadership should impart necessary 
fitness knowledge to the players, as well as providing structure to their session and encouragement to 
continue. Leadership in games can be provided similarly to real life exercise classes. A group leader 
(either paid or simply a more experienced player) could help other players learn basic skills, and help 
in developing workout strategies. The game Neverwinter Nights perhaps provides a model for this kind 
of game structure, where a dungeon master guides a group of players. As another model, the online game 
Earth and Beyond granted experience rewards to advanced players who provided galaxy tours to new arrivals 
in the game. A leader who is knowledgeable and supportive would enhance the enjoyment of the experience. 
Therefore the game must have a mechanism to designate qualified group leaders. Alternatively, the game 
s publisher could provide certified instructors for an additional game fee. Games can of course take 
advantage of the fact that they are based on a computer to use artificial intelligence to provide guidance 
to players. This could be directly, by providing a non­player character (NPC) leader, or indirectly, 
for example using quests to guide players. The game setting provides multiple ways of providing guidance 
to players, ranging from live experts, other players acting as leaders, or simply embedding direction 
into the game mechanics. As we have seen, examples of how to do this can be drawn from existing non-exercise 
games.  3.3 Requirement 3: Provide achievable short and long-term goals Bandura [1] defines self-efficacy 
as an individual s belief of their ability to control events in their lives. These beliefs influence 
how people feel, think, motivate themselves and behave. Self-efficacy affects a person s outlook, aspirations, 
and the belief in their ability to complete goals, including exercise goals. People can have varying 
levels of self-efficacy. Those with high self-efficacy are motivated and expect positive outcomes from 
events. They set high goals and view difficulties as tasks that can be surmounted through self improvement. 
Those with low self­efficacy expect their actions to result in poor outcomes. They see challenges as 
insurmountable, and may quit before trying. Low self-efficacy is therefore a barrier to starting and 
continuing exercise programs. It is easy for unfit people to fixate on the enormity of the challenge 
of achieving fitness goals (such as achieving a goal weight), and therefore become quickly demotivated. 
According to a study by Mitchell et al. of participants in a Weight Watchers program, 75% of dropouts 
from the program had been identified with low self-efficacy, whereas 2/3 of those who remained had high 
self-efficacy. The dropouts were experiencing similar weight loss to people who continued [12], and so 
were defeated by their own expectation of failure rather than by objective analysis of their performance. 
To mitigate low self-efficacy, well-designed exercise programs are built around short-term goals that 
can be readily achieved, allowing participants to immediately feel a sense of progress and achievement. 
Attaining short term success e.g., progressing from 10 minutes per session on an exercise bike to 15 
minutes per session breaks up long term goals into manageable steps. Similarly, exercise games must 
provide activities in the game that represent short and long term goals. Many games provide lessons in 
how this might be done. World of Warcraft, for example, is structured around quests. As players progress, 
they gain levels, and access to new regions with new quests. Initial quests are easy and can be completed 
within a few minutes. Advanced quests can take hours to complete.  3.4 Requirement 4: Hide players 
fitness level According to Hagger et al. [7], people with low self-efficacy expect their actions to yield 
negative outcomes. They are easily convinced of the futility of their actions. Therefore when they face 
difficulties in performing a task, they are prone to giving up. People with low self-efficacy require 
guidance and encouragement to overcome their difficulties. Ideally, people should be in an environment 
where they feel confident and comfortable. Unfortunately, it may be hard for an obese person to feel 
comfortable at the swimming pool, or a skinny person to feel confident in a weight room. The simple fact 
of having a non-athletic body type can in of itself be sufficiently demotivating to cause people to quit. 
Games have the potential to greatly help this situation. However, some traditional game mechanics can 
greatly exacerbate it. For example, in Warcraft 3, players compete against each other. Practice is important, 
and new players face frequent and decisive challenges. New players may be derided as newbs until their 
skill improves. In an exercise game, an obvious design choice is to link performance to fitness level. 
This approach can be dangerous if it throws players into a Warcraft 3-like atmosphere, where they will 
suffer the demotivating experience of losing consistently until their fitness improves. For example, 
GameBike uses a bicycle to control the speed of a player s car in a racing game; fitter players will 
always win, since they can pedal harder and longer. A better approach might be to use biometric feedback 
(such as the player s heart rate) to scale the player s speed, allowing an unfit player to be competitive 
with an athlete as long as he is working hard relative to his own fitness level. Other games reward progress 
by reflecting a player s advances in his avatar, such as through fancier armour or weapons. An obvious 
way of carrying this approach into an exercise game would be to show the avatar becoming progressively 
fitter over time. This approach would negatively affect self-efficacy, recreating the discouraging atmosphere 
of being the unfit person at the gym or swimming pool, and opening the player up to mocking trash talk 
. In summary, designers of exercise games should be aware of the importance of self-efficacy in starting 
and continuing exercise programs. Games should avoid situations where players perceive themselves to 
be hopelessly behind their fitter opponents, or open themselves up to mockery based on their own lack 
of fitness. To accomplish this, games should not reveal the fitness levels of other players. 3.5 Requirement 
5: Avoid systemic barriers to grouping In a study conducted by Hohepa et al., 44 students from a New 
Zealand high school were questioned on their views on participating in physical activities [9]. The students 
cited barriers to physical activity as being a lack of peer support, perceived incompetence, pressure 
to participate in non-physical activities, and restrictions to entering teams. Perceived incompetence 
was noted as a barrier because students did not wish to be judged by their peers. Students were concerned 
that skilled players would flaunt their abilities and therefore demotivate the new players. They also 
feared they would let the team down if they played. As a result of the perceived incompetence through 
peer influences, players had disincentives to begin or continue their physical activity. This result 
is consistent with those of Wininger et al. [21] and Hagger et al. [7], who relate poor exercise role 
identity and poor self-efficacy to unwillingness to perform exercise. Particularly interesting in this 
study is the importance of groups in exercise. The barriers cited by the surveyed students include being 
heavily influenced by the activities that friends do, by feeling they would fail to do well in a group 
exercise situation, or by simply not being allowed to join a team at all. In general, people are far 
more likely to be active if they have supportive peers to exercise with. Multiplayer games often contain 
mechanics that make it impossible for particular players to group. Players may be divided by server, 
by team (e.g., Horde vs Alliance), or by level. These mechanics imply that friends may not be able to 
play together. It is important not to carry these restrictions over to exercise games. Therefore, exercise 
games should avoid mechanics that segregate players. For example, exercise games should not include a 
leveling mechanism; if one is included, it should copy mechanics such as the City of Heroes sidekick 
system whereby players can be temporarily raised in level when joining a group.  3.6 Requirement 6: 
Actively assist players in forming groups As discussed in the previous section, Hohepa et al. showed 
lack of peer support to be a key barrier to physical activity [9]. Students explained that they didn 
t have friends who were physically active, and therefore were themselves not active. Students also blamed 
peer expectations to participate in sedentary social activities. The students value having friends to 
exercise with, and when friends aren t available, themselves do not engage in physical activity. It is 
therefore important for exercise games to provide mechanisms that help participants find other people 
to play with and that foster a sense of community within the game. Online games have mechanisms supporting 
grouping. Many games provide activities which require more than one player to complete. Games often include 
guild structures allowing larger numbers of players to associate, and building communities that last 
beyond a single play session. It is important that grouping mechanisms require as little overhead as 
possible. Players should not have to travel long distances to link up with friends. There should be facilities 
for easily finding other players who are looking for company. Additionally, there should be easy ways 
of communicating with friends outside the game so that play dates can be arranged, since scheduled meetings 
may be more motivational than spontaneous ones. To summarize, people view a lack of peers as a barrier 
to physical activity. Online games can greatly help in matching people to other interested peers. Mechanisms 
to develop online friendships  Figure 4. Life is a Village and to schedule regular play dates can help 
with motivation to continue exercise.  3.7 Requirements and Tradeoffs In the preceding sections, we 
have presented six requirements for computer-aided exercise games. These requirements are drawn from 
the exercise motivation literature. In many cases, standard game mechanics help meet these requirements; 
in others, the requirements help identify cases where the usual way of organizing games would be lead 
to reduced motivation to perform exercise. There are many important requirements that are not listed 
here. Perhaps the most important is simply that games should be fun. If a game is not enjoyable, it will 
be hard to motivate people to play it, no matter how beneficial its exercise component. Additionally, 
it is important that games provide balanced exercise appropriate to the player s abilities, without risk 
of injury. Finally, since these requirements come from the exercise motivation literature, some requirements 
specific to virtual worlds are not revealed, for example, a tennis game will benefit from haptic feedback. 
Some of our requirements conflict. For example, in order to provide players with long-term goals (requirement 
3), a game normally requires some sense of progression, where players gain rewards for achieving goals. 
However, other requirements imply that progression must be hidden (requirement 4) to avoid revealing 
other players fitness levels and that progression not affect game play (requirement 5) to avoid systemic 
barriers to grouping. Similarly, games must provide a supportive environment (requirements 2 and 4), 
but should provide access to a peer group (requirement 6). It is difficult to police players of multiplayer 
games to ensure that they do not mock or smack talk other players. This behaviour is common in online 
games, and certainly does not foster a welcoming environment. Although the requirements suggest that 
group play is vital to increasing motivation, often people may prefer to play alone. Such players should 
not be penalized by the game. Game designers must choose how to trade off these conflicts to achieve 
a successful design. In the next section, we describe the design of our computer-aided exercise game 
Life is a Village, and discuss our approach to meeting these requirements (figure 4).  4. LIFE IS A 
VILLAGE We have developed Life is a Village (LIAV) as a multi-player computer-aided exercise game taking 
place in a virtual world. The player controls an avatar by pedaling a Tunturi E6R recumbent bicycle and 
steering with a wireless PS2 controller. The bicycle s controls obey the physics of the world pedaling 
harder increases speed; it is harder to pedal when going uphill, and easier when going downhill. Players 
can adjust the bicycles gear , trading off higher tension on the pedals for faster speed. The recumbent 
bicycle is stable and comfortable to sit in, therefore more approachable than a traditional bicycle for 
people who are overweight or unused to exercise. Cycling is a low-impact exercise with low risk of injury. 
It is easy to take breaks as necessary, simply by stopping pedaling. Therefore, this equipment is suitable 
for people who have previously done little exercise.  Players core goal is to build a village. This 
is a long-term goal that requires many hours of play over multiple play sessions to accomplish (requirement 
3). To create a building for the village, the player must gather resources. For example, a log cabin 
is built from wood and stone. To gather a resource, a player must first find it (by cycling around in 
the virtual world, looking for a resource marker), and then dispatch one of her villagers to gather the 
resource. The villager travels to the resource, harvests, drops off the resource at the village, repeating 
until the resource is exhausted. Resources to build simple buildings are easily found, requiring only 
a few minutes of light cycling (figure 5). Rare resources allow more advanced and interesting buildings 
to be created, but are harder to find and access, perhaps being available only on a mountain top. This 
provides players with easily achievable initial goals, as well as longer term goals that can only be 
achieved as their fitness improves (requirement 3). Initial versions of the game proved challenging for 
new players, as they were not sure how to begin. To aid this, we developed a quest system. Players can 
talk to a villager to receive a quest to gather some number of a random item (e.g., four umbrellas, five 
ninja statues). The player must then search for those items and return them to the quest giver. Quest 
rewards include items that can be added to the village. With the quest system, players are able to jump 
right into the game, with clear direction as to what to do (requirement 2). In a future extension, we 
plan to tie this feature to exercise goals, for example, linking the difficulty of the quest to players 
fitness level or providing bonuses for completion within a time determined by the player s capabilities. 
The game has a simple musical soundtrack (requirement 1). This could be integrated better with exercise 
by linking the pace and style of music to the player s actions. For example, if the game determines that 
the player should be resting (based on a heart-rate monitor), the game could slow the pace of the music. 
Life is a Village has a novel cooperative play mode (requirement 6). Two players cooperate to collect 
items in a quest, while trying to avoid snowballs thrown by enemies. Being hit by a snowball impairs 
the players vision (fogs up the display), slowing down the collection. Two co-located players control 
the same avatar. One (the cyclist) is responsible for cycling and navigating. The other (the swatter) 
stands, using a Wii Remote to fend off the snowballs by making tennis-like forehand or backhand gestures. 
To successfully hit an incoming snowball, the swatter must correctly choose between forehand or backhand 
swing, and time the swing correctly. Both players see feedback from their actions via the avatar: the 
cyclist in the avatar s speed and direction, and the swatter in the avatar s swinging animations. Snowballs 
make a 3D swooshing sound as they fly through the air, making the game engaging and fun (requirement 
1). The two players have complementary roles, so people with radically different fitness levels can play 
together (requirement 5). We plan in the future to extend this approach to allow distributed players 
to play together (requirement 6). 4.1 Analysis of Life is a Village The design of Life is a Village shows 
one of many possible ways to balance our requirements. Some requirements, such as integrate music (requirement 
1) are relatively easy to meet. Others, such as facilitate leadership for novice players Figure 5. Recumbent 
Bicycle used to control Life is a Village (requirement 2) are more challenging, but provide fascinating 
opportunities for inventive design. Design becomes interesting once the requirements are combined. For 
example, as discussed above, the use of music can be combined with a leadership function by using the 
style and tempo of the music as a cue to the player to speed up or slow down the pace of the exercise. 
The requirements hide players fitness levels (requirement 4) and remove systemic barriers to grouping 
(requirement 5) are complementary. LIAV uses asymmetric roles in groups to allow people of differing 
fitness levels to play together. When two people cycle together, it is difficult if one is faster than 
the other. However, by splitting the roles into cyclist and swatter, each can perform actions to the 
best of their abilities without directly hindering the other. A highly useful tool for meeting these 
requirements is biometric feedback. A device as simple as a heart rate monitor can be used to determine 
whether the player is exercising at a desired intensity. This can help the game pace exercise appropriately 
(requirement 2), suggest appropriate goals (requirement 3), and scale the interaction between players 
(requirement 4). Our future plans are to build the use of biometric feedback into LIAV and experiment 
with its effectiveness.  5. CONCLUSION There has been a proliferation of games in recent years that 
require players to physically exert themselves. An underlying hypothesis of such games is that people 
will find it fun to exercise, and consequently will improve their physical fitness. While anecdotal evidence 
has indicated some success stories, this paper has presented the first attempt to link the exercise motivation 
literature to requirements for exercise games. The literature suggests that to successfully motivate 
people who currently do not exercise, games should address problems of poor exercise self-identity and 
low self-efficacy. These problems are helped by providing strong guidance to players, providing access 
to a group of peers, and fostering a supportive and unintimidating environment. We have shown how these 
can be translated into six requirements for exercise games. While adhering to these requirements will 
not in themselves guarantee a fun and engaging game, they will help address barriers to taking part in 
an exercise program.  Finally, we have presented Life is a Village, a novel exercise game based on these 
requirements. The design of Life is a Village helps to illustrate the tradeoffs amongst the requirements, 
and the broad space of possible designs they open up. Life is a Village continues to be under development. 
Future work includes turning the game into a persistent, multiplayer world, and adding biometric feedback 
as a control mechanism to the game.   ACKNOWLEDGEMENTS In addition to the authors, the following people 
have contributed to the development of Life is a Village: Will Roberts, Irina Skvortsova, Rob Fletcher, 
the students of CISC 836 (Video Game Development) and the students of ARTF 338 (Time-Based Media). We 
gratefully acknowledge their contributions. We would like to thank Shaelyn Strachan for her help in navigating 
the literature in sports psychology. This work has been supported by the Natural Science and Engineering 
Research Council of Canada and the NECTAR research network.  REFERENCES [1] Bandura, A. Health Promotion 
by Social Cognitive Means. Health Education &#38; Behavior. 31 (2004), 143-164. [2] Boutcher, J., and 
Trenske, M. The effects of sensory deprivation and music on perceived exertion and affect during exercise. 
Journal of Sport and Exercise Psychology. 12 (1990), 167-176. [3] Callero, P. Role-identity salience. 
Social Psychology Quarterly. 48, 3 (1985), 203-215. [4] Cheok, A.D., Fong, S.W., Goh, K.H., Yang, X., 
Liu, W., Farzbiz, F., and Li. Y. Human Pacman: a Mobile Entertainment. Mobile HCI (2003), 209-243. [5] 
Curry, T., and Weaner, J. Sport identity salience, commitment, and the involvement of self in role: measurement 
issues. Sociology of Sport Journal. 4 (1987), 280-288. [6] Hämäläinen, P., Ilmonen, T., Höysniemi, J., 
Lindholm, M., and Nykänen, A. Martial Arts in Artificial Reality. Enhancing Virtual Spaces and Large 
Displays, 2 Apr. 2005. Portland: ACM, 2005. 781-790. [7] Hagger, M.S., Chatzisarantis, N.L.D., Biddle, 
S.J.H. A Meta-Analytic Review of the Theories of Reasoned Action and Planned Behavior in Physical Activity: 
Predictive Validity and the Contribution of Additional Variables. Journal of Sports &#38; Exercise Psychology. 
24 (2002), 3-32. [8] Heumer, G., Carlson, D., Kaligiri, S.H., Maheshwari, S., Hasan, W., Jung, B., and 
Schrader, A. Paranoia Syndrome a Pervasive Multiplayer Game. International Symposium on Pervasive Gaming 
Applications, (May 2006). http://tinyurl.com/ywplrk. [9] Hohepa, M., Schofield, G., and Kolt, G.S. Physical 
Activity: What Do High School Students Think? Journal of Adolescent Health. 39 (2006), 328-336. [10] 
Khoo, E.T., Lee, S.P., Cheok, A.D., Kodagoda, S., Zhou, Y., Toh, G.S. Age Invaders: social and physical 
inter­generational family entertainment. Conference on Human Factors in Computing Systems. (2006), 243-247. 
[11] Lee, K.P. The effects of musical tempos on psychophysical responding during sub-maximal treadmill 
running. Master s thesis, Pennsylvania State University, 1987. [12] Mitchell, C., and Stuart, R.B. Effect 
of Self-Efficacy on Dropout From Obesity Treatment. Journal of Consulting and Clinical Psychology. 52, 
6 (1984), 1100-1101. [13] Mueller, F., Gunner, S., Thorogood, A., O'Brien, S., and Wulf, V. Sports over 
a Distance. Personal and Ubiquitous Computing, 2007. http://tinyurl.com/2yansu. [14] Mokka, S., Väätänen, 
A., Heinilä, J., and Välkkynen, P. Fitness Computer Game with a Bodily User Interface. Second International 
Conference on Entertainment Computing. (2003), 1-3. [15] Parker, J.R. Human Motion as Input and Control 
in Kinetic Games, FuturePlay, London, Ontario, Canada. October 10­12, 2006. [16] Parker, J.R. Games for 
Physical Activity: A Preliminary Examination of the Nintendo Wii, 6th International Symposium on Computer 
Science in Sport, Calgary. June 3­6, 2007. [17] Strömberg, H., Väätänen, A., Räty, V., A group game played 
in interactive virtual space, Design of Interactive Systems (2002), 56-63. [18] Steptoe, A., and Cox, 
S. Acute effects of aerobic exercise on mood. Health Psychology. 7, 4 (1988), 329-340. [19] Wales, D.N. 
The effects of tempo and disposition in music on perceived exertion, brain waves, and mood during aerobic 
exercise (Master s thesis, Pennsylvania State University, 1985). [20] Westcott, W. Role-model instructors. 
Fitness Management. (March 1991), 48-50. [21] Wininger, S.R., and Pargman, D. Assessment of Factors Associated 
with Exercise Enjoyment. Journal of Music Therapy. 40 (2003), 57-73.  
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2007</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	</section>
	<section>
		<section_id>1328233</section_id>
		<sort_key>310</sort_key>
		<section_seq_no>8</section_seq_no>
		<section_type>SESSION</section_type>
		<section_title><![CDATA[Graphics, visual techniques, and sound in games (part 2)]]></section_title>
		<section_page_from>174</section_page_from>
	<article_rec>
		<article_id>1328234</article_id>
		<sort_key>320</sort_key>
		<display_label>Pages</display_label>
		<pages>7</pages>
		<article_publication_date>11-14-2007</article_publication_date>
		<seq_no>1</seq_no>
		<title><![CDATA[Automated avatar creation for 3D games]]></title>
		<page_from>174</page_from>
		<page_to>180</page_to>
		<doi_number>10.1145/1328202.1328234</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1328234</url>
		<abstract>
			<par><![CDATA[<p>Immersion is a key factor in video games and virtual reality simulation environments. Users' presence in a virtual environment is highly dependent on the user's identification with their avatar. Creating more realistic looking avatars thus enables a higher level of presence. Current video games allow character customizability via techniques such as hue adjustment for stock models, or the ability to select from a variety of physical features, clothing and accessories in existing player models. Occasionally user uploadable facial texture is available for avatar customization. We propose a dramatic leap forward in avatar customization through the use of an inexpensive, non-invasive, portable stereo video camera to extract model geometry of real objects, including people, and to then use these textured 3D models to drive avatar creation. The system described here generates the 3D textured and normal-mapped geometry of a personalized photorealistic user avatar suitable for animation and real-time gaming applications.</p>]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node>I.4.8</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010225.10010227</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Computer vision tasks->Scene understanding</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010245</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Computer vision problems</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010225.10010227</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Computer vision tasks->Scene understanding</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010245</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Computer vision problems</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Experimentation</gt>
			<gt>Measurement</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP14272765</person_id>
				<author_profile_id><![CDATA[81314482997]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Andrew]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Hogue]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Ontario Institute of Technology, Oshawa, Ontario, Canada]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P925270</person_id>
				<author_profile_id><![CDATA[81342495400]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Sunbir]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Gill]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[York University, Toronto, Ontario, Canada]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14189614</person_id>
				<author_profile_id><![CDATA[81100545481]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Michael]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Jenkin]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[York University, Toronto, Ontario, Canada]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[A. Baumberg. Blending images for texturing 3d models. In <i>Proceedings of the British Machine Vision Conference</i>, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>132022</ref_obj_id>
				<ref_obj_pid>132013</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[P. Besl and N. McKay. A method for registration of 3-d shapes. <i>IEEE Transactions on Pattern Analysis and Machine Intelligence (PAMI)</i>, 14(2):239--256, February 1992.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>893689</ref_obj_id>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[P. Debevec, Y. Yu, and G. Boshokov. Efficient view-dependent image-based rendering with projective texture-mapping. Technical Report CSD-98-1003, 20 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[U. Dhond and J. Aggarwal. Structure from stereo - a review. <i>IEEE Trans. Systems</i>, Man, and Cybernetics, 19:1489--1510, 1989.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1251665</ref_obj_id>
				<ref_obj_pid>1251556</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[G. Dudek, P. Giguere, C. Prahacs, S. Saunderson, J. Sattar, L. Torres, M. Jenkin, A. German, A. Hogue, A. Ripsman, J. Zacher, E. Milios, H. Liu, P. Zhang, M. Buehler, and C. Georgiades. AQUA: An Amphibious Autonomous Robot. <i>IEEE Computer</i>, 40(1):46--53, January 2007.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>358692</ref_obj_id>
				<ref_obj_pid>358669</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[M. Fischler and R. Bolles. Random sample consensus: A paradigm for model fitting with application to image analysis and automated cartography. <i>Communications of the ACM</i>, 24(6):381--385, 1981.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>709482</ref_obj_id>
				<ref_obj_pid>646921</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[S. Frisken. Constrained elastic surface nets: Generating smooth surfaces from binary segmented data. In <i>Proceedings of the First International Conference on Medical Image Computing and Computer-Assisted Intervention</i>, pages 888--898, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[S. Gill. Polygonal meshing for stereo video surface reconstruction. Master's thesis, York University, Toronto, Ontario, Canada, 2007.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[P. S. Heckbert and M. Garland. Survey of polygonal surface simplification algorithms. Technical Report CMU-CS-95-194, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>311554</ref_obj_id>
				<ref_obj_pid>311535</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[W. Heidrich and H.-P. Seidel. Realistic, hardware-accelerated shading and lighting. In A. Rockwood, editor, <i>Siggraph 1999, Annual Conference Proceedings</i>, pages 171--178, Los Angeles, 1999. Addison Wesley Longman.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[B. Horn. Closed-form solution of absolute orientaiton using unit quaternions. <i>AI Magazine</i>, A(4):629, April 1987.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[L. Kobbelt and M. Botsch. A survey of pointbased techniques in computer graphics. <i>ACM Trans. Graph.</i>, 22(3):641--650, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>237270</ref_obj_id>
				<ref_obj_pid>237170</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[V. Krishnamurthy and M. Levoy. Fitting smooth surfaces to dense polygon meshes. <i>Computer Graphics</i>, 30(Annual Conference Series):313--324, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Linden Research Inc. Second life. http://www.secondlife.com, 2007.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[C. Loop. Smooth subdivision surfaces based on triangles. Master's thesis, Utah University, USA, 1987.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>37422</ref_obj_id>
				<ref_obj_pid>37401</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[W. E. Lorenson and H. E. Cline. Marching cubes: A high resolution 3d surface construction algorithm. In <i>Proceedings of the 14th Annual Conference on Computer Graphics and Interactive Techniques</i>, pages 163--169, 1987.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>851523</ref_obj_id>
				<ref_obj_pid>850924</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[D. G. Lowe. Object recognition from local scale-invariant features. In <i>International Converence on Computer Vision</i>, pages 1150--1157, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[B. Lucas and T. Kanade. An Iterative Image Registration Technique with an Application to Stereo Vision. In <i>International Joint Conference on Artificial Intelligence (IJCAI)</i>, pages 674--679, 1981.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1242110</ref_obj_id>
				<ref_obj_pid>1242073</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[M. Meehan, B. Insko, M. Whitton, and J. Frederick P. Brooks. Physiological measures of presence in stressful virtual environments. In <i>SIGGRAPH '02: Proceedings of the 29th annual conference on Computer graphics and interactive techniques</i>, pages 645--652, New York, NY, USA, 2002. ACM Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Point Grey Research Inc. http://www.ptgrey.com, 2007.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[W. Press, S. Teukolsky, W. Vetterling, and B. Flannery. <i>Numerical Recipes in C.</i> Cambridge University Press, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[M. A. Sabin. Recent progress in subdivision: a survey. <i>Advances in Multiresolution for Geometric Modelling. Mathematics + Visualization</i>, pages 203--230, 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>598475</ref_obj_id>
				<ref_obj_pid>598429</ref_obj_pid>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[D. Scharstein and R. Szeliski. A taxonomy and evaluation of dense two-frame stereo correspondence algorithms. <i>International Journal of Computer Vision</i>, 47(1--3):7--42, April 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[S. Se and P. Jasiobedzki. Photorealistic 3d model reconstruction. In <i>Proceedings of IEEE International Conference on Robotics and Automation, ICRA2006</i>, pages 3076--3082, 2006.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2211743</ref_obj_id>
				<ref_obj_pid>2211641</ref_obj_pid>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[S. Se, D. Lowe, and J. Little. Vision-based global localization and mapping for mobile robots. <i>IEEE Transactions on Robotics</i>, 21(3):364--375, June 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1061354</ref_obj_id>
				<ref_obj_pid>1061347</ref_obj_pid>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[A. Sheffer, B. Levy, M. Mogilnitsky, and A. Bogomyakov. Abf++: fast and robust angle based flattening. <i>ACM Trans. Graph.</i>, 24(2):311--330, 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1295187</ref_obj_id>
				<ref_obj_pid>1295186</ref_obj_pid>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[A. Sheffer, E. Praun, and K. Rose. Mesh parameterization methods and their applications. <i>Foundations and Trends&#337; in Computer Graphics and Vision</i>, 2006.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[J. Shi and C. Tomasi. Good Features to Track. In <i>IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR)</i>, pages 593--600, Jun. 21--23 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[M. Sizintsev and R. Wildes. Coarse-to-fine stereo vision with accurate 3-d boundaries. Technical Report CS-2006-07, York University, June 28 2006.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>30</ref_seq_no>
				<ref_text><![CDATA[Sony Entertainment Inc. Home beta. http://www.homebetatrial.com, 2007.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>31</ref_seq_no>
				<ref_text><![CDATA[B. Triggs, P. McLauchlan, R. Hartley, and A. Fitzgibbon. <i>Bundle Adjustment -- A Modern Synthesis</i>, pages 278--375. Lecture Notes in Computer Science. Springer-Verlag, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>32</ref_seq_no>
				<ref_text><![CDATA[P. Vanezis, M. Vanezis, G. McCombe, and T. Niblett. Facial reconstruction using 3-d computer graphics. <i>Forensic Science International</i>, 108:81--95, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>33</ref_seq_no>
				<ref_text><![CDATA[L. Wang, S. B. Kang, R. Szeliski, and H.-Y. Shum. Optimal texture map reconstruction from multiple views. In <i>Proceedings of the 2001 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2001</i>, volume 1, pages 347--354, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>267583</ref_obj_id>
				<ref_obj_pid>267580</ref_obj_pid>
				<ref_seq_no>34</ref_seq_no>
				<ref_text><![CDATA[F. M. Weinhaus and V. Devarajan. Texture mapping 3d models of real-world scenes. <i>ACM Comput. Surv.</i>, 29(4):325--365, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>35</ref_seq_no>
				<ref_text><![CDATA[E. Weisstein. Rodrigues' Rotation Formula. From MathWorld---A Wolfram Web Resource. http://mathworld.wolfram.com/RodriguesRotationFormula.html, 2006.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>36</ref_seq_no>
				<ref_text><![CDATA[S. Wuhrer, R. Atanossov, and C. Shu. Fully automatic texture mapping for image-based modeling. Technical Report NRC/ERB-1141, August 2006.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>37</ref_seq_no>
				<ref_text><![CDATA[B. Zitova and J. Flusser. Image registration methods: a survey. <i>Image and Vision Computing</i>, 21:977--1000, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Automated Avatar Creation for 3D Games Andrew HogueSunbir Gill and Michael Jenkin Faculty of Business 
and IT Dept. of Computer Science and Engineering University of Ontario Institute of Technology York University 
Oshawa, Ontario, CanadaToronto, Ontario, Canadaandrew.hogue@uoit.ca {sunbir,jenkin}@cse.yorku.ca ABSTRACT 
Immersion is a key factor in video games and virtual reality simulation environments. Users presence 
in a virtual en­vironment is highly dependent on the user s identi.cation with their avatar. Creating 
more realistic looking avatars thus enables a higher level of presence. Current video games allow character 
customizability via techniques such as hue adjustment for stock models, or the ability to select from 
a variety of physical features, clothing and accessories in existing player models. Occasionally user 
uploadable facial texture is available for avatar customization. We propose a dramatic leap forward in 
avatar customization through the use of an inexpensive, non-invasive, portable stereo video camera to 
extract model geometry of real objects, includ­ing people, and to then use these textured 3D models to 
drive avatar creation. The system described here generates the 3D textured and normal-mapped geometry 
of a person­alized photorealistic user avatar suitable for animation and real-time gaming applications. 
 Categories and Subject Descriptors I.4.8 [Image Processing and Computer vision]: Scene Analysis sensor 
fusion, stereo, range data, photometry, mo­tion, tracking  General Terms Experimentation, Design, Algorithms, 
Measurement 1. INTRODUCTION Immersion is key to create a compelling modern video game experience. Users 
presence in a virtual environment is highly dependent on the amount of their immersion. Presence is further 
augmented with the user s identi.cation with their avatar[19]. Creating more realistic looking avatars 
enables a higher level of identi.cation with the character and thus an increased level of presence. As 
a consequence, many current video games are capable of some level of user-customization of the playable 
character. Most notably are the Mii avatars Permissionto makedigital/hard copy of partofthis work for 
personalor classroomuse is granted withoutfee providedthat the copiesarenot madeor distributedforprofit 
or commercialadvantage, thecopyright notice, thetitleof thepublication,and itsdate of appear, andnotice 
is giventhat copying is by permission of the ACM, Inc.To copy otherwise, torepublish,to postonservers,orto 
redistribute to lists,requiresprior specificpermissionand/or a fee. FuturePlay 2007, November 15-17, 
2007, Toronto, Canada. Copyright 2007 ACM 978-1-59593-943-2/07/0011...$5.00 for the NintendoTM WiiTM 
game console. These are 3D cari­catures that the user can customize to .t his or her personal­ity. Adjustable 
attributes include hair shape and color, eye shape and color, height, width, and the ability to add acces­sories 
to the player s avatar. Other existing game environ­ments such as Tony Hawk s Underground 2, Second Life[14] 
and Sony s Home[30] for the Playstation 3 allow for a certain level of player customization. Ubisoft 
s game Tom Clancy s Rainbow Six Vegas is perhaps the leader in terms of pho­torealistic avatar customization. 
The user can capture two images of themselves (head on and side pro.le) using the XBox Live camera. These 
images are then texture mapped to an existing model in the game, thus enabling increased presence. The 
photo-realistic customization is limited to the head but is very e.ective at capturing the appearance 
of the player. In this paper we build on existing techniques to de­velop a system that creates an accurate 
3D representation of the user. The system described in this paper generates the 3D model information 
without an existing stock 3D model and can be used to extract 3D models of not only humans, but also 
of entire rooms and scenes, to aid in avatar and virtual scene construction. 1.1 Existing 3D Modelling 
Approaches Although there is this growing need for such technology, to date few e.ective low-cost, eye-safe 
systems have been de­veloped that can create compact, accurate photorealistic 3D representations of users 
for use as personal avatars. The traditional technique for generating 3D surface models of humans is 
through the use of laser line scanning (see [32] for example). In these systems, a laser line scanner 
is used to obtain local surface geometry and this information is then merged with surface intensity (colour) 
information in or­der to obtain a 3D surface model. Although this technique has been used successfully 
to build 3D models of actors and agents the approach is not without its problems. First, laser line scanners 
are reasonably slow, obtaining only a single 1D line stripe at a time of the object under view. To obtain 
more complete 3D models it is necessary to sweep the line across the object in various directions and 
from various starting points. Second, the laser scanning process itself does not obtain colour information 
and a second visible light capture system must be used in order to obtain appropriate texture information. 
Third, although these laser scanners are nor­mally considered eye safe due to the use of low power visible 
light lasers, many users are uncomfortable using them as the laser is .red directly into their face. 
  (a) (b) (c) (d) Figure 1: Recovering 3D structure. (a) and (b) show a single frame from the stereo 
image sequence being captured. (c) shows local temporal matches between the 3D structure from the current 
frame and the existing model projected into the right camera view. These matches are used to estimate 
the camera ego­motion between frames. (d) shows the current 3D model rendered to a particular viewpoint. 
See text for details. Given the problems inherent with laser scanning approaches, this paper demonstrates 
how a passive stereo video se­quences obtained with natural illumination can be used to construct avatars 
safely and e.ciently. We demonstrate how accurate point cloud models of heads and torsos can be ac­quired 
and how compact photorealistic polygon-based repre­sentations of these point clouds can be constructed. 
Stereo video 3D surface reconstruction, more broadly, is an emerg­ing technology for scanning scenes 
to produce 3D models. Its uses are currently being investigated in the mining industry, as a means of 
producing mine maps, and by law enforcement agencies, as a forensic data collection tool (see [24]). 
This is in large part due to its advantages over its laser-based ri­vals. Stereo video is relatively 
inexpensive, fast, mobile, and is capable of producing photorealistic texture from captured video during 
3D model creation. These reasons, coupled with its non-invasiveness and portability make stereo video 
an attractive technology for scanning faces of people for a range of applications.  1.2 Stereo Video 
Reconstruction The problem of obtaining 3D surface models from a pair of cameras has been studied extensively 
(see [4] for a review of various approaches). As the technology has advanced it is now possible to use 
these algorithms to extract a dense set of 3D measurements per image frame. Integrating these mea­surements 
from di.erent viewpoints enables the construction of a 3D point model which can be converted to a polygonal 
mesh representation for fast rendering and manipulation. In the development of such a system there are 
a number of critical design decisions that in.uence the algorithm s per­formance. Perhaps the most important 
of these relates to how the ego-motion of the stereo sensor is estimated in order to integrate measurements 
taken from di.erent viewpoints. The Instant Scene Modeler [24], for example, extracts highly salient 
SIFT features[17] with their corresponding 3D loca­tions from the current frame and matches them with 
a large database of features extracted from previous time frames. The position and orientation of the 
camera relative to some arbitrary world frame is estimated using these matches[25]. Although this technique 
works well, as the database of fea­tures grows more e.cient search algorithms must be devel­oped to achieve 
real-time performance. This technique also eliminates the camera motion information which can be a huge 
asset when creating dense 3D models. An alternative strategy is to estimate the ego-motion using more 
traditional computer vision techniques based on the registration of subsequent 3D point clouds. This 
is the ap­proach used by the stereo-inertial AQUASENSOR[5]. The strategy used in the AQUASENSOR algorithm 
uses relative ego-motion coupled with 3D point registration algorithms to create 3D models. The AQUASENSOR 
combines range information extracted from stereo imagery with 3DOF orien­tation from an inertial measurement 
unit (IMU). We utilize a terrestrial version of the AQUASENSOR which lacks the IMU data and is a pure 
vision-based approach. Although not using the IMU may limit accuracy for reconstruction of large arbitrary 
scenes (on the order of tens of meters) for the application considered here the sensor moves only a few 
feet. This allows us to use a pure stereo vision approach for extracting 3D information from the scene. 
The hand­held sensor records full frame-rate (30fps) stereo video to disk which is later analyzed to 
extract the 3D model and the camera trajectory of the scene. It is important to note that although the 
sensor does not process the collected data in real-time, the algorithms used to analyze the data were 
developed with real-time performance in mind and with op­timization can indeed run at framerate. Recovering 
accurate depth from stereo imagery is performed by leveraging the optimized sum-of-squared di.erences 
(SSD) algorithm implemented in the Point Grey Triclops library[20]. There are many di.erent stereo algorithms 
that could be used for this step (see [23] for an overview of other meth­ods) however the SSD approach 
provides a good tradeo. between accuracy and speed. The output of the stereo mod­ule provides a dense 
set of 3D points per acquired image frame. Afterwards, the unbounded handheld motion of the camera is 
estimated by tracking 3D features temporally and computing a six degree-of-freedom (6DOF) transformation 
to align the consecutive frames. The sensor position and orientation over multiple frames is estimated 
using a linear least-squares algorithm for an initial estimate which is then re.ned using a non-linear 
least-squares minimization. The pose is integrated over time to recover the entire trajectory of the 
camera as it has moved throughout the environment. This also implies that any error in the pose estimate 
will accumulate over time, however in the application presented the accumulated error can be ignored 
since the total distance traveled is small. The details of the technique are presented below and are 
summarized in Figure 1.  Figure 2: A recovered point cloud. Four views are shown. Aligning sets of 
3D points requires that a rotation and trans-lation for the sequence in a two stage process. First, using 
lation be estimated between the model and the current set RANSAC [6] we compute the best linear least 
squares trans­of points. Typically this is done by using the variants of the formation using Horn s absolute 
orientation method [11]. Iterative Closest Point (ICP) algorithm[2]. ICP works well Given two 3D point 
clouds rt0 and rt1 at times t0 and t1 for highly accurate sets of data such as those extracted from respectively, 
we estimate the rotation and translation re­laser range scans. However, the 3D information extracted 
quired to bring rt1 into accordance with rt0 . The centroid, from stereo can be quite noisy as the points 
get further from r¯t0 ,r¯t1 , of each point cloud is computed and subtracted from t0 = rt0 - r¯t0 andthe 
camera. This causes correspondence problems which can the points to obtain two new point sets, r lead 
to divergence. This can be overcome by utilizing motion r t1 = rt1 - r¯t1 information from the image 
sequence as a guide to direct the correspondence problem. Since the camera is moving, there To compute 
the rotation, R(·), we minimize the error func­is a direct correlation with the motion of the 3D point 
sets tion t0,i - sR(rt1,i)||2 between frames. Computing the 2D motion from the images n X provides cues 
as to how features are moving in the environ­ ||r (1) ment. We retain the 3D information corresponding 
to this i=1 computed motion and thus we know the correspondences be- The rotation, R(·), and scale, s, 
are estimated using a linear tween the two images in 3D. The 3D rotation and translation least-squares 
approach (detailed in [11]). After estimating can be computed using these corresponding points. Estimat­the 
rotation, the translation is estimated by transforming ing the camera trajectory is bene.cial in two 
ways. First, the centroids into a common frame and subtracting. it allows the algorithm to converge faster 
by having knowl­edge of the corresponding points between the overlapping To achieve a higher registration 
accuracy we re.ne the rota­3D point sets. Second, it enables us to map the triangles tion and translation 
using a nonlinear Levenberg-Marquardt of our output mesh to actual camera images for texturing minimization 
[21] over six parameters. This is a necessary purposes. To estimate the camera trajectory good features 
are ex­tracted from the reference camera at time t using the Kanade­Lucas-Tomasi feature tracking algorithm 
(see [28, 18]) and are tracked from the previously captured image at time t-1. Any type of image features 
could be used to estimate the camera motion; we employ the KLT tracker due to its rela­tively good run-time 
performance. A survey of other tech­step as the solution from the initial RANSAC estimate is prone to 
small errors negatively a.ecting the visual quality of the registration. The residual error is minimized 
through a non-linear minimization stage. For this .nal pose re.ne­ment stage, we parameterize the rotation 
as a Rodrigues vec­tor [35] and simultaneously estimate the rotation and trans­lation parameters by minimizing 
the transformation error n X ||rt0,i - (R(rt1,i)+ T )||2 (2)niques can be found in [37]. Using the disparity 
map ex­ i=1 tracted for both time steps, tracked features that do not have a corresponding disparity 
at both time t and t - 1 are eliminated. Surviving features are subsequently trian­gulated to determine 
the metric 3D points associated with each disparity. In order to deal with potential confounding matches 
from the ego-motion estimation process, we employ robust sta­tistical estimation techniques to label 
the feature tracks as belonging to either a static or non-static world model. This is achieved by estimating 
a six degree-of-freedom (6DOF) transformation model under the assumption that the scene is stationary. 
The resulting 3D temporal correspondences are associated with stable scene points for the basis of later 
processing. The camera orientation is represented as a quaternion and we estimate the least-squares best-.t 
rotation and trans-In practice, we .nd that the minimization takes few iter­ations (as few as 4-10) to 
minimize the error to accept­able levels and as such does not preclude real-time opera­tion. Another 
factor aiding algorithm performance is the deterministic size of the parameters in the minimization. 
This approach to pose estimation di.ers from the tradi­tional Bundle-Adjustment approach [31] in the 
structure­from-motion literature in that it does not re.ne the 3D lo­cations of the features as well 
as the trajectory. We chose not to re.ne the 3D structure to limit the number of unknowns in our minimization 
and thus provide a solution to our sys­tem more quickly. The minimization occurs to reduce the error 
of registration only for subsequent frames. Thus the time spent per iteration is limited by the maximum 
num­ber of features tracked per frame. This is set empirically to 1000 features to ensure the minimization 
time is not the limiting factor for performance. The algorithm is capable of estimating the full six 
degree-of-freedom handheld mo­  (a) (b) (c) (d) Figure 3: Polygonal mesh obtained from a point cloud. 
(a, c) show views of the generated triangle mesh and (b, d) show their respective wireframe renderings. 
tion of the sensor as it moves throughout the environment. Since we use the area-based sum-of-squared-distance 
stereo algorithm, there is an arti.cial thickening of the 3D points around the edges of the model. This 
creates unwanted ef­fects such as haloing around the objects to be reconstructed. This can be alleviated 
by using a smaller window size for the stereo algorithm but it does not eliminate the e.ect com­pletely. 
The halo e.ect becomes more problematic when looking at the subject from a pro.le view and then rotating 
around the subject. The set of 3D points associated with the halo tends to occlude the subject s face 
resulting in a noisy model. This can be alleviated in several ways; by us­ing a stereo algorithm such 
as the one described in [29] or by moving the camera in a way that this cannot occur. Lateral movements 
from the left to the right of the subject seem to perform the best for creating facial models, and vertical 
motions seem to perform the best for anterior or posterior full-body models. The output of the stereo 
algorithm is a 3D coloured point cloud (see Figure 2). Although this cloud captures the salient scene 
structure it is not directly useful as a head/face model given its large size (each stereo frame may 
provide tens of thousands of points, and at 30 frames per second, even a minute of data collection provides 
hundreds of frames). In addition to providing too many (and redundant) data points, the data may contain 
holes and outliers which need to be .lled and pruned. Also, representing the scene as a set of 3D points 
is not the most e.cient in terms of rendering using modern graphics hardware. These issues are addressed 
in the following sections by extracting a polygonal mesh more suitable for real-time rendering.  2. 
MESHING POINT-CLOUDS Creating polygonal meshes is a standard form of data com­pression for 3D models 
and has an extensive history. It has been over twenty years since the breakthrough publi­cation of the 
classic (and highly used) Marching Cubes[16] algorithm. A comprehensive survey of the topic has been 
published recently (see [12]). Other meshing techniques ex­ist that alleviate several issues that plague 
the Marching Cubes algorithm; for example, Marching Cubes is subject to a stair-stepping e.ect on slanted 
data generating notice­able visual artifacts. One of the techniques we have found to be exceptionally 
useful for the purpose of scanning face and body models is the Constrained Elastic Surface Nets (de­scribed 
in [7]) algorithm. This meshing approach involves voxelizing the point-cloud into a discrete volume, 
meshing the volume by sub-dividing the voxels and creating a vertex centered in each of them, applying 
a relaxation function to vertex positions, and then triangulating adjacent vertices. A more detailed 
description and analysis of our meshing strat­egy can be found in [8]. Prior to attempting to mesh the 
point-cloud several prepro­cessing steps are performed. First, the point-cloud is culled to a cube that 
contains the volume of interest. This subset of points then goes through a merging step to reduce the 
number of points in the volume. Merging helps reduce re­dundant data resulting from overlapping 3D points 
produced from the range images. This improves the performance of the meshing step dramatically. The space 
encompassing the point-cloud is divided into a voxel grid at a speci.ed reso­lution. Points contained 
within non-empty voxels are then averaged to produce a single voxel value. This averaging is done for 
all point attributes: position, intensity and (nor­malized) normal information. The last pre-processing 
step involves removing spurious data points. These are .oating outlier data points and points lying along 
the camera tra­jectory (artifacts of the stereo algorithm). These points are easy to detect by sweeping 
a small volume in space-time along the camera trajectory and removing the intersecting points. The voxel 
representation is then meshed using a variation of the Surface Nets algorithm (see [7]). However, we 
omit the relaxation step (and hence do not subdivide the voxels). The reason for this is that the subdivided 
voxels yield many more mesh faces and the relaxation function does not pro­vide enough smoothing in this 
case to make the higher cost associated with the additional mesh faces worthwhile. In­stead we post-process 
the mesh to .ll small holes and smooth the resulting representation. Hole closing. The .rst follow-up 
processing step is to close any holes present in the mesh. These holes are primarily the result of highly 
specular or textureless surfaces which yield areas of very sparse point-cloud data. These holes are fairly 
small and we take two approaches to closing them. To detect the holes we .rst identify boundary mesh 
edges. We then enumerate through chains of boundary edges that form loops. Edge loops of size three can 
be closed trivially by creating a new triangle to .ll it. Edge loops of greater than size three are .lled 
by .rst computing the mean vertex from all the vertices in the edge loop chain. We then construct a triangle 
fan with this averaged vertex as a center out to every edge in the loop. This works very well for small 
holes  (a) (b) (c) (d) (e) Figure 4: Mesh Unwrapping. (a) and (b) show the input mesh to the unwrapping 
algorithm. (c) shows the .attened version of the mesh and (d) its wireframe representation. (e) shows 
the computed normal map gradient. and does not require an advanced 3D tessellation algorithm such as 
Delauney Triangulization. Smoothing. With the mesh free of holes we address the smoothing issue. Mesh 
smoothing is a solution to address­ing the problem of noise in the point-cloud information. We tackle 
smoothing using a mesh subdivision smoothing algo­rithm. These are iterative algorithms that consist 
of divid­ing the faces of a mesh and applying a relaxation function to the vertices. We have found applying 
a single iteration of Loop Subdivision[15] improves visual quality signi.cantly (see [22] for a recent 
survey on the topic). The discrete iterative nature of the meshing algorithm pro­duces a fairly large 
uniform mesh when run at resolutions required to extract a good facial pro.le. The size increases again 
once subdivision has been applied. With rendering performance of a model being inversely proportional 
to its size we reduce the number of faces in the mesh using a mesh decimation algorithm (see [9]). We 
iteratively .nd and col­lapse the edge that has least impact on the model geometry. The result is a dramatically 
reduced non-uniform mesh with approximately the same 3D pro.le as the original input. The results of 
the point-cloud meshing can be seen in Figure 3.  3. TEXTURE MAPPING WITH RANGE IM-AGES The task of 
texture-mapping a 3D model given real-world images and associated camera position and orientation infor­mation 
is very complex. Small changes in color between ad­jacent triangles seem unnatural and can easily catch 
the at­tention of the human eye. The discontinuity between di.er­ent textures applied to adjacent mesh 
faces is referred to as seaming. Even with a near pixel-perfect geometric mapping of di.erent captured 
images to adjacent faces, the brightness distortion from camera gain is enough to result in seaming. 
Thus many approaches to texture-mapping (see [36, 1, 33, 3, 34]) revolve around addressing this issue. 
(See [27] for a recent survey of mesh parameterization approaches.) Our approach is similar to the technique 
described in [36]. We compute the mapping of a triangle to a range image by projecting the triangle to 
the image plane in world-space by using its associated camera position and orientation. Our mapping process 
begin by selecting an optimal range im­age, i.e., the image that is able to map the most mesh tri­angles, 
and use that to texture the model. Triangles that do not map within the bounds of the image or have a 
zero area mapping are then mapped with a best-.t strategy: the range image chosen is the one that yields 
the largest pro­jected area on the texture. This fairly simple approach is able to yield a texture that 
is free of any prominent seaming artifacts. The next step is to compose a single texture from the mesh 
mapping. Retaining all the range images as textures for model would dramatically increase the size of 
the model and preclude real-time performance. To produce an e.cient model representation we use an automatic 
UV Parameteri­zation algorithm to map the vertices of the mesh from 3D to a 2D plane. This is often referred 
to as a mesh unwrapping. We can then render the unwrapped mesh fully textured as our new single uni.ed 
texture map; texture UV-coordinates for the 3D mesh are simply the vertex positions of the un­wrapped 
mesh (see Figure 4(a) and (b)). Angle-based Flattening (ABF)[26] is used to perform the mesh unwrapping. 
The algorithm minimizes the di.erence in the interior angles of the triangles between the mesh tri­angles 
from 3D to 2D. This e.ectively minimizes stretch and skew artifacts of the parameterization. It also 
maintains ad­jacency between faces in the rendered texture, i.e. internal mesh edges are consistent, 
which makes the texture much friendlier for post-processing such as scaling or image .lter­ing.  4. 
PER-PIXEL ILLUMINATION A potential defect with low resolution polygon meshes is that the mesh may undersample 
the underlying geometry result­ing in illumination artifacts. In essence the mesh incorrectly samples 
the position and orientation of the surface of the object (here a face) and the lighting model then highlights 
these artifacts. One approach to addressing this potential defect is to explicitly model local surface 
normal information that might not be properly captured by the geometry of the polygon mesh. Bump Mapping[13] 
is a technique similar to texture mapping, however, instead of obtaining intensity information from a 
2D map, displacement from the surface is taken into consideration when lighting calculations are performed 
to generate .ne surface detail without the cost of additional geometry data. Normal mapping is the dual 
to bump mapping; instead of encoding displacement in the 2D map, the surface normal is encoded directly. 
With cur­rent video hardware supporting multiple texture paths and dot-product blending per-pixel di.use 
illumination can be achieved without run-time performance overhead (see [10]).  (a) (b) (c) (d) (e) 
Figure 5: Final Model. (a)-(e) provides multiple views of the textured and normal mapped mesh. The raw 
point cloud data obtained with the sensor provides dense samples of environmental structure. We compute 
lo­cal normal information from the point-cloud simply by av­eraging the normals between a pixel and its 
adjacent pixels with depth values. A vertex is assigned a normal that is the normalized sum of point 
normals local to that vertex. This improves the surface detail of a model when lighting is applied. We 
propagate this normal information further by generating a normal map. We use the unwrapped mesh information 
and subdivide it multiple times to achieve higher resolution (in the same way the meshing algorithm produces 
the mesh). Normals for the new vertices are sampled from the point­cloud respective to their positions 
in 3D space. The normal map is produced by encoding the normals as vertex colors and rendering linearly 
interpolated gradient-.lled triangles to an image (see Figure 4(c) and (d)). Figure 5 illustrates the 
quality of model that can be constructed from our stereo im­age sensor. After creating the photo-realistic 
3D avatar, this model can be animated using traditional rigging techniques in commercial applications 
such as Maya, 3D Studio Max, or Blender 3D to attach existing stock animations to the models. By applying 
a skeletal bone structure to the model, it can be animated and exported into the game environment where 
the user can now play as, or against, themselves.  5. RESULTS AND DISCUSSION The system presented here 
can be used to extract accurate 3D information from the stereo video capture. Advantages to using this 
type of system over existing laser scanning sys­tems to acquire 3D information include (i) It is a passive, 
eye-safe system. No energy is emitted into the environment. This is a particularly important issue in 
the generation of 3D head models as laser light would be projected towards the subject s eyes. (ii) The 
system is low cost, requiring only the use of two computer cameras. It would be pos­sible, for example, 
to utilize o.-the-shelf synchronized web cameras to collect the necessary imagery. (iii) The system generates 
photorealistic 3D models of human faces, heads, bodies, other objects or even entire rooms without requiring 
special markers to be placed in the environment. (iv) There is no need to calibrate multiple camera positions 
or to cali­brate multiple (e.g. laser and visible light) sensors together. The camera motion is obtained 
from the visual motion alone without the need of specially placed markers in the scene. Models obtained 
with this technique can then be rigged and animated with commercial animation packages such as Maya and 
Morpheme and imported into the game or simulation environmenttobeusedasanavatarinthe3Dworld. This technology 
is suitable for creating photo-realistic avatars for use in games and simulation environments and can 
lead to a more immersive experience for the user. Acknowledgements The support of the University of Ontario 
Institute of Tech­nology, OGS, NSERC, CRTI and MDA is gratefully ac­knowledged.  6. REFERENCES [1] A. 
Baumberg. Blending images for texturing 3d models. In Proceedings of the British Machine Vision Conference, 
2002. [2] P. Besl and N. McKay. A method for registration of 3-d shapes. IEEE Transactions on Pattern 
Analysis and Machine Intelligence (PAMI), 14(2):239 256, February 1992. [3] P. Debevec, Y. Yu, and G. 
Boshokov. E.cient view-dependent image-based rendering with projective texture-mapping. Technical Report 
CSD-98-1003, 20 1998. [4] U. Dhond and J. Aggarwal. Structure from stereo -a review. IEEE Trans. Systems, 
Man, and Cybernetics, 19:1489 1510, 1989. [5] G. Dudek, P. Giguere, C. Prahacs, S. Saunderson, J. Sattar, 
L. Torres, M. Jenkin, A. German, A. Hogue, A. Ripsman, J. Zacher, E. Milios, H. Liu, P. Zhang, M. Buehler, 
and C. Georgiades. AQUA: An Amphibious Autonomous Robot. IEEE Computer, 40(1):46 53, January 2007. [6] 
M. Fischler and R. Bolles. Random sample consensus: A paradigm for model .tting with application to image 
analysis and automated cartography. Communicationsofthe ACM, 24(6):381 385, 1981. [7] S. Frisken. Constrained 
elastic surface nets: Generating smooth surfaces from binary segmented data. In Proceedings of the First 
International Conference on Medical Image Computing and Computer-Assisted Intervention, pages 888 898, 
1998. [8] S. Gill. Polygonal meshing for stereo video surface reconstruction. Master s thesis, York University, 
Toronto, Ontario, Canada, 2007. [9] P. S. Heckbert and M. Garland. Survey of polygonal surface simpli.cation 
algorithms. Technical Report CMU-CS-95-194, 1997. [10] W. Heidrich and H.-P. Seidel. Realistic, hardware-accelerated 
shading and lighting. In A. Rockwood, editor, Siggraph 1999, Annual Conference Proceedings, pages 171 
178, Los Angeles, 1999. Addison Wesley Longman. [11] B. Horn. Closed-form solution of absolute orientaiton 
using unit quaternions. AI Magazine, A(4):629, April  1987. [12] L. Kobbelt and M. Botsch. A survey 
of pointbased techniques in computer graphics. ACM Trans. Graph., 22(3):641 650, 2003. [13] V. Krishnamurthy 
and M. Levoy. Fitting smooth surfaces to dense polygon meshes. Computer Graphics, 30(Annual Conference 
Series):313 324, 1996. [14] Linden Research Inc. Second life. http://www.secondlife.com, 2007. [15] C. 
Loop. Smooth subdivision surfaces based on triangles. Master s thesis, Utah University, USA, 1987. [16] 
W. E. Lorenson and H. E. Cline. Marching cubes: A high resolution 3d surface construction algorithm. 
In Proceedings of the 14th Annual Conference on Computer Graphics and Interactive Techniques, pages 163 
169, 1987. [17] D. G. Lowe. Object recognition from local scale-invariant features. In International 
Converence on Computer Vision, pages 1150 1157, 1999. [18] B. Lucas and T. Kanade. An Iterative Image 
Registration Technique with an Application to Stereo Vision. In International Joint Conference on Arti.cial 
Intelligence (IJCAI), pages 674 679, 1981. [19] M. Meehan, B. Insko, M. Whitton, and J. Frederick P. 
Brooks. Physiological measures of presence in stressful virtual environments. In SIGGRAPH 02: Proceedings 
of the 29th annual conference on Computer graphics and interactive techniques, pages 645 652, New York, 
NY, USA, 2002. ACM Press. [20] Point Grey Research Inc. http://www.ptgrey.com, 2007. [21] W. Press, S. 
Teukolsky, W. Vetterling, and B. Flannery. Numerical Recipes in C. Cambridge University Press, 2002. 
[22] M. A. Sabin. Recent progress in subdivision: a survey. Advances in Multiresolution for Geometric 
Modelling. Mathematics + Visualization, pages 203 230, 2005. [23] D. Scharstein and R. Szeliski. A taxonomy 
and evaluation of dense two-frame stereo correspondence algorithms. International Journal of Computer 
Vision, 47(1-3):7 42, April 2002. [24] S. Se and P. Jasiobedzki. Photorealistic 3d model reconstruction. 
In Proceedings of IEEE International Conference on Robotics and Automation, ICRA2006, pages 3076 3082, 
2006. [25] S. Se, D. Lowe, and J. Little. Vision-based global localization and mapping for mobile robots. 
IEEE Transactions on Robotics, 21(3):364 375, June 2005. [26] A. She.er, B. Levy, M. Mogilnitsky, and 
A. Bogomyakov. Abf++: fast and robust angle based .attening. ACM Trans. Graph., 24(2):311 330, 2005. 
[27] A. She.er, E. Praun, and K. Rose. Mesh parameterization methods and their applications. Foundations 
and Trends.o in Computer Graphics and Vision, 2006. [28] J. Shi and C. Tomasi. Good Features to Track. 
In IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR), pages 593 600, 
Jun. 21-23 1994. [29] M. Sizintsev and R. Wildes. Coarse-to-.ne stereo vision with accurate 3-d boundaries. 
Technical Report CS-2006-07, York University, June 28 2006. [30] Sony Entertainment Inc. Home beta. http://www.homebetatrial.com, 
2007. [31] B. Triggs, P. McLauchlan, R. Hartley, and A. Fitzgibbon. Bundle Adjustment -A Modern Synthesis, 
pages 278 375. Lecture Notes in Computer Science. Springer-Verlag, 2000. [32] P. Vanezis, M. Vanezis, 
G. McCombe, and T. Niblett. Facial reconstruction using 3-d computer graphics. Forensic Science International, 
108:81 95, 2000. [33] L.Wang,S.B.Kang,R.Szeliski,and H.-Y.Shum. Optimal texture map reconstruction from 
multiple views. In Proceedings of the 2001 IEEE Computer Society Conference on Computer Vision and Pattern 
Recognition, 2001, volume 1, pages 347 354, 2001. [34] F. M. Weinhaus and V. Devarajan. Texture mapping 
3d models of real-world scenes. ACM Comput. Surv., 29(4):325 365, 1997. [35] E. Weisstein. Rodrigues 
Rotation Formula. From MathWorld A Wolfram Web Resource. http://mathworld.wolfram.com/RodriguesRotation 
Formula.html, 2006. [36] S.Wuhrer,R.Atanossov,andC.Shu.Fullyautomatic texture mapping for image-based 
modeling. Technical Report NRC/ERB-1141, August 2006. [37] B. Zitova and J. Flusser. Image registration 
methods: asurvey. Image and Vision Computing, 21:977 1000, 2003.   
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2007</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>1328235</article_id>
		<sort_key>330</sort_key>
		<display_label>Pages</display_label>
		<pages>8</pages>
		<article_publication_date>11-14-2007</article_publication_date>
		<seq_no>2</seq_no>
		<title><![CDATA[IMTool]]></title>
		<subtitle><![CDATA[an open framework for interactive music composition]]></subtitle>
		<page_from>181</page_from>
		<page_to>188</page_to>
		<doi_number>10.1145/1328202.1328235</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1328235</url>
		<abstract>
			<par><![CDATA[<p>In computer games, music often serves to create a more immersive and captivating experience for the target audience. As such, it often needs to adapt in real-time to changes in the game state. Otherwise, it might not blend well with the game environment and might even be detrimental to the players' experience of the game. In this paper, we describe IMTool: an open framework for interactive music composition. It includes an authoring tool whose interface is designed to maximize composers' productivity and a music engine which can be integrated to a game engine through an easy-to-grasp Application Programming Interface (API). Our model is based on finite state machines. We introduce a hybridization between extended and probabilistic finite state machines. This results in automata which include both registers and probabilities. The former allow to create nonlinear music which can adapt to the context of the game. The latter allow to create variations in musical themes more easily. The main motivation of our work is to create a reusable system that may facilitate the implementation of interactive music in future computer games.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[content creation]]></kw>
			<kw><![CDATA[interactive music]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>H.5.5</cat_node>
				<descriptor>Modeling</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>K.8.0</cat_node>
				<descriptor>Games</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10011007.10010940.10010941.10010969.10010970</concept_id>
				<concept_desc>CCS->Software and its engineering->Software organization and properties->Contextual software domains->Virtual worlds software->Interactive games</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003251.10003258</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Multimedia information systems->Massively multiplayer online games</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010476.10011187.10011190</concept_id>
				<concept_desc>CCS->Applied computing->Computers in other domains->Personal computers and PC applications->Computer games</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010469.10010475</concept_id>
				<concept_desc>CCS->Applied computing->Arts and humanities->Sound and music computing</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Design</gt>
			<gt>Experimentation</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P308553</person_id>
				<author_profile_id><![CDATA[81100465201]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Yves]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Chiricota]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Universit&#233; du Qu&#233;bec &#224; Chicoutimi, QC, Canada]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P925245</person_id>
				<author_profile_id><![CDATA[81342495425]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Jean-Michel]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Gilbert]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Universit&#233; du Qu&#233;bec &#224; Chicoutimi, QC, Canada]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Ableton. Live. PC &amp; Mac, 2001--2007.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Atari Games. Skull and Crossbones. Arcade, 1989.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Audiokinetic. Wwise 2007.1. PC, 2007.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[A. Brandon. Adaptive Audio. IAsig Archives, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[A. Clark. Defining Adaptive Music. Gamasutra, 2007. http://www.gamasutra.com/features/20070417/clark_01.shtml.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[D. Cope. An Expert System for Computer-Assisted Composition. <i>Computer Music Journal</i>, 1987.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Creative Labs. ISACT Production Studio. PC, 2003--2006.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[D. S. Dabby. Musical variations from a chaotic mapping. <i>Chaos: An Interdisciplinary Journal of Nonlinear Science</i>, 6, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[DigiDesign. Pro Tools. PC &amp; Mac, 1989--2007.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[C. Doud. Composing, Producing and Implementing an Interactive Music Soundtrack for a Video Game. Game Developers Conference, San Jose, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Firelight Technologies. FMOD Designer. PC &amp; Mac, 2007.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[L. Gilbertz. iMuse Island. {Online}. Available: http://imuse.mixnmojo.com/.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Grame Computer Music Research Lab. MidiShare. Open source. {Online}. Available: http://midishare.sourceforge.net/.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[P. Hanappe, J. Green, S. Letz, M. Nentwig, and A. Schmitt. Fluidsynth. Open source. {Online}. Available: http://www.nongnu.org/fluid/.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[http://www.free-scores.com/.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2312354</ref_obj_id>
				<ref_obj_pid>2312063</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[C.-M. Huang and C.-M. Lo. An EFSM-Based Multimedia Synchronization Model and the Authoring System. <i>IEEE JOURNAL ON SELECTED AREAS IN COMMUNICATIONS</i>, 14, 1996]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Image-Line Software. FL Studio. PC, 1998--2007.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[K. Kondo. Painting an Interactive Musical Landscape. Game Developers Conference, San Francisco, 2007.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[M. Z. Land and P. N. McConnell. Interactive Music Streaming Engine (iMUSE). United States Patent, 1991. {Online}. Available: http://pat2pdf.org/patents/pat5315057.pdf]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[P. Langston. Six Techniques for Algorithmic Music Composition. In <i>Proceedings of the International Computer Music Conference (ICMC)</i>, 1989.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>129738</ref_obj_id>
				<ref_obj_pid>129712</ref_obj_pid>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[D. Lee and M. Yannakakis. Online minimization of transition systems. In <i>Proceedings of the twenty-fourth annual ACM symposium on Theory of computing</i>, pages 264--274. ACM Press New York, NY, USA, 1992]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[LucasArts. Monkey Island 2: LeChuck's Revenge. PC MS-DOS, Floppy &amp; CD-ROM, 1991]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[LucasArts. Grim Fandango. PC, Windows, CD-ROM, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[S. Manousakis. Musical l-systems. Master's thesis, Conservatoire Royal de La Haye, 2006.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[Nintendo. Super Mario Brothers. Nintendo Entertainment System, 1985.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[Nintendo. The Legend of Zelda: Ocarina of Time. Nintendo 64 &amp; Nintendo GameCube, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[Nintendo. New Super Mario Bros. Nintendo DS, 2006.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[Nintendo. The Legend of Zelda: Twilight Princess. Nintendo GameCube &amp; Wii, 2006.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[J. Page and M. Kelly. PS3 Audio: More Than Extra Channels. Game Developers Conference, San Francisco, 2007.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>30</ref_seq_no>
				<ref_text><![CDATA[I. Peterson. Mozart's Melody Machine. <i>Science News Online</i>, 2001]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>31</ref_seq_no>
				<ref_text><![CDATA[PropellerHead Software. Reason. PC &amp; Mac, 2000--2005]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>32</ref_seq_no>
				<ref_text><![CDATA[S. Selfon. GDC Audio Boot Camp. Game Developers Conference, San Francisco, 2007.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>33</ref_seq_no>
				<ref_text><![CDATA[Sony. ACID Pro. PC &amp; Mac, 1998--2006.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>34</ref_seq_no>
				<ref_text><![CDATA[Sony Computer Entertainment of America. The Mark of Kri. PlayStation 2, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>35</ref_seq_no>
				<ref_text><![CDATA[L. Spector and A. Alpern. Induction and Recapitulation of Deep Musical Structure. In Working <i>Notes of the IJCAI-95 Workshop on Artificial Intelligence and Music</i>, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>36</ref_seq_no>
				<ref_text><![CDATA[Steinberg. Cubase. PC &amp; Mac, 1989--2006.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>37</ref_seq_no>
				<ref_text><![CDATA[Stormfront Studios. The Lord of the Rings: The Two Towers. PlayStation 2, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>38</ref_seq_no>
				<ref_text><![CDATA[J. Szinger. On Composing Interactive Music. {Online}. Available http://www.zingman.com/spew/CompIntMusic.html]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>39</ref_seq_no>
				<ref_text><![CDATA[H. K. Taube. Markov Chains. In <i>Notes from the Metalevel</i>, pages 211--232. Taylor &amp; Francis, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 IMTool: An Open Framework for Interactive Music Composition Yves Chiricota Département d informatique 
et mathématique Université du Québec à Chicoutimi 555, boul. de l Université, Chicoutimi, QC Canada G7H 
2B1 Yves_Chiricota@uqac.ca Jean-Michel Gilbert Groupe de Recherche en Informatique Université du Québec 
à Chicoutimi 555, boul. de l Université, Chicoutimi, QC Canada G7H 2B1 Jean-Michel_Gilbert@uqac.ca ABSTRACT 
In computer games, music often serves to create a more im­mersive and captivating experience for the 
target audience. As such, it often needs to adapt in real-time to changes in the game state. Otherwise, 
it might not blend well with the game environment and might even be detrimental to the players experience 
of the game. In this paper, we describe IMTool: an open framework for interactive music compo­sition. 
It includes an authoring tool whose interface is de­signed to maximize composers productivity and a music 
engine which can be integrated to a game engine through an easy-to-grasp Application Programming Interface 
(API). Our model is based on .nite state machines. We introduce a hybridization between extended and 
probabilistic .nite state machines. This results in automata which include both reg­isters and probabilities. 
The former allow to create non­linear music which can adapt to the context of the game. The latter allow 
to create variations in musical themes more easily. The main motivation of our work is to create a reusable 
system that may facilitate the implementation of interactive music in future computer games. Categories 
and Subject Descriptors H.5.5 [Information Interfaces and Presentation]: Sound and Music Computing Modeling; 
K.8.0 [Personal Com­puting]: General Games General Terms Algorithms, Experimentation, Design  Keywords 
Content creation, interactive music 1. INTRODUCTION In computer games, the player is not always required 
to do things in the same order and in exactly the same way. Some­times, there are even multiple paths 
for the story to follow. Permissionto make digital/hardcopy of partofthiswork for personalor classroomuse 
is grantedwithoutfee providedthat the copiesarenot made or distributedforprofit or commercialadvantage, 
the copyright notice, the title of the publication,and itsdate of appear, andnotice is giventhat copying 
is bypermissionoftheACM,Inc.To copy otherwise, torepublish,to poston servers, or to redistribute tolists, 
requires prior specificpermissionand/or a fee. FuturePlay 2007, November 15-17, 2007, Toronto, Canada. 
Copyright 2007 ACM 978-1-59593-943-2/07/0011...$5.00 Consequently, each play through the game is di.erent 
from the next. It is in that aspect that they are very di.erent from movies which never change from one 
viewing to the next. We can then argue that game music should also be very di.er­ent from .lm music. 
However, many composers score game music in the same way they score .lm music. When this is the case, 
we say that their music is linear because there is only one path (line) that it can follow. As such, 
without further editing, it cannot easily adapt to in-game events. One would ask, What are the reasons 
that make linear mu­sic so popular among game composers? The most likely explanation is that it is easier 
to compose than interactive music [32]. Also, it is less expensive for video game compa­nies to implement 
since it means less music to compose and fewer interactions between the composer(s) and the audio programming 
team. Finally, there has been a trend lately in the video game industry to have game music recorded by 
professional orchestras, and linear music is especially well suited for such a purpose. But, according 
to Koji Kondo, this is not good practice because when game music is played by live orchestras and bands, 
the rhythm of the music be­comes the rhythm of the conductor and oftentimes does not match the rhythm 
of the game. As such, it becomes back­ground music that may as well be piped in from another unrelated 
room [18]. Some might believe that Kondo is the only one to believe that sequenced music is better than 
or­chestrated music. On the contrary, some audio programmers from SCEE have recently stated that, with 
the advent of next-gen consoles, the future of game audio may well lie with software synthesizers and 
MIDI technology. This is not very surprising since next-gen consoles have enough CPU power to process 
in real-time all the samples and the DSP e.ects1 that are used on the original track [29]. This means 
that, done properly,and given appropriate sound banks,next-gen synthesized music could have the potential 
to sound almost as good as music recorded by a live orchestra while staying synchronized to the rhythm 
of the game. However, while we have argued that linear music is more popular than interactive music in 
the video games indus­try, there are more than a few games that implement in­teractive music, whether 
based on prerecorded music or se­quenced music. Recent examples would include The Mark of Kri from SCEA 
[34], The Lord of the Rings: The Two 1DSP e.ects can be embedded in a MIDI stream as system exclusive 
messages.  Towers from Stormfront Studios [37], and The Legend of Zelda: Twilight Princess from Nintendo 
[28]. Less recent ex­amples would include Monkey Island 2: LeChuck s Revenge and Grim Fandango both by 
LucasArts [22, 23]. Looking at the various implementations, we can see that each game company seems to 
have a slightly di.erent de.nition of in­teractive music. Nevertheless, each one of these games im­plements 
something its developers call interactive music. As for us, we will de.ne an interactive music track 
as a track for which several musical parameters change seamlessly and in real-time in response to any 
change in the game state. Implementing this level of interactivity in the music requires extensive communication 
between the composer(s), the au­dio programming team, and the producer(s) of the game [10]. We thus propose 
a framework for interactive music composition based on MIDI and Soundfont technology which aim to facilitate 
communication between each member of the previous teams involved with interactive music. Also, our framework 
will allow each member of the team to test new interactive music ideas without having to integrate them 
into the game and thus test them more quickly. In some way, the bene.ts of our approach are not dissimilar 
to the bene.ts of scripting languages for level design.  2. BACKGROUND AND RELATED WORK To be useful, 
an interactive composition framework must in­clude two components: an interpreting music engine and an 
authoring tool. Obviously, the .rst component is required to integrate the music into the game. As for 
the second component, while it is optional, it greatly simpli.es content creation for the music engine. 
In fact, without it, musicians would have a hard time creating content for an interactive music engine 
without help from the programmers. Such ascenariousually impliesextra work that could be better spent 
elsewhere. In this particular case, it would probably be better to give the audio programming team a 
linear score and let them implement the interactivity themselves. In this section, we will take a look 
at some common use cases for interactive music in the games industry. We will also take a look at some 
existing implementations and soft­ware packages for interactive music composition. This will help us 
understand the features that the industry requires of interactive music engines and tools. 2.1 Algorithmic 
Composition Due to the interactive nature of video games, a generic music engine is intrinsically tied 
to algorithmic composition. This is due to the fact that the order of the player s actions in the game 
is unde.ned, and because of that, the music must often be altered in real-time and in signi.cant ways 
in order to accommodate to the new game state. Another reason why algorithmic composition techniques 
have been used in video games is to prevent ear fatigue caused by repetitive music loops [18, 26]. Before 
we continue, a de.nition is in order: algorithmic com­position is the technique of using algorithms, 
whether com­puterized or otherwise, to automate the task of musical com­position. It is usually done 
as a three-stage process where a human composer .rst de.nes: A mapping between non-musical information 
and mu­sical information.  An algorithm for the generation of the said non-musical information.  If 
required, input data for the algorithm.  Next, the composer uses the algorithm to generate some non­musical 
information. Finally, he applies the mapping to get a musical piece which is, usually, taken as such. 
However, in some cases, the composer might want to further edit, by hand, the resulting piece. This last 
case does not interest us since it is not possible for a composer to hand-edit music generated in real-time 
such as is used in a computer game. It is worth noting though that this does not preclude the composer, 
or anyone else for that matter, from feeding new input data into the algorithm through an input device. 
This is the basis of interactive music which we will discuss in Section 2.2. A famous example of algorithmic 
music composition can be foundinthe Musikalische W¨ urfelspiel:a musical dice game that is sometimes 
attributed to Mozart [30]. In this dice game, the player is required to roll a pair of 6-sided dice sixteen 
times then pick up measures from a table according to the results of the dice rolls. In this case, the 
algorithm does not require any input data. Over the years, there have been numerous approaches to al­gorithmic 
composition, ranging from musical dice to genetic algorithms [35] to fractals and chaos theory [8]. Depending 
on the kind of result one expects to achieve with algorith­mic composition, no method is in fact better 
than any other. Some methods excel at creating totally new genres of mu­sic while others are more pro.cient 
at improvising within strictly de.ned limits (like musical genres for instance). Fi­nally, other methods 
are better suited for stitching melody segments together according to a prede.ned set of (proba­bilistic) 
rules. For our purposes, we will only concern ourselves with the stitching approaches. These include 
but are not limited to: expert systems [6], grammar-based approaches [24] and stochastic approaches like 
Markov chains [39], Langston s Ri.ology [20] or the Musikalische W¨ urfelspiel.Notice that some of these, 
like Markov chains, can be represented as state machines. This make them easier to understand for users 
with little to no formal training in mathematics. For similar reasons, the approach we present in Section 
3 is based on .nite state machines.  2.2 Interactive Music Depending on whom you ask, interactive music 
has many de.nitions. This is why, lately, several new monikers have appeared to try and di.erentiate 
the various concepts pre­viously designated as interactive music. Among these are adaptive music and 
reactive music. In this paper, we will keep using interactive music since this is the term every­one 
is familiar with, but we really mean adaptive music as de.ned by Clark: music that changes with (adapts 
to) the state of the game [5]. This de.nition is compatible with the de.nition we gave in Section 1. 
 As such, it is not something new to the game industry. Some might remember how the music of the .rst 
Super Mario Brothers [25] game increased its tempo to signify that the player was about to run out of 
time. Another example of earlyinteractive music can be foundinthe game Skull and Crossbones [2]. In this 
game, the music became more in­tense when the boss appeared, more triumphant as his en­ergy went down, 
and more dire as the player s health went down [4]. Another landmark of interactive music is Monkey Island 
2: LeChuck s Revenge in which LucasArts introduced the iMUSE2 system [19]. Using this system, a programmer 
could modify in real-time the tempo, volume and pan level of the score. He could also transpose the whole 
composition in addition to enabling/disabling individual instrument parts. With iMUSE, it was also possible 
to start the playback at an arbitrary point in any given music .le whether MIDI in earlier versions 
or PCM in later ones. However, what made iMUSE really shine was what composers did with it. For example, 
in Monkey Island 2, there were several areas in the game where a basic theme was introduced and whose 
instrumentation was then subtly modi.ed when certain trig­ger conditions were met. The website iMUSE 
island relates of the Rollercoaster Song whichcan be heardatthe endof the game [12]. The song is actually 
made of four variations of LeChuck s Theme which transition smoothly into one an­other thus giving the 
player the impression that the song is just one big symphonic piece with variations. It is also worth 
noting that the piece can transition from one varia­tion to another at any point in time; the engine 
seamlessly resuming the piece where it left o.. This provided for a much more natural experience than 
if the engine had played the song every time up to the end before switching to a new variation. Later 
works went even further with interactive music, fusing the gameplay and the music into a single symbiotic 
entity. The dancing enemies found in New Super Mario Bros. [27] are a funexample of what canbe achievedwhenthe 
game­play and the music support each other. This an example where synchronizing the gameplay to the music 
can intro­duce subtle new gameplay elements into an otherwise well known game genre. For instance, in 
the game, a player can stand on the head of an enemy and time his jump with the music (and thus with 
the enemy s jump) in order to reach a higher platform [18]. Of course, dancing enemies are only the tip 
of the iceberg and the whole potential of this idea has yet to be fully explored.  2.3 Music Creation 
Tools According to the Interactive Audio Special Interest Group (IASIG), some of the most popular tools 
in the games indus­try include Live [1], Reason [31], Pro Tools [9], Cubase [36], ACID Pro [33], and 
FL Studio [17]. However, after testing them, we came to the conclusion that none of them were de­signed 
from the ground up with interactive music in mind. Still, these tools are among the best for music composition. 
As for interactive music composition,we found that Wwise 2007.1 [3] is a great tool for this task. In 
fact, the developers 2Interactive Music Streaming Engine of Wwise seem to have tackled the problem in 
a way that is very similar to our approach: by chaining musical segments according to a set of transition 
rules. In Wwise,composers can also set various parameters to modify the musical seg­ments. However, in 
contrast to our approach, Wwise works with pre-rendered wave .les while we work with raw MIDI data. Thus, 
it canbe saidthat Wwise is more targeted at sound designers while our approach is more targeted at com­posers. 
Ultimately, having access to the raw musical data will also allow us to apply transformation algorithms 
to orig­inal pieces, thus easing further the composition process. Among other tools that can do interactive 
music, we found FMOD Designer [11] which has most of the features required to create a compelling interactive 
music track. However, it is more complex to use than Wwise and can require more work from the programming 
team to integrate the results into a .nished game. Finally, we also found ISACT Production Studio [7] 
which is said to be a good tool for interactive music.  3. COMPOSITION FRAMEWORK In the last section, 
we observed that an interactive com­position framework can t be useful if it doesn t include at least 
a music engine and an authoring tool. That is why we provide both. In this section, we will describe 
the internals of our music engine as well as the features of our editor. 3.1 The music engine The music 
engine hybridizes probabilistic and extended .­nite state machines. Recall that .nite state machines 
(also called .nite automata) are usually represented with graphs where nodes correspond to states and 
arcs to transitions between states. In our system, user-de.ned MIDI sequences are associated to nodes. 
Roughly, the engine s main function consists in generating paths in these automata. The play­back of 
the MIDI sequences in the order de.ned by these paths leads to musical pieces. We will .rst describe 
prob­abilistic .nite state machines (PSFM) and then extended .nite state machines. Our implementation 
of PSFM is related to Markov chains. It uses the empty set as input alphabet and produce words de.ned 
over a .nite output alphabet A.To each node is as­sociated an output symbol belonging to A;transitions 
from a node to its neighbors is determined by a probability func­tion. In our software, probabilities 
associated to transitions are de.ned by the user. Figure 1 shows a simple example of PSFM as implemented 
in our engine. The output alphabet A consists either of MIDI sequences loaded from the inter­face or 
the empty word e.The use of e allows for more complex musical constructions. It is up to the composer 
to choose musically meaningful sequences for constructing an automaton. Since there is no input alphabet, 
the sequence of transitions is completely determined by the sequence of random num­bers generated by 
the computer for a given run. It follows that our PFSM model is equivalent to .rst-order Markov chains. 
Table 1 is the Markov transition table that corre­sponds to Figure 1.  Figure 1: Example of PFSM / 
graph representation for a .rst-order Markov chain Probabilistic automata are best at introducing random 
vari­ations into a composition. However, they do not o.er much .exibility to composers. Indeed, it is 
very di.cult to de­scribe common musical structures like ABABC with them. Furthermore, they do not provide 
the necessary mechanisms to implement robust communication between the game en­gine and the music engine. 
To overcome the limitations of probabilistic .nite state machines, we combined them with extended .nite 
state machines (EFSM) (see [21, 16]). Our probabilistic extended .nite state machines can be formally 
described as a 7-tuple (S,S0,F,T,A,V,G), where S is a .nite set of states (represented as nodes),  
S0 .S is a start state,  F .S is a (possibly empty) set of .nal states,  T .S ×S is a .nite set of 
transitions,  A is an output alphabet (MIDI sequences),  V is a .nite set of (integer) registers, and 
 G : S .A.{e} is an output function mapping each state to the output alphabet.  In other words, the 
function G associate to each state a (possibly empty) MIDI sequence. The registers in set V are, in fact, 
temporary variables which thegameenginecan modify in real-timeand in which cal­culations can be done. 
Registers can be tested against each others values or against constants. They can be read and modi.ed 
by both the music engine and the game engine. As such,theyserve adualpurpose: composers can use them 
to implement complex musical structures within the authoring tool while programmers can use them to implement 
commu­nication between thegameengineand themusic engine. C D E C 0.25 0.00 0.75 D 0.67 0.33 0.00 E 0.20 
0.30 0.50 Table 1: Example of .rst-order transition table To determine the transition sequence, probabilistic 
extended .nite state machines associate to each transition a 4-tuple (C,f,p,r), where C is a boolean 
predicate called the enabling function,  f is a register update function,  p is a probability value, 
and  r is a priority value (a positive integer).  Apredicate C may consist either of a register-register 
com­parison, a register-constant comparison or the boolean con­stant TRUE. They determine which transitions 
the automa­ton will be allowed to follow. Whenever a state s is visited, the next state is chosen according 
to the priority of its outgoing transitions. The engine veri.es each transition predicate from higher 
to lower priorities. Priorities serve to resolve the ambiguity as to which transition should be followed 
when more than one condition is true. We use the convention that transitions whose enabling function 
is the boolean constant TRUE have the lowest priority among all, i.e. they are tested last. Additionally, 
we require that, once a predicate evaluate to TRUE, the sum of probabilities of all the transitions sharing 
that predicate must be 1.0. Update functions serve to apply operations to the registers (a.k.a. the elements 
of the set V). For example, it is possi­ble to increment a register whenever the automaton follows a 
transition. These features allow the creation of counting loops for instance. Predicates, update functions, 
probabil­ities, and priorities are user-de.ned through the editor, as describedinthe next section. To 
better integrate with game engines, our implementation is designed to run in a multithreaded environment 
where the game engine runs in one thread and the music engine in another. On modern multiprocessor systems, 
thanks to lockless synchronization, this architecture promises a very low latency when reading and writing 
to the registers. MIDI playback and Soundfont support are implemented using the Figure 2: The user interface 
 Fluidsynth software synthesizer and the MidiShare sched­uling libraries [14, 13]. Finally, we provide 
an API to bind everything together. Its most useful functions are Initial­ize, LoadFile, GetRegister, 
SetRegister, StartPlayback, PausePlayback and StopPlayback.  3.2 The editor For the editor, we wanted 
to make a tool that would be powerful yet easy to use. In this view, we designed the tool around a familiar 
three-pane interface, and we used the classicWindows look and feel. Wehavealsodoneaway with most dialog 
boxes in order to minimize the number of clicks theuser willhaveto make. Figure 2shows thethree panes: 
a project explorer and a property window on the left and the designareaonthe right. Figure 3 shows an 
enlarged view of the project explorer. It is through there that the user will add and remove .les from 
his current project. Currently, the task is performed by right-clicking on the project tree. Depending 
on where the click has landed, the software will propose di.erent sets of meaningful tasks. Selecting 
an item through a left-click in the project explorer will display its properties in the prop­erty window. 
Notethatthere aretwo .letypes that the user can import: Soundfonts and MIDI .les. Both have similar properties: 
an user-de.ned display name and a .le­name. However, Soundfonts have an additional property: bank o.set. 
This property allows composers to use multiple Soundfonts in the same project by o.seting the instrument 
bank to which they will be loaded (usually bank 0). These additional Soundfonts can then be used by issuing 
a Bank Select Message in the MIDI stream. This is done using an external MIDI editor. Automata are not 
saved as separate .les from the project and thus cannot be imported. Figure 3: Project explorer The 
lower-left pane is the aforementioned property window. It contextually displays the properties of any 
item the user selects either in the project explorer or in the design area. It also allows the user to 
make modi.cations to these prop­erties. Figure 4 shows the panel displaying the properties for two di.erent 
transitions. Notice that most of the prop­erties correspond to those de.ned in the preceding section, 
although we used di.erent names to make the interface more user-friendly. However, the type property 
is editor-speci.c and serves to prevent mistakes by the user by imposing the constraint that transitions 
must either have an user-de.ned probability value or an user-de.ned enabling function but not both. In 
the .rst case, we call the transitions stochas­tic transitions, and we .x their enabling function to 
the Figure 4: Transition properties constant TRUE.Otherwise, we callthe transitions condi­tional transitions, 
and we .x their probability value at 1.0. The interesting thing about this constraint is that it does 
not restrict the expressivity of the model too much, as illus­trated by Figure 5(a) and 5(b). (a) Without 
types (b) With types Figure 5: Types do not limit the expressivity of the model The rightmost pane of 
the editor s main window is the de­sign area. This is where, using the node creation tool, the transition 
creation tool, and the deletion tool (see Figure 6) that the user will design his musical automata. Left-clicking 
on a node or a transition in this pane will select it and dis­play its properties in the property window. 
We have also added a play node tool to allow the user to listen to one or more unrelated nodes. The design 
area also provides visual feedback when the user presses play on the design toolbar, i.e. the current 
node is highlighted in red (see Figure 7). Figure 6: Design Toolbar Finally, to provide for better testing 
of the interactive ele­ments of a composition, we have also integrated a debugger which takes the place 
of the property window while the vir­tual machine is playing and displays the state of the registers 
in real-time. Figure 7 illustrates the debugger interface. The composer can also pause the playback, 
make some changes to the register values in the debugger window, and resume the playback using the new 
values. There is also a tool to step through the virtual machine one state at a time, either from a paused 
state or from the beginning. This feature is useful because the machine can have states that the user 
wouldn t be able to normally pause on because they either have no MIDI data or MIDI data that is too 
short. Using these features, the user can do many of the common interactive music tasks as de.ned by 
Kondo [18], Doud [10],  Figure 7: The debugger user interface and Szinger [38] or as implemented by 
iMUSE [19] and Wwise 2007.1 [3]. However, MIDI editing must currently be done using an external editor, 
and we do not yet sup­port real-time modi.cations to the MIDI stream, e.g. tempo changes and track muting. 
  4. AN APPLICATION TO GAME MUSIC In this section, we present an example to illustrate how our framework 
can be used to design game music. It is based on a ritornello extracted from the .rst musical phrase 
of Rach­manino. s prelude op. 23 no 5(thescore and the MIDI se­quence both come from FreeScore [15]). 
This phrase, shown in Figure 8, comprises the .rst nine measures of the pre­lude. We have chosen this 
piece for its stirring character and for its structure, where melody, harmony and rhythm are tightly 
coupled. Figure 8: First musical phrase of Rachmanino. s prelude Figure 9: Ritornello from Rachmanino. 
s prelude Analysis of this phrase leads to ten sequences corresponding to musically meaningful sub-phrases. 
Besides the codetta in sub-phrase m10, there are two main motives in this phrase. The .rst motive appears 
in sub-phrases m2, m3, m8 and m9. These correspond to di.erent tones and variations of themotive. Thesame 
goesfor thesecond motive which appears in sub-phrases m4 to m7. This second motive ac­tively engages 
the player and gives him the impression that he must hurry along. We used a MIDI editor to extract these 
sub-phrases to make it possible to import them into our software. Figure 9 represents the automaton we 
constructed from the original musical piece after we imported the MIDI sequences. Each node of the corresponding 
graph is mapped to a MIDI sequence. Notice that some nodes do not have any sequence associated with them. 
These serve to encode the structure of our musical piece. This ritornello is well suited for the kind 
of casual games where the player must perform some task in a limited amount of time in order to proceed 
to the next level. It consists of a main cycle which is played two times, possibly with some minor variations, 
before entering the loop formed by sub­phrases m4, m5, m6 and m7 (bottom right part of Figure 9). The 
purpose of this loop is to put some pressure on the player if he takes too much time to achieve his task, 
i.e. it gives him the impression that he must hurry up. The automaton uses conditional transitions labelled 
with a C on Figure 9 to ensure that the music engine goes through the main cycle two times only before 
entering the m4 m7 loop for the .rst time. Because, at this point, R0 is not greater than 3, the engine 
is allowed to exit the loop once. However, it won t be allowed to exit the loop again when it enters 
a second time. Conditional transitions also serve to ensure that the music engine will not repeat the 
other m4 m7 sequence (top right) more than once. As for stochastic transitions, they are used both to 
encode the mostly deterministic structure of the main cycle and to break the monotony of the in.nite 
m4 m7 loop (bottom right).  We could also add some end-of-level transitions which would reset R0 and 
start the tune all over again. Then, using the API mentioned in section 3, the game engine could set 
and unset a register in the virtual machine which would trigger those end-of-level transitions.  5. 
CONCLUSION AND FUTURE WORKS In this paper, we presented a framework for interactive mu­sic composition 
which allows users to create musical pieces containing stochastic variations, patterns triggered by game 
events and patterns triggering game events. This means that it allows on-the-.y improvisation along pre-composed 
patterns and bidirectional communication between the game engine and the music engine, i.e. they both 
can react to each other. However, while in its actual state the framework can be used for real game development 
with pretty good results, much work remains to be done in order to turn it into a full-.edged interactive 
music solution for the industry. At the present time, the registers can only be used to deter­mine the 
sequencing order of the musical segments. In the future, we plan to add support for real-time modi.cations 
to the MIDI stream through them, i.e. by mapping in-game pa­rameters to registers, it should become possible 
to smoothly adjust musical parameters according to in-game events. An example would be using a register 
to map the volume of an instrument to the player character s remaining health. We also plan to include 
a module to record from a MIDI instru­ment and edit MIDI sequences. This will allow musicians to create 
complete works with greater expressivity and improve our tool e.ciency. Finally, we will investigate 
hierarchical .nite state machines and parallel transition networks (PaT-Nets). We believe that both paradigms 
will allow composers to better express themselves. Hierarchical .nite state machines should allow them 
to isolate, save and reuse parts of their compositions by allowing states to be mapped to sub-automata. 
PaT-Nets should simplify the creation of music with o.beat rhythms by allowing multiple automata to execute 
in parallel. 6. ACKNOWLEDGMENTS The authors would like to thank the Natural Sciences and Engineering 
Research Council of Canada (NSERC) for its support.  7. REFERENCES [1] Ableton. Live. PC &#38; Mac, 
2001 2007. [2] Atari Games. Skull and Crossbones. Arcade, 1989. [3] Audiokinetic. Wwise 2007.1. PC, 2007. 
[4] A. Brandon. Adaptive Audio. IAsig Archives, 2001. [5] A. Clark. De.ning Adaptive Music. Gamasutra, 
2007. http://www.gamasutra.com/features/20070417/ clark_01.shtml. [6] D. Cope. An Expert System for Computer-Assisted 
Composition. Computer Music Journal, 1987. [7] Creative Labs. ISACT Production Studio. PC, 2003 2006. 
 [8] D. S. Dabby. Musical variations from a chaotic mapping. Chaos: An Interdisciplinary Journal of Nonlinear 
Science, 6, 1996. [9] DigiDesign. Pro Tools. PC &#38; Mac, 1989 2007. [10] C. Doud. Composing, Producing 
and Implementing an Interactive Music Soundtrack for a Video Game. Game Developers Conference, San Jose, 
2003. [11] Firelight Technologies. FMOD Designer. PC &#38; Mac, 2007. [12] L. Gilbertz. iMuse Island. 
[Online]. Available: http://imuse.mixnmojo.com/. [13] Grame Computer Music Research Lab. MidiShare. Open 
source. [Online]. Available: http://midishare.sourceforge.net/. [14] P. Hanappe, J. Green, S. Letz, M. 
Nentwig, and A. Schmitt. Fluidsynth. Open source. [Online]. Available: http://www.nongnu.org/fluid/. 
[15] http://www.free-scores.com/. [16] C.-M. Huang and C.-M. Lo. An EFSM-Based Multimedia Synchronization 
Model and the Authoring System. IEEE JOURNAL ON SELECTED AREAS IN COMMUNICATIONS, 14, 1996. [17] Image-Line 
Software. FL Studio. PC, 1998 2007. [18] K. Kondo. Painting an Interactive Musical Landscape. Game Developers 
Conference, San Francisco, 2007. [19] M. Z. Land and P. N. McConnell. Interactive Music Streaming Engine 
(iMUSE). United States Patent, 1991. [Online]. Available: http://pat2pdf.org/patents/pat5315057.pdf. 
[20] P. Langston. Six Techniques for Algorithmic Music Composition. In Proceedings of the International 
Computer Music Conference (ICMC), 1989. [21] D. Lee and M. Yannakakis. Online minimization of transition 
systems. In Proceedings of the twenty-fourth annual ACM symposium on Theory of computing, pages 264 274. 
ACM Press New York, NY, USA, 1992. [22] LucasArts. Monkey Island 2: LeChuck s Revenge. PC, MS-DOS, Floppy 
&#38; CD-ROM, 1991. [23] LucasArts. Grim Fandango. PC, Windows, CD-ROM, 1998. [24] S. Manousakis. Musical 
l-systems. Master s thesis, Conservatoire Royal de La Haye, 2006. [25] Nintendo. Super Mario Brothers. 
Nintendo Entertainment System, 1985. [26] Nintendo. The Legend of Zelda: Ocarina of Time. Nintendo 64 
&#38; Nintendo GameCube, 1998. [27] Nintendo. New Super Mario Bros. Nintendo DS, 2006. [28] Nintendo. 
The Legend of Zelda: Twilight Princess. Nintendo GameCube &#38; Wii, 2006. [29] J. Page and M. Kelly. 
PS3 Audio: More Than Extra Channels. Game Developers Conference, San Francisco, 2007. [30] I. Peterson. 
Mozart s Melody Machine. Science News Online, 2001. [31] PropellerHead Software. Reason. PC &#38; Mac, 
2000 2005. [32] S. Selfon. GDC Audio Boot Camp. Game Developers Conference, San Francisco, 2007. [33] 
Sony. ACID Pro. PC &#38; Mac, 1998 2006. [34] Sony Computer Entertainment of America. The Mark of Kri. 
PlayStation 2, 2002. [35] L. Spector and A. Alpern. Induction and Recapitulation of Deep Musical Structure. 
In Working Notes of the IJCAI-95 Workshop on Arti.cial Intelligence and Music, 1995.  [36] Steinberg. 
Cubase. PC &#38; Mac, 1989 2006. [37] Stormfront Studios. The Lord of the Rings: The Two Towers. PlayStation 
2, 2002. [38] J. Szinger. On Composing Interactive Music. [Online]. Available: http://www.zingman.com/spew/CompIntMusic.html. 
[39] H. K. Taube. Markov Chains. In Notes from the Metalevel, pages 211 232. Taylor &#38; Francis, 2004. 
  
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2007</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>1328236</article_id>
		<sort_key>340</sort_key>
		<display_label>Pages</display_label>
		<pages>8</pages>
		<article_publication_date>11-14-2007</article_publication_date>
		<seq_no>3</seq_no>
		<title><![CDATA[Adaptive multiple texture approach to texture packing for 3D video games]]></title>
		<page_from>189</page_from>
		<page_to>196</page_to>
		<doi_number>10.1145/1328202.1328236</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1328236</url>
		<abstract>
			<par><![CDATA[<p>This paper presents an adaptive multiple texture approach to the problem of texture packing for 3D video games. In modern graphics hardware, texture size is typically constrained to width and height dimensions that are powers of two. To reduce the texture management overhead caused by storing individual textures, texture packing algorithms are used to pack multiple textures into a single powers-of-two texture. Current texture packing techniques are very limiting as they are capable of packing textures only into a single texture of predefined size. This can result in significant wasted texture space due to the powers-of-two texture size restrictions. In the proposed technique, individual arbitrarily sized rectangular textures are packed into multiple textures in an adaptive manner. This approach reduces the amount of wasted texture space in a more efficient manner by adaptively determining the quantity as well as size of textures being used during the packing process. Experimental results demonstrate the effectiveness of this technique in packing textures in an efficient and automated fashion. This makes it well suited for improving texture management in future 3D video games, where resources are limited and a high frame rate needs to be achieved to provide a truly immersive experience.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[3D]]></kw>
			<kw><![CDATA[adaptive]]></kw>
			<kw><![CDATA[texture packing]]></kw>
			<kw><![CDATA[video games]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.7</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010226.10010239</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Image and video acquisition->3D imaging</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010226.10010239</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Image and video acquisition->3D imaging</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP43145223</person_id>
				<author_profile_id><![CDATA[81314487059]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Alexander]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wong]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Waterloo, Waterloo, Ontario, Canada]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP39027818</person_id>
				<author_profile_id><![CDATA[81100112596]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Andrew]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kennings]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Waterloo, Waterloo, Ontario, Canada]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>354790</ref_obj_id>
				<ref_obj_pid>354401</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[B. Bell and S. Feiner. Dynamic space management for user interfaces. In <i>User Interface Software</i>, pages 239--248, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[M. Bernard and F. Jacquenet. Free space modeling for placing rectangles without overlapping. <i>Journal of Universal Computer Science</i>, 3(6):703--720, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[E. Catmull. Computer display of curved surfaces. In <i>IEEE Conference on Computer Graphics, Pattern Recognition, and Data Structures</i>, pages 11--17, 1975.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[M. Corporation. <i>DirectX 9 reference manual</i>, chapter D3DPTEXTURECAPS_NONPOW2CONDITIONAL Microsoft Corporation, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[P. Decaudin and F. Neyret. Packing square tiles into one texture. In <i>Eurographics 2004</i>, pages 49--52, August 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[P. Erdos and R. Graham. On packing squares with equal squares. <i>Journal of Combinatoral Theory (A)</i>, 19:119--123, 1975.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[E. Friedman. Packing unit squares in squares: a survey and new results. <i>The Electronic Journal of Combinatorics</i>, DS7:1--24, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>200352</ref_obj_id>
				<ref_obj_pid>200323</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[D. Jennings. On packings of squares and rectangles. <i>Discrete Mathematics</i>, 138(1):293--300, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[K. Kaul and C. Bohn. A genetic texture packing algorithm on a graphical processing unit. In <i>The Ninth International Conference on Computer Graphics and Artificial Intelligence</i>, 2006.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[W. Li and A. Kaufman. Texture partitioning and packing for accelerating texture-based volume rendering. In <i>Graphics Interface 2003</i>, pages 81--88, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[H. Nagamochi. Packing unit squares in a rectangle. <i>The Electronic Journal of Combinatorics</i>, R37:1--13, 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1228915</ref_obj_id>
				<ref_obj_pid>1228784</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[K. Vorwerk, A. Kennings, D. Chen, and L. Behjat. Floorplan repair using dynamic whitespace management. In <i>Journal of Universal Computer Science</i>, pages 552--557, 2007.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Adaptive Multiple Texture Approach to Texture Packing for 3D Video Games Alexander WongAndrew Kennings 
University of Waterloo University of Waterloo 200 University Ave. West 200 University Ave. West Waterloo, 
Ontario Waterloo, Ontario Canada Canada N2L 3G1 N2L 3G1 a28wong@engmail.uwaterloo.ca akenning@cheetah.vlsi.uwaterloo.ca 
ABSTRACT This paper presents an adaptive multiple texture approach to the problem of texture packing 
for 3D video games. In modern graphics hardware, texture size is typically con­strained to width and 
height dimensions that are powers of two. To reduce the texture management overhead caused by storing 
individual textures, texture packing algorithms are used to pack multiple textures into a single powers-of­two 
texture. Current texture packing techniques are very limiting as they are capable of packing textures 
only into a single texture of prede.ned size. This can result in signi.­cant wasted texture space due 
to the powers-of-two texture size restrictions. In the proposed technique, individual ar­bitrarily sized 
rectangular textures are packed into multiple textures in an adaptive manner. This approach reduces the 
amount of wasted texture space in a more e.cient man­ner by adaptively determining the quantity as well 
as size of textures being used during the packing process. Experimen­tal results demonstrate the e.ectiveness 
of this technique in packing textures in an e.cient and automated fashion. This makes it well suited 
for improving texture management in future 3D video games, where resources are limited and a high frame 
rate needs to be achieved to provide a truly im­mersive experience. Categories and Subject Descriptors 
I.3.7 [Computer Graphics]: Texture  General Terms Algorithms  Keywords texture packing, video games, 
3D, adaptive 1. INTRODUCTION Permissionto make digital/hardcopy of part ofthis work for personal or 
classroom use isgranted withoutfeeprovidedthatthecopies are not made ordistributedfor profitorcommercialadvantage, 
the copyright notice, the titleofthe publication, and itsdateof appear,andnoticeis giventhat copyingis 
by permissionoftheACM,Inc. To copy otherwise, to republish,topost on servers, or to redistribute to lists,requires 
prior specific permissionand/or afee. FuturePlay 2007, November 15-17, 2007,Toronto,Canada. Copyright 
2007 ACM 978-1-59593-943-2/07/0011...$5.00 A fundamental technique used in modern 3D video games is 
texture mapping [3]. In texture mapping, 2D images are mapped to the surface of 3D models to give them 
the ap­pearance of greater detail and color. The main advantage of texture mapping is that it provides 
greater perceptual quality to 3D models without the increased computational complexity of using greater 
geometry for the models. This makes it well suited for real-time 3D applications such as video games, 
where a high frame rate needs to be achieved to provide a truly immersive experience. The increase in 
graphical detail and visual realism in 3D video games have resulted in a dramatic increase in texture 
content both quantitatively and qualitatively. Therefore, it is important to keep the computational complexity 
given the large volume of texture data being used in a real-time 3D environment. The use of a large volume 
of individual textures results in performance penalties due to the need for an increased number of context 
switches in the graph­ics pipeline, as well as the performance cost of managing individual textures. 
One common approach used to address the aforementioned problems is texture packing, where independent 
texture con­tent are arranged in such a way that they can be stored in a larger texture. By packing individual 
textures into a larger texture, the number of context switches is signi.cantly re­duced as texture switches 
can be performed through texture coordinate o.setting. Furthermore, it is much less complex to manage 
a single texture than to manage a large number of individual textures. An example of texture packing 
is illustrated in Figure 1. Many techniques have been proposed for the purpose of tex­ture and and block 
packing [6, 5, 9, 11, 10, 8, 7]. We note that the texture packing problem is not a problem unique to 
graphics research. The problem of packing small rect­angles into a single larger rectangle occurs, for 
example, in operations research and in VLSI physical design (e.g., .xed­outline .oorplanning) [1, 2, 
12]. Conventional texture pack­ing techniques attempt to pack a set of individual textures into a single 
texture in such a way that the smallest possible area is utilized. A number of issues arise when these 
con­ventional texture packing techniques are used in the context of modern 3D video games. First, many 
of these algorithms  Figure 1: Example of a set of 9 individual textures packed into a single larger 
texture assume that the initial size of the texture within which the individual textures are packed into 
is known a priori. There­fore, the texture artist must manually decide on the initial texture size, which 
can be di.cult to do when a large num­ber of textures are being packed into the single texture. The second, 
and more serious issue, is that all current tex­ture packing techniques assume that all textures must 
be packed into a single large texture. However, current graphics hardware have certain limitations when 
dealing with texture data that can make single texture packing very ine.cient. First, current consumer 
graphics hardware are restricted to maximum texture sizes of 4096 × 4096. Therefore, conven­tional texture 
packing algorithms are unable to handle situ­ations where the total area of the individual textures exceed 
the maximum texture size. Second, a majority of consumer graphics hardware only support textures with 
height and width dimensions that are powers of two (with only lim­ited support of non-power-of-two textures 
in recent graphics hardware [4]). These dimension restrictions can result in signi.cant wasted texture 
space when conventional texture packing algorithms are used. For example, suppose that conventional texture 
packing al­gorithms are used to pack nine 128 × 128 textures. Since these techniques pack textures into 
a single larger texture, the valid texture sizes that will .t these textures while min­imizing wasted 
space are 512 × 512, 1024 × 256, 256 × 1024, 2048 × 128, and 128 × 2048. Examples of texture packing 
using a 512 × 512 texture and a 1024 × 256 texture are illus­trated in Figure 2. This results in 43.75% 
of texture space being wasted in the texture packing process. This is worsen by the fact that the absolute 
wasted texture space increases substantially as the powers of two increases. Therefore, a method that 
strikes a balance between the number of tex­tures used for packing and the amount of wasted texture space 
based on the set of individual textures being packed is desired. The main contribution of this paper 
is an e.cient adaptive texture packing algorithm for packing individual textures into multiple larger 
textures in an automated fashion. Based on the set of textures that need to be packed, the proposed method 
automatically determines the number and size of textures used for packing such that the amount of texture 
 Figure 2: Example of packing nine 128×128 textures into a single 512 × 512 texture and a single 1024 
× 256 texture. The hashed area represents wasted texture space space being wasted is kept as low as possible 
while reducing the number of textures used. This allows for more e.cient texture management in future 
3D video games while reduc­ing resource requirements, thus allowing for an improved game experience. 
In this paper, the proposed texture packing method is pre­sented in Section 2. A detailed analysis of 
the texture pack­ing performance of the proposed method is presented in Sec­tion 3. Finally, conclusions 
are drawn and future work is discussed in Section 4. 2. PROPOSED ADAPTIVE TEXTURE PACKING ALGORITHM 
In the proposed method, a set of ninput textures {T1,T2,...,Tn}is packed into a set of m output textures 
{O1,O2,...,Om}, where n>m. Each output texture has the following restric­tions: The width and height 
of the texture are powers of two, and  The width and height of the texture cannot exceed the maximum 
texture dimensions.  The number and size of output textures are not known a pri­ori. Therefore, the 
set of output textures will vary based on the input textures such that a balance between the number of 
textures and the amount of wasted texture space. The main advantage of the proposed method is that the 
amount of wasted texture space can be substantially reduced while keeping the number of textures being 
managed as low as pos­sible. An overview of the proposed texture packing method is illustrated in Figure 
3. The set of input textures are ana­lyzed and an initial guess for the size and number of output textures 
is made. The set of input textures are then packed based on the initial guess and analyzed to further 
adjust the number and size of output textures to reduce wasted texture space and produce the .nal set 
of output textures.  Figure 3: Overview of the proposed texture packing algorithm 2.1 Initial Texture 
Packing In the initial texture packing stage, it is necessary to deter­mine an initial estimate for the 
size and number of out­put textures needed to pack the set of n input textures {T1,T2,...,Tn} during 
the multiple texture packing stage. The dimension for each texture in the set of input textures is known 
a priori. Let (wi,hi) be the width and height dimensions of input texture Ti. As a .rst step to the es­timation 
process, the total texture area covered the set of input textures is computed as follows: n A= wihi 
(1) i=1 Suppose we wish to pack the entire set of input textures into a single square texture F. Since 
the width and height of a texture must be powers of two, the texture F would have the dimensions (wF 
,hF )=(2j ,2j ), where j is a parameter that controls the size of the texture. Therefore, the following 
condition must hold true if the set of input textures were to .t into the texture F: A= 22j (2) Based 
on the above condition, a good initial estimate for parameter j would be the following: log2(A) j = 
(3) 2 We note that j in Equation (3) is limited by the graphical hardware limitations for texture size. 
In this case we restrict j in which case the algorithm will obviously fail to produce a solution if only 
a single output texture is used. However, our algorithm handles this case as an over-.tted scenario which 
is described later in the paper. To determine an initial estimate of the number and size of the output 
textures within which the input textures are packed, the set of input textures are .rst packed purpose­fully 
into the square texture F so that the texture area usage can be analyzed. In the proposed algorithm, 
a texture pack­ing system based on the whitespace management concepts presented in [12] and [1] was utilized. 
White space manage­ment is a well-known technique that has been widely used in user interfaces for the 
purpose of 2D and 3D layout. How­ever, such a technique has not been utilized for the purpose of automatic 
multiple texture packing, which has its own set of requirements. The proposed texture packing system 
allows multiple arbitrarily sized rectangular textures to be packed into a texture area while accounting 
for the restric­tions imposed by current graphics hardware. The proposed texture packing system works 
as follows: 1. The set of input textures {T1,T2,...,Tn} are sorted in decreasing order based on their 
texture area (i.e., from largest to smallest). 2. The whitespace list is initialized with a single whites­pace 
rectangle with the same dimensions as texture F. 3. The largest un.tted input texture is packed into 
tex­ture F and the whitespace list is modi.ed by replacing the single whitespace rectangle with adjacent 
whites­pace rectangles formed around the packed texture. 4. For the next largest un.tted input texture, 
the whites­pace list is checked to .nd the smallest whitespace rectangle that can hold the input texture. 
If no ap­propriate whitespace rectangle is found, the algorithm is terminated and texture F is classi.ed 
as over-.tted . Otherwise, the input texture is packed into the appro­priate whitespace partition within 
texture F.If all input textures have been packed into texture F,the algorithm is terminated and texture 
F is classi.ed as .tted . 5. The whitespace list is modi.ed by recalculating the largest available rectangles 
within texture F and the algorithm proceeds back to Step 4.  A example of the proposed texture packing 
system is shown in Figure 4.  Figure 4: Example of the proposed texture packing system 2.1.1 Fitted 
Scenario If the texture F was classi.ed as .tted , the percentage of wasted texture space, W, is calculated 
as follows: A W = (4) 22j Once the percentage of wasted texture space has been calcu­lated, it is necessary 
to determine whether a single texture solution or a multiple texture solution provides a better .t for 
the current set of input textures. To determine whether a multiple texture solution is necessary, a check 
is performed to see if either of the following conditions are met: 1. The area covered by an individual 
input texture is greater than 25% of texture F. 2. The total area covered by the set of input textures 
is greater than 75% of the texture F.  If either of the conditions hold true, then the packed texture 
F is set as the .nal output texture O1, as the single texture .tting provides a very good .t for these 
scenarios and no further output textures are needed. If the conditions are not met, an initial estimate 
utilizing multiple textures is desired. The initial estimate utilizing multiple textures was derived 
in the following manner. First, by failing to satisfy the afore­mentioned conditions, it is reasonable 
to make the assump­tion that the entire set of input textures can be packed into three quarters of the 
square texture F. However, due to the fact that the dimensions of the output textures must be powers 
of two, it is not possible to construct a rectangular output texture with an area equal to 3(22j)/4. 
One approach to addressing this problem is to subdivide the square texture × 2j/2 into four 2j/2 square 
textures, thus retaining dimen­sions that are powers of two. Since only three of the smaller textures 
are needed, the fourth texture can be discarded. This approach leads to a texture space savings of 25% 
when compared to that used by the texture F. However, this approach also results in three times as many 
output tex­tures. To reduce the number of output textures required, two of the remaining output textures 
can be merged into a 2j × 2j/2 rectangular texture. This reduces the number of output textures from 
three to two. Based on the above reasoning, in the event that a multiple texture estimate is desired 
for the under-.tted case, the ini­tial estimated set of output textures consists of the following two 
textures: 1. An output texture (O1) with dimensions (w1,h1)= (2j ,2j/2). 2. An output texture (O2) with 
dimensions (w2,h2)= (2j/2 ,2j/2).  2.1.2 Over-.tted Scenario If the texture F was classi.ed as over-.tted 
, the initial es­timates for the output textures can be derived based the following logic. As previously 
mentioned, the square tex­ture F was constructed such that its area is greater than or equal to the total 
area covered by the set of input tex­tures. Therefore, the fact that the texture F cannot hold the entire 
set of input textures implies that the dimensions of the input textures are not powers of two. Furthermore, 
the total area of the remaining input textures that did not .t into F cannot exceed 22j - Apacked,where 
Apacked is the total area of all input textures that can be packed into F.In the situation where the 
area covered by an individual input texture is greater than 25% of F, then it is not possible to .t more 
than one texture within F. As such, a very good .t for this situation is a single output texture with 
dimensions (w1,h1)=(22j ,2j). In the situation where the area covered by an individual input texture 
is less than 25% of F,the remaining textures is likely to .t within an output texture with dimensions 
(w2,h2)=(2j/2 ,2j/2), which has an area that is a quarter of texture F. Based on the above reasoning, 
the initial estimates for the over-.tted scenario can be determined in the following man­ner. First, 
a check is performed to see if the area covered by an individual input texture is less than 25% of the 
tex­ture F. If the area covered by an individual input texture is less than 25% of the texture F, the 
initial estimated set of output textures consists of the following two textures: 1. An output texture 
(O1) with dimensions (w1,h1)= (2j ,2j).  2. An output texture (O2) with dimensions (w2,h2)= (2j/2 ,2j/2). 
If the area covered by an individual input texture is greater than 25% of the texture F, the initial 
estimated set of output textures consists of one output texture (O1) with dimensions (w1,h1)=(22j ,2j). 
 2.2 Multiple Texture Packing Once the initial estimates for the number and size of output textures 
has been established, texture packing is performed on the set of initial output textures in the following 
manner: 1. The texture packing system described in Section 2.1 is used to pack the set of input textures 
into output texture O1. 2. The remaining textures that cannot be packed into O1 are packed into O2 in 
situations where multiple output textures exist.  Once the initial multiple texture packing has been 
performed, an analysis of texture space usage is performed on O2 to fur­ther re.ne the size and number 
of output textures used. 2.2.1 Fitted Scenario For the cases where the texture F was classi.ed as .tted 
, the size and number of output textures can often be re.ned to obtain a better .t for the set of input 
textures. The main obstacle to reducing the texture space needed to store the set of input textures is 
the fact that the output textures must maintain power-of-two dimensions. Therefore, re.ne­ments in output 
texture sizes must satisfy the restrictions in texture dimensions to function properly on the majority 
of consumer graphics hardware. The approach taken by the proposed texture packing method is to decrease 
the area of output textures by half in alternating dimensions until the minimum power-of-two texture 
size is found. Based on the above reasoning, the following texture re.ne­ment process is performed: 1. 
Check if the texture usage of O2 is zero. If the texture usage is zero, set O1 to size (w1/2,h1)andset 
O2 to size (w1/2,h1/2) and repack. If all textures .t within these two textures, terminate the algorithm. 
Other­wise, set O1 back to its original size, remove O2,and terminate the algorithm. 2. Check if the 
textures that cannot be packed into O1 canbepackedinto O2. If the textures cannot be packed, remove O2 
and set F as O1 and terminate the algorithm. Otherwise, divide the height of O2 by half, repack, and 
proceed to Step 2. 3. Check if the re.ned O2 can hold all remaining textures. If the textures cannot 
be packed, revert to the previ­ous size of O2, repack, and terminate the algorithm. Otherwise, divide 
the width of O2 by half, repack, and proceed to Step 3.  4. Check if the re.ned O2 can hold all remaining 
textures. If the textures cannot be packed, revert to the previous size of O2, repack, and terminate 
the algorithm. Oth­erwise, divide the height of O2 by half, repack, and proceed to Step 2. An example 
of this re.nement process is shown in Figure 5. Figure 5: Example of the re.nement process for the .tted 
scenario. The texture is reduced by half in alternating dimensions until the minimize size is achieved. 
2.2.2 Over-.tted Scenario For the cases where the texture F wasclassi.edas over­.tted , the texture re.nement 
process is re.ned iteratively in the following manner. First, a check is performed to see if all input 
textures can be packed into the current set of output textures. If the input textures cannot be packed, 
the width and height of the smallest output texture is doubled in an alternating manner until either: 
 All input textures can be packed into the re.ned set of output textures, or  the size of the smallest 
output texture is equal to the size of the largest output texture.  If all the input textures can be 
packed into the re.ned set of output textures, then a .t is found and the resulting set of output textures 
are used as the .nal set of output textures. If the size of the smallest output texture is equal to the 
size of the largest output texture and a .t is still not found, a new output texture with a size equal 
to the smallest output texture prior to re.nement is added to the set of output textures and the re.nement 
process is performed repeatedly until all the input textures can be packed into the set of output textures. 
Once the .nal number and size of output textures are determine, the input textures are packed into the 
set of .nal output textures.  3. TEXTURE PACKING PERFORMANCE ANALYSIS To demonstrate the e.ectiveness 
of the proposed adaptive texture packing method, texture packing was performed on four test sets of generated 
input textures. A brief description of each test set is provided below. TEST 1: Set of 133 [32 × 32] 
textures. TEST 2: Setof31[50 × 50] textures. TEST 3: Set of 149 [64 × 64] textures. TEST 4: Setof10[300 
× 300] textures. To judge the e.ectiveness of the proposed method quanti­tatively, the percentage of 
wasted texture space was deter­mined. For comparison purposes, the test input textures in each test set 
was packed into the smallest possible power-of­two texture. The percentage of wasted texture space for 
each scenario is shown in Table 1. It can be observed that the amount of wasted texture space was signi.cantly 
reduced using the pro­posed method when compared to the use of a single texture. Examples of the resulting 
packed output textures are shown in Figure 6, Figure 7, and Figure 8. This demonstrates the e.ectiveness 
of the proposed texture packing method in providing a balance between the amount of textures and the 
amount of texture space used. 4. CONCLUSIONS AND FUTURE WORK This paper proposes a novel adaptive texture 
packing algo­rithm that utilizes multiple textures in an automated man­ner. The proposed method adapts 
the size and number of output textures based on the set of arbitrarily sized input textures to reduce 
the amount of wasted texture space while maintaining a small number of textures. It is believed that 
the proposed technique can be used e.ectively for the pur­pose of texture packing to improve texture 
management in future 3D video games. Future work include investigating al­ternative packing methods to 
further improve texture pack­ing e.ciency.  5. REFERENCES [1] B. Bell and S. Feiner. Dynamic space management 
for user interfaces. In User Interface Software, pages 239 248, 2000. [2] M. Bernard and F. Jacquenet. 
Free space modeling for placing rectangles without overlapping. Journal of Universal Computer Science, 
3(6):703 720, 1997. [3] E. Catmull. Computer display of curved surfaces. In IEEE Conference on Computer 
Graphics, Pattern Recognition, and Data Structures, pages 11 17, 1975. [4] M. Corporation. DirectX 9 
reference manual, chapter D3DPTEXTURECAPS NONPOW2CONDITIONAL. Microsoft Corporation, 2003. [5] P. Decaudin 
and F. Neyret. Packing square tiles into one texture. In Eurographics 2004, pages 49 52, August 2004. 
[6] P. Erdos and R. Graham. On packing squares with equal squares. Journal of Combinatoral Theory (A), 
19:119 123, 1975. [7] E. Friedman. Packing unit squares in squares: a survey and new results. The Electronic 
Journal of Combinatorics, DS7:1 24, 1998. [8] D. Jennings. On packings of squares and rectangles. Discrete 
Mathematics, 138(1):293 300, 1995. [9] K. Kaul and C. Bohn. A genetic texture packing algorithm on a 
graphical processing unit. In The Ninth International Conference on Computer Graphics and Arti.cial Intelligence, 
2006. [10] W. Li and A. Kaufman. Texture partitioning and packing for accelerating texture-based volume 
rendering. In Graphics Interface 2003, pages 81 88, 2003. [11] H. Nagamochi. Packing unit squares in 
a rectangle. The Electronic Journal of Combinatorics, R37:1 13, 2005. [12] K. Vorwerk, A. Kennings, D. 
Chen, and L. Behjat. Floorplan repair using dynamic whitespace management. In Journal of Universal Computer 
Science, pages 552 557, 2007. Table 1: Percentage of wasted textures space for test scenarios Scenario 
Input Textures (Quantity/Size) Output Textures (Quantity/Size) Wasted Texture Space Using Proposed Method 
Wasted Texture Space Using Single Texture TEST 1 133/(32 × 32) 1/(512 × 256) 1/(128 × 64) 2.26% 48.05% 
TEST 2 31/(50 × 50) 1/(256 × 256) 1/(256 × 128) 21.16% 40.87% TEST 3 149/(64 × 64) 1/(1024 × 512) 1/(512 
× 256) 6.88% 41.80% TEST 4 10/(300 × 300) 1/(1024 × 1024) 1/(512 × 512) 31.34% 57.08%  Figure 6: TEST 
1: a) Texture packing using single texture, b) Texture packing using proposed method Figure 7: TEST 2: 
a) Texture packing using single texture, b) Texture packing using proposed method  Figure 8: TEST 3: 
a) Texture packing using single texture, b) Texture packing using proposed method  
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2007</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	</section>
	<section>
		<section_id>1328237</section_id>
		<sort_key>350</sort_key>
		<section_seq_no>9</section_seq_no>
		<section_type>SESSION</section_type>
		<section_title><![CDATA[Short papers]]></section_title>
		<section_page_from>197</section_page_from>
	<article_rec>
		<article_id>1328238</article_id>
		<sort_key>360</sort_key>
		<display_label>Pages</display_label>
		<pages>4</pages>
		<article_publication_date>11-14-2007</article_publication_date>
		<seq_no>1</seq_no>
		<title><![CDATA[Filtering of analogue sticks on joypads for improved control precision]]></title>
		<page_from>197</page_from>
		<page_to>200</page_to>
		<doi_number>10.1145/1328202.1328238</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1328238</url>
		<abstract>
			<par><![CDATA[<p>Analog joysticks especially on game pads present a major challenge to the game play programmer. The usable range of those joysticks that generates valid output data is normally very small. The difficulty is here to implement a system that makes the game easily controllable for the player. In this article we discuss a couple of filtering techniques that have been applied in several shipped games to overcome this problem. These techniques are derived from observations on how those analogue joysticks are used, from where the precision and latency problem stems and how to design an infinite impulse response filter to overcome this problem.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[filter]]></kw>
			<kw><![CDATA[game development]]></kw>
			<kw><![CDATA[joystick]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>J.7</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010405.10010476</concept_id>
				<concept_desc>CCS->Applied computing->Computers in other domains</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010476</concept_id>
				<concept_desc>CCS->Applied computing->Computers in other domains</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Experimentation</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P47289</person_id>
				<author_profile_id><![CDATA[81100428734]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Christoph]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[L&#252;rig]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Artificial Minds and Movements, Montr&#233;al, Canada]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[J. Chestnutt and et al. An intelligent joystick for biped control. In <i>2006 IEEE International Conference on Robotics and Automation</i>, 2006.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>515418</ref_obj_id>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[C. Crawford. <i>The Art of Interactive Design: A Euphonious and Illuminating Guide to Building Successful Software.</i> No Starch Press, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>940762</ref_obj_id>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[C. Crawford. <i>Chris Crawford on Game Design.</i> New Riders Games, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[B. S. Processing. <i>Introduction to DSP IIR filter.</i> http://www.bores.com/courses/intro/iir/index.htm.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[S. Smith. <i>Digital Signal Processing: A Practical Guide for Engineers and Scientists.</i> Newnes, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[N. T. Thomas Funkhouser and J.-M. Jot. Computational sound for graphics, virtual reality and interactive systems. In <i>Course Notes no. 45 SIGGRAPH 2002</i>, September 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Filtering of analogue sticks on joypads for improved control precision Christoph Lürig Arti.cial Minds 
and Movements 416 Maisonneuve Ouest, Bureau 600 Montréal, Quebec H3A1L2, Canada clurig@a2m.com ABSTRACT 
Analog joysticks especially on game pads present a major challenge to the game play programmer. The usable 
range of those joysticks that generates valid output data is normally very small. The di.culty is here 
to implement a system that makes the game easily controllable for the player. In this article we discuss 
a couple of .ltering techniques that have been applied in several shipped games to overcome this problem. 
These techniques are derived from observations on how those analogue joysticks are used, from where the 
precision and latency problem stems and how to design an in.nite impulse response .lter to overcome this 
problem. Categories and Subject Descriptors J.7 [Computers in other systems]: Consumer products  General 
Terms Experimentation, Design  Keywords Joystick, Filter, Game Development 1. INTRODUCTION As Chris 
Crawford explains in [3] every game and every interactive system in general performs three steps. It 
is a combination of listening, thinking and telling. While most of todays technology that has a high 
degree of visibility is used for the telling part in interactive systems the listening part is a lot 
weaker developed but actually makes up most of the fun of the game-play experiences as it de.nes the 
degree of freedom the player ultimatively has [2]. The importance of joystick input processing is also 
emphasized by the famous CCC formula. Character, Camera and Control are the three most important and 
often most di.cult parts of a game. The control and listening part includes in most console games of 
today the interpretation of analogues joystick values of a joypad. These joysticks have the following 
characteristics: Permission to makedigital/hardcopy of part of this workfor personal or classroomuseis 
grantedwithoutfeeprovided thatthecopiesarenot made or distributedfor profit orcommercial advantage, the 
copyright notice, the titleofthepublication,and itsdateof appear,andnoticeisgiventhat copyingis by permission 
ofthe ACM, Inc. To copy otherwise,to republish,topost on servers, or to redistribute to lists,requires 
prior specificpermissionand/ora fee. FuturePlay 2007, November 15-17,2007, Toronto,Canada. Copyright2007ACM. 
 Figure 1: Explanation of joystick elongation. Near the central position of the joysticks the analogue 
values are pretty much indeterministic. One speaks of a dead zone of a joystick.  Some joysticks have 
a kind of outer dead zone. In this case the maximum reading value for one axis is reached before the 
maximal mechanical elongation of the joystick. In this regions the reading value remains constant. With 
elongation the angular distance of the joystick away from the rest position is meant (see .gure 1). 
 As the physical distance between the rest position and the maximal elongation on a joypad stick is very 
small players often overreact in their steering behavior and move the stick to the very extreme position 
very quickly.  A spring in the joystick brings the stick back to the central position. Often players 
let the stick slip back to the central resting position when they want to reduce the elongation. This 
results in some more over extreme reaction as also described in the previous points.  When pushed into 
the upper right position, some joy­sticks return a value of (1.0, 1.0) other return a value  v1.0 v1.0 
of ( , ). In the.rstcaseacircularmovement 2.02.0 of the stick describes a square and in the other case 
it describes a circle. In order to overcome those problems input values from the joystickhavetobeprocessedtogivetheplayerthefeelingof 
controllability of the game. Traditionally the approaches are the application of a look up table for 
the joystick values and the attempt to keep the latency time of the game as small as possible. These 
approaches will be explained in section 2.  Joystick Value Output value Input value Elongation Figure 
2: Simple joystick value mapping function Chestnutt et al. [1] have developed a system for higher level 
interpreation and modi.cation of joystick data for a biped control to help avoid the biped bumping into 
things. Aspects like those also play a role in game development are usually handled by the collision 
system. This paper here focusses on the low level interpretation and modi.cation of joystick data. The 
approach followed in this papers and that has also been applied by the author will be presented in section 
3. The central idea is here to borrow a lesson from .lter design to compensate for the overreaction part 
of the players when in­terpreting values small analogue sticks on a joypad. The .l­ter that will be used 
in this application is an in.nite impulse response .lter. A comprehensive and practical overview of .lter 
design can be found in [5]. A quick introduction to the subject can be found on line at [4]. The game 
developer is most likely to know the concept of .lters from game audio programming as explained in [6]. 
 2. EXISTING FILTERING APPROACHES Most joystick .lters that are used in games today are a di­rect functional 
mapping from an input to the output range. These .lters address the problems of the dead zone. Within 
thedeadzoneavalueofzeroisreturnedtoavoidtheindeter­ministic readings of the joystick in this region. 
Depending on the pad that is used this region can make up to 10 or 15 per cent of the total value range 
of the joystick. Going outwards of this region often a linear or quadratic function is used to map the 
rest of the values up to the maximum. For the case of a quadratic function an example is shown in .gure 
2. The application of the quadratic function results in a higher resolution of the joystick in the lower 
value range. It gives the user a more precise control for slow movements which comes in handy as a support 
for aiming in shooter games. For more complicated control games like car racing often a spline editor 
is used by the game designer to calibrate the input behavior of the joystick. Of the described problems 
however only the dead-zone problem is solved with this ap­proach. All the other problems remain. This 
includes also the problem with the dead zone at the end of elongation range of the joystick, where the 
returned value remains con­stant (see .g. 3). This problem can not be solved by a look­up function. It 
can be extremely irritating for the player, when no further response is happening even though the stick 
Figure 3: Dead zone at the end of the joystick elon­gation range has not reached its maximum elongation 
position. In order to overcome the rest of the mentioned problems the aspect of time has to come into 
play when joystick data is processed. With the help of time also the problems that stem from the relatively 
small elongation range can be eliminated. The approach of using timing aspects will be discussed in the 
next sections.  3. FILTERING THE JOYSTICK VALUES WITH AN INFINITE IMPULSE RE-SPONSE FILTER The basic 
thought about applying this technique is, that when the user moves the small stick on a pad he probably 
does it too quick and too far. As there is always a time lag -latency -between the user input and the 
visual result, the fact that the input movement is too strong is noticed too late. In order too overcome 
this problem, one can insert an in.nite impulse response .lter. The in.nite impulse response .lter is 
a .lter of the general form as described in equation (1). XX y(n)= ck · x(n - k)+ dj · y(n - j) (1) kj 
where x is a series of input values and y theire corresponding output values. The .lter result is in 
consequence a weighted average of some of the previous .lter input and output val­ues. It bears the name 
in.nite impulse response because these .lters can react on a dirac impulse over an in.nite amount of 
time. Because these .lters can also depend on previous .ltered values they are also called recursive 
.lters. The .lter that is used for the joystick processing is a reduced form of equation (1). The .lter 
used in our case is described in equation (2). y(n)= c · x(n)+(1.0 - c) · y(n - 1) (2) If the joystick 
is moved instantaneously in one direction this .lter shows an asymptotic convergence behavior towards 
the .nal value. Depending on the choice of c . (0, 1) this con­vergence is more or less fast. A low convergence 
makes the control system less nervous but also more heavy. Practice has shown that at a constant frame 
rate of 30fps a value of around 0.96 is a good starting point for experimentation.  Case c_1 Case c_2 
 Figure 4: The di.erent .lter cases for joystick posi­tions. In the case of shooter type games this made 
especially the aiming process a lot easier, as over reaction in aiming with the gun as less often the 
case. Choosing lower convergence rates made the gun feel heavier. This could be an inter­esting tweaking 
point for future applications, if several very di.erent types of weapons are about to be used in a game. 
Practice has shown that for the back swinging of the joy­stick into the rest position a lower convergence 
rate would be preferable. When using the small joysticks on a pad the tendency for an exaggerated swinging 
back into the rest po­sition is stronger than from moving from the rest position to an outer position. 
On the other hand when pulling the joystick over the rest position into the other direction ( e.g. fromlefttoright),ahigherrateof 
cshould be used. We use c1 as a damping coe.cient for moving the joystick from a rest to an outer position 
and c2 as a damping coef­.cient for moving the joystick from an outer position to a rest position. We 
can parametrize equation (2) for ease of readability and get equation (3). h(n,c):= c· x(n)+(1.0 - c) 
· y(n- 1) (3) In consequence we have c1 >c2 and can modulate the above described phenomenon with the 
equation (4). 8 ><h(n,c1)if(|x(n)| >|y(n- 1)|) y(n)= .(x(n) · y(n- 1) <0), (4) > : h(n,c2)else This process 
is illustrated in .gure 4. The idea to take the faster converging c1 when the joystick is moved through 
the rest position is motivated by the fact that if this happens the player probably wants to quickly 
move to the opposite direction and not just let the joystick slip from his thumb. In the latter case 
the joystick would have just moved to the rest position in which case the slower converging c2 constant 
would have been used. By applying the combined .lter a relatively easy and smooth aiming process can 
be obtained. The steadiness of the aim­ing process with a joystick on one hand but also the agility on 
the other hand depends signi.cantly on the choice of the parameters c1 and c2. Those in.nite impulse 
response .lters introduced the aspect of time to the processing of joystick data. Also equation (4) has 
shown, that it may be interesting to distinguish whether the joystick is pulled over its rest position 
or not. Both aspects are also playing a signi.cantly role in the following section, where the impact 
and resolution of the outer dead zone problem illustrated in .gure 3 is discussed.  4. DIFFERENTIAL 
INPUT PROCESSING In action adventure or shooter games analog joystick values are also used to control 
the main chanrater. This control posed some additional problems as the walking velocity of the character 
is determined here. As already mentioned some joysticks have an outer dead zone. Due to the outer dead 
zone as represented in .gure 3 the maximal walking velocity is reached before the maximal elongation 
position of the joystick, when walking velocity is derived from elongation. This turned out to be extremely 
irritating for the player. For animation reasons many char­acter based games basically distinguish between 
walking and running. Often it turns out to be impossible to make this distinction possible for the player 
with this constellation. One standard approach in the past for digital joypads has been to derive this 
information from the time the pad has been pressed. When the pad has been pressed in one di­rection the 
movement mode is set to walking and switched to running after a couple of seconds. This approach has 
a serious drawback. Depending on the situation for instance in the case of .eeing that running had to 
start immediately. On the other hand when walking is required like in a sneak situation it would be dangerous 
to switch to running veloc­ity accidentally when the joystick is pressed continuously too long into one 
direction. The .rst solution idea is here to use the time derivative of the joystick input to distinguish 
walking and running. In the moment the joystick is pressed into one direction the moving velocity is 
used as an indicator to distinguish between walk­ing and running. When the area of maximal joystick reading 
was reached the last decision was kept. This solution turned out to be very unstable and unpredictable 
especially under varying frame rate conditions. The approach that .nally solved that problem lied in 
a kind of coarse granular discretization of the di.erence quotient. The total range of the joystick has 
been distinguished in three di.erent zones. The inner dead zone, the outer dead zone of constant reading 
and the area in between. Within the inner dead zone the controlled character was standing. When the inner 
dead zone was left the character switched to walking. When the outer dead zone was reached the time di.erence 
between leaving the inner zone and entering the outer zone was measured. The leaving time from the center 
is kept as tlc. The entering time of the outer zone is kept as teo. If the di.erence is below a threshold 
t1 >teo - tlc the velocity was switched to running. Otherwise it was kept as walking. Switching back 
from running to walking was possible if the joystick-position was out of the outer zone since a time 
t2 with t2 <t1. If the joystick left the outer zone at tlo switching back to walking was possible, when 
t- tlo >t2. Using this approach quick changes could be done to the walking direction while the character 
was kept in running mode. This is illustrated in the joystick position  Figure 5: The di.erent zones 
used for joystick in­terpretation. in .gure 5. The explanation of the di.erent states is as follows: 
State A In central dead region we are standing. The last time we are in this region is kept as time tlc. 
State B We are walking and in the middle region of the joystick area. State C When entering the outer 
area time teo is deter­mined. Depending on the di.erence between tlc and teo the decision between running 
and walking is done. This decision is kept. State D The in between area has been entered again. If the 
joystick remains longer than t2 in this area, we switch back to walking mode. One special consideration 
is applied, when reentering the central dead zone. If in the central deadzone is reached the state is 
switched to stopping no matter whether we came from running or walking. This way it is made sure, that 
a precise stop of the character is always possible. For the general administration of the states according 
to the timing this has no in.uence. This means when the joystick is pulled quickly through the inner 
dead zone and the time passed since the outer dead zone has been left is still smaller than t2 the state 
of the character is switched back to running.  5. EXPERIENCES All discussed joystick .lter modi.cations 
have been analyzed by developers and a game play laboratory. The .ltering as explained in this paper 
have been accepted useful by all parties. Most of them did not see the .ltering techniques that were 
applied explicitly but had the impression that the controls worked more smooth. What most players also 
noted was the feeling of heaviness, when the convergence constants de.nedusedinequation(4)were chosentoolow. 
The game play experience derived from the di.erential input processing presented in section 4 are a bit 
more contradic­tory. About 8 out of 10 people from the developers I asked were satis.ed with the result 
and could easily grab the con­trol system. They felt comfortable with the way of choosing the walking 
speed. The other two people were irritated by the result. The formulation about was used because 1 out 
the eight persons who responded positively was kind of hes­itant about the result. The game play laboratory 
labeled it at least as a better solution than simply deriving the walking speed from the joystick elongation. 
Some journalists later on explained it as a bit irritating in their review. 6. SUM UP In this article 
we have presented the general problems a game developer faces when processing input data from a small 
analog joystick on a pad. We have shown di.erent .l­tering approaches to overcome some of the precision 
issues that naturally appear on those small input devices. Most of the techniques presented approached 
the problem by in­corporating temporal aspects in the analysis of the joystick data. Most of the approaches 
were accepted without hesitation by test players in development and in the laboratory. The dif­ferential 
processing of joystick data returned a bit contradic­tory results. This is probably due to the fact that 
using this kind of time derivative information directly to distinguish between two states is very uncommon. 
Therefore players are not used to it. As always also frame rate and latency turned out to be major factors 
in the quality of the control system. The shorter the latency in the complete game is the easier it is 
for the player to understand and learn the control system. 7. THANKS I would like to thank Ingo Frick 
from the former company Massive Development with whom I discussed aspects of the IIR techniques for input 
.ltering. Furthermore I would like to thank Ethan Larson from Ubisoft from whom stems the basic idea 
to use movement velocity of the joystick to over­come the issue of the outer dead zone in the walking 
mode in character based games.  8. REFERENCES [1] J. Chestnutt and et al. An intelligent joystick for 
biped control. In 2006 IEEE International Conference on Robotics and Automation, 2006. [2] C. Crawford. 
The Art of Interactive Design: A Euphonious and Illuminating Guide to Building Successful Software. No 
Starch Press, 2002. [3] C. Crawford. Chris Crawford on Game Design.New Riders Games, 2003. [4] B.S.Processing. 
Introduction to DSP IIR .lter. http://www.bores.com/courses/intro/iir/index.htm. [5] S. Smith. Digital 
Signal Processing: A Practical Guide for Engineers and Scientists. Newnes, 2002. [6] N. T. Thomas Funkhouser 
and J.-M. Jot. Computational sound for graphics, virtual reality and interactive systems. In Course Notes 
no. 45 SIGGRAPH 2002, September 2002.   
			]]></ft_body>
		</fulltext>
		<article_type art_type="short_paper" />
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2007</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>1328239</article_id>
		<sort_key>370</sort_key>
		<display_label>Pages</display_label>
		<pages>4</pages>
		<article_publication_date>11-14-2007</article_publication_date>
		<seq_no>2</seq_no>
		<title><![CDATA[Bridging the gap]]></title>
		<subtitle><![CDATA[balancing faculty expectations and student realities in computer gaming courses]]></subtitle>
		<page_from>201</page_from>
		<page_to>204</page_to>
		<doi_number>10.1145/1328202.1328239</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1328239</url>
		<abstract>
			<par><![CDATA[<p>As game design and game development emerges as an academic discipline, it is important for programs to balance the technical and creative aspects of the curriculum. Students must be exposed to both the technical and content creation experiences that define the field, and also be exposed to critical areas such as games and media history, games analysis, literature, media study, and psychology. Furthermore, students must understand the ramifications of cultural and societal factors as they intersect games and entertainment technology. In this paper, the authors examine how a technically focused game program can provide students with a broader exposure to the world of game development. In particular, the authors will discuss where their treatment succeeded and failed, and how the curriculum has evolved over several offerings.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[games education]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>K.8.0</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010405.10010476.10011187</concept_id>
				<concept_desc>CCS->Applied computing->Computers in other domains->Personal computers and PC applications</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010476.10011187</concept_id>
				<concept_desc>CCS->Applied computing->Computers in other domains->Personal computers and PC applications</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP43138543</person_id>
				<author_profile_id><![CDATA[81100494587]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Christopher]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Egert]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Rochester Institute of Technology]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP43140016</person_id>
				<author_profile_id><![CDATA[81406591703]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Stephen]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Jacobs]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Rochester Institute of Technology]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP14263721</person_id>
				<author_profile_id><![CDATA[81100322033]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Andrew]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Phelps]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Rochester Institute of Technology]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Carnegie Mellon University Entertainment Technology Center Home Page, 2007. Retrieved July 10, 2007 from http://www.etc.cmu.edu/.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>940762</ref_obj_id>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Crawford, C., 2003. Chris Crawford on Game Design. New Riders Group, Indianapolis.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>995699</ref_obj_id>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[DeMaria, R. and Wilson, J. L., 2003. High Score!: The Illustrated History of Electronic Games, Second Edition, McGraw-Hill/Osborne.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1207081</ref_obj_id>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Freeman, D., 2004. Creating Emotion in Games, New Riders Group, Indianapolis.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Game Career Guide Home Page, 2007. Retrieved July 10, 2007 from http://www.gamecareerguide.com/.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Game Programming and New Media Schools, 2007. Retrieved July 10, 2007 from http://www.gameprogrammer.com/links/schools.html.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[IGDA Curriculum Framework: The Study of Games and Game Development (Version 2.3 beta), 2003. Retrieved July 1, 2007 from http://www.igda.org/academia/IGDA_Curriculum_Framewo rk_Feb03.pdf.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>559522</ref_obj_id>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Kent, S. L., 2001. The Ultimate History of Video Games: From Pong to Pokemon--The Story Behind the Craze That Touched Our Lives and Changed the World, Three Rivers Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1207478</ref_obj_id>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Koster, R., 2005. A Theory of Fun for Game Design, Paraglyph Press, Scottsdale, AZ.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[M&#228;yr&#228;, F., Pac-Man and the Ivory Tower, The Ivory Tower, IGDA Column, Retrieved July 10, 2007 from http://www.igda.org/columns/ivorytower/ivory_Mar03.php, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>572887</ref_obj_id>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Murray, J. H., 1997. Hamlet on the Holodeck: The Future of Narrative in Cyberspace, p. 78, The Free Press, New York.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>572887</ref_obj_id>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Murray, J. H., 1997. Hamlet on the Holodeck: The Future of Narrative in Cyberspace, pp. 132--135, The Free Press, New York.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Rochester Institute of Technology Game Design and Development Home Page, 2007. Retrieved July 13, 2007 from http://games.rit.edu/.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1213088</ref_obj_id>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Rollings, A. and Adams, E., 2003. Andrew Rollings and Ernest Adams on Game Design, New Riders Group, Indianapolis.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>600034</ref_obj_id>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Ryan, M.-L., 2001. Narrative as Virtual Reality: Immersion and Interactivity in Literature and Electronic Media, The John Hopkins University Press, Baltimore, MD.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[University of Southern California Home Page, 2007. Retrieved July 11, 2007 from http://www.usc.edu/.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Bridging the Gap: Balancing Faculty Expectations and Student Realities in Computer Gaming Courses Christopher 
Egert Stephen Jacobs Andrew Phelps Game Design and Development Game Design and Development Game Design 
and Development Rochester Institute of Technology Rochester Institute of Technology Rochester Institute 
of Technology +1 585 475 4873 +1 585 475 7803 +1 585 475 6758 caeics **at** rit.edu sxjics **at** rit.edu 
amp5315 **at** rit.edu ABSTRACT As game design and game development emerges as an academic discipline, 
it is important for programs to balance the technical and creative aspects of the curriculum. Students 
must be exposed to both the technical and content creation experiences that define the field, and also 
be exposed to critical areas such as games and media history, games analysis, literature, media study, 
and psychology. Furthermore, students must understand the ramifications of cultural and societal factors 
as they intersect games and entertainment technology. In this paper, the authors examine how a technically 
focused game program can provide students with a broader exposure to the world of game development. In 
particular, the authors will discuss where their treatment succeeded and failed, and how the curriculum 
has evolved over several offerings.  Categories and Subject Descriptors K.8.0 [Computing Milieux]: Personal 
Computing- General, Games General Terms Design, Theory  Keywords Games Education 1. INTRODUCTION A 
number of colleges and universities now offer some form of games curriculum [5,6], which are widely varied 
in their content and focus. Curricular offerings originate from departments such as computer science, 
art, liberal arts, media studies, communications, and other disciplines. Some institutions examine games 
within a broader context of entertainment technology [1]. There are also institutions that consider game 
design and development a discipline in its own right [13]. Permission to make digital/hard copy of part 
of this work for personal or classroom use is granted without fee provided that the copies are not made 
or distributed for profit or commercial advantage, the copyright notice, the title of the publication, 
and its date of appear, and notice is given that copying is by permission of the ACM, Inc. To copy otherwise, 
to republish, to post on servers, or to redistribute to lists, requires prior specific permission and/or 
a fee. FuturePlay 2007, November 15-17, 2007, Toronto, Canada. Copyright 2007 ACM 978-1-59593-943-2/07/0011...$5.00 
Furthermore, some institutions are beginning to offer multiple programs and approaches to the discipline 
[16]. The variety of institutional approaches to game curriculum can be evidenced within the IGDA draft 
proposal [7]. In order to accommodate for the diversity within curricular approaches, the proposal divides 
core game topics into three major groups. Though not formally named, the authors attributed these groups 
to games literacy, game design and creation, as well as business aspects of game production. The first 
group addresses games as a medium. The group includes topics such as the history of games, critical analysis 
of games, and the impact of games upon individuals and society. In short, the group addresses issues 
of where video games have come from, how they speak to us, and where they are going. The second group 
addresses the process of creating games. The group addresses both the programmatic and artistic skills 
required to create compelling entertainment experiences. Topics include areas such as design, programming, 
visual, audio, interface, and story. Coursework examines specific aspects of game creation as well as 
the overall architecture of game systems. The third group addresses the commercial and industrial aspects 
of game development. In particular, the group allows for exploration of the production process from a 
development management perspective. In addition, it addresses the business and legal aspects of game 
production from the studio and publisher standpoint. In addition to IGDA s core areas, the authors have 
found that others factors are equally important in creating a comprehensive game curriculum. The first 
challenge is to leverage the strengths of the discipline from which the game curriculum emerged while 
still addressing the breath and depth of the game development field. The second challenge is to close 
the gap between faculty and student experiences within games and media history, game analysis, literature, 
media study, and psychology as well as the technical ability to realize games as well as ramifications 
of cultural and societal factors as they intersect games and entertainment technology. This paper addresses 
these challenges and will be framed within the context of courses created at the Rochester Institute 
of Technology for the Masters of Science in Game Design and Development program.  2. GAMES AT RIT A 
BALANCING ACT The Rochester Institute of Technology first began to offer game related courses in the 
year 2000, which was a course in game engine programming. Students engaged in the creation of an operational 
game level from concept to delivery with minimal support infrastructure. Fast forward a few years and 
several technical courses and spin-offs proved to be an attractor for students within different degree 
programs (CS/IT/SE/CE, etc.) who possessed a strong technical background. Over the past half­decade, 
it became readily apparent that these technical courses were successful enough to become the cornerstone 
of a degree program. However, as the degree development progressed, it became apparent that students 
needed a way to extend their skills beyond graphical or even technical areas. The richer world of game 
development includes the appreciation of games as a medium. Students also needed to discover how all 
of the elements of game construction work together to create an entertainment experience. To address 
this need, the faculty created courses that explore the games medium through a content­centered perspective. 
  3. OUR APPROACH The approach at R.I.T. was to create three courses to address the medium of computer 
games and entertainment technology. The first course addressed the history and critical analysis of games 
and electronic media. The second course addressed the creation and critique of interactive narrative. 
The third course examined elements related to game world design. Each of these courses contained a theoretical 
and practical curriculum component. 3.1 History and Critical Analysis This course includes the study 
and analysis of game content and play, the role of personal computing technologies for entertainment 
purposes, the evolution of consumer entertainment technologies, and the history of computer, console, 
and arcade video games. Students are first introduced to the history of non­electronic games followed 
by the study of entertainment and computing technologies in general. The goal is to provide a framework 
that illustrates how and why the technology for video and computer games emerged. The course then focuses 
on the evolution of games for arcade use, home entertainment, and beyond. In addition, the course helps 
students to realize the scope of computer game genres and how cultural differences help to redefine what 
video games mean in other countries. The course also serves to give students an understanding of the 
wider computing and entertainment media ecology and where video games fit in [3,8]. Finally, the course 
introduces students to the techniques, vocabulary, and practice of media analysis in general and video 
games analysis in particular; a pervasive thread throughout all three courses. Social influences and 
cultural impacts associated with the video game phenomena are also discussed. Assignments include weekly 
writing on readings and lectures and exercises that allow students to create timelines that illustrate 
their media consuming history in context with computing gaming and electronic media history. These exercises 
help to personalize the impact of game and media history while showing the student the breadth and scope 
of prior work in a meaningful context. 3.2 Interactive Narrative The course begins by covering a range 
of traditional linear media types including short story, novel, cinema, poetry, screenplays, and television 
treatments. From traditional structure, study then branches out to explore non-traditional and non-linear 
narrative in popular media. This includes exploration of structures from simple branching [11] to complex 
rhizomes [12]. It also includes the use of art and audio to convey an appropriate message or mood within 
a game environment [2,14]. Students explore media conventions that not only help to convey a story, but 
also help in creating a sense of presence and engagement in the medium [15]. Finally, students experience 
the process surrounding video game treatments and game concept sketches, storyboards, design documents, 
character treatments, and analysis. Students learn to translate knowledge and norms pertaining to linear 
narrative treatments to interactive stories. Assignments include weekly exploration of existing game 
concepts and treatments in conjunction with lectures from industry practitioners. These experts help 
students realize the importance of interactive narrative and the need of people entering the industry 
to understand the nature of writing for entertainment titles. Students tie their work in interactive 
narrative to the construction of a game prototype throughout the course. This provides a larger context 
in which the student can see how narrative choices impact various levels of a game, and also complements 
the individual assignments.  3.3 Game World Design The Game World Design course extends the experience 
from Interactive Narrative. The course begins by returning to the concepts of fun, entertainment, and 
engagement, but this time through formal structures of game and play [9]. Next, the course examines the 
nature of large story arcs in games that go beyond a particular game instance. As part of this exploration, 
students learn about the differences between space and place as a context for story. The course presents 
story arcs from literature, and the concept of bibles from film and television, focusing upon the environmental, 
cultural, and societal elements that help define and constrain the interactions in a particular treatment. 
This is explored in games with particular emphasis upon video game franchises that both rely upon and 
break the rules of consistency within their universes. The course then proceeds to the concept of level 
design. Students look back at how levels relate to the game story (the bigger picture ) and how they 
contextualize the actions of players within the game. Students explore the nature of level balancing 
to address issues of challenge, skill, and playability within a game. Finally, the course examines the 
nature of player characters and non-player characters within the game world. In particular, students 
are challenged to explore the development of characters that are engaging and empathetic [4]. Assignments 
in this course include writing for story arcs, levels, and characters. In addition, students are asked 
to develop a game prototype that speaks to challenges in these three areas, demonstrating transference 
of skills from other media types as well as an understanding of appropriateness and implementation viability 
within the game. The output from the narrative and game world design courses also comprises a game design 
document that students can choose to implement later. In initial design and practice, these courses were 
taught in sequence over the first year of graduate study. The courses were designed to integrate with 
the graphics for game programming sequence. It was the faculty intent that students would be able to 
use experiences from both sets of courses to help them make better game creation decisions   4. A GAP 
BETWEEN FACULTY AND STUDENTS In the development of the new coursework described above, an important first 
step was to understand those graduate students wishing to participate in computer game studies. The faculty 
began the process by exploring their own backgrounds along with their colleagues in academia and industry. 
It was the faculty intent to correlate what was known about motivating gaming students with the needs 
of the field in general. First, faculty made the assumption that students entering the study of game 
design and development would have appropriate technical skill to design architectures and implement solutions 
related to game systems. As the game courses originated from a computing department, it was assumed that 
students attracted to coursework would have strong computing backgrounds. The faculty assumed students 
would be interested in the study of programming languages, data formats, data structures, and algorithms 
related to game creation. The faculty also assumed students would have a strong interest in the software, 
API s, and tools associated with game creation. Second, faculty assumed that students were highly motivated 
to study computer games. The assumption was that students would have a passion for games and the game 
creation process. In addition, the assumption was that students would not be satisfied with toy problems. 
Instead, students would want experiences in which they implemented complete solutions from start to finish. 
Third, faculty speculated that students wanted to create experiences that were entertaining and engaging. 
Students wanted to go beyond the technology of a particular problem, and that they had a strong desire 
to create experiences on par with those they purchased and played at home. Finally, faculty speculated 
that students with a passion for video game development would have backgrounds that extend beyond the 
technology of games. Faculty noted that they and their industry peers had diverse degree backgrounds, 
including computing, art, communications, and media study. Consistent with Mäyrä s observations [10], 
faculty and their industry peers also possessed diverse interests in popular media and communications 
including comics, manga and anime, music, and role-playing, as well as interests in literature, cinema, 
photography, journalism, television, art, illustration, interaction, and mediated experiences. In fact, 
the faculty related to game studies often defined themselves in part by their other interests.  5. EXPERIENCES 
FROM THE CLASSROOM The three courses have been deployed over the last three years at the graduate level. 
During this time, we have collected some informal observations of our students regarding the nature of 
these courses. Input was gathered from both current students and alumni working within the games industry. 
Over the span of these course offerings, the authors were encouraged by many positive trends observed 
in the students. First, students had a better appreciation for the history of video games. They were 
more in tune with what preceded their work as well as the interconnections between various media influences 
upon game design and development. Second, students received a better understanding of narrative techniques 
and their transference to game writing, were better equipped to deal with game writing nuances, and were 
able to recognize flaws in narrative structure. Third, students were able to see the connections between 
stories, levels, and characters. As part of the experience, students were able to see how changes in 
one area impact the relationships between the other two. Finally, students gained a better appreciation 
of how to properly interact with peers possessing diverse backgrounds. Despite the success of this approach, 
there were a couple of items that will require further investigation. First, although students saw the 
importance of study within these topic areas, they were unable to satisfactorily transfer the lessons 
learned to their technical courses. This problem is not the fault of the students, but rather an issue 
of learning how to create synergy between the two types of courses while maintaining a technical focus. 
Second, although faculty stressed the importance of becoming good consumers of computer games, entertainment 
technology, and popular media as a means of broadening one s exposure, the constraints of a 40 contact 
hour course did not allow faculty to explore such concepts to an adequate depth. In general, faculty 
found that students entering game courses did have an affinity for computer technology. The courses attracted 
students from all areas of computing including information technology, computer science, software engineering, 
as well as other technical fields. Faculty also noticed that students enrolled in the game courses were 
passionate about video games. Many of them were very outspoken regarding the games they played as well 
as their expectations entering gaming courses. Both factors often contributed to students exceeding faculty 
expectations across all games-related coursework. However, at another level, faculty noticed that their 
expectations diverged from the observed student reality. First, it was clear that although students understood 
the nature of games, they were not always fully cognizant of what it truly takes to produce a game title. 
Students did not fully realize the scope and extent of the industry, including the size of production 
teams and the many multidisciplinary roles people played in the development of a title. For example, 
students are able to quickly identify the need for graphics, audio, interactions, and story in a game, 
but sometime fail to realize that artists, modelers, audio engineers, musicians, Foley artists, user 
interface designers, writers, and programmers must all interact to create the experience. Second, students 
did not always realize the impact and influence of popular culture upon gaming. Students are often surprised 
to find that people in gaming are well-versed in other forms of entertainment and expression, and that 
this knowledge can help in the formulation of game mechanics. Third, as game consumers, students have 
a strong understanding of what they like, but have little understanding of what they don t. This colors 
their expectations of game development, as students may only see the importance of skills necessary to 
implement games from their favorite genre. Finally, students were able to clearly understand the relationship 
between games and technology, but struggled to define the relationship between games and what makes them 
fun. Concepts such as flow, immersion, and engagement were clear in the context of traditional linear 
media, but they tended to compartmentalize those concepts with linear media and had trouble transferring 
them to games.  6. CLOSING THE GAP In observing this gap, the faculty made several decisions regarding 
the nature of the coursework in history and game analysis, interactive narrative, and game world design. 
First, faculty must find innovative ways of inspiring students to become critical consumers of popular 
media. It should be noted that although game faculty often have such broad and diverse backgrounds, the 
same should not be expected of students. Faculty should find ways to elevate popular culture and media 
experiences within their coursework. Second, coursework must explicitly provide linkages between multidisciplinary 
elements to help students understand the value of such approaches. Then they must move beyond mere understanding 
of the vocabulary and theory of a given course. They must truly embrace the transference of such concepts 
back and forth across their courses as well as in the creation of their games. 6.1 Next Steps In response 
to our evaluation, we will be making the following changes in the delivery of this curriculum. These 
will be made based on formal course evaluation, informal student discussions and faculty observation 
before, during and after the course delivery. First, prototyping will be moved out of the course sequence 
in order to spend more time on the development of treatments and the examination of conventions for game 
development. This will provide more time in our classes to focus on the issues previously describe. At 
the same time, faculty will formulate a strategy for strengthening the dependencies between the game 
programming classes will draw upon lessons learned in history and critical analysis, interactive narrative, 
and game world design. Second, the History and Game Analysis as well as Interactive Narrative classes 
will be co-listed, allowing faculty to look at concepts from multiple perspectives simultaneously. Third, 
the game design document generated across the three courses will now be used to inform game programming 
courses to better reinforce the linkage between concepts in each area. At this point, the majority of 
feedback related to these courses is both anecdotal and derived from course evaluations. In the future, 
the faculty intends to examine these courses in greater detail at both the student and alumni level. 
  7. REFERENCES [1] Carnegie Mellon University Entertainment Technology Center Home Page, 2007. Retrieved 
July 10, 2007 from http://www.etc.cmu.edu/. [2] Crawford, C., 2003. Chris Crawford on Game Design. New 
Riders Group, Indianapolis. [3] DeMaria, R. and Wilson, J. L., 2003. High Score!: The Illustrated History 
of Electronic Games, Second Edition, McGraw-Hill/Osborne. [4] Freeman, D., 2004. Creating Emotion in 
Games, New Riders Group, Indianapolis. [5] Game Career Guide Home Page, 2007. Retrieved July 10, 2007 
from http://www.gamecareerguide.com/. [6] Game Programming and New Media Schools, 2007. Retrieved July 
10, 2007 from http://www.gameprogrammer.com/links/schools.html. [7] IGDA Curriculum Framework: The Study 
of Games and Game Development (Version 2.3 beta), 2003. Retrieved July 1, 2007 from http://www.igda.org/academia/IGDA_Curriculum_Framewo 
rk_Feb03.pdf. [8] Kent, S. L., 2001. The Ultimate History of Video Games: From Pong to Pokemon--The Story 
Behind the Craze That Touched Our Lives and Changed the World, Three Rivers Press. [9] Koster, R., 2005. 
A Theory of Fun for Game Design, Paraglyph Press, Scottsdale, AZ. [10] Mäyrä, F., Pac-Man and the Ivory 
Tower, The Ivory Tower, IGDA Column, Retrieved July 10, 2007 from http://www.igda.org/columns/ivorytower/ivory_Mar03.php, 
2003. [11] Murray, J. H., 1997. Hamlet on the Holodeck: The Future of Narrative in Cyberspace, p. 78, 
The Free Press, New York. [12] Murray, J. H., 1997. Hamlet on the Holodeck: The Future of Narrative in 
Cyberspace, pp. 132-135, The Free Press, New York. [13] Rochester Institute of Technology Game Design 
and Development Home Page, 2007. Retrieved July 13, 2007 from http://games.rit.edu/. [14] Rollings, A. 
and Adams, E., 2003. Andrew Rollings and Ernest Adams on Game Design, New Riders Group, Indianapolis. 
[15] Ryan, M.-L., 2001. Narrative as Virtual Reality: Immersion and Interactivity in Literature and Electronic 
Media, The John Hopkins University Press, Baltimore, MD. [16] University of Southern California Home 
Page, 2007. Retrieved July 11, 2007 from http://www.usc.edu/.   
			]]></ft_body>
		</fulltext>
		<article_type art_type="short_paper" />
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2007</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>1328240</article_id>
		<sort_key>380</sort_key>
		<display_label>Pages</display_label>
		<pages>4</pages>
		<article_publication_date>11-14-2007</article_publication_date>
		<seq_no>3</seq_no>
		<title><![CDATA[Playscripts a new method for analyzing game design and play]]></title>
		<page_from>205</page_from>
		<page_to>208</page_to>
		<doi_number>10.1145/1328202.1328240</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1328240</url>
		<abstract>
			<par><![CDATA[<p>We propose a methodological framework for game analysis that uses the notion of 'scripting' as the basis for game interpretation and design. Drawing upon several disciplines and domains, this paper provides a template for critical analysis by outlining seven forms of scripting at work in games, and how these scripts either complement or compete with each other in various types of games. This system of analysis not only comprises the different technical, social or cognitive scripts that operate within the various modules of any given game, but also provides a method for the comparative study of different games, as well as a framework for building improved scripting and work flow tools for game designers.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[games]]></kw>
			<kw><![CDATA[ludology]]></kw>
			<kw><![CDATA[narrative]]></kw>
			<kw><![CDATA[scripting]]></kw>
			<kw><![CDATA[scripts]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>K.8.0</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010405.10010476.10011187</concept_id>
				<concept_desc>CCS->Applied computing->Computers in other domains->Personal computers and PC applications</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010476.10011187</concept_id>
				<concept_desc>CCS->Applied computing->Computers in other domains->Personal computers and PC applications</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<person_id>P925250</person_id>
				<author_profile_id><![CDATA[81342487689]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Jessica]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Aldred]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Carleton University, Ottawa, Canada]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P244169</person_id>
				<author_profile_id><![CDATA[81100135223]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Robert]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Biddle]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Carleton University, Ottawa, Canada]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P925225</person_id>
				<author_profile_id><![CDATA[81392598439]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Chris]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Eaket]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Carleton University, Ottawa, Canada]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P925221</person_id>
				<author_profile_id><![CDATA[81342496152]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Brian]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Greenspan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Carleton University, Ottawa, Canada]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P925230</person_id>
				<author_profile_id><![CDATA[81342503796]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[David]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Mastey]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Carleton University, Ottawa, Canada]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P925263</person_id>
				<author_profile_id><![CDATA[81336493394]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>6</seq_no>
				<first_name><![CDATA[Minh]]></first_name>
				<middle_name><![CDATA[Q.]]></middle_name>
				<last_name><![CDATA[Tran]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Carleton University, Ottawa, Canada]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P925248</person_id>
				<author_profile_id><![CDATA[81342515637]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>7</seq_no>
				<first_name><![CDATA[Jennifer]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Whitson]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Carleton University, Ottawa, Canada]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[E. Aarseth. Playing research: Methodological approaches to game analysis. In <i>Proceedings of the Digital Arts and Culture Conference</i>, Melbourne, Australia, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>286067</ref_obj_id>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[H. Beyer and K. Holtzblatt. <i>Contextual design: Defining customer-centered systems.</i> Morgan Kaufmann Publishers, San Francisco, CA, USA, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[W. Brooker. The many lives of the jetman: A case study in video game analysis. <i>Intensities: The journal of cult media</i>, 2(2), 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[N. Dutton and M. Consalvo. Game analysis: Developing a methodological toolkit for the qualitative study of games. <i>Game Studies: the international journal of computer game research</i>, 6(1), 2006.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[G. Frasca. Ludology meets narratology: Similitude and differences between (video)games and narrative. <i>Parnasso</i>, (3), 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[D. Herman. Scripts, sequences, and stories: elements of a postclassical narratology. <i>PMLA</i>, 112(5), 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[H. Jenkins. Game design as narrative architecture. In N. Wardrip-Fruin and P. Harrigan, editors, <i>First Person: New Media as Story, Performance, Game</i>, Cambridge, MA, USA, 2004. MIT Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>103681</ref_obj_id>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[B. Laurel. <i>Computers as Theatre.</i> Addison-Wesley, Reading, MA, USA, 1991.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[N. Postman. <i>Aumusing Ourselves to Death.</i> Penguin, New York, NY, USA, 1985.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1215723</ref_obj_id>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[K. Salen and E. Zimmerman. <i>Rules of play: game design fundamentals.</i> MIT Press, Cambridge, MA, USA, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[R. C. Schank and R. P. Abelson. <i>Scripts, Plans, Goals and Understanding: an Inquiry into Human Knowledge Structures.</i> L. Erlbaum, Hillsdale, NJ, USA, 1977.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Playscripts A new method for analyzing game design and play Jessica Aldred, Robert Biddle, Chris Eaket, 
Brian Greenspan, David Mastey, Minh Q. Tran, Jennifer Whitson Hypertext and Hypermedia Lab Carleton University, 
Ottawa, Canada jessica.aldred@gmail.com ABSTRACT We propose a methodological framework for game analysis 
that uses the notion of scripting as the basis for game inter­pretation and design. Drawing upon several 
disciplines and domains, this paper provides a template for critical analysis by outlining seven forms 
of scripting at work in games, and how these scripts either complement or compete with each other in 
various types of games. This system of analysis not only comprises the di.erent technical, social or 
cogni­tive scripts that operate within the various modules of any given game, but also provides a method 
for the comparative study of di.erent games, as well as a framework for building improved scripting and 
work .ow tools for game designers. Categories and Subject Descriptors K.8.0 [Personal Computing]: Games 
 General Terms Scripts  Keywords Games, Scripting, Narrative, Ludology 1. INTRODUCTION 1.1 Scripting 
and Other Metaphors The interpretive power of the script as a concept is that it traverses several categories 
simultaneously: game design, human interaction, world building, storytelling, ludology and cognitive 
behaviours. As such, the notion of scripting, widely construed, is a powerful analytical concept which 
allows an integrated view of game design and user interaction. Neil Postman has remarked that . . . our 
languages are our me­dia. Our media are our metaphors. Our metaphors create the content of our culture 
[9]. Video games are certainly no exception to this rule, and thus we must be acutely aware of the metaphors 
we use when thinking about games and game design. As abstract tools for thinking, our metaphors Permissionto 
make digital/hardcopy ofpartofthiswork for personalor classroom use is grantedwithoutfeeprovidedthat 
the copiesarenot made or distributedfor profitorcommercialadvantage,the copyright notice, the titleof 
the publication, andits dateofappear, and noticeis given that copyingisbypermissionoftheACM,Inc. Tocopyotherwise,to 
republish,topost onservers,orto redistributeto lists,requiresprior specificpermissionand/or afee. FuturePlay 
2007, November 15-17,2007, Toronto, Canada. Copyright 2007 ACM 978-1-59593-943-2/07/0011...$5.00 can 
either constrain our thinking or open up new realms of engagement for gameplay, game design and methodological 
analysis. In our multidisciplinary research group at Carleton s Hy­pertext and Hypermedia Lab, in conjunction 
with a local developer of serious games, we have been using methods of contextual inquiry [2] to address 
issues of engagement and usability in various serious games. Based on our analyses, we are creating a 
framework for the analysis of games and game modules with a goal of ultimately providing better scripting 
tools and work .ows for game designers. The current pa­per is a .rst attempt at developing a general 
structure for game analysis. Our approach supplements other recent at­tempts at general methodologies 
for the critical analysis of games, such as Brooker [3], Aarseth [1], and Dutton and Consalvo [4]. In 
particular, we agree with Dutton and Con­salvo that games should be studied as texts that are subject 
to qualitative, critical analysis as cultural artifacts; we have therefore focused on the various forms 
of scripting through which game texts are inscribed.  2. OVERVIEW 2.1 Scripting Categories Our use 
of the term script acknowledges both the narroto­logical implications of the word (as in a dramatic script) 
and its ludological overtones (as in the LindenScript of Sec­ond Life). The ambivalence of the term stems 
from one of our central research questions: How are cultural and psy­chological scripts (of the user) 
similar to computer scripting languages (within a game) and how do the two interact? To this end, we 
have come up with seven main categories of scripts that are deployed in games and gameplay, and seek 
to understand how their interaction either contributes to or detracts from user engagement. Our seven 
categories include: 1. Dramatic Scripts 2. Interface Scripts 3. Interactive Scripts 4. Ludic Scripts 
 5. Implementation Scripts 6. Cognitive-Narratological Scripts 7. Metagaming Scripts   Any given 
game will tend to have several of these scripts in play at all times, although we propose that the nature 
of a game (and its e.ectiveness) results from the interplay of the di.erent kinds of scripts that the 
game comprises.  2.2 Descriptions of Categories 2.2.1 Dramatic Scripts The dramatic script provides 
the contextual environment for the game-its story content, as well as the backdrop of the game world 
(or fabula). It may be told either by game developers through supplementary material (such as hand­books 
or cut scenes) on the lore, history, and background of the game, or through the progression of an avatar 
through the narrative architecture of a gamespace [7], or through some combination thereof. Analogous 
to the elements of a theatrical dramatic script, the world-building elements of the dramatic script include 
plot, character, dialogue, ideas, atmosphere, mise-en-sc`ene, and various synthespians . All of these 
elements should contribute to feel[ing] yourself par­ticipating in the ongoing action of the representation, 
which is one of the hallmarks of interactivity [8]. We contend that the dramatic script strives to construct 
a complete and be­lievable world through the use of language, image and sound, but that in striving to 
do so, it must contend with other scripts (some cooperative, some competitive) that operate within the 
game and its user. 2.2.2 Interface Scripts If the dramatic script provides a representational frame with 
which the user can interact, the interface script is the se­quence of user actions that must be completed 
in order to e.ect change in the game environment. The types of allow­able actions are dependent on the 
input device and gaming platform: for example, if the input device is a mouse, then the interface script 
would consist of mouse clicks. Master­ing the interface script is part of playing the game, as the user 
would not otherwise be able to interact with the game environment and realize the goals of its dramatic 
and lu­dic scripts. The interface script allows the user to control avatars, or move objects in the game 
world. It must be easy to learn, but the complexity of the script must also be matched with the appropriate 
level of control in the game. We will consider how interface scripts that have been pre­viously learned 
may be applied to new games, since games of the same genre tend to have similar interface scripts, but 
will also examine how this transference of scripts may cause certain dissonances between player expectations 
(treated be­low under the purview of cognitive-narratological scripts ) and actual gameplay. 2.2.3 Ludic 
Scripts Building upon Gonzalo Frasca s de.nition of ludus as an activity organized under a system of 
rules that de.nes a victory or a defeat, a gain or a loss [5], we suggest that the ludic ele­ments of 
any game also follow a kind of script, the nature of which is to specify the rules of the ludus. For 
example, we might consider traditional games like poker and blackjack, which consist of the same static 
elements (a deck of cards), but have di.erent rules. The rules are in essence scripts that contribute 
strongly to the nature of the games that result. We might even conceive of the same ludic script being 
ap­plied to other elements: for example, we might play poker with dice instead of cards. However, contrary 
to Aarseth s suggestion that the ludic script is the game (thus dismissing all other aspects of the game), 
we propose that the nature of a game comes from the interplay of the di.erent kinds of scripts that the 
game comprises. So we would not consider poker played with cards as the same game with poker dice, nor 
would we consider Tomb Raider to be the same game without Lara. 2.2.4 Interactive Scripts The interactive 
script is the sum result of interface scripts (user actions) on dramatic and ludic scripts within the 
game world. It represents the results of the user s actions, as those actions produce game-world e.ects 
that unfold in space and time. It is the adaptation of the game world to the user, and vice versa. While 
the former adaptation is governed by the ludic, implementation, and dramatic scripts as out­lined herein, 
the latter is shaped by the user s cognitive­narratological scripts and those created through extra-gamic 
opportunities for metagaming. As the site in which human and machinic agendas both collude and collide, 
the interac­tive script thus both necessitates and enables an integrated view of gameplay in which agency 
is post-human and radi­cally distributed. It also elucidates the interplay and tension between the various 
scripts that compose any given game. 2.2.5 Implementation Scripts The game software is a computer program, 
and as such can be regarded as a script for the computer. Although we may think of the program as a list 
of instructions in machine lan­guage, it actually has more structure than that. First, even if a list, 
all machine languages not only follow the list, but also follow links within the list, branching back 
and forward. Second, there is typically not just one language involved in any given program, but several. 
The computer s central pro­cessor will use one language, but a game may be written in a higher level 
language, which is translated either beforehand (compilation) or dynamically (interpretation). Furthermore, 
the main focus of all digital computers is that programs themselves can be stored as data, so that some 
sets of data can be regarded themselves as programs to be interpreted by other programs. In essence, 
complex software is structured as a set of collaborating devices or components, each with its own language, 
behaviour and domain focus. The idea for this kind of software architecture is to model and mirror the 
structure of the application domain, in this case the game behaviour and the gameplay. This component 
architecture means that games are not monolithic scripts, but sets of scripts. The same game played on 
a di.erent platform (a Microsoft Windows PC vs. an Apple Macintosh, for exam­ple, or a Microsoft XBox 
vs. a Sony Playstation) will have some of the same component scripts and some di.erent com­ponent scripts. 
More signi.cantly for our model, many of the other kinds of scripts we discuss are implemented, more 
or less, as component scripts in the implementation. This means that this structure and the reusability 
it engenders, can a.ect the game itself as seen from beyond. 2.2.6 Cognitive-Narratological Scripts The 
notion of the script has a particular valence within cognitive schema theory, originally developed in 
the 1970s. Schema theory predicts that, by listening to stories, pre­literate children internalize scripts 
of expectations, or schemata, that allow them to form general inferences about narrative logic. These 
formative scripts help us to structure narratives in memory, and are called upon whenever we listen to 
or tell stories again: Scripts are like cultural templates that enable users familiar with narrative 
conventions to transform se­quential textual cues into complex cognitive models of sto­ries and the worlds 
they represent [6]. Schanck and Abelson  [11] expanded the notion of the cognitive script to account 
not only for represented narratives, but any commonplace instance of connected discourse or lived experience. 
Order­ing a meal at a restaurant, using an automatic teller, or playing a game of hide and seek have 
all been studied as activities that depend on shared cognitive scripts, which in­.uence individual and 
group behaviour without constraining it absolutely. Cognitive scripts interoperate with most of the other 
script­ing levels we have identi.ed. They in.uence decisions made about dramatic scripts during game 
production and during play at the level of interface and interaction; they govern scripts for dramatic 
or dialogic interactions with non-player characters (NPCs), and shape conversational scripts with other 
players before, during and after gameplay. It is cog­nitive scripts that allow a user to adapt familiar 
interfaces to unfamiliar games, transferring habituated knowledge of Lara Croft s .ghting style to The 
Matrix 2: Path of Neo. 2.2.7 Metagaming Scripts The metagame is the site where the above mentioned scripts 
interact with the social and physical context of the player, including their styles of play, attitudes, 
and understandings of how the game world and the real world operate. While metagaming can follow certain 
scripts (e.g. the cognitive script one has going into the game about how it should be played), some of 
the best examples of metagaming rely on o.-script behaviour (breaking out of character to discuss rules). 
The metagame bridges the liminal space between the magic circle of game play and game-related concerns 
that are not part of the game itself. Following Salen and Zimmerman s de.nition [10], metagaming scripts 
set the stage for how both the cognitive and interactive scripts will be played out. The schemata, skills 
and resources that are brought into the game in.uence the player s interactive script, which in turn 
in.uences what he or she takes away from the game, including narratives about success and failure and 
social re­lationships with other players. Metagaming also occurs between games (in the form of train­ing, 
socializing, and strategizing) and, perhaps most impor­tantly, during the game itself. This metagaming 
is rooted in communication between players about real-life issues and discussions about rules. This o.-script 
communication, while out of character and not about the game itself, works our kinks in the game play, 
facilitating the .ow of the game and a return to more or less scripted gaming behaviour. All of these 
metagaming elements follow players after the game has ended and in.uence whether they return to play 
again, as well as their self-conceptions and conceptions about the world around them. The complex social 
worlds of MMOGs, with their built-in communication devices, orbiting commu­nity websites, inspired art, 
and complex social networks that extend beyond the game space, epitomize the interaction of di.erent 
scripts within the metagame.  3. SCRIPT INTERACTIONS 3.1 Issues The scripts we have been discussing 
here are not imple­mented or experienced hierarchically. In fact, most aspects of games and gameplay 
require interaction between several of these scripts simultaneously. For each game, some scripts will 
tend to dominate over others, with each occurring in di.erent ratios depending on the genre, gaming culture 
at the time, developer, engine and so on. Similarly, the framework we have discussed here allows for 
comparative analyses that examine the relative strengths and weaknesses of di.erent games in each scripting 
domain, as well as the common scripts that work intertextually be­tween games, genres and platforms. 
We believe this frame­work, emerging as it does from various disciplines, provides a rich toolset for 
intra and inter-game analysis.  3.2 Competing, Complementary and Intertex­tual Scripts 3.2.1 Examples 
of Competing Scripts Scripts are said to be competing when one script overpowers the others, interrupting 
the intricate balance of the game. This can occur in an FPS where characters walk through walls that 
are supposed to be solid. In such cases, the nor­mally transparent implementation script competes with 
the dramatic and interactive scripts. Another example of con­.icting scripts are cheat cartridges for 
console-based games that allow users to manipulate the game in ways other than the developer intended 
(e.g. using cheat codes to slow the speed of the game down to make it easier to play, or to obtain unlimited 
in-game resources). While originally these cheat cartridges produced a con.ict between the metagaming 
and implementation scripts, more recently developers have con­sciously included features only accessible 
through the use of cheat cartridges (known as Easter Eggs), signaling a new era of complementarity. 3.2.2 
Examples of Complementary Scripts Scripts are complimentary when they work together to im­prove game 
play or a player s immersion and sense of .ow in the game space. Generally, complementary scripts interact 
with each other seamlessly, such as in Grand Theft Auto where the interactive script of driving around 
and listen­ing to the radio complements the ludic and dramatic scripts of heading across town to complete 
a mission. But not all examples of complementary scripts are so seamlessly inte­grated. For example, 
there have been debates within the MMORPG community over how to best integrate commu­nication functions. 
To some, the speech-balloon over charac­ters heads o.ers a greater level of immersion insofar as play­ers 
can look direct at the characters they are communicating with, while others argue that scrolling text 
or chat box op­tions are a less cartoonish option. Ultimately, in games like Eve Online, the chat box 
system is built into the interface script and explained via the dramatic script: the scrolling text is 
a more realistic representation of what a star craft control panel would actually look like.  3.2.3 
Examples of Intertextual Scripts Scripts are intertextual when they allude to and interact with scripts 
from other games. For example, in Animal Crossing for Nintendo GameCube, players collect classic Nin­tendo 
games such as Donkey Kong, Super Mario Brothers, and Punch Out!!!. These games can be played as mini-games 
within the larger Animal Crossing framework, in.uencing the metagame by adding a sense of nostalgia/recognition 
of games past. In addition, the integration of these mini-games with their di.erent rule-sets, play styles, 
and backstories act to enrich both the dramatic and the ludic scripts of the larger game. Another popular 
example of an intertextual script is found in Nintendo s Super Smash Brothers, which is a series of .ghting 
games that features characters from classic Nin­tendo games and second-party developers. The game space 
becomes a mash-up where di.erent dramatic scripts collide. For example, Donkey Kong can .ght Link from 
The Legend of Zelda, Pikachu from Pokemon can .ght Samus Aran from Metroid, Kirby can .ght Captain Falcon 
from F-Zero, and so on. Player s cognitive scripts are challenged in that they must transfer the habituated 
knowledge of characters play styles and the interface scripts necessary to move them to the largely di.erent 
context of a close-combat .ghting game. Intertextual scripts can also reference other texts in popular 
culture, such as when popular novels, .lms, and music ap­pear in games (e.g. top 40 music playing on 
car stereos in Grand Theft Auto, or monuments in Second Life where char­acters can download Neil Stephenson 
s novel Snowcrash). Intertextual scripts enrich the metagame, bringing the out­side world and references 
to other games into the game world, and testing the assumption that games are entirely self-contained 
play spaces removed from the outside world.  4. SUMMARY As we have outlined above, the metaphor of 
the script pro­vides a multivalent, adaptable tool that facilitates nuanced exploration of individual 
game texts and their users, as well as complex comparative analyses of di.erent types of digital games 
and gaming communities. By mobilizing seven types of scripts -Dramatic, Interface, Interactive, Ludic, 
Imple­mentation, Cognitive-Narratological and Metagaming -and examining how they may compete, complement, 
and/or in­teract with each other in the context of game play, we hope to provide a methodology for analyzing 
aspects of games that are too often studied in isolation. In so doing, script analysis as described herein 
highlights the interplay of indi­vidual elements that contribute to (or detract from) a co­herent and 
engaging user experience, elucidating how the scripts of users, games, designers and programmers may 
combine to create highly immersive game worlds, or con­versely, how they may utterly fail to do so. On 
a very practical level, since the elements of games often studied in isolation from one another are also 
typically designed by di.erent individuals within gaming companies, in the fu­ture this syncretic approach 
will ultimately allow us to assist game designers in the creation of better scripting tools for games, 
tools which would incorporate the multivalent notion of scripts by design.  5. REFERENCES [1] E. Aarseth. 
Playing research: Methodological approaches to game analysis. In Proceedings of the Digital Arts and 
Culture Conference, Melbourne, Australia, 2003. [2] H. Beyer and K. Holtzblatt. Contextual design: De.ning 
customer-centered systems. Morgan Kaufmann Publishers, San Francisco, CA, USA, 1998. [3] W. Brooker. 
The many lives of the jetman: A case study in video game analysis. Intensities: The journal of cult media, 
2(2), 2001. [4] N. Dutton and M. Consalvo. Game analysis: Developing a methodological toolkit for the 
qualitative study of games. Game Studies: the international journal of computer game research, 6(1), 
2006. [5] G. Frasca. Ludology meets narratology: Similitude and di.erences between (video)games and narrative. 
Parnasso, (3), 1999. [6] D. Herman. Scripts, sequences, and stories: elements of a postclassical narratology. 
PMLA, 112(5), 1997. [7] H. Jenkins. Game design as narrative architecture. In N. Wardrip-Fruin and P. 
Harrigan, editors, First Person: New Media as Story, Performance, Game, Cambridge, MA, USA, 2004. MIT 
Press. [8] B. Laurel. Computers as Theatre. Addison-Wesley, Reading, MA, USA, 1991. [9] N. Postman. 
Aumusing Ourselves to Death. Penguin, New Yor, NY, USA, 1985. [10] K. Salen and E. Zimmerman. Rules of 
play: game design fundamentals. MIT Press, Cambridge, MA, USA, 2004. [11] R. C. Schank and R. P. Abelson. 
Scripts, Plans, Goals and Understanding: an Inquiry into Human Knowledge Structures. L. Erlbaum, Hillsdale, 
NJ, USA, 1977.   
			]]></ft_body>
		</fulltext>
		<article_type art_type="short_paper" />
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2007</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>1328241</article_id>
		<sort_key>390</sort_key>
		<display_label>Pages</display_label>
		<pages>4</pages>
		<article_publication_date>11-14-2007</article_publication_date>
		<seq_no>4</seq_no>
		<title><![CDATA[Wiizards]]></title>
		<subtitle><![CDATA[3D gesture recognition for game play input]]></subtitle>
		<page_from>209</page_from>
		<page_to>212</page_to>
		<doi_number>10.1145/1328202.1328241</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1328241</url>
		<abstract>
			<par><![CDATA[<p>Gesture based input is an emerging technology gaining widespread popularity in interactive entertainment. The use of gestures provides intuitive and natural input mechanics for games, presenting an easy to learn yet richly immersive experience. In Wiizards, we explore the use of 3D accelerometer gestures in a multiplayer, zero sum game. Hidden Markov models are constructed for gesture recognition, providing increased flexibility and fluid tolerance. Users can strategically effect the outcome via combinations of gestures with limitless scalability.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[HMM]]></kw>
			<kw><![CDATA[games]]></kw>
			<kw><![CDATA[gestures]]></kw>
			<kw><![CDATA[interactive systems]]></kw>
			<kw><![CDATA[pattern recognition]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>H.5.2</cat_node>
				<descriptor>Input devices and strategies (e.g., mouse, touchscreen)</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.5.5</cat_node>
				<descriptor>Interactive systems</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>K.8.0</cat_node>
				<descriptor>Games</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10011007.10010940.10010941.10010969.10010970</concept_id>
				<concept_desc>CCS->Software and its engineering->Software organization and properties->Contextual software domains->Virtual worlds software->Interactive games</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003251.10003258</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Multimedia information systems->Massively multiplayer online games</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003121.10003129</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)->Interactive systems and tools</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010476.10011187.10011190</concept_id>
				<concept_desc>CCS->Applied computing->Computers in other domains->Personal computers and PC applications->Computer games</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003121.10003125.10011666</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)->Interaction devices->Touch screens</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003121.10003125</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)->Interaction devices</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<person_id>P925256</person_id>
				<author_profile_id><![CDATA[81342500865]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Louis]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kratz]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Drexel University, Philadelphia, PA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP43143939</person_id>
				<author_profile_id><![CDATA[81547107056]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Matthew]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Smith]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Drexel University, Philadelphia, PA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P438779</person_id>
				<author_profile_id><![CDATA[81100384511]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Frank]]></first_name>
				<middle_name><![CDATA[J.]]></middle_name>
				<last_name><![CDATA[Lee]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Drexel University, Philadelphia, PA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[J. Andersson and C. Phillips. Simple wiimote library for linux, 2007.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1162264</ref_obj_id>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[C. M. Bishop. <i>Pattern Recognition and Machine Learning (Information Science and Statistics).</i> Springer, August 2006.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>618526</ref_obj_id>
				<ref_obj_pid>616052</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[W. T. Freeman, D. B. Anderson, P. A. Beardsley, C. N. Dodge, M. Roth, C. D. Weissman, W. S. Yerazunis, H. Kage, K. Kyuma, Y. Miyake, and K. ichi Tanaka. Computer vision for interactive computer graphics. <i>IEEE Computer Graphics and Applications</i>, 18(3):42--53, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[A. Heap. Real-time hand tracking and gesture recognition using smart snakes, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[A. Inc. Livemove white paper. Technical report, AiLive Inc., http://www.ailive.net/, 2006.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1130545</ref_obj_id>
				<ref_obj_pid>1134820</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[P. Keir, J. Payne, J. Elgoyhen, M. Horner, M. Naef, and P. Anderson. Gesture-recognition with non-referenced tracking. In <i>3DUI '06: Proceedings of the 3D User Interfaces (3DUI'06)</i>, pages 151--158, Washington, DC, USA, 2006. IEEE Computer Society.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1149819</ref_obj_id>
				<ref_obj_pid>1149818</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[J. Kela, P. Korpipaa, J. Mantyjarvi, S. Kallio, G. Savino, L. Jozzo, and D. Marca. Accelerometer-based gesture control for a design environment. <i>Personal Ubiquitous Comput.</i>, 10(5):285--299, 2006.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[C. Keskin, A. Erkan, and L. Akarun. Real time hand tracking and 3d gesture recognition for interactive interfaces using hmm. In <i>Proceedings of the Joint International Conference ICANN/ICONIP 2003.</i> Springer.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1052385</ref_obj_id>
				<ref_obj_pid>1052380</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[J. Mantyjarvi, J. Kela, P. Korpipaa, and S. Kallio. Enabling fast and effortless customisation in accelerometer based gesture interaction. In <i>MUM '04: Proceedings of the 3rd international conference on Mobile and ubiquitous multimedia</i>, pages 25--31, New York, NY, USA, 2004. ACM Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1125679</ref_obj_id>
				<ref_obj_pid>1125451</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[J. Payne, P. Keir, J. Elgoyhen, M. McLundie, M. Naef, M. Horner, and P. Anderson. Gameplay issues in the design of spatial 3d gestures for video games. In <i>CHI '06: CHI '06 extended abstracts on Human factors in computing systems</i>, pages 1217--1222, New York, NY, USA, 2006. ACM Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>108253</ref_obj_id>
				<ref_obj_pid>108235</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[L. R. Rabiner. A tutorial on hidden markov models and selected applications in speech recognition. pages 267--296, 1990.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>842465</ref_obj_id>
				<ref_obj_pid>839289</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[J. Segen and S. Kumar. Fast and accurate 3d gesture recognition interface. In <i>ICPR '98: Proceedings of the 14th International Conference on Pattern Recognition-Volume 1</i>, page 86, Washington, DC, USA, 1998. IEEE Computer Society.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[J. Segen and S. Kumar. Human-computer interaction using gesture recognition and 3d hand tracking. In <i>ICIP (3)</i>, pages 188--192, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[J. M. Teixeira, T. Farias, G. Moura, J. Lima, S. Pessoa, and V. Teichrieb. Gefighters: an experiment for gesture-based interaction analysis in a fighting game. In <i>SBGames</i>, Brazil, 2006.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Wiizards: 3D Gesture Recognition for Game Play Input Louis Kratz Matthew Smith Frank J. Lee Dept. of 
Computer Science Digital Media Labs Dept. of Computer Science Drexel University Drexel University Drexel 
University 3141 Chestnut Street 3141 Chestnut Street 3141 Chestnut Street Philadelphia, PA 19104 Philadelphia, 
PA 19104 Philadelphia, PA 19104 louis.kratz@drexel.edu mas97@drexel.edu fjl@drexel.edu ABSTRACT Gesture 
based input is an emerging technology gaining wide­spread popularity in interactive entertainment. The 
use of gestures provides intuitive and natural input mechanics for games, presenting an easy to learn 
yet richly immersive expe­rience. In Wiizards, we explore the use of 3D accelerometer gestures in a multiplayer, 
zero sum game. Hidden Markov models are constructed for gesture recognition, providing increased .exibility 
and .uid tolerance. Users can strategi­cally e.ect the outcome via combinations of gestures with limitless 
scalability. Categories and Subject Descriptors H.5.2 [Information Interfaces and Presentation]: User 
Interfaces Input devices and strategies; K.8.0 [Personal Computing]: General Games; I.5.5 [Pattern Recogni­tion]: 
Implementation Interactive systems General Terms Games, Interactive systems, Pattern Recognition  Keywords 
Gestures, HMM, Games 1. INTRODUCTION Gesture recognition as an input mechanic has been explored academically 
in a variety of approaches. Two de.nitions of gestures have been popular in the literature. The .rst 
de­.nes a gesture as the spatial orientation of a person or hand. This approach was utilized by Freeman 
et. al. [3], Segen et al. [13] [12] and GeFighters [14]. The second de.nition of gestures classify speci.c 
motion paths of the user. This work explores the use of accelerometers to classify motion paths via a 
Bayesian approach. By using accelerometer data, the path that the user creates can be recorded directly, 
rather than relying on tracking to estimate the motion di.eren­tials. Other approaches include Heap [4] 
who uses active shape models to track the user and identi.es gestures by Permissiontomake digital/hardcopyofpartofthiswork 
for personalor classroom use isgranted without fee providedthat the copies are notmade or distributedforprofit 
or commercialadvantage,thecopyright notice,the titleof the publication,and its date of appear, and noticeis 
given that copying is bypermission of the ACM, Inc.To copy otherwise, to republish, to post onservers, 
or toredistributetolists, requires prior specificpermission and/or a fee. FuturePlay 2007, November15-17, 
2007,Toronto, Canada. Copyright 2007 ACM 978-1-59593-943-2/07/0011...$5.00 Figure 1: Wiizards presents 
a two player, spell based environment. the shapes parameters. Heap s approach, while accurate, requires 
the use of vision based system for the shape model, which introduces latency and speed issues not found 
in ac­celerometers. Keskin et. al. [8] also uses a vision based approach. Accelerometer based gesture 
recognition has been explored, though the construction of such have varied. Keir et al. [6] created a 
gesture recognition system for accelerometers using curve .tting. The curve .tting approach presented 
by Keir who integrates the accelerometer data for absolute position. Payane [10] uses the gesture recognition 
created by Keir as a game input mechanic. Payane s work, though similar in spirit to ours, does not have 
the advantages of a Bayesian method. Wiizards uses Hid­den Markov Models [11] (HMMs) to classify gestures 
from the accelerometer data. This Bayesian approach provides more .exibility on a per user basis, and 
handles noisy sen­sors data within the model. A HMM is a statistical model whose hidden states exhibit 
the Markov process. HMMs are parametrized by the number of states in the model N, a probability distribution 
function for each state Bi,initial state distribution p, and a transition probability matrix A . HMMs 
have been used in other applications for gesture recog­nition, however. Keskin et. al. [8], for example, 
use HMMs  Figure 2: The unique ordering of gestures for spell creation. in their vision based approach. 
In addition Kela et al. [7] use accelerometer gestures for design applications. Kela s con­struction, 
however, transforms the 3D signal into a sequence of discrete symbols whose tolerance of noise and ambiguity 
to the accelerometer state is not investigated. Mantyjarvi et al. [9] also uses discrete HMMs for controlling 
a DVD player. Gesture recognition in gaming is just now being explored in commercial products. AiLive 
[5] has produced a product for gesture recognition and training for the Nintendo RTM , ® Wii but has 
not released the details of their machine learning techniques.  2. IMPLEMENTATION 2.1 Game Overview 
Wiizards is a two player zero-sum game. The goal for each player is to damage the opposition to a critical 
point while limiting damage to themselves. The player casts spells by performing gestures, the order 
of which determines the ef­fect that they have. The gestures are unique arm motions di­vided into three 
categories: Actions, Modi.ers and Blockers. Each of these serve a di.erent purpose in the combination 
of the gestures to complete a total spell. 2.2 Strategic Composition The user interface is divided into 
three sections: a bar re­vealing the current status of all the gestures available to each of the players, 
a playing .eld, and a queue for each player indicating the current spell (Figure 1). The gesture bar 
serves two purposes: a visual reminder to the player of how to perform the gesture, and the cool down 
time remain­ing. Alpha transparency is used to indicate how long until a particular gesture available. 
The amount of transparency indicates how long until it will be available again. When the representation 
of the gesture is fully visible and opaque it is available for the player to use. At current the game 
is in mid development with the queuing system, gesture recogni­tion system, and GUI completed. 2.4 Communication 
Design ® Our software utilizes three main components: the Nintendo R TM Wii controller, the gesture recognition 
system, and the graphical game implementation. Communication with the Nintendo RTM controller is done 
via publicly available ® Wii open source libraries [1]. The accelerometer data is then directed into 
our HMM gesture recognition package. The results of such are communicated to Adobe RTM via ® Flash XML. 
 2.5 Gesture Recognition 2.5.1 Model Construction The observations for the models are the accelerometer 
data from the Nintendo RTM controller. The device provides ® Wii a gravitational reading for three axis, 
making our observa­tions a three dimensional vector o as indicated in (1). This data is normalized using 
the wiimote calibration information [1]. The order in which the gestures are composed is vital to determining 
the behavior of a spell. Each spell consists of oi = blockers and modi.ers, and must conclude with an 
action. 24 x y z 35 (1) Modi.ers e.ect only the gestures following them in the spell (Figure 2). For 
example, if a spell consists of gestures XYZ, the modi.er X will e.ect Y and Z, while Y will only e.ect 
Each gesture, or observation vector, is a collection of obser­ vations. Z. To successfully block a spell, 
players must directly mimic their opponent s gestures. For example, to block spell XYZ, a player must 
perform gestures BXYZ where B is a blocker. Blockers can also be modi.ed by gestures performed prior 
to them. A queue is populated as players perform gestures. When the spell is cast, the elements are removed 
from the queue in order, modifying the parameters of proceeding gestures. The ability to combine multiple 
gestures in spell creation provides highly customizable and scalable game play expe­rience. The level 
of customization also gives a wider range of possibilities to each of the players, making the game scalable 
in strategy and individual skill level. Players more .uent in the gestural language of the game can explore 
di.erent strategies as they .nd more e.ective usages for each gesture. Gesture management is also a major 
strategic component to the game. Each gesture has a cool down time limiting how often it may be used, 
forcing the player to make use of a wide verity of gestures.  2.3 Visual Feedback Gi = o1,o2,...,om 
(2) Since the observations are vectors, multi-variant Gaussian distributions are used for the emission 
probabilities. There­fore each emission probability Bi is classi.ed by a 3 dimen­sional mean vector, 
and a 3×3 covariance matrix. The model parameters Bi,A,and p, are trained using the Baum-Welch algorithm 
[2]. 2.5.2 Gesture Classi.cation We create a separate model Mi for each gesture to be rec­ognized. To 
classify an observation sequence as a speci.c gesture, we maximize over the probability of the sequence 
foreachmodelasshowninequation3. Gesture(G) = arg max p(G|Mi) (3) i The probability of a gesture G given 
a model M is the dis­tribution of the observations and the hidden states, as cal­culated by the Viterbi 
Algorithm [2].  HMM State Recognition Rates 100 Training Convergence Rate 100 90 80 80 Correct Classification 
Percentage Correct Classification Percentage 60 40 20 70 60 50 0Number of States Figure 3: Percentage 
of classi.cations for varied model size. Figure 4: Average correct classi.cation for varied training 
set sizes.  3. IMPLEMENTATION RESULTS 3.1 Model Size Exploration To train our gesture recognizer 
models, we gathered training data from 7 di.erent users. Each user was presented with Classification 
Without Local Training images of the gestures from the game, and performed each gesture over 40 times. 
Thenumberofstateswasvaried foreachgesture, and an HMM was created with the data from all of the users. 
We then measured the percentage of correct classi.cations based on those models, results of which are 
show in Figure 3. A recognitionrateofover90%wasachievedwithonlyten states. For the game implementation, 
we use 15 states which achieves over 93% recognition rate with our test data. 100 Correct Classification 
Percentage 80 60 40 20 0  3.2 Training Convergence Rate The gesture recognizer models were trained 
with the sam­ple data to measure how quickly a model would adapt to each user. For each user, we trained 
models with an in­creasing number of observation sequences, and then evalu­ated the percentage of correct 
classi.cations with the sam­pledata. Themodelsusedhave15states. Theresultsof this are shown in Figure 
4. Signi.cant accuracy, over 80%, is achieved with a training set of only 10 gestures. At 20 gestures 
the recognition rate is over 95%. This data also indicates that user-dependent training is more reliable 
than Figure 5: Average correct classi.cation without user training. HMM Recognizer Performance 2200 
the global training measured in Figure 3. regardless of how much training data is used. The sample 2000 
1800 1600 1400 1200 1000 800 600 400 200 0 standard deviation is indicated by the vertical bars. This 
 large sample standard deviation indicates that some gestures Number of States are frequently being misclassi.ed. 
3.3 Implementation Performance Figure 6: Average model sizes. evaluation time for increasing The time 
to evaluate the probability of a gesture is directly related to the number of states in the HMM. We measured 
 HMM Trainer Performance 30 25 20 15 10 5 0Number of States Figure 7: Average training time for increasing 
model sizes. the average time to evaluate a gesture for HMMs with vary­ing number of states. These experiments 
were run on an Intel Core 2 processor at 2.66Ghz with 4GB of RAM. As showninFigure6, anHMMwith15states 
canevaluate over 250 gestures per second. Note that this number is for a single model, thus equation 
3 will introduce a scaling factor. Training the HMMs, however, can not be achieved in a real time environment. 
We measured the average training time for a set of 10 gestures for increasing model sizes. These results 
are presented in Figure 7. The time for training signi.cantly increases with the number of states. Our 
im­plementation which uses 15 states takes about 10 seconds to train. The training for each user must 
therefore be done o.ine, with a trade o. between the training time and recog­nition rate.  4. CONCLUSION 
Natural, innovative input is increasingly becoming the sell­ing point for interactive applications. With 
this work we ex­plore how simple, easy to learn controls can lend themselves to a highly strategic and 
player driven experience. Wiizard s stack based spell approach grants the players the freedom to play 
at their skill level and strategy of their choice. Our hid­den Markov model construction allows the players 
a level of input .exibility while providing easy extensions for more de­tailed game play. The accuracy 
of the recognition depends on time spent on user training, and the number of states in the model. For 
high accuracy, user speci.c training is required. Our gesture recognition system can perform in real 
time with high accuracy after an initial training period. The imple­mentation achieves signi.cant recognition 
rates with 10 - 20 user samples, however we consider the machine training time of 10 seconds to be limiting. 
Our game implementation will handle this by providing training sessions for each player. The goal will 
be to train both the user and the system to­gether in an entertaining fashion. After this initial training 
period, in game data can be used to update the model. Fu­ture work will explore the use of adaptive HMMs 
to avoid this training overhead and explore alternative input devices such as multi touch displays. Average 
Time to Train HMM  5. REFERENCES [1] J. Andersson and C. Phillips. Simple wiimote library for linux, 
2007. [2] C.M.Bishop. Pattern Recognition and Machine Learning (Information Science and Statistics). 
Springer, August 2006. [3] W.T.Freeman,D.B.Anderson,P.A.Beardsley, C.N.Dodge,M.Roth,C.D.Weissman,W.S. 
Yerazunis,H.Kage,K.Kyuma,Y.Miyake,and K. ichi Tanaka. Computer vision for interactive computer graphics. 
IEEE Computer Graphics and Applications, 18(3):42 53, 1998. [4] A. Heap. Real-time hand tracking and 
gesture recognition using smart snakes, 1995. [5] A. Inc. Livemove white paper. Technical report, AiLive 
Inc., http://www.ailive.net/, 2006. [6] P. Keir, J. Payne, J. Elgoyhen, M. Horner, M. Naef, and P. Anderson. 
Gesture-recognition with non-referenced tracking. In 3DUI 06: Proceedings of the 3D User Interfaces (3DUI 
06), pages 151 158, Washington, DC, USA, 2006. IEEE Computer Society. [7] J. Kela, P. Korpipaa, J. Mantyjarvi, 
S. Kallio, G. Savino, L. Jozzo, and D. Marca. Accelerometer-based gesture control for a design environment. 
Personal Ubiquitous Comput., 10(5):285 299, 2006. [8] C. Keskin, A. Erkan, and L. Akarun. Real time hand 
tracking and 3d gesture recognition for interactive interfaces using hmm. In Proceedings of the Joint 
International Conference ICANN/ICONIP 2003. Springer. [9] J. Mantyjarvi, J. Kela, P. Korpipaa, and S. 
Kallio. Enabling fast and e.ortless customisation in accelerometer based gesture interaction. In MUM 
04: Proceedings of the 3rd international conference on Mobile and ubiquitous multimedia, pages 25 31, 
New York, NY, USA, 2004. ACM Press. [10] J. Payne, P. Keir, J. Elgoyhen, M. McLundie, M.Naef,M.Horner,andP.Anderson.Gameplay 
issues in the design of spatial 3d gestures for video games. In CHI 06: CHI 06 extended abstracts on 
Human factors in computing systems, pages 1217 1222, New York, NY, USA, 2006. ACM Press. [11] L. R. Rabiner. 
A tutorial on hidden markov models and selected applications in speech recognition. pages 267 296, 1990. 
[12] J. Segen and S. Kumar. Fast and accurate 3d gesture recognition interface. In ICPR 98: Proceedings 
of the 14th International Conference on Pattern Recognition-Volume 1, page 86, Washington, DC, USA, 1998. 
IEEE Computer Society. [13] J. Segen and S. Kumar. Human-computer interaction using gesture recognition 
and 3d hand tracking. In ICIP (3), pages 188 192, 1998. [14] J. M. Teixeira, T. Farias, G. Moura, J. 
Lima, S. Pessoa, and V. Teichrieb. Ge.ghters: an experiment for gesture-based interaction analysis in 
a .ghting game. In SBGames, Brazil, 2006.   
			]]></ft_body>
		</fulltext>
		<article_type art_type="short_paper" />
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2007</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>1328242</article_id>
		<sort_key>400</sort_key>
		<display_label>Pages</display_label>
		<pages>4</pages>
		<article_publication_date>11-14-2007</article_publication_date>
		<seq_no>5</seq_no>
		<title><![CDATA[Video game habits]]></title>
		<subtitle><![CDATA[a reasoned action approach]]></subtitle>
		<page_from>213</page_from>
		<page_to>216</page_to>
		<doi_number>10.1145/1328202.1328242</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1328242</url>
		<abstract>
			<par><![CDATA[<p>This paper describes research done in the domain of habit as it pertains to habitual video game play. A reasoned action understanding of habit is provided to illustrate a potential research perspective.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[deficient self-regulation]]></kw>
			<kw><![CDATA[habit]]></kw>
			<kw><![CDATA[reasoned action]]></kw>
			<kw><![CDATA[video games]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>J.4</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010405.10010455</concept_id>
				<concept_desc>CCS->Applied computing->Law, social and behavioral sciences</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010455</concept_id>
				<concept_desc>CCS->Applied computing->Law, social and behavioral sciences</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Human Factors</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P925267</person_id>
				<author_profile_id><![CDATA[81342501410]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Ryan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Lange]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Michigan State University, East Lansing, MI]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Entertainment Software Association. (2007). Facts and research: Game player data. Retrieved from: http://www.theesa.com/facts/gamer_data.php]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Woodcock, B. S. (July, 2006). An analysis of MMO subscription growth. Retrieved from: http://www.MMOchart.com/]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1159988</ref_obj_id>
				<ref_obj_pid>1159982</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Yee, N. (2006). The Demographics, Motivations and Derived Experiences of Users of Massively-Multiuser Online Graphical Environments. Presence: Teleoperators and Virtual Environments, 15, 309--329.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Yee, N. (2004). Addiction. The Daedalus Project: The psychology of MMORPGs. Retrieved from: http://www.nickyee.com/daedalus/archives/000818.php]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Miller II, S. A. (2002, March 31). Death of a game addict: Ill Hudson man took own life after long hours on Web. Retrieved from: http://www.jsonline.com/story/index.aspx?id=31536]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Xinhuanet (2005, November 1). Death of net game addict alert others. Retrieved from: http://news.xinhuanet.com/english/2005-11/01/content_3714003.htm]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Verplanken, B., &amp; Aarts, H. (1999). Habit, attitude, and planned behaviour: Is habit an empty construct or an interesting case of goal-directed automaticity? European Review of Social Psychology, 29, 591--604.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Triandis, H. C. (1979). Values, attitudes and interpersonal behavior. Nebraska Symposium on Motivation, 27, 195--259.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Landman, J. &amp; Manis, M. (1983). Social cognition: Some historical and theoretical perspectives. In L. Berkowitz (Ed.), Advances in experimental social psychology (Vol. 16, pp. 49--123). New York: Academic Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Anderson, C. A., Berkowitz, L., Donnerstein, E., Huesmann, L. R., Johnson, J. D., Linz, D., Malamuth, N. M., &amp; Wartella, E. (2003). The influence of media violence on youth. Psychological Science in the Public Interest, 4 (3), 81--110.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Fiske, S. T., &amp; Taylor, S. E. (1984). Social cognition. Reading, MA: Addison-Wesley.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Heatherton, T. F., &amp; Nichols, P. A. (1994). Personal accounts of successful versus failed attempts at life change. Personality and Social Psychology Bulletin, 20, 664--675.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Ouellette, J. A., &amp; Wood, W. (1998). Habit and intention in everyday life: The multiple processes by which past behavior predicts future behavior. Psychological Bulletin, 124 (1), 54--74.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Verplanken, B., &amp; Wood, W. (2006). Interventions to break and create consumer habits. Journal of Public Policy &amp; Marketing, 25 (1), 90--103.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Wood, W., Tam, L., &amp; Witt, M. G. (2005). Changing circumstances, disrupting habits. Journal of Personality and Social Psychology, 88 (6), 918--933.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Heatherton, T. F., &amp; Nichols, P. A. (1994). Personal accounts of successful versus failed attempts at life change. Personality and Social Psychology Bulletin, 20, 664--675.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Crawley, A. M., Anderson, D. R., Santomero, A., Wilder, A., Williams, M., Evans, M. K., &amp; Bryant, J. (2002). Do children learn how to watch television? The impact of extensive experience with Blue's Clues on preschool children's television viewing behavior. Journal of Communication, 52 (2), 264--280.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Bargh, J. A. (1989). Conditional automaticity: Varieties of automatic influence on social perception and cognition. In J. S. Uleman &amp; J. A. Bargh (Eds.), Unintended Thought (pp. 3--51). New York: Guilford Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Aarts, H., &amp; Dijksterhuis, A. (2000). Habits as knowledge structures: Automaticity in goal-directed behavior. Journal of Personality and Social Psychology, 78 (1), 53--63.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Verplanken, B., &amp; Faes, S. (1999). Good intentions, bad habits and effects of forming implementation intentions on healthy eating. European Journal of Social Psychology, 29, 591--604.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Bargh, J. A. (1990). Auto-motives: Preconscious determinants of social interaction. In R. M. Sorrentino &amp; E. T. Higgins (Eds.) Handbook of motivation and cognition (pp. 93--130). New York: Guilford Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Bargh, J. A., &amp; Gollwitzer, P. M. (1994). Environmental control of goal-directed action: Automatic and strategic contingencies between situations and behavior. Nebraska Symposium on Motivation, 41, 71--124.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[Bargh, J. A., &amp; Pietromonaco, P. (1982). Automatic information processing and social perception: The influence of trait information presented outside of conscious awareness on impression formation. Journal of Personality and Social Psychology, 43, 437--449.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[Verplanken, B., &amp; Faes, S. (1999). Good intentions, bad habits and effects of forming implementation intentions on healthy eating. European Journal of Social Psychology, 29, 591--604.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[Bargh, J. A., Gollwitzer, P. M., Chai, A., Barndollar, K., &amp; Troschel, R. (2001). The automated will: Nonconscious activation and pursuit of behavioral goals. Journal of Personality and Social Psychology, 81 (6), 1014--1027.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[LaRose, R., Lai, Y.-J., Lange, R., Love, B., and Wu, Y. (2005). Sharing or piracy? An exploration of downloading behavior. Journal of Computer-Mediated Communication, 11 (1). Retrieved from: http://jcmc.indiana.edu/vol11/issue1/larose.html]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[Ajzen, I. (1991). The theory of planned behavior. Organizational Behavior and Human Decision Processes, 50 (2), 179--211.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[LaRose, R., Lin, C. A., &amp; Eastin, M. S. (2003). Unregulated Internet usage: Addiction, habit or deficient self-regulation? Media Psychology, 5, 225--253.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[Bandura, A. (1991). Social cognitive theory of self-regulation. Organizational Behavior and Human Decision Processes, 50, 248--287.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>30</ref_seq_no>
				<ref_text><![CDATA[Verplanken, B., &amp; Orbell, S. (2003). Reflections on past behavior: A self-report index of habit strength. Journal of Applied Social Psychology, 33 (6), 1313--1330.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Video Game Habits: A Reasoned Action Approach Ryan Lange Michigan State University 409 Comm Arts Building 
East Lansing, MI 48824-1212 1-517-355-8372 langerya@msu.edu ABSTRACT This paper describes research done 
in the domain of habit as it pertains to habitual video game play. A reasoned action understanding of 
habit is provided to illustrate a potential research perspective.  Categories and Subject Descriptors 
J.4 [Human and Social Sciences]: Psychology, Sociology  General Terms Human Factors, Theory.  Keywords 
Video games, habit, reasoned action, deficient self-regulation. 1. INTRODUCTION Habitual video game play 
has been condemned for many years by people in the media as universally negative. But like any habit, 
game play can be a benefit or a burden depending on how the habit interacts with a player s life. The 
media often discusses people who have manifested video game habits that are dangerous to themselves and 
others, but does not examine the factors that might lead to that negative behavior pattern. If the motivations 
for having a very strong video game habit could be understood, it may be possible to create an intervention 
that would allow these extreme gamers to balance their game play with the rest of their lives. 2. ARE 
VIDEO GAMES DANGEROUS? The large number of people involved in video gaming demonstrates the importance 
of examining gaming habits. According to the ESA [1], 69% of American heads of households play video 
games, which based on the most recent US Census data would indicate that there are at least 72 million 
video game Permission to make digital/hard copy of part of this work for personal or classroom use is 
granted without fee provided that the copies are not made or distributed for profit or commercial advantage, 
the copyright notice, the title of the publication, and its date of appear, and notice is given that 
copying is by permission of the ACM, Inc. To copy otherwise, to republish, to post on servers, or to 
redistribute to lists, requires prior specific permission and/or a fee. FuturePlay 2007, November 15-17, 
2007, Toronto, Canada. Copyright 2007 ACM 978-1-59593-943-2/07/0011...$5.00 players. As many video games 
are targeted at males between 18 and 24, the actual population is likely much higher considering individuals 
who are not heads of households (dependent children, roommates, and so on). One of the largest areas 
in video gaming today is the Massively Multiplayer Online Game (MMO). As of July of 2006, there are over 
12 million people worldwide subscribed to various MMOs [2]. Yee has found that many MMO players, despite 
having full time jobs, still manage to play between 10 and 20 hours per week [3]. This time commitment 
is not insignificant, being equivalent to a second part-time job. Perhaps more troublingly, up to 40% 
of online gamers in a survey conducted by Yee consider themselves addicted to their various MMO to some 
degree [4]. Even if they are not addicted in the clinical sense, the perception of addiction is an important 
indicator of the strength of these habits. Many people are concerned about the compelling qualities of 
video games because of how powerful video game habits can become. Suicides [5] and accidental deaths 
[6] have been attributed to excessive video game play, causing many public figures to want to take action 
against the video game industry. However, these exceptional cases are just that anomalous incidents 
that are not representative of the average video game player. Most players are able to use video games 
without negative life consequences, but still may develop a video game habit .  3. WHAT IS A HABIT? 
Many scholars have devised definitions of habit. For our purposes, we use the Verplanken and Aarts definition 
of habit as learned sequences of acts that have become automatic responses to specific cues, and are 
functional in obtaining certain goals or end states [7]. The trigger for this automatic behavior pattern 
is often believed to be cues from the external environment, a legacy from the behaviorist perspective. 
Triandis and others have understood habitual behaviors as being part of schemas [8]. Scholars who support 
the idea of schemas claim that people have cognitive structures which represent both general and specific 
knowledge in a single higher-order unit called schemas, and these schemas help us organize reality in 
a way we can understand more easily [9]. These cognitive structures can be activated by environmental 
stimuli [10, 11]. When these schema are activated, or primed, their effects can occur even below one 
s conscious awareness [12]. If we understand habit as being contained within schemas, we can infer that 
the chain of behaviors that lead to achieving a goal are collected into a unit, or several related units, 
that can be triggered by certain environmental or internally generated prompts.  4. STABLE CONTEXT 
VERSUS GOAL-DRIVEN PERCEPTIONS OF HABITS Scholars tend to infer the existence of habit by observing the 
existence of a behavior that manifests regularly given a stable environment [13, 14]. However, the idea 
of a stable environment being of crucial importance may be ill-founded. Reasoned action theories do not 
have an explanation of what aspects of the environment are the most important to keep stable for the 
successful execution of a habit. While superficial variance in the environment is acceptable [14], what 
is superficial? It may be that the number of cues needed for a particular habit may be larger or smaller 
based on the habit as well as individual differences. It has been difficult to show the strong effects 
that theorists argue should exist in direct tests. Wood, Tam and Witt directly acknowledge that there 
is no direct evidence that shows habitual behaviors are cued immediately by recurring stimuli [15]. Even 
with a relatively clear example of context change such as in the case of Heatherton and Nichols [16], 
we do not see the large, powerful effects we would expect based on this literature s assumptions. In 
that study, only 36% of successful reports of behavior change involved changing one s environment. If 
the environment was truly the main cause of habitual behavior, the effects of a severe change in the 
environment should have been larger. It has previously been observed that people can be trained to execute 
complex media behaviors even at a very young age, such as in the case of Crawley [17]. We can understand 
Crawley s findings in the context of Bargh [18], who refers to the creation of semi-automatic response 
patterns. Semi-automatic response patterns are a string of automatic and volitional behaviors that run 
to completion once they are begun. Each step of the response pattern requires some controlled act to 
stop or continue the pattern, but this act can be very small. The creation of these response patterns 
is not driven purely by the environment, but rather by an individual s goals. Goals drive the behaviors 
of individuals, even when their behavior patterns are automated [19]. While goals do not by themselves 
create habits, as they can manifest through a variety of means, goals are the driving force behind the 
creation of a habitual behavior. Habits can be understood, according to Aarts and Dijksterhuis, as associations 
between goals and actions, creating a mental link. These associations are created by choices that are 
made both frequently and consistently, creating an automatic response tendency as time passes. Habits 
are generally thought of as uncontrolled, and focus one s attention on one behavioral option at the expense 
of others [20]. Social scientists have observed that the more a behavior is repeated and rewarded, the 
more likely it is that the behavior (or set of behaviors) will be reinforced [21, 22]. Bargh proposes 
that this repetition reinforces the behavior, creating a more accessible and powerful cognitive schema. 
If this is the case, the environment is less important to the formation of habits than the creation of 
a developed cognitive schema that would include the relevant ideas and behaviors used to execute that 
behavior. 5. A REASONED ACTION PERSPECTIVE ON VIDEO GAME HABITS Media behaviors like playing video games 
may be the result of reasoned or unreasoned action. While a behavior may be initially reasoned, we tend 
to find that a habit is not created on purpose [23]. A person may start with a conscious goal and pursue 
that goal with conscious effort, but if that action is repeated again and again over time, the necessary 
cognitive steps eventually become abbreviated through automaticity [24, 25]. Learning needed to take 
place in order for an individual to understand that performing a behavior would lead to a certain outcome. 
As a result, the goal intentions may be lost, but the purpose of the goal intentions is still being achieved. 
A person may find that their media use behavior can be optimized in some way. For instance, a person 
may develop a favorite MMO and play that game exclusively. Once the means by which optimal gratification 
is achieved is found, no further searching is needed. Eventually, the act of searching is forgotten, 
and only the use of the medium is important. The behavior, not the goal intention that originally created 
the behavior, becomes the new goal. When habits reach this point of becoming behavior-centered rather 
than goal centered, it demonstrates what happens when perceived behavioral control is deficient; a behavior 
that was originally encoded to reach a productive goal as part of a schema, and automated to achieve 
that goal more efficiently, has now become a behavior that is enacted solely to perpetuate itself. This 
kind of media use behavior has been seen in illegal music downloading, in which some individuals will 
collect vast numbers of music files, far more than they could ever reasonably consume [26].  6. MODEL 
OF A VIDEO GAME HABIT A video game behavior may start as a highly controlled behavior. A person may select 
a specific video game for any number of reasons. They may be attracted to the brand or the genre or game, 
or might have gotten a strong recommendation from a trusted source. Based on their selection criteria, 
they took steps to gain access to the game. As most video game purchases are non-trivial expenses, some 
degree of reasoned thought took place to make that specific selection. Even downloading a free game or 
pirating a game illegally requires a certain degree of intentionality that cannot happen mindlessly . 
After receiving access to a video game, learning must take place to allow for the development of self-efficacy. 
Even a game in a familiar genre has its own distinct idiosyncrasies that must be discovered and mastered 
by new players. This is an active process of exploration and practice that eventually allows for mastery. 
The amount of time it takes to master the basic elements of a game may vary from person to person and 
from game to game, but persistent effort usually allows a player to gain some degree of mastery of a 
well-designed game. Once a person has developed skill at a game, playing the game becomes less effortful. 
Gradually, the experience of playing a game should become more dominant than having to focus continually 
on operating controls. Basic tasks become automated, allowing for a person to focus on more advanced 
skills. The game itself becomes transparent, and over time this repeated behavior may become habitual 
as it is integrated into a person s life. For instance, a person may schedule their daily life around 
being able to return home from work at a given time and log on to their favorite MMO.  This integration 
into routine allows for the automation of the behavior. It becomes increasingly easy to engage in the 
game playing activity as it is integrated into the schema of one s daily life. This is the power of addictive 
games to become a constant presence in the life of a person with a very strong video game habit. It is 
as much of a given behavior to that person as having one s morning cup of coffee or taking a typical 
route to work. It is no longer a behavior that requires any active thought, having become completely 
routinized. Habits in this stage of development can potentially be harmful. However, it is still possible 
for a person to break a strong habit.  7. TAKING CONTROL BACK FROM THE HABIT A habit can be broken or 
weakened if a person regains agency over their own behavior. One type of agency is described in the theory 
of planned behavior [27] as perceived behavioral control (PBC), constructed through control beliefs. 
Control beliefs refer to the presence or absence of resources or opportunities. The more perceived resources 
or opportunities a person has over a behavior, the more control they feel they have over that behavior. 
It seems intuitively correct that media habits seem relatively easy to control. They do not seem to create 
the kind of strong physiological dependencies that are seen with vices like smoking or drinking, instead 
operating purely in the psychological realm. However, one could argue that the high degree of control 
may encourage the creation of a powerful habit that will persist over a long period of time. The initial 
control may fade as the habit is initiated, and over time it becomes automated and out of the direct 
control of the individual. This loss of control can be thought of as a state of deficient self-regulation. 
 8. DEFICIENT SELF-REGULATION AND VIDEO GAME HABITS Behaviors that are thought of as being out of control 
, such as excessive music downloading or destructive levels of video game play, may be instances of deficient 
self-regulation (DSR). Deficient self-regulation is a state in which conscious self-control is diminished, 
and environmental factors become more of a factor in influencing behavior [28]. The idea of deficient 
self-regulation arises from Bandura s function of self-regulation within social cognitive theory [29]. 
Bandura defines the self-regulation function as the method by which individuals observe, judge and self-administer 
incentives or punishments to change their behavior. When self-regulation is deficient, negative outcomes 
may or may not occur. It is possible that an absence of self-regulation may not have any negative consequences. 
LaRose et al. believe most media use problems are benign problems that are manageable without professional 
interventions, and fall on a continuum rather than being an all-or-nothing state of addiction . Media 
use problems appear to be worsened by depression and low self-efficacy (a belief in this case that one 
cannot stop using a given medium). As a result of their study of possibly undesirable levels of Internet 
use, LaRose et al. argued that habits may develop through direct stimulus-response associations between 
the stimuli (the media content) and the outcome (positive emotions). These associations were implemented 
via repetitive and conscious decisions, but with automation, the conscious nature of the choice was lost. 
9. ONGOING RESEARCH A project presently under development will examine how people who play console-based 
video games (XBox, Playstation, etc.) understand their gaming behavior in terms of the theory of planned 
behavior and a measure of habit known as the Self-Report Habit Index [30]. The SRHI is a measure of habit 
that relies on measuring the automated nature of the behavior rather than only the number of times it 
is repeated as other, less robust measures of habit have in the past. The data collection for this project 
is scheduled for the early fall. 10. CONCLUSIONS Video games are a growing mass medium. The compelling 
content found in today s games has the power to immerse people deeply in a virtual world. Like any human 
behavior, playing video games can become a habit. Most people who play video games do so in a responsible 
way, but some video gamers form extreme habits that are destructive to themselves and others. These cases 
are likely caused by deficient self-regulation, initially created by reasoned action that eventually 
spiraled out of control. We can counteract negative habits by the use of conscious agency. Even when 
self-regulation is deficient, it can be returned to an individual so long as they are able to see that 
they can regain control of their behavior. By creating new goals and demonstrating that they have control 
over their environment, a negative habit should be able to be softened or removed entirely. 11. REFERENCES 
[1] Entertainment Software Association. (2007). Facts and research: Game player data. Retrieved from: 
http://www.theesa.com/facts/gamer_data.php [2] Woodcock, B. S. (July, 2006). An analysis of MMO subscription 
growth. Retrieved from: http://www.MMOchart.com/ [3] Yee, N. (2006). The Demographics, Motivations and 
Derived Experiences of Users of Massively-Multiuser Online Graphical Environments. Presence: Teleoperators 
and Virtual Environments, 15, 309-329. [4] Yee, N. (2004). Addiction. The Daedalus Project: The psychology 
of MMORPGs. Retrieved from: http://www.nickyee.com/daedalus/archives/000818.php [5] Miller II, S. A. 
(2002, March 31). Death of a game addict: Ill Hudson man took own life after long hours on Web. Retrieved 
from: http://www.jsonline.com/story/index.aspx?id=31536 [6] Xinhuanet (2005, November 1). Death of net 
game addict alert others. Retrieved from: http://news.xinhuanet.com/english/2005­11/01/content_3714003.htm 
[7] Verplanken, B., &#38; Aarts, H. (1999). Habit, attitude, and planned behaviour: Is habit an empty 
construct or an interesting case of goal-directed automaticity? European Review of Social Psychology, 
29, 591-604.  [8] Triandis, H. C. (1979). Values, attitudes and interpersonal behavior. Nebraska Symposium 
on Motivation, 27, 195-259. [9] Landman, J. &#38; Manis, M. (1983). Social cognition: Some historical 
and theoretical perspectives. In L. Berkowitz (Ed.), Advances in experimental social psychology (Vol. 
16, pp. 49-123). New York: Academic Press. [10] Anderson, C. A., Berkowitz, L., Donnerstein, E., Huesmann, 
L. R., Johnson, J. D., Linz, D., Malamuth, N. M., &#38; Wartella, E. (2003). The influence of media violence 
on youth. Psychological Science in the Public Interest, 4 (3), 81­ 110. [11] Fiske, S. T., &#38; Taylor, 
S. E. (1984). Social cognition. Reading, MA: Addison-Wesley. [12] Heatherton, T. F., &#38; Nichols, P. 
A. (1994). Personal accounts of successful versus failed attempts at life change. Personality and Social 
Psychology Bulletin, 20, 664-675. [13] Ouellette, J. A., &#38; Wood, W. (1998). Habit and intention in 
everyday life: The multiple processes by which past behavior predicts future behavior. Psychological 
Bulletin, 124 (1), 54­ 74. [14] Verplanken, B., &#38; Wood, W. (2006). Interventions to break and create 
consumer habits. Journal of Public Policy &#38; Marketing, 25 (1), 90-103. [15] Wood, W., Tam, L., &#38; 
Witt, M. G. (2005). Changing circumstances, disrupting habits. Journal of Personality and Social Psychology, 
88 (6), 918-933. [16] Heatherton, T. F., &#38; Nichols, P. A. (1994). Personal accounts of successful 
versus failed attempts at life change. Personality and Social Psychology Bulletin, 20, 664-675. [17] 
Crawley, A. M., Anderson, D. R., Santomero, A., Wilder, A., Williams, M., Evans, M. K., &#38; Bryant, 
J. (2002). Do children learn how to watch television? The impact of extensive experience with Blue s 
Clues on preschool children s television viewing behavior. Journal of Communication, 52 (2), 264-280. 
[18] Bargh, J. A. (1989). Conditional automaticity: Varieties of automatic influence on social perception 
and cognition. In J. S. Uleman &#38; J. A. Bargh (Eds.), Unintended Thought (pp. 3­51). New York: Guilford 
Press. [19] Aarts, H., &#38; Dijksterhuis, A. (2000). Habits as knowledge structures: Automaticity in 
goal-directed behavior. Journal of Personality and Social Psychology, 78 (1), 53-63. [20] Verplanken, 
B., &#38; Faes, S. (1999). Good intentions, bad habits and effects of forming implementation intentions 
on healthy eating. European Journal of Social Psychology, 29, 591-604. [21] Bargh, J. A. (1990). Auto-motives: 
Preconscious determinants of social interaction. In R. M. Sorrentino &#38; E. T. Higgins (Eds.) Handbook 
of motivation and cognition (pp. 93-130). New York: Guilford Press. [22] Bargh, J. A., &#38; Gollwitzer, 
P. M. (1994). Environmental control of goal-directed action: Automatic and strategic contingencies between 
situations and behavior. Nebraska Symposium on Motivation , 41, 71-124. [23] Bargh, J. A., &#38; Pietromonaco, 
P. (1982). Automatic information processing and social perception: The influence of trait information 
presented outside of conscious awareness on impression formation. Journal of Personality and Social Psychology, 
43, 437 449. [24] Verplanken, B., &#38; Faes, S. (1999). Good intentions, bad habits and effects of forming 
implementation intentions on healthy eating. European Journal of Social Psychology, 29, 591-604. [25] 
Bargh, J. A., Gollwitzer, P. M., Chai, A., Barndollar, K., &#38; Troschel, R. (2001). The automated will: 
Nonconscious activation and pursuit of behavioral goals. Journal of Personality and Social Psychology, 
81 (6), 1014-1027. [26] LaRose, R., Lai, Y.-J., Lange, R., Love, B., and Wu, Y. (2005). Sharing or piracy? 
An exploration of downloading behavior. Journal of Computer-Mediated Communication, 11 (1). Retrieved 
from: http://jcmc.indiana.edu/vol11/issue1/larose.html [27] Ajzen, I. (1991). The theory of planned behavior. 
Organizational Behavior and Human Decision Processes, 50 (2), 179-211. [28] LaRose, R., Lin, C. A., &#38; 
Eastin, M. S. (2003). Unregulated Internet usage: Addiction, habit or deficient self-regulation? Media 
Psychology, 5, 225-253. [29] Bandura, A. (1991). Social cognitive theory of self­regulation. Organizational 
Behavior and Human Decision Processes, 50, 248-287. [30] Verplanken, B., &#38; Orbell, S. (2003). Reflections 
on past behavior: A self-report index of habit strength. Journal of Applied Social Psychology, 33 (6), 
1313-1330.   
			]]></ft_body>
		</fulltext>
		<article_type art_type="short_paper" />
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2007</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>1328243</article_id>
		<sort_key>410</sort_key>
		<display_label>Pages</display_label>
		<pages>4</pages>
		<article_publication_date>11-14-2007</article_publication_date>
		<seq_no>6</seq_no>
		<title><![CDATA[Musical interaction in computer games]]></title>
		<page_from>217</page_from>
		<page_to>220</page_to>
		<doi_number>10.1145/1328202.1328243</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1328243</url>
		<abstract>
			<par><![CDATA[<p>In general, the role of sound in interactive media environments, has been limited to the production of a soundtrack which will enhance the player's sensory experience of the game. Much less attention has been placed on the role of sound as an input to a game. This paper will explore such a game, with a view toward exploring the potential role of sound in computer games, and practical design ideas which may advance the current state of the art.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[audio games]]></kw>
			<kw><![CDATA[audio interaction]]></kw>
			<kw><![CDATA[video game audio]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>J.5</cat_node>
				<descriptor>Performing arts (e.g., dance, music)</descriptor>
				<type>S</type>
			</primary_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010405.10010469.10010471</concept_id>
				<concept_desc>CCS->Applied computing->Arts and humanities->Performing arts</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010469.10010471</concept_id>
				<concept_desc>CCS->Applied computing->Arts and humanities->Performing arts</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Human Factors</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP43124683</person_id>
				<author_profile_id><![CDATA[81321496403]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[J.]]></first_name>
				<middle_name><![CDATA[R.]]></middle_name>
				<last_name><![CDATA[Parker]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Calgary]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P925238</person_id>
				<author_profile_id><![CDATA[81343494595]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[J.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Heerema]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Calgary]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Atlus Video Games, &#60;b&#62;Contact&#60;/b&#62; (2006), Nintendo]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>47314</ref_obj_id>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[E. Oran Brigham, &#60;b&#62;Fast Fourier Transform and Its Applications&#60;/b&#62;, Prentice-Hall Signal Processing Series, 1988]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[J. W. Cooley and John Tukey, &#60;b&#62;An algorithm for the machine calculation of complex Fourier series&#60;/b&#62;, Math. Comput. 19, 297--301 (1965).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Mihaly Csikszentmihalyi, &#60;b&#62;Finding Flow: The Psychology of Engagement With Everyday Life&#60;/b&#62;, Basic Books (HarperColins), New York. 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Forrester, Michael A. (2000), &#60;b&#62;Auditory Perception and Sound as Event&#60;/b&#62;, Sound Journal (25 April 2005).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Gaver, W. W. (1993a). &#60;b&#62;How do we hear in the world: Explorations in ecological acoustics.&#60;/b&#62; Ecological Psychology, 5(285--313).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Harmonix (2003). &#60;b&#62;Karaoke revolution&#60;/b&#62;, Konami.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>502372</ref_obj_id>
				<ref_obj_pid>502348</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Takeo Igarashi, John F. Hughes, &#60;b&#62;Voice as Sound: Using Nonverbal Voice Input for interactive Control&#60;/b&#62;, Proceedings of the 14th Annual Sympolium of User Interface Software and Technology (UIST-01), pages 155--1556, New York, November 11014, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Nintendo (2005). &#60;b&#62;Nintendogs&#60;/b&#62;, Nintendo.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[J. R. Parker, &#60;b&#62;Human Motion as Input and Control in Kinetic Games&#60;/b&#62;, FuturePlay, East Lansing MI, 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[J. R. Parker, S. Chan, B. Behm, &#60;b&#62;Generating Audio Textures by Example&#60;/b&#62;, Journal of Game Development, 2006]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Radical Entertainment (2003). &#60;b&#62;Simpson's hit and run&#60;/b&#62;, Vivendi Universal.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[John Romero (1993). &#60;b&#62;Doom&#60;/b&#62;, id Software, GT Interactive, Activision]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Thorn, R. (1998). &#60;b&#62;Hearing is Believing - the Evidence&#60;/b&#62; Sound Journal, 1(http://speke.ukc.ac.uk/sais/sound-journal/thorn981.html), 35--45.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[van Tol, R. and Huiberts, S., &#60;b&#62;AudioGames.net&#60;/b&#62;, (2006) http://www.audiogames.net/, (June 30, 2006)]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Vasan, Peter and Schober, Michael F, &#60;b&#62;Detecting and Resolving Metrical Ambiguity in a Rock Song Upon Multiple Rehearings.&#60;/b&#62; The 8th International Conference on Music Perception &amp; Cognition, Evanston Illinois, USA, August 3--7,]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Musical Interaction in Computer Games J. R. Parker Sport Technology Laboratory, Faculty of Kinesiology, 
University of Calgary jparker@ucalgary.ca ABSTRACT In general, the role of sound in interactive media 
environments, has been limited to the production of a soundtrack which will enhance the player s sensory 
experience of the game. Much less attention has been placed on the role of sound as an input to a game. 
This paper will explore such a game, with a view toward exploring the potential role of sound in computer 
games, and practical design ideas which may advance the current state of the art. Categories and Subject 
Descriptors J. Computer Applications (J.5 ARTS AND HUMANITIES) Music General Terms Algorithms, Human 
Factors Keywords Video game audio, audio interaction, audio games. 1. INTRODUCTION The ubiquitous term 
video game implies a natural bias towards visual interaction in computer games. It is true that most 
people acquire 80%-90% of their perceptual input through vision, but it is also true WKDW PDQ\ SHRSOH 
IXQFWLRQ YHU\ ZHOO ZLWK D VLJQLÀFDQW GHJUHH RI YLVXDO impairment. Video games that lack sound have never 
been popular, despite the presence of excellent graphics and other features. Sound is typically assumed 
to be present, but is generally not expected to be a selling point or major feature. Nonetheless, when 
it is badly done, there is a negative impact on game sales. Therefore, we conclude that sound is a key 
aspect of a modern video game [10,11]. Game development teams retain musicians to create a sound track, 
usually at great expense. These Foley operators are responsible for creating sound effects and placing 
then in the game (or movie) and are key members of a modern game development team. Many effects are now 
recorded on CDs and sold as sets, but there is still a need for sound design and certainly for music 
composition. Many games have musical themes for each character, and segues for each character between 
each activity; composition is a key part of the overall design and feel . In order to improve the methodologies 
for sound design in gamesVSHFLÀFDOO\ LW LV LPSRUWDQW WR KDYH VRPH NQRZOHGJH RI KRZ FRPSXWHU DXGLR ZRUNV 
LQ JHQHUDO ZK\ LW·V LPSRUWDQW DQG KRZ PXVLFDO DVVHWV ÀW into the scheme of a game. 2. WHY IS AUDIO IMPORTANT? 
At the lowest level, sound carries with it a sense of another presence, and of activity. It is there 
to make the player feel less alone (I. E. connected with something else, or continuity) and reminds them 
that the game is going on, even if they are idle or drawn away for the moment. Permission to make digital/hard 
copy of part of this work for personal or classroom use is granted without fee provided that the copies 
are not made or GLVWULEXWHG IRU SURÀW RU FRPPHUFLDO DGYDQWDJH WKH FRS\ULJKW QRWLFH WKH WLWOH RI the publication, 
and its date of appear, and notice is given that copying is by permission of the ACM, Inc. To copy otherwise, 
to republish, to post on servers, RU WR UHGLVWULEXWH WR OLVWV UHTXLUHV SULRU VSHFLÀF SHUPLVVLRQ DQG RU 
D IHH FuturePlay 2007, November 15-17, 2007, Toronto, Canada. Copyright 2007 ACM 978-1-59593-943-2/07/0011...$5.00 
J. Heerema Interdisciplinary Graduate Program, University of Calgary heerema@andromeda.ab.ca It s also 
about activity in the simple sense that fast music is associated with a great deal of activity, and slow 
music is associated with little activity. Importantly, sound carries with it more emotion than any other 
part of WKH JDPH ,W LV VDLG E\ SV\FKRORJLVWV WKDW ZH OHDUQ ÀUVW E\ VHHLQJ QH[W by hearing. However, the 
sense of hearing seems to be closely connected to emotions, with certain soft sounds being able to sooth 
us, and sharp orORZ IUHTXHQF\ VRXQGV LQVSLULQJ IHDU >  @ 6RXQGV DSSHDU WR LQÁXHQFH emotions more easily 
and quickly than vision is able to.  3. AUDIO IN VIDEO GAMES Current video games use audio in four distinct 
aspects: music, speech, effects, and input. Music carries with it a continuity aspect (background), an 
emotion aspect (spooky vs. comical) and a tempo aspect (fast vs. slow). The use of character themes is 
a standard practice (a good example of this is the game The Simpson s Hit and Run [12]), as is composing 
a segue between activities (eg: walking to running). Speech is used in games that involve human-like 
characters to communicate information to player. For example, the player may overhear conversations that 
give valuable information, or they may beJLYHQ D EULHÀQJ RU FRPPDQG IURP D QRQ SOD\HU FKDUDFWHU Sound 
effects VHUYH PXOWLSOH UROHV WKH\ PD\ VHUYH DV FRQÀUPDWLRQ WKDW a requested activity has taken place, 
or they might serve as a warning that something has happened -your branch broke - or is about to happen 
-footsteps are approaching, look out! Effects need to be representative of the sounds that things make 
in the world, insofar as the objects in the game are real. As such, another function of effects is to 
add to a sense of reality and presence in an environment. Audio input to a game is typically speech, 
as in Nintendogs [9], in which the player commands the game characters to perform various tricks. Another 
game that uses audio input is Contact [1], in which theSOD\HU LQÁDWHV D EDOORRQ E\ EORZLQJ LQWR WKH JDPH 
FRQVROH·V PLFURSKRQH $ GLIÀFXOW WR ORFDWH ÀQDO H[DPSOH LV WKH Tactical Iraqi language teaching game which 
can listen to spoken Arabic and (occasionally) identify what LV EHLQJ VDLG > @ %H\RQG WKHVH H[DPSOHV 
LW LV GLIÀFXOW WR ÀQG DXGLR LQSXW in computer games. To summarize, the use of sound in games at this 
time is mostly reactive rather than interactive.  4. AUDIO GAMES An audio game is one that uses sound, 
rather than pictures, as the main game state modality. An early example of the genre is Bear Hunt, a 
variation on Hunt the Wumpus, an old text-based UNIX game. Bear Hunt was devised in the early 1980 s 
by a company named QSound in Calgary, Alberta, Canada. The idea was simple you would stand in front of 
a pair of stereo loudspeakers, holding a toy gun. Occasionally a bear would charge at you from some particular 
direction within the stereo ÀHOG DQG \RX ZRXOG EH H[SHFWHG WR VKRRW DW LW <RX FRXOG RQO\ KHDU WKH bear 
of course, as there was no visual display. This game was developed to promote the company s 3D sound 
product. There are relatively few audio games, and many them are intended for play by the vision impaired. 
It is the opinion of the authors that the full potential of audio as a game playing mode is nowhere close 
to having been reached. Let us look at some audio games to see which aspects of sound are being utilized. 
 Karaoke Revolution Karaoke is derived from two Japanese words: Kara = missing and Oke = orchestra. 
The game is typically used in a social setting, but has also been used therapeutically to help people 
who suffer from performance anxiety. In this game, the player chooses from a selection of songs [7], 
which plays while the printed lyrics follow along on the screen. It is therefore neither completely audio, 
nor completely video (nor are most video games completely video!) The player is expected to sing along, 
and the computer scores the player according to how well they follow the melody. The visual display is 
often not needed, since most folks know the words for the song they re going to sing. This game does 
not deal with issues such as ornamentation if the player doesn t sing the song exactly the way the original 
singer does, their scores will suffer. Other audio-intense games include: Mueckenjagd (Mosquito Hunt) 
-The player hears a a mosquito buzzing about. The player s orientation is controlled by keys, and pressing 
the space bar smacks the player s hands together, with the goal of smacking the mosquito. Bobby s Revenge 
² 6DQWD &#38;ODXV ÁLHV SDVW DQG WKH SOD\HU FDQ KHDU the sounds of sleigh bells. In a nod towards making 
the game nonlethal, the player attempts to shoot Santa with a paintball gun. Top Speed 2 A racing game 
which provides 3D sounds to the player, which they use to guide the car. Sounds indicate proximity to 
the road margins, and to objects which the car can collide with. Ten Pin Alley The background sounds 
for this bowling simulation are quite convincing. Simple tones guide the player s aim in a way that resembles 
the way blind people actually bowl. These games, and more, may be found at the web site http://www. audiogames.net 
[15]. The red notes don t always mean mistakes, of course. They could be reasonable interpretations of 
the score, or ornamentation. The more basic lesson types focus on learning the music, while more advanced 
lessons focus on musical interpretation. An example of a visual display of intonation is shown below. 
The lower part of the screen shows intonation, and the exact timing of each note played. Visual Music 
has been set to display a heavy vertical line every bar, and a lighter line every quarter note. If every 
note were perfectly, and had no vibrato at all, everything would be drawn along the middle 0 cent line 
 the line that represents the exact pitch of the note. If the instrument is out of tune, then every note 
would be same amount VKDUS RU ÁDW WKH OLJKW KRUL]RQWDO OLQHV DUH cents apart). One of the primary things 
that keep pitch lines from being a straight horizontal line on a sustained note is vibrato. Sharper 50 
40 30 10 0 -10 -20 -30 -40 -50 Time Fig. 2. Vibrato If the player s intonation (pitch) is perfect, 
a wavy burgundy line (see Fig. 2) marching across the screen will always be right over the centre on 
pitch line. Sustained tones should be centred over the big horizontal on pitch line.  5. NON-SPOKEN 
SOUND AS INPUT (VISUAL MUSIC) Although there has been a little research and development work done on 
the use of the spoken word to control a computer application (E.G. [8]) almost none has been done into 
the input of non-speech sounds. We are developing a game for teaching music, and will use this game as 
an example of the use of non-spoken audio input. Some detail will be given so as to show how much useful 
information can be extracted from what seems to be straightforward audio input. The game, Visual Music, 
is designed to make practice time more effective by making the player more aware of how well they are 
playing or singing. This is done by engaging both the auditory and visual centres while music is being 
played. The system listens to the performance of the player/student and assesses it on the basis of rhythmic 
quality, melodic accuracy, and in advanced instances the intonation and expression. In coaching mode 
the score is displayed on the screen along with the notes that are being played by the student (differences 
are shown in Fig. 3. Note transitions Note transitions are another aspect of musical performance which 
can be evaluated by this system. If the player is a singer, the transition between notes is apt to be 
a continuous change in pitch from one note to the next. With other instruments, the transition may be 
more abrupt. If LQWRQDWLRQ LV QRW À[HG E\ WKH LQVWUXPHQW WKH SOD\HU PD\ ÀQG WKDW WKHLU intonation is 
not perfect during the transition from one note to another. This can be easily seen when the music is 
visualized. Finally, the player can compare their performances with those of virtuoso players. In the 
example in Figure 3, the intonation display is set to show Jean-Pierre Rampal s performance (in black) 
of the overture to the Spring movement of Vivaldi s The Four Seasons over the player s performance (in 
grey) of an ornament: the intonation region shows exactly a semitone.  Fig. 1. Note tracking Fig. 4. 
Ornament interpretation In this example, it can be seen that the player s performance of the ornament 
matches the notated interval more closely than Mr. Rampal s. :KHQ KH SOD\HG WKH RUQDPHQW WKH ÀUVW QRWH 
WRRN RQO\ DERXW D WKLUG RI WKH 16th note, while the player s was closer to half. However, Mr. Rampal 
s transitions are faster and cleaner. Looking more closely, we see that Mr. Rampal managed to play the 
ornament so that it matched the timing of his vibrato: an advanced aspect of musical performance. The 
game play aspects of this software are in development, but will involve scores relating to constancy 
in melody and rhythm, vibrato, and the ability to read and play melodies in real time. Players will be 
able to play along with famous musicians, and have their performances compared. It may ultimately be 
able to play along with other players at distant locations on the Internet. A key novel aspect of the 
Visual Music system is its ability to simply listen to music and to analyse it while it is being performed. 
This is an example of a natural interface. An interface to a game (or any software) is termed natural 
if the activity used in the real world situation is recognized and used by the interface, and means the 
same thing to the software system or game. A non-natural interface causes an interruption in the ÁRZ 
[4] of the activity being performed so as to perform the interaction, and this often results in a splitting 
of attention that is not productive or amenable to the effective completion of the task being performed. 
Clearly, audio input can be used in inappropriate and non-natural ways, too, which must be avoided. Technical 
Aspects of Visual Music 7KH WHFKQLFDO FKDOOHQJHV DVVRFLDWHG ZLWK PXVLF LQSXW DUH VLJQLÀFDQW In particular, 
recognizing high frequencies requires high sampling rates and analysis speeds, while low frequency sounds 
require more time for samples to be acquired, so that at least one complete waveform is capture for analysis. 
Visual Music uses multiple techniques simultaneously on distinct frequency ranges, along with a resolution 
scheme such as is foundLQ GDWD IXVLRQ DSSOLFDWLRQV $OWKRXJK WKH VSHFLÀF WHFKQLFDO DSSURDFKHG used by 
Visual Music LV SURSULHWDU\ ZH EULHÁ\ GHVFULEH VRPH RI WKH technical issues using mostly non-mathematical 
language below. Detecting Note Pitch The basic goal of note recognition is taken as identifying the correct 
semitone in an equally tempered diatonic scale (note that Visual Music goes well beyond this goal, as 
illustrated earlier). The pitch range of interest is initially (and somewhat arbitrarily) targeted to 
be the range of a modern piano, excluding the upper and lower octaves. Since it s invention in 1965, 
the Fast Fourier Transform (FFT) has revolutionized our ability to practically extract frequency information 
from uniformly sampled signals[2,3]. There are limitation to the FFT however, which limits the degree 
to which it can be relied on to achieve our goals. Using this transform for a sampling frequency of f 
samples per second, the amplitude components of the FFT will represent a frequency range from DC to f/2. 
Each of the n/2 values will represent the energy in one of f/2 equally sized buckets , or frequency ranges. 
In order to be generally useful for an educational game, it will be necessary to utilize audio sampling 
equipment which can be readily obtained by individuals and educational institutions. An overview of the 
sound input devices available for personal computers suggest that it is generally possible to obtain 
16-bit samples at a sampling rate of 44 kHz. Given that we wish to be able to capture the highest note 
on a piano, these sampling requirements are within the capabilities of better consumer-grade audio digitizers 
and computer equipment, and the time SHULRG UHTXLUHG WR FROOHFW VXIÀFLHQW VDPSOHV LV RQO\ DERXW PVHFV 
 However, capturing the lowest note on a piano requires a collection time period of about 300 ms, which 
is longer than desired. Based on this analysis and further work, we conclude that Fourier analysis appears 
to identify notes well in the upper range of our frequency of interest, but not very well in the lower 
range. Something more is needed to identify notes in the lower range. One thing that the lower frequencies 
have going for them, is thatWKHUH DUH PDQ\ PRUH VDPSOHV GHÀQLQJ HDFK ZDYHIRUP WKDQ LQ WKH KLJKHU UDQJHV 
:H PD\ EH DEOH WR ÀQG DQRWKHU ZD\ WR GLVWLQJXLVK EHWZHHQ QRWHV in this range. If so, we may be able to 
rely on Fourier Analysis to tell us that we have a note located in the lower frequency range, and then 
use a geometric approach to distinguish between notes. One geometric approach to consider is that of 
zero-crossings We know that the amplitude samples are roughly centred around a zero line. To determine 
WKH VSHFLÀF DPSOLWXGH YDOXH WR XVH DV WKH ´]HUR OLQHµ ZH FDQ VLPSO\ WDNH the arithmetic mean of all of 
the samples in the period of interest. In general, zero crossings occur when the energy of a harmonic 
frequency perturbs the amplitude signal enough for the signal to cross the zero line. This tends to occur 
in two cases: harmonics which have relatively high energy in comparison to the fundamental frequency, 
or where the amplitude of the fundamental frequency is already close toWKH ]HUR OLQH 7KH ÀUVW FDVH LV 
QRW D SUREOHP IRU XV LI ZH DOUHDG\ NQRZ the wavelength to within a minor third (which happens to be what 
we get from the Fourier analysis). The second case is more problematic, but FDQ EH DGGUHVVHG E\ DSSO\LQJ 
D GLJLWDO ORZ SDVV ÀOWHU WR WKH WLPH GRPDLQ signal. At least, that s our working hypothesis: there doesn 
t appear to be any research in the area. )LJXUH  LOOXVWUDWHV D PXVLFDO VLJQDO KDYLQJ D VLJQLÀFDQW VHFRQG 
harmonic. In this example, zero crossings corresponding to the fundamental frequency occur at intervals 
of 0.33. However, zero crossings which are attributable to the presence of the second harmonicRFFXU DW 
D VLJQLÀFDQWO\ KLJKHU IUHTXHQF\  > @ Fig. 5 Zero crossings Detecting Note Onset It is initially tempting 
to assume that tempo analysis can rely on amplitude variations to tell us how long each note is being 
played.+RZHYHU D PXVLFLDQ PD\ ZHOO FKDQJH QRWHV ZLWKRXW D VLJQLÀFDQW amplitude variation in the signal 
(it s called playing legato). Another issue is that the previous section (determining what note is being 
played) made the implicit assumption that the same note will be played for long enough for us to analyse. 
However, real-world musical performance is unlikely to accommodate this rather naive assumption: the 
previous 100 msec of samples is as likely as not to contain a note transition, in which case Fourier 
analysis will fail to provide meaningful results (the theoretical underpinnings of Fourier analysis depend 
on the signal being periodic over the period of time being measured - strictlyVSHDNLQJ LW VKRXOG EH LQÀQLWH 
LQ OHQJWK DOWKRXJK YDULRXV ZLQGRZLQJ IXQFWLRQV DWWHPSW WR PDNH D ÀQLWH VDPSOH SHULRG DFW DV WKRXJK LW 
ZHUH LQÀQLWH LQ OHQJWK One possibility is to look at zero crossings again, treating the intervals between 
crossings as a series. When zero crossings stop occurring at the predicted intervals in the stream of 
time domain samples, there is a good probability that the note has changed. A more sophisticated DSSURDFK 
LV WR ORRN DW VHOI VLPLODULWLHV RU WKH ÀW RI D SKDVH ORFNHG ORRS over a range of frequencies. When either 
of these metrics change, there is a high probability of a note transition. Note transitions do not occurLQVWDQWDQHRXVO\ 
 ,QVWHDG WKH\ RFFXS\ D ÀQLWH SHULRG RI WLPH -RLQW time-frequency domain analysis can reveal a variety 
of note transition patterns.  For the purpose of this game, it s proposed that the transition period 
be ignored, and that only periods where a note is clearly being played be considered for analysis. However, 
the period of uncertainty must be VLJQLÀFDQWO\ OHVV WKDQ RXU DYHUDJH GHOD\ RI  PVHFV $Q DSSURSULDWH 
tentative goal is probably a tenth of this, or 10 msecs: about 400 time­domain amplitude samples. A suitable 
algorithm probably looks something like this: 1. Fourier analysis to get into the right ballpark for 
pitch. 2. Zero crossing or phase locked loop to narrow down the wavelength of the fundamental frequency. 
 3. Zero crossing analysis to determine note transition times. 4. Re-do the pitch determination on each 
side of note transitions, as the transition may have affected pitch determination. 5. Display the note 
&#38; duration on screen. 6. Apply scoring criteria. 7. AN EXAMPLE Perhaps we can make this clearer 
with an example. We ll take the case  RI D FRXSOH RI ORZ QRWHV VLQFH WKH\ DUH WKH PRVW GLIÀFXOW WR UHFRJQL]H 
We ll assume that the player starts by playing the C below middle C, and WKHQ VNLSV GRZQ D PDMRU ÀIWK 
WR ) 7KH ÀUVW QRWH KDV D FHQWUH IUHTXHQF\ of about 262 Hz, and the second note is at about 175 Hz. Following 
RXU SURFHVV ZH EHJLQ ZLWK )RXULHU DQDO\VLV 7KH ÀUVW QRWH ZLOO KDYH VLJQLÀFDQW HQHUJ\ DW WKH IXQGDPHQWDO 
IUHTXHQF\ SOXV HQHUJ\ DW WKH ÀUVW few harmonics: 523 Hz, 784 Hz, and 1046 Hz. Using a 4096 point FFT, 
we see peaks in the corresponding frequency buckets returned by the FFT, which are 10.8 Hz apart. This 
gives relatively high values in locations 25, 50, 75, and 100. Taking the lowest of these, we assume 
that the fundamental frequency is somewhere in the range of 254 to 276 Hz. Several notes fall within 
this range, so we look at zero crossings. We EXLOG XS D WDEOH RI ]HUR FURVVLQJ ORFDWLRQV VWDUWLQJ ZLWK 
WKH ÀUVW RQH ZH encounter in this 4096 point sample. We get something like: 0 42 168 210 336 (in practice, 
this table might be more complex; particularly if high frequency noise exists). However, Fourier analysis 
has already told us that we can discard zero crossings with distances that are not between 160 and 174 
samples apart. Based on this, we see that there are zero crossings 168 samples apart. This translates 
to a frequency of 262.6 Hz, or the C below middle C. Now, we can keep following this sequence RI ]HUR 
FURVVLQJV XQWLO ZH ÀQG WKDW WKHUH FRPHV D WLPH ZKHQ D ]HUR crossing fails to occur at the predicted interval. 
At this point, we surmise that the have come to the end of the note, and that we need to make a note 
of the sample number at which we stopped seeing the expected zero crossing. This will translate into 
the duration of the note. It is now that Fourier Analysis begins again, in order to determine the next 
note being played, or perhaps a few samples later to skip over note transition effects. At the end of 
this step, we should have a list of notes and durations. )LQDOO\ FRPHV WKH WDVN RI ÀWWLQJ WKH PHDVXUHG 
 GXUDWLRQV LQWR D WLPH signature. Time Signature Considerations 6FRULQJ QRWHV LV D QRQWULYLDO H[HUFLVH 
2QH GLIÀFXOW\ LV WKDW WKH VDPH sequence of notes can potentially be scored in more than one way. We evade 
this issue by starting with a score our task then becomes the much simpler one of determining whether 
the player is following the score or not. 7KH HDVLHVW DSSURDFK LV WR WDNH WKH ÀUVW IHZ QRWHV PDWFK WKHLU 
durations to the score, and use that at the time metric. For this game, it s not clear that strict tempo 
should be required from the player, so this SDWWHUQ PDWFKLQJ DSSURDFK LV OLNHO\ WR EH MXVW ÀQH WKURXJKRXW 
,W·V FOHDU that most of these processes occur asynchronously to the main game loop. On a system with 
multiple processors, they could be allocated to a separate processor. On a single processor system, this 
is a good candidate for a lightweight thread or two. Conclusions When looking carefully at the design 
of the existing audio games, it s clear that they use sound in only incidental ways. The ways in which 
sound is used in current-generation computer games, is limited partly by the effectiveness of the available 
technology, partly by cost concerns, and partly by an implicitly visual way of thinking. $ VSHFLÀF H[DPSOH 
RI D PL[HG YLGHR DXGLR JDPH KDV EHHQ GHVFULEHG Video Music. Unlike many games which use audio input, 
it was not designed for visually impaired players, but for a general audience of musicians.   REFERENCES 
[1] Atlus Video Games, Contact (2006), Nintendo [2] E. Oran Brigham, Fast Fourier Transform and Its Applications, 
Prentice-Hall Signal Processing Series, 1988 [3] J.W. Cooley and John Tukey, An algorithm for the machine 
calculation of complex Fourier series, Math. Comput. 19, 297 301 (1965). [4] Mihaly Csikszentmihalyi, 
Finding Flow: The Psychology of Engagement With Everyday Life, Basic Books (HarperColins), New York. 
1997. [5] Forrester, Michael A. (2000), Auditory Perception and Sound as Event, Sound Journal (25 April 
2005). [6] Gaver, W. W. (1993a). How do we hear in the world: Explorations in ecological acoustics. Ecological 
Psychology, 5(285-313). [7] Harmonix (2003). Karaoke revolution, Konami. [8] Takeo Igarashi, John F. 
Hughes, Voice as Sound: Using Non­verbal Voice Input for interactive Control, Proceedings of the 14th 
Annual Sympolium of User Interface Software and Technology (UIST-01), pages 155-1556, New York, November 
11014, 2004. [9] Nintendo (2005). Nintendogs, Nintendo. [10] J.R. Parker, Human Motion as Input and Control 
in Kinetic Games, FuturePlay, East Lansing MI, 2005. [11] J.R. Parker, S. Chan, B. Behm, Generating Audio 
Textures by Example, Journal of Game Development, 2006 [12] Radical Entertainment (2003). Simpson s hit 
and run, Vivendi Universal. [13] John Romero (1993). Doom, id Software, GT Interactive, Activision [14] 
Thorn, R. (1998). Hearing is Believing - the Evidence . Sound Journal, 1(http://speke.ukc.ac.uk/sais/sound-journal/ 
thorn981.html), 35-45. [15] van Tol, R. and Huiberts, S., AudioGames.net, (2006) http:// www.audiogames.net/, 
(June 30, 2006) [16] Vasan, Peter and Schober, Michael F, Detecting and Resolving Metrical Ambiguity 
in a Rock Song Upon Multiple Rehearings. The 8th International Conference on Music Perception &#38; Cognition, 
Evanston Illinois, USA, August 3 7,  
			]]></ft_body>
		</fulltext>
		<article_type art_type="short_paper" />
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2007</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>1328244</article_id>
		<sort_key>420</sort_key>
		<display_label>Pages</display_label>
		<pages>4</pages>
		<article_publication_date>11-14-2007</article_publication_date>
		<seq_no>7</seq_no>
		<title><![CDATA[A fast temporal compression/expansion algorithm for sampled audio]]></title>
		<page_from>221</page_from>
		<page_to>224</page_to>
		<doi_number>10.1145/1328202.1328244</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1328244</url>
		<abstract>
			<par><![CDATA[<p>An algorithm for compressing or expanding the duration of an arbitrary sound is presented, in which the frequencies present in the sound are not changed by the process. This means that music can be slowed without changing the key, and that sped up or slowed down voices can still be recognized. The process can be performed in a small fraction of real time, meaning that it can be done live, while the sounds are being captured.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[pitch]]></kw>
			<kw><![CDATA[sound duration]]></kw>
			<kw><![CDATA[transformation]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>J.5</cat_node>
				<descriptor>Performing arts (e.g., dance, music)</descriptor>
				<type>S</type>
			</primary_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010405.10010469.10010471</concept_id>
				<concept_desc>CCS->Applied computing->Arts and humanities->Performing arts</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010469.10010471</concept_id>
				<concept_desc>CCS->Applied computing->Arts and humanities->Performing arts</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Human Factors</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP43124683</person_id>
				<author_profile_id><![CDATA[81321496403]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[J.]]></first_name>
				<middle_name><![CDATA[R.]]></middle_name>
				<last_name><![CDATA[Parker]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Calgary, Calgary, Alberta, Canada]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P925237</person_id>
				<author_profile_id><![CDATA[81342493209]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[J.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Drews]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Calgary, Calgary, Alberta, Canada]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P925239</person_id>
				<author_profile_id><![CDATA[81342506611]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[J.]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Owoc]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Calgary, Calgary, Alberta, Canada]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Dolson, M., The Phase Vocorder: A Tutorial, <i>Computer Music Journal</i>, Volume 10 No. 4, pp. 14--27, 1986.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Master, A., Sinusoidal Modeling Parameter Estimation via a Dynamic Channel Vocoder Model, <i>Proc. IEEE International Conference on Acoustics, Speech, and Signal Processing</i> (ICASSP), Orlando, Fl, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>517664</ref_obj_id>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Tim Morris, Multimedia Systems: Delivering, Generating, and Interacting with Multimedia, Springer-Verlag (Series on Applied Computing), 2000. 1-85233-248-4.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[J. R. Parker and Brad Behm, Synthesis of Sound Effects for Computer Games, <i>FuturePlay</i>, October 13--15, 2005, East Lansing, MI.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1027618</ref_obj_id>
				<ref_obj_pid>1027527</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[J. R. Parker and Keith Chung, Index-Frame Audio Transmission, <i>ACM Multimedia</i>, New York, October 10--16, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>965454</ref_obj_id>
				<ref_obj_pid>965400</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Parker, J. R. and Chan, S., Sound Synthesis for the Web, Games and Virtual Reality, <i>SIGGRAPH 2003</i> Sketches and Applications, San Diego, CA. July 28--30, 2003]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 A FAST TEMPORAL COMPRESSION/EXPANSION ALGORITHM FOR SAMPLED AUDIO J.R. Parker, J. Drews, J. Owoc Digital 
Media Laboratory Department of Computer Science University of Calgary Calgary, Alberta, Canada ABSTRACT 
An algorithm for compressing or expanding the duration of an arbitrary sound is presented, in which the 
frequen­cies present in the sound are not changed by the process. This means that music can be slowed 
without changing the key, and that sped up or slowed down voices can still be recognized. The process 
can be performed in a small fraction of real time, meaning that it can be done live, while the sounds 
are being captured. Categories and Subject Descriptors J. Computer Applications (J.5 ARTS AND HUMANI- 
TIES) Music   General Terms Algorithms, Human Factors Keywords Sound duration, pitch, transformation. 
1. INTRODUCTION The passage of time is essential to the perception of sounds. Speech and music have the 
property that the meaning of one small part depends on what has come immediately before. This is true 
of text also, but imme­diately before with respect to text means just to the left of in the English language 
(or to the right of in Hebrew, and has other meanings in other written languages). With respect to spoken 
English, immediately before has a temporal meaning, referring to something that has happened very recently. 
Music can be described in many ways, but is essentially a time-ordered sequence of musical notes separated 
by varying amounts (durations) of silence. Permissionto makedigital/hardcopy of partofthiswork for personalor 
classroomuse is grantedwithoutfee providedthat the copiesarenot made or distributedforprofit or commercial 
advantage, the copyright notice, the titleof the publication,and itsdate of appear, andnotice is giventhat 
copying is bypermissionof theACM, Inc.To copy otherwise, torepublish,to poston servers,or to redistribute 
to lists,requires prior specificpermissionand/or a fee. FuturePlay 2007, November 15-17, 2007, Toronto, 
Canada. Copyright 2007 ACM 978-1-59593-943-2/07/0011...$5.00 There is a significant commercial market 
for systems used to transcribe the content of meetings. Voices are recorded at a business meeting, talk, 
or lecture and are typed by a stenographer into a computer file. The audio playback system usually has 
a foot pedal controlling the speed of the playback so that the typist is not slowed by the speech rate 
on the tape, and is not given speech at a rate faster than they can type. One of our own pet projects 
involves the teaching of music. A valuable application of an audio speed control is the slowing of a 
musical piece so that a student can play it. As the student improves, the speed can be increased until 
the student can play it at regular speed. This Tai-Chi-like approach to music education is being advanced 
here with the addition of a system that com­pares the original piece against what the student plays. 
Adjusting the pitch (frequency) of a sound indepen­dently from its duration is a complementary operation, 
and has been a technique used in the music industry for some years. If a singer is unable to reach a 
high note or has not held a note for long enough, then these manipu­lations can be invoked to extend 
the singer s range and constancy. Typical software methods involve a variation on the phase vocorder 
[1,2] that requires the computa­tion of a Fourier transform, with the flaws that this entails. Until 
now it has not been obvious how to do this in software without the use of the Fourier transform or the 
use of specific hardware devices. Our algorithm uses neither of these. What will be described is a method, 
implemented in software only, that can shift the duration or frequencies of sounds in real time.  2. 
SAMPLING AND AUDIO REPRESENTATION A brief summary of digital audio is as follows: sound is stored on 
a computer as an array of numbers, where each number represents a sound amplitude A voltage, actually) 
at a point in time. A collection of these sam­ples sent to a speaker will be displayed as a sound that 
is an approximation of the original. The more samples are captures each second, the better is the approximation 
to the actual audio signal. We scale (normalize) each sam­ple so that it has a maximum value of 1 and 
a minimum value of -1. Because of this simple representation, we are able to manipulate the sound by 
performing simple mathematical operations, resampling, and interpolations, resulting in a change of pitch 
and duration of the audio out­put.   For example, adding an extra sample in between the pre­existing 
ones will produce an audio file that is twice as long as the original. The value of this sample would 
reasonably be the average of the two adjacent samples. This increases the duration perfectly but it also 
lowers the pitch (range of fre­quencies). This is because the resulting signal is now stretched in time, 
and the same number of cycles in a longer time is defined as a lower frequency. On the other hand, if 
every second sample is removed, the audio file will be shorter, but will also be higher pitched. Removing 
every second sample compresses the audio sam­ple in time, with the result having the same number of cycles 
in a shorter time period. The result is a higher pitched sound. If it is desirable to increase the duration 
of a sound with­out changing its pitch, it seems intuitive to try copying many samples (a cluster) at 
a time from the original into the copy; that is, instead of interpolating individual samples, a consec­utive 
set of samples could be copied from the original once and placed next to each other multiple times in 
the duplicate. If it was possible to copy one entire cycle of a sampled sine wave in this way, the frequency 
of the wave would be pre­served. If the duration is lengthened in this way, there would be a corresponding 
increase in the number of cycles in the result, and the frequency would remain constant. Unfortunately, 
as a duration modification algorithm, this method is flawed. Although it works very well for simple sounds, 
it poorly represents the more complex ones. It is very hard to match up the ending of one complex signal 
with the beginning of another. The result is a discontinuity at the join points. This happens many times 
each second, and cre­ates an unpleasant clicking noise that ruins the sound. There seems to be no simple 
variation of the algorithm that elimi­nates this clicking noise. Figure 1 shows a signal that is a sine 
wave followed by the first half of its reverse (top) and then the extension by copying of this sound 
(below). Instead of completely removing a cluster, it could be re­mixed with the main body of the sound, 
for example with an alpha blend (linear fade) at the beginning and end. By doing this the discontinuities 
are smoothed out while at the same time preserving frequencies. Using this technique it is possi­ble 
to overlap the clusters in such a way that you can extend or shrink the sound to any arbitrary duration. 
 3. SHIFTING DURATION To change the duration of a sound, fixed size (duration) blocks of data are taken 
from the original sound sample are reused; they can be overlapped, for example, and fade one into another. 
This will involve two sets of audio samples stored as arrays, one holding the original signal and one 
holding the data being synthesized. The optimal cluster dura­tion has been found to be 100ms in the general 
case. Any larger and sounds will stutter, any shorter and the frequency will shift (see above for explanation). 
However, there may be different durations that are best for different types of audio data - this is the 
subject of current research efforts. The overlap will always be 50% of the cluster size, but again this 
is a heuristic, and is the object of study. To extend the sound, blocks of audio data are copied over 
clusters from the original sound each starting at a different index; the index is the number of the block, 
starting at the beginning of the data. The number of indices into the origi­nal will depend on the desired 
change of duration. To extend the sound, the indices that begin the clusters will be grouped tightly 
so that when these indexed clusters are copied to the two arrays, the length of the array will be longer 
then the original data. To reduce the duration of the sound, simply take fewer indices from the original. 
This will result in fewer clusters to overlap and ultimately a shorter output sound. Depending on the 
arbitrary length chosen by the user different spreads of indices will be used. Figure 2 shows this reduction 
in dura­tion (Cluster size = 4 Overlap = 2). Each iteration of the algorithm takes a block from the original 
sample, places it where it belongs in the output, and sums the corresponding values in the two data sets 
with appropriate weights. The Gaussian shaped curves in the figure represents the weights, and the sum 
will never exceed 1. Using this technique, it is now possible to modify the duration of a wave file to 
an arbitrary length without chang­ing its frequency.  4. ADJUSTING FREQUENCY Using the techniques discussed 
so far, it is now possible to modify the frequency of a sound and its duration as a single process. By 
modifying the duration of a sample followed by a simple resampling step it is possible to change the 
sound to an arbitrary frequency, and then revert the duration back to its original length. The result 
is as if the audio sample had shifted in key or register. To decrease the pitch of a sound, all of the 
frequencies that comprise that sound are lowered. Let s take an example: if it were desired to decrease 
the frequencies by a factor of two, we would use interpolation to double the length of the sound and 
flatten the sine wave. This results in a sample that is twice as long and half the frequency. It is now 
possible to use our compression algorithm to change the duration of the sound by a factor of ½ (1 / the 
frequency ratio) and the result is a sound of original length that contains lower frequencies. On the 
other hand, to increase the frequencies, it is first necessary to decrease the length of the sampled 
signal by discarding every Nth sample (or by resampling using inter­polation and averaging). This has 
the side effect of increas­ing the pitch, so the next step is to change the duration by a factor of (1/ 
the frequency ratio). E.g. To double the fre­quency first remove every second sample. Now take the shorter 
sound and use the algorithm to expand it by a factor of 1/(1/2), which equals 2. This doubles the length 
of the shortened sound resulting in a song of original length and double the frequency.  5. RESULTS: 
PURE TONES AND COMBINATIONS Using the methods described above, a software system was created that can 
alter the duration of a sampled audio file, and that can also alter the frequencies found within such 
a file. The results were demonstrably excellent. It turned out to be possible to modify duration and 
frequency with no intro­duction of artifacts except for some minor envelope effects and transient clipping. 
The algorithms are even reversible. Figure 3 shows a sample of a music file. Below it, is a sample of 
the same music file with its duration increased then decreased and its frequency increased then decreased. 
Note that the basic appearance is the same, the envelope is correct, and the only involve the loss of 
sharp, transient peaks that amounted to very high frequency information that was clipped in the process. 
 6. PERFORMANCE A key feature of our algorithm is its speed. A 150 second audio file can be expanded 
by a factor of four into a 600 sec­ond audio file in 4 seconds. Reducing the duration of a sam­ple is 
significantly faster. In general our algorithm can modify the duration of a sound in 1-2% of its original 
dura­tion. In the worst case that has been encountered, an audio file was expanded to 10 times its original 
duration in 10-15% real time. Adjusting the pitch is slightly more costly due to the fact that there 
is an additional calculation. We can decrease the frequencies in a 2.5 minute sound by 4 times in just 
15 sec­onds. Increasing the pitch is even faster because there is no interpolation needed. In general 
our algorithm can modify the pitch of a sound in 2-5% real time (for.25-10 times the pitch). Worst case,.1 
times the pitch can be calculated in 16­20% real time. Any higher then that and too many of the extreme 
notes are lost for the modification to be useful.   The method proposed here has been compared against 
those published and available as software tools. It compares favourably, especially with respect to artifacts 
(very few) and speed (very fast). 7. CONCLUSIONS With the aid of this algorithm it is possible to modify 
sounds under software control without the need of special hardware. These modifications can be done quickly 
and accurately with little taxing of processor resources. Also, there are no practi­cal limitations as 
to how much a sound can be stretched or compressed. Based on our experiments, sounds of over 100 KHz 
could be sampled and scaled down to the human range of hearing in real time, giving a very interesting 
augmenta­tion. This was shown in the lab by multiplying audio sample frequencies until they were into 
the 120 KHz range, then reversing the process. The result was almost indistinguish­able from the original. 
The only limitation to increasing and decreasing the frequency is losing the extreme high or low notes 
to hearing limitations. This could be handled by using Figure 3. (Left) A pure tone at musical c0 increased 
in frequency. (Left, lower) A pure tone at G0 extended in duration by x2. (Above) a real sampled signal 
and the same signal after chang­ing frequency and returning, and then changing duration and returning. 
Artifacts exist, but do not significantly affect how the signal sounds. a nonlinear mapping at the high 
range., and rolling off at the low end of the spectrum. There are intelligibility problems with speech 
sped up by more than a factor of 8.  8. REFERENCES [1] Dolson, M., The Phase Vocorder: A Tutorial, Computer 
Music Journal, Volume 10 No. 4, pp. 14-27, 1986. [2] Master, A., Sinusoidal Modeling Parameter Estimation 
via a Dynamic Channel Vocoder Model, Proc. IEEE Interna­tional Conference on Acoustics, Speech, and Signal 
Process­ing (ICASSP), Orlando, Fl, 2002. [3] Tim Morris, Multimedia Systems: Delivering, Generat­ing, 
and Interacting with Multimedia, Springer-Verlag (Series on Applied Computing), 2000. 1-85233-248-4. 
[4] J.R. Parker and Brad Behm, Synthesis of Sound Effects for Computer Games, FuturePlay, October 13-15, 
2005, East Lansing, MI. [5] J.R. Parker and Keith Chung, Index-Frame Audio Trans­mission, ACM Multimedia, 
New York, October 10-16, 2004. [6] Parker, J.R. and Chan, S., Sound Synthesis for the Web, Games and 
Virtual Reality, SIGGRAPH 2003 Sketches and Applications, San Diego, CA. July 28-30, 2003  
			]]></ft_body>
		</fulltext>
		<article_type art_type="short_paper" />
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2007</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>1328245</article_id>
		<sort_key>430</sort_key>
		<display_label>Pages</display_label>
		<pages>4</pages>
		<article_publication_date>11-14-2007</article_publication_date>
		<seq_no>8</seq_no>
		<title><![CDATA[Game development 2.0]]></title>
		<page_from>225</page_from>
		<page_to>228</page_to>
		<doi_number>10.1145/1328202.1328245</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1328245</url>
		<abstract>
			<par><![CDATA[<p>In recent years a massive trend towards collaboratively created game modifications has appeared and changed the very way the game industry is working. A similar tendency towards user-participation is visible within the Web 2.0 movement, which is considered to be the Internet's next evolutionary step. This paper argues that both trends are caused by the same phenomenon. By bringing the two trends together, the concepts of what could be called Game Development 2.0 will become clear. In consequence, this also allows to interpret its latest occurence as in-world player-centric and collaborative development as an important step towards an upcoming 'Web 3D 2.0'.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[game development 2.0]]></kw>
			<kw><![CDATA[metaverse]]></kw>
			<kw><![CDATA[web 2.0]]></kw>
			<kw><![CDATA[web 3D 2.0]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P925228</person_id>
				<author_profile_id><![CDATA[81392617201]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Daniel]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Volk]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Universitaet der Bundeswehr Muenchen, Neubiberg, Germany]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[J. A. L. Banks. Opening the production pipeline: Unruly creators. In <i>Changing Views: Worlds in Play.</i> University of Vancouver, 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1196681</ref_obj_id>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[R. A. Bartle. <i>Designing Virtual Worlds.</i> New Riders Publishing, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[A. Bruns. The future is user-led: The path towards widespread produsage. In <i>PerthDAC: Digital Arts &amp; Culture</i>, 2007.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[C. Campbell. Report predicts $58.4 billion games market. <i>Business Week</i>, 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[J. K&#252;cklich. Precarious playbour: Modders and the digital games industry. <i>Fibreculture Journal</i>, 5, 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[S. Morris. Wads, bots and mods: Multiplayer fps games as co-creative media. In <i>Level Up Conference Proceedings.</i> University of Utrecht, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[D. B. Nieborg. Am i mod or not? In <i>Creative Gamers Seminar - Exploring Participatory Culture in Gaming.</i> University of Tampere, 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[C. Ondrejka. Escaping the gilded cage: User created content and building the metaverse. New York Law School Law Review, http://ssrn.com/abstract=538362 (last accessed 16.06.07).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[T. O'Reilly. What is web 2.0 - design patterns and business models for the next generation of software. http://www.oreillynet.com/pub/a/oreilly/tim/ news/2005/09/30/what-is-web-20.html (last accessed 16.06.07).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[O. Sotamaa. Have fun working with our product!: Critical perspectives on computer game mod competitions. In <i>Changing Views: Worlds in Play.</i> University of Vancouver, 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[T. Trump, W. Klingler, and M. Gerhards. Web 2.0 studie. Result Media, 2007.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Game Development 2.0 Daniel Volk Institute for Software Technology Universitaet der Bundeswehr Muenchen 
85577 Neubiberg, Germany daniel.volk@unibw.de ABSTRACT In recent years a massive trend towards collaboratively 
cre­ated game modi.cations has appeared and changed the very way the game industry is working. A similar 
tendency to­wards user-participation is visible within the Web 2.0 move­ment, which is considered to 
be the Internet s next evolu­tionary step. This paper argues that both trends are caused by the same 
phenomenon. By bringing the two trends to­gether, the concepts of what could be called Game Develop­ment 
2.0 will become clear. In consequence, this also allows to interpret its latest occurence as in-world 
player-centric and collaborative development as an important step towards an upcoming Web 3D 2.0 .  
Keywords Game Development 2.0, Web 2.0, Web 3D 2.0, Metaverse 1. INTRODUCTION In the last 35 years the 
computer game industry has evolved from dormroom-based one-man-shows to a fully grown en­tertainment 
industry, which is expected to reach a sales vol­ume of $58.4 billion in 2007 according to new research 
from Informa Telecoms&#38;Media [4]. Within this industry, current AAA titles for game consoles and the 
PC market are typi­cally developed within a two to three year timeframe by huge interdisciplinary development 
teams, thus requiring budgets in the order of several million US$. On the other side, a huge consumer 
base -occasional customers by nature -are eagerly awaiting the next blockbuster game. So far, there is 
no real di.erence compared to other branches of the high-risk entertainment industry, but there is a 
spe­cial aspect that had not been discussed yet. Starting a few years ago, some hardcore gamers began 
to modify their games, obeying the principle if you do not like it, change it! [7]. What at .rst appeared 
to be a restricted phenomenon, mainly because of the required technical knowledge, mean­while has become 
a widely applied do-it-yourself movement within the gaming community. Permissionto make digital/hardcopy 
ofpartofthiswork for personalor classroom use isgranted without fee providedthat the copies are not madeordistributed 
for profitorcommercialadvantage,thecopyright notice, the titleofthepublication,and itsdateof appear,andnotice 
is giventhat copying isby permissionoftheACM,Inc. To copyotherwise, to republish,toposton servers, orto 
redistribute to lists,requiresprior specific permissionand/or afee. FuturePlay 2007, November 15-17, 
2007, Toronto, Canada. Copyright 2007 ACM 978-1-59593-943-2/07/0011...$5.00 Taking a glance at the current 
success of web platforms like YouTube or Wikipedia, trends similar to the modding scene can be identi.ed. 
On this note, I argue that this whole mod­ding thing is no game-related only phenomenon, but is part 
of a paradigm shift widely labeled as Web 2.0. Following this argumentation, my goal is to identify the 
basic principles of what I call Game Development 2.0 and to do an outlook at its current trends. So, 
at .rst, I give a short introduction into the .eld of game modi.cations (section 2), which provides a 
better under­standing of its inner working. Afterwards, the trends for­merly adressed are mapped to the 
agnate Web 2.0 world (section 3), which helps to extract the concepts behind Game Development 2.0. Finally, 
the upcoming in-world co-creation and its corresponding kind of platform are discussed in terms of a 
future Web 3D 2.0 .  2. GAME MODIFICATIONS In fact, game modding is not exactly a new phenomenon. Ever 
since the early days of computer games, game develop­ers have always been among their best customers. 
Although, I would never worry that this fact will ever really change, the former producer-consumer unity 
obviously broke apart with the ongoing commercialization of the computer game indus­try. As a consequence, 
gamers who disliked some aspects of a mainstream game, started to modify it handyman-style. One prerequisite 
for creating such modi.cations (legally) is developer-based support. This means, e.g., releasing the 
game code, or o.ering easy-to-use tools (often simpli.ed pro­fessional content-production tools) for 
the less technically adept modders. Whereas, the latter clearly shifted game modding towards non-technical 
development in recent years and caused a watershed in the evolution of the participatory culture of mod 
making [5]. The internet as a medium of free exchange and distribution is an important prerequisite, 
too. It simply builds the plat­form for modding teams and communities, which typically become manifest 
in fan pages, game portals, news sites or discussion forums [6]. So, modding itself established essen­tially 
as a web-centric collaborative process. To understand the developers motives for supporting the modding 
movement, it should be taken into account, that modding teams deliver fresh content, sometimes even years 
after the original release of a game1 . This often vastly pro­longes shelf-life and creates a local customer 
base, which is 1To pick UT2004 as an example here: more then 20 of the 149 listed mods had been updated 
within the last month.  very accessible to related products like addons and sequels [10]. Furthermore, 
high-quality mods are a free form of ad­vertisement; outstanding modi.cations may even establish their 
own brands and become precious assets in the manu­facturer s portfolio. The players main reason for entering 
the modding scene is fun in most cases, since modding is just seen as an extension of gaming itself in 
the .rst place [7]. Besides that, partic­ipating in this open-source code-sharing culture [6] makes collaboration 
beeing frequently a quite inspiring experience. So, just to be part of the modding community and often 
also of a speci.c modding team is also an important aspect of the movement. Additionally, the possibly 
close cooperation with professional development also o.ers the opportunity of get­ting noticed by game 
studios. Thus, it is not surprising that modders also use their projects for showing o. their skills. 
With this work-oriented approach, their ultimate goal is, to break into the industry [5]. Corresponding 
to this spectrum of motivational factors, also the way of doing things may vary signi.cantly. Hence, 
the number of participating modders ranges from single persons to whole communities, whereby the kind 
of collaboration is de.ned by the intensity of their common focus. Accordingly, fun-oriented groups follow 
a more relaxed style of modding, very similar to a decentralized open-source software devel­opment methodology 
[5] -producing results of variable form and quality. In direct contrast to this, modding teams with the 
more ambitious goal of high-quality results have a more industry-like organisation [10]. Moreover, also 
Massively Multiplayer Online Games (MMOGs) embody the concept of modding in the broader sense, as those 
persistent worlds are completely de.ned by the existence and interaction of its users [2]. At last, the 
modding movement o.ers remarkable bene.ts for the game industry. Besides the more indirect advan­tages 
mentioned before, there is a trend towards in.uenc­ing the value chain directly. As a result, commercializa­tion 
of mod content in form of additional products is widely done. Community-based material often even replaces 
pro­fessionally produced content, crowdsourcing main parts of development this way. This can also imply 
organizational changes of current development processes, because the mod­ding community adheres to more 
decentralized and unstruc­tured methodology (besides the common outsourcing chal­lenge of asynchronous 
and distributed work). These di.er­ences turn cooperation into a quite di.cult venture, since modders 
fun-oriented motivation is a fairly instable ally for professional development [1]. Apart from adjusting 
di.erent methodologies, also the ap­proach of completely separating technical development from user-centric 
game creation is a widely applied solution here. But whatever methodology is .nally used, with modding 
being part of development, the participatory culture sur­rounding the modding community shifts towards 
a more co­creative one [6].  3. GAME DEVELOPMENT 2.0 The term Game Development 2.0 is coined after Web 
2.0, which in turn is a rather fuzzy buzzword lacking a consoli­dated de.nition. It exists more as a 
gravitional core orbited by basic concepts, which we need to clarify before mapping game development 
trends to them. The term Web 2.0 itself was coined in a conference brain­storming session between O Reilly 
and MediaLive Interna­tional [9] and has been rede.ned several times. To sum up a broad range of di.erent 
de.nitions , I state that it is most important to realize that Web 2.0 is not (or at least not primarily) 
about technology. It is all about a changed understanding of the Web as a social platform, instead of 
its former interpretation as a static document-delivery system. So, the current evolutionary step (called 
Web 2.0) towards a kind of global brain primarily develops along two main dimensions, which are outlined 
in .gure 1 (adapted from [11]). Figure 1: User Typology As shown, both the user s level of participation 
in the pro­duction process and his level of collaboration with others is of relevance here. In order 
to characterize the Web in its two di.erent versions now, the main focus (see the dot) of Web 1.0 can 
be found in the lower left hand corner. Its typ­ical user is searching for entertainment or information 
and just collaborates marginally, e.g., by sending emails. The corresponding counterpart in the gaming 
world would be a gamer, who buys a nicely-boxed single-player game at Wal­mart and possibly uses the 
multiplayer mode with a bunch of his friends in a home network. The standard Web 2.0 user instead is 
collaborating more or less all the time, as well in a more consuming role, e.g., by commenting Weblogs, 
as in a more productive role, e.g., by publishing YouTube videos, whereat, the inner core of Web 2.0 
users is collaboratively producing (see the second dot) [11]. Referring to this, the corresponding kind 
of game user could be the modder, of course, as modifying a game is nearly always participative and collaborative 
in some way (the typically wide range of game-related creations proves the community s productive role 
here). Furthermore, we also need to include the phenomenon of MMOGs within the Web 2.0 area, of course. 
Here, in contrast to modding, no literal sense production is provided by most representatives. But if 
we consider the player (and his collaboration with others) as dynamic part of the persistent world, he 
surely participates in the creation of a living virtual world [2]. In order to understand the reasons 
for the described usage shifts in both the web and the game world, the two dimen­sions of .gure 1 will 
be discussed in more detail now. 3.1 The Producing Consumer Apart from a small percentage of custom 
software, today s software and game markets mainly adhere to the industrial value chain model. The main 
focus of this model is on mass production of mainstream products, which are then brought to a passive 
consumer base by specialized distributors. The creative act of creation is just done once within the 
process. Consumers do not actively participate, they are monitored by the producer in terms of market 
research. So, there is a unidirectional relationship between a powerful producer and a customer base, 
consisting of unimportant single customers. For standard products, there is no real customization, but 
a low price. But the introduction of the Internet as a network had two impacts on this industrial model. 
First, the net infrastruc­ture enabled personal product customization via customer self-services. Second 
(and more importantly), costumers got connected among themselves and started collaborating. In this way, 
customers were now able to exchange information and estimations about products. This new type of customer, 
exploits network e.ects by forming groups and approaching the producer as one. This levels the playing 
.eld and allows consumers to actively participate in the development pro­cess (e.g., by blackballing 
unwanted technology). At last, the very nature of software helps to understand the .nal step from a participating 
towards a truly co-creating user, currently taking place -see .gure 2 (adapted from [3]). This new type 
of user is characteristic of Web 2.0 and Game De­velopment 2.0.  Figure 2: Knowledge Age Value Chain 
As software is inherently insubstantial, its physical manifes­tation is just an arti.al invention of 
industrial production, because it simply had to be physically packaged and dis­tributed by the help of 
conventional sales channels. Adding the Internet s possibility to distribute in no time and at no cost, 
a physical representation as a versioned product is not necessary any more -software gains immediacy 
[3]. Requir­ing this immediacy, and further on easy-to-use tools and free access to information, the 
consumer now can actively co­create by taking a piece of information, adding some value by recombining 
or extending it and then redistributing it again.  3.2 Let s Collaborate Figure 2 already indicates 
that this approach needs more than one co-creating consumer to really unfold its poten­tial. In this 
manner, .gure 3 (adapted from [3]) shows a networked mass of co-creating consumers, reimplementing the 
model from .gure 2 on a higher level. In this way, an almost organic beeing is created, which harnesses 
network e.ects (an increase in the user base also increases the ben­e.ts gained). However, the being 
needs a critical mass to start existing, as the warm-up phase in MMOGs life cycles tellingly shows. Once 
this critical mass is reached and the inner functioning of the being starts to work, data on an epic 
scale can be created (examples like Wikipedia impressively prove this fact). In contrary to conventional 
products, the created data exhibits neither versioning nor packaging nor a precise shape, it is rather 
more of a perpetual beta [3]) -a fact that also holds true for player-created content. In addition, the 
mentioned epic scale of data is easier to achieve, if the full power of the crowd is enabled. This means 
 Figure 3: The Power of the Crowd providing the easy and fun-to-use tools, known from mod­ding in the 
form of editors that are suitable for novices, too. While professional developers create better content 
on aver­age (the typically small number of blockbusters), the sheer number of additional fun-oriented 
co-creators compensates for that (their niche products small margins sum up to a considerable amount). 
This aspect is illustrated in .gure 4, which shows the concept of the so called Long Tail, as introduced 
in 2004 by Wired Magazine s Chris Anderson. Figure 4: The Long Tail It should have become pretty much 
obvious so far, that cre­ating a platform of participation also means creating a plat­form for collaboration. 
This at last supplements the overall picture of .gure 1 by its second dimension, which is directly de.ned 
by the characteristics of the user group and the form and intensity of its members interaction. Taking 
the group characteristics into account .rst, at least three exemplary forms of groups widely found in 
the game world can be di.erentiated: Small and closely cooperat­ing teams with a common goal (e.g., a 
modding team), somewhat larger and more loosely collaborating communi­ties with common conventions (e.g., 
a MMOG guild), and networks of cursorily connected users (e.g., a gamers net­work). Furthermore, for 
the mentioned interaction to take place, an appropriate form of Awareness (e.g. seeing another Avatar) 
is necessary. Based on it, communication (e.g., chat­ting), coordination (e.g., scheduling tasks within 
a modding project), and cooperation (based on collective artefacts, like, e.g., a common versioning repository) 
need to be supported. Finally, to say it even more compact: the corresponding platform obviously needs 
to integrate a broad range of col­laboration support.  4. GAME DEVELOPMENT PLATFORMS With discussing 
the dimensions of participation and collab­oration, which primarily de.ne the Web 2.0 phenomenon, it 
has become clear so far, that both the modding movement and MMOGs de.nitely match the prerequisites for 
a Game  Figure 5: Current Game Platforms Considering non-persistent single-or multiplayer games (left 
hand side of .gure 5) .rst, we can identify a product-centric understanding, combined with a strong modding 
commu­nity. Our discussion of modding in section 2 reveals a marked participatory dimension which can 
also appear in its strong form as co-creation. However, development tools are used outside the game and 
collaborative co-creation activities do not take place within the game; rather they are based on the 
Web as an abstract platform. In multiplayer games, a small portion of the collaboration occurs within 
the game itself, but is limited to short-time interaction. Therefore, the product-based modding category 
.lls the whole Web 2.0 area in 1, based on the Web as a platform. In contrast, MMOGs (right hand side 
of .gure 5) are services providing online gaming infrastructure .rst of all -from a technical point of 
view. Switching to the social perspective, collaboration between players itself is an inherent (and built­in) 
part of online gaming (another Web 2.0 principle [9]), which also essentially de.nes the virtual world. 
In addition, a smaller part of the platform is also placed outside the per­sistent world, e.g., in form 
of fan sites. As true co-creation within online worlds is typically not provided, MMOGs are service-based 
speci.c platforms that would .t into the lower half of the Web 2.0 area in .gure 1. To sum it up, the 
above two categories clearly match the Web 2.0 concept of .gure 1, even if they are either depen­dent 
on the Web as suitable platform or restricted to elemen­tary forms of participation. But the last obstacle 
towards a truly co-creative platform of collaboration is just about to be removed by a new bunch of rather 
generic Collaborative Virtual Environments (CVEs). As LindenLab s SecondLife is clearly most cutting-edge 
in the context of this paper and therefore most representative for this category, we should take a look 
at its features here. On the one hand, SecondLife is a MMOG-like service with the game as a speci.c platform 
for collaboration (right hand side of .gure 5). On the other hand, real co-creation is enabled by so-called 
atomistic creation [8] -as a re­sult, SecondLife measures up to typical modding platforms. But contrary 
to common non-persistent modding (left hand side of .gure 5), the co-creation takes place within the 
vir­tual world. Hence, speaking .guratively, LindenLab merges both categories of .gure 5, therewith replacing 
the Web as main source for both collaboration and co-creation. In this way, SecondLife becomes a prototypic 
environment for fu­ture in-world co-creative and collaborative game develop­ment -tending towards a Web 
3D 2.0 approach.  5. CONCLUSIONS AND FUTURE WORK Considering all the above similarities and common prin­ciples 
between Web 2.0 and the modding movement (re­spectively MMOGs), I believe it is legitimate to categorize 
them as Game Development 2.0 . This would also under­line the impact of the current trend towards collaborative 
user-creation, which has just started to in.uence game de­velopment and will surely turn it inside out 
in future. Concerning the prerequisites for the 2.0 paradigm , games appear to be especially suited to 
the phenomenon at hand. That is, because games are based on fun by nature, which easily enables the full 
power of the crowd. Consequently, the Web 2.0 e.ect of platform beats application every time [9] also 
holds true for the game world (simply consider the shelf-lifes of modded games or the huge success of 
MMOGs like World of Warcraft). Despite the fact that co-creative CVEs surely match the upper statements, 
too, I would go further here. Take Sec­ondLife as prime example for this category: its ability to allow 
arbitrary content-creation ultimately establishes it as a generic platform similar to the Web itself. 
So, with the context of this paper as starting point, interesting questions about the de.nition and form 
of an upcoming in-world game development process and their implications for the corre­sponding platform 
-ultimately an early kind of Web 3D 2.0 -arise and will be the focus of my future work.  6. REFERENCES 
[1] J. A. L. Banks. Opening the production pipeline: Unruly creators. In Changing Views: Worlds in Play. 
University of Vancouver, 2005. [2] R.A.Bartle. Designing Virtual Worlds.New Riders Publishing, 2003. 
 [3] A. Bruns. The future is user-led: The path towards widespread produsage. In PerthDAC: Digital Arts 
&#38; Culture, 2007. [4] C. Campbell. Report predicts $58.4 billion games market. BusinessWeek, 2005. 
 [5] J. K¨ ucklich. Precarious playbour: Modders and the digital games industry. Fibreculture Journal, 
5, 2005. [6] S. Morris. Wads, bots and mods: Multiplayer fps games as co-creative media. In Level Up 
Conference Proceedings. University of Utrecht, 2003. [7] D. B. Nieborg. Am i mod or not? In Creative 
Gamers Seminar -Exploring Participatory Culture in Gaming. University of Tampere, 2005. [8] C. Ondrejka. 
Escaping the gilded cage: User created content and building the metaverse. New York Law School Law Review, 
http://ssrn.com/abstract=538362 (last accessed 16.06.07). [9] T. O Reilly. What is web 2.0 -design patterns 
and business models for the next generation of software. http://www.oreillynet.com/pub/a/oreilly/tim/ 
news/2005/09/30/what-is-web-20.html (last accessed 16.06.07). [10] O. Sotamaa. Have fun working with 
our product!: Critical perspectives on computer game mod competitions. In Changing Views: Worlds in Play. 
University of Vancouver, 2005. [11] T. Trump, W. Klingler, and M. Gerhards. Web 2.0 studie. Result Media, 
2007.   
			]]></ft_body>
		</fulltext>
		<article_type art_type="short_paper" />
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2007</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>1328246</article_id>
		<sort_key>440</sort_key>
		<display_label>Pages</display_label>
		<pages>4</pages>
		<article_publication_date>11-14-2007</article_publication_date>
		<seq_no>9</seq_no>
		<title><![CDATA[Oh, the thinks you can think]]></title>
		<subtitle><![CDATA[language barriers in serious game design]]></subtitle>
		<page_from>229</page_from>
		<page_to>232</page_to>
		<doi_number>10.1145/1328202.1328246</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1328246</url>
		<abstract>
			<par><![CDATA[<p>It is well-known that problems in interdisciplinary communication between knowledge communities can seriously hinder innovation [1, 7, 8, 10]. The games studies community is a highly interdisciplinary community, and there are, not surprisingly, regular terminology debates that question the definitions of some of our most fundamental terms such as 'game' and 'simulation'. While game analysis and criticism for the purposes of social and humanities research may not require direct collaboration between disparate disciplines, game design does, especially when the game is being designed for serious purposes. This paper is a discussion of some of the accepted meanings of key terms, discuss some of the implications of an inability to agree on the meanings of basic terminology and offer several strategies to address this problem.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[communication]]></kw>
			<kw><![CDATA[knowledge sharing]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>K.3</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10003456.10003457.10003527</concept_id>
				<concept_desc>CCS->Social and professional topics->Professional topics->Computing education</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010489</concept_id>
				<concept_desc>CCS->Applied computing->Education</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003456.10003457.10003527</concept_id>
				<concept_desc>CCS->Social and professional topics->Professional topics->Computing education</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010489</concept_id>
				<concept_desc>CCS->Applied computing->Education</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Human Factors</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P158074</person_id>
				<author_profile_id><![CDATA[81100546832]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Katrin]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Becker]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Calgary]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>1058305</ref_obj_id>
				<ref_obj_pid>1058222</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Aimeur, E., Brassard, G. and Paquet, S. Personal knowledge publishing: fostering interdisciplinary communication. <i>Intelligent Systems, IEEE, 20</i> (2). 46--53.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Becker, K. and Parker, J. R. Digital Games vs Simulations <i>2006 SCS International Conference on Modeling and Simulation - Methodology, Tools, Software Applications (M&S-MTSA'06)</i> Calgary, Alberta, 2006]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Gredler, M. E. Games and Simulations and Their Relationships to Learning in Jonassen, D. H. ed. <i>Handbook of research on educational communications and technology</i>, Association for Educational Communications and Technology., Lawrence Erlbaum, Mahwah, N.J., 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Heyman, R. D. <i>Why didn't you say that in the first place? : how to be understood at work.</i> Jossey-Bass Publishers, San Francisco, 1994.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Huizinga, J. <i>Homo Ludens: a study of the play element in culture.</i> Roy Publishers, New York, 1950.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1076823</ref_obj_id>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Juul, J. <i>Half-real: video games between real rules and fictional worlds.</i> MIT Press, Cambridge, Mass., 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Odlyzko, A. M. The Rapid Evolution of Scholarly Communication. <i>Learned Publishing, 15</i> (2). 7--19.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Rehal, S., Communication of Insights in Early Stages of Collective Design Processes. in <i>Work Life 2000</i>, (Brussels, 1998).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1215723</ref_obj_id>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Salen, K. and Zimmerman, E. <i>Rules of play : game design fundamentals.</i> MIT Press, Cambridge, Mass., 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Sengers, P., How-To Tips for Interdisciplinary Communication. in <i>Society for Literature and Science, 1996</i>, (Atlanta, Georgia, 1996).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Shaw, M. L. G. and Gaines, B. Comparing Conceptual Structures: Consensus, Conflict, Correspondence and Contrast., 1989 retrieved from: http://pages.cpsc.ucalgary.ca/~gaines/reports/PSYCH/COCO/COCO.pdf on Sept 12, 2004]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Sutton-Smith, B. <i>The ambiguity of play.</i> Harvard University Press, Cambridge, Mass., 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Whorf, B. L. <i>Language, thought, and reality; selected writings.</i> MIT Press, Cambridge, 1956.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Oh, the Thinks You Can Think: Language Barriers in Serious Game Design Katrin Becker University of Calgary 
becker@minkhollow.ca Abstract It is well-known that problems in interdisciplinary communication between 
knowledge communities can seriously hinder innovation [1, 7, 8, 10]. The games studies community is a 
highly interdisciplinary community, and there are, not surprisingly, regular terminology debates that 
question the definitions of some of our most fundamental terms such as game and simulation . While game 
analysis and criticism for the purposes of social and humanities research may not require direct collaboration 
between disparate disciplines, game design does, especially when the game is being designed for serious 
purposes. This paper is a discussion of some of the accepted meanings of key terms, discuss some of the 
implications of an inability to agree on the meanings of basic terminology and offer several strategies 
to address this problem. Categories and Subject Descriptors: K.3 [Computing Milieux]: Computers and Education 
General Terms: Design, Human Factors Keywords: Communication, Knowledge Sharing 1. Introduction Is it 
a game or a simulation? Are digital games like traditional board games, face-to-face play, theatre, or 
something else? Is Serious Game a misnomer? Does it matter? It is well-known that problems in interdisciplinary 
communication between knowledge communities can seriously hinder innovation [1, 7, 8, 10]. The game studies 
community is a highly interdisciplinary one, and there are, not surprisingly, regular terminology debates 
that question the meanings of some of our most fundamental terms. While game analysis and criticism for 
social and humanities research may not require direct collaboration between disparate disciplines, game 
design does, especially when being designed for Permission to make digital/hard copy of part of this 
work for personal or classroom use is granted without fee provided that the copies are not made or distributed 
for profit or commercial advantage, the copyright notice, the title of the publication, and its date 
of appear, and notice is given that copying is by permission of the ACM, Inc. To copy otherwise, to republish, 
to post on servers, or to redistribute to lists, requires prior specific permission and/or a fee. FuturePlay 
2007, November 15-17, 2007, Toronto, Canada. Copyright 2007 ACM 978-1-59593-943-2/07/0011...$5.00 serious 
purposes as their design teams will often involve subject matter experts (SMEs) and professionals from 
multiple disciplines. This paper is a discussion of some of the implications of an inability to agree 
on the meanings of basic terminology. While it is too soon in the evolution of game studies for a definitive 
solution to be offered, a heightened awareness of the issues are essential, and several strategies to 
address this problem are offered.  2. Whorf-Sapir and Game Design Human language is a highly contextual 
symbol system and is generally accepted to influence how we make sense of the world [13]. We use language 
to represent concepts, ideas, things, and so on. BUT, language is also routinely vague and ambiguous 
[4], SO in order to use language as a tool for communication, we need to use words that all participants 
understand in the pretty much the same way. For example, when the same words are used to mean different 
(even slightly) different things communication suffers. Game can be understood in many ways and the design 
process will proceed along divergent lines if one s idea of game is Who Wants to be a Millionaire or 
The Elder Scrolls IV: Oblivion. Collaborative research and serious game design efforts require knowledge 
experts, often from radically different traditional bases and backgrounds. This is a good thing in many 
ways, but it also leads to problems. Using words that have pre-existing but different meanings for different 
communities can cause significant difficulties. To communicate effectively, we need a common language. 
Suppose we are building a learning activity that includes introductory activities, a digital object (a 
program) and a de-briefing activity. The software developers who implement the program that is the digital 
object might refer to just the digital object as the game, the company marketing the product may call 
the entire unit a game, and the teacher leading the instruction may not consider any of it a game. Who 
s right? The answer may well be no-one, and everyone. Ultimately we use these words to communicate ideas 
and we in turn use those ideas to make serious games. Terminology debates get in the way.  3. What 
is a Game? Is a game still a game when it is not being played, and can anything become a game if we play 
with it? A precise definition of game is well beyond the scope of this paper, but a working understanding 
would seem essential for any members of a development team engaged in making one. There are many definitions 
of game with which most in game design are familiar, like Huizinga [5], Salen &#38; Zimmerman [9], Sutton-Smith 
[12], and Juul [6]. We all have some sense of what a game is, yet coming up with a clear and precise 
definition is difficult. The lack of a clear definition should not prevent us from examining games, or 
from building them and using them as tools for other purposes. Games, however difficult they might be 
to define, clearly exist. A definition that is too broad, such as one that implies anything we treat 
as a game becomes one is not useful, and a definition of game that is too narrow excludes development 
choices that might otherwise be beneficial. A development team must be clear on what it is building and 
yet retain sufficient flexibility to allow innovation. 4. Simulation vs Game Common sources of friction 
and debate, especially in serious games are the relative definitions of the terms simulation and game 
. One line of reasoning argues that digital games are a form of software that belongs to the larger category 
of simulation programs. According to the computer simulation community, (digital) simulations are based 
on models that are consistent - a set of rules we can describe, and some sort of purpose. Models are 
abstractions. There is no precondition that the model must be based on reality. For other communities 
like Education however, simulations necessarily model reality and are distinct from games, which do not 
[3]. Reality and abstraction need not be mutually exclusive, as it is possible to create a totally fabricated 
set of rules for a totally hypothetical system made up in a dream and it can still be modeled using a 
simulation - it's still a simulation. The (digital) simulation community has been doing computer simulations 
since the beginning of computing, and simulation, modeling and gaming are intertwined [2]. Other communities, 
including education and the military only see the tiniest sliver of what the computer simulation community 
is doing, and it is ill advised to base a definition on that alone. There are many different types of 
simulations (stochastic, discrete, continuous, etc.) and most games fall under the subcategory of discrete 
event simulations. While not all simulations are games, in this community all games are simulations. 
If one looks at the algorithms of a digital game (i.e. one that is not a digital version of a traditional 
game) -we find that they are simulations. If software or devices added to a computer allowing it to be 
used like a television, it does not stop being a computer. If one adds a front end onto a simulation 
to overlay contest mechanics and allow people to interact with it as a game, it is still a simulation. 
 5. Philosophical Perspectives Is a game only a game when people are actively playing it? Should a Fisher-Price 
stacking toy be classified as a weapon if it gets used to choke someone by shoving it down their throat? 
Classifying objects by their use as opposed to their original intent can cause problems. That's not to 
say that the classification of a particular object must be static, but classification by use may cause 
problems when designing a game. What do we call a game that has not yet been played? SIMs and Katamari 
Damacy remain entertainment games, even when used in educational contexts. Oregon Trail remains a serious 
game, even if I play it just for fun. Serious game development should keep the main goal in mind, including 
who it is for and what they are supposed to be getting out of it. A lot of the conflicts between the 
humanities and sciences have to do with big worldviews and not small everyday problems. You may not be 
able to convince your colleague that your metaphysical assumptions are better than theirs, but you may 
still find that you can come to agreement about ways to interpret concrete problems that everyone has 
experience with. Staying in the concrete keeps the argument from devolving to the does the table really 
exist, or is it only a social construction? kind of arguments that don't seem to get anyone anywhere 
[10].  6. The Problem with Reality Relativism implies that there can be no true objective reality. One 
difficulty with the reference to 'reality' in simulations is that for some this means a necessary connection 
to what we currently know about the world. It is then further restricted by their reality. What we currently 
know about the world is a moving target. Data about the moon were hypothetical in the early part of the 
20th century, theoretical in the middle of the 20th century and observed in the later part of the same 
century. Were the programs written to model the moon not simulations until we had actually been there? 
Questions arise when a definition of simulation must adhere to reality: 1) Whose reality? What is reality? 
Objective? Subjective? There are no clear answers to these questions: philosophers have been grappling 
with this for millennia - it may be the central question of philosophy. 2) Perceptions of what is being 
simulated are contextual. World of Warcraft can be seen as a simulation of a social economy or a fantasy. 
3) Any (complex) system can be viewed at various levels of abstraction. Different levels of abstraction 
reveal different aspects of the system. Tetris can be a model of a packing problem, or just a game. 
 Ultimately, this reality problem may be a core conflict between the way different groups use and perceive 
these terms (simulation / game) We say "A reality"; they hear "THE reality". In Educational Technology, 
fidelity is a measure of realism . Is something classed as real because we have seen and touched it, 
or because we believe it to be real? If so, a Venus simulation cannot be a simulation because it is not 
real - we have never been there. Venus is a real place, but some of what we know is theoretically determined 
(i.e. not real), and much is deduced from indirect evidence. If games have to have competition, and simulations 
must be real, where does that leave the Venus model? Is it a mathematical model real? Are the models 
we implement of quantum devices and elements are NOT simulations? They are largely based on mathematical 
theory, but we have no REAL quantum anything to simulate. A truly realistic simulation does not exist, 
although some flight trainers come close. Simulations all require abstractions. It permits chess to be 
seen as a simulation of territory, and monopoly to be seen as an abstraction of real estate development. 
It also permits World of Warcraft to be abstractions of society, and Pikmin to be an abstraction of resource 
acquisition. Snooker is a physics game; sandcastles are architectural models. This view broadens the 
spectrum to allow for legitimate applications of models and activities in learning situations that might 
otherwise never be considered.  7. Why it Matters Unfortunately, when different expert groups use the 
same terminology to mean different things, there is conflict [11], and progress and effective communication 
is impeded. If games are seen as different from simulations, people will design, use, assess, and value 
them differently. It is hard to see how this is useful. This distinction prompts some educators to use 
this as a justification to dismiss the educational potential of some games because the story is rooted 
in fantasy. Tying simulations to reality limits their applications. It can end up being a way to restrict 
imagination and creativity. In some ways it is the grown up equivalent of telling someone she can't colour 
the trees in her drawing purple because real trees must be green. These distinctions often come as a 
result of value judgments that are being made. A particular application can be seen to have intrinsic 
merit due to it being classified as a simulation, but something else is "just" a game and therefore lacks 
merit. Margaret Gredler [3] defines games as "competitive exercises in which the objective is to win 
and players must apply subject matter or other relevant knowledge in an effort to advance in the exercise 
and win." She also claims that "bells and whistles" should be minimal and fulfill no important purpose. 
She finds it problematic when learners are led to enter incorrect answers for the sounds or graphics. 
These distinctions create a division between both the applicability and perceived value of a program 
used for instruction depending on whether it is categorized as a game or as a simulation. It also implies 
that trying some action in order to "see what happens" is undesirable. It is certainly possible that 
this is not a distinction between objects, but rather a design decision. If the reward for an incorrect 
answer outweighs that for a correct one, the gameplay is poorly designed (unless you are actually trying 
to tempt them for a reason). Dr. Gredler also claims that players should not loose points for incorrect 
answers as this is not conducive to effective learning. One of the most significant lessons we are learning 
from game design is that participants both welcome and expect consequences to poor choices in a game. 
No risk, no gain. Games are a great way to acquire subject matter knowledge, not just to apply it.  
8. Digital vs Non-Digital In order to communicate we need a *common* language or shared understanding. 
Some have suggested that digital games are a logical evolution of traditional games or that computer 
games are a digital form of traditional face to face training exercises. Making it digital changes things 
- in terms of the play experience, what is required to support the game, what players can and cannot 
do, and possibly other things as well. For example, one can cheat at solitaire when playing with a deck 
of cards. One cannot cheat when playing solitaire on the computer, or at least, not in the same way. 
There is a different dynamic on the computer vs. with a physical deck. If digital games were simply a 
variation on traditional games, one would expect that the population of gamers and the population of 
traditional game players would be similar, yet the overwhelming popularity of digital games confirms 
that this cannot be the case. Playing Canasta, with real cards and everyone in the same room is a different 
experience from playing over the net with just a computer simulated deck, which is also different from 
sitting someplace around a table (or what-have-you) in Second Life with other avatars.  There are some 
games that only exist as computer games such as Tetris, Super Mario, Katamari Damacy, and in fact many 
commercial video games could not be played without the help of a computer. MMOs have some similarities 
with both traditional paper-book-and-model RPGs as well as LARPs (live action role play), but there are 
also significant differences (player location, number of participants, non-player rule structures and 
enforcement to name a few). Wii Sports is part simulation of the real sports they represent, part something 
else. Digital games, board games, and classroom training simulations may all be rightly called games, 
but if so, it is akin to saying that a paint brush, a riveting press, and an MRI machine are all tools. 
There is value in understanding commonalities between different forms of games, but failing to recognize 
the differences prevents designers and developers from taking full advantage of the medium. 9. Conclusions 
Most scientists realize that definitions can t always be black &#38; white, and defining a category does 
not preclude possibilities of other views. The fact that viruses are neither living nor non-living does 
not prevent us from using a definition of life that is 10. References 1. Aimeur, E., Brassard, G. and 
Paquet, S. Personal knowledge publishing: fostering interdisciplinary communication. Intelligent Systems, 
IEEE, 20 (2). 46 - 53. 2. Becker, K. and Parker, J.R. Digital Games vs Simulations  2006 SCS International 
Conference on Modeling and Simulation - Methodology, Tools, Software Applications (M&#38;S-MTSA'06) Calgary, 
Alberta, 2006 3. Gredler, M.E. Games and Simulations and Their Relationships to Learning. in Jonassen, 
D.H. ed. Handbook of research on educational communications and technology, Association for Educational 
Communications and Technology., Lawrence Erlbaum, Mahwah, N.J., 2004. 4. Heyman, R.D. Why didn't you 
say that in the first place? : how to be understood at work. Jossey-Bass Publishers, San Francisco, 1994. 
 5. Huizinga, J. Homo Ludens: a study of the play element in culture. Roy Publishers, New York, 1950. 
 6. Juul, J. Half-real: video games between real rules and fictional worlds. MIT Press, Cambridge, Mass., 
2005. 7. Odlyzko, A.M. The Rapid Evolution of Scholarly Communication. Learned Publishing, 15 (2). 7-19. 
 useful. Viewing something as a hybrid gives one access to perspectives and tools unavailable if one 
just views it as a continuum. It's kind of like genetics: donkeys and horses are quite distinct although 
they share some qualities; they are different in other ways. You can t handle, train, or even feed them 
the same. A mule may look like the mid-point, but is in fact parts of each - there is no continuum. Understanding 
the behaviour and needs of each parent helps understand the behaviour and needs of the hybrid. One of 
the biggest problems in the segregation of games from other simulations is the lingering connotation 
in some circles that simulations are OK, but games are frivolous. This distinction allows certain applications 
to be legitimized or dismissed merely by attaching one or the other label. Simulations are academically 
or educationally acceptable and games can be dismissed or trivialized. Sengers offers some guidelines 
[10] to help keep discussions on topic: minimize discipline-specific jargon, explain terminology as you 
understand it and qualify statements (justifications based on logic help to clarify perspectives but 
avoid value judgments about the correctness of one view over another), refrain from politics (unless 
of course the game being developed is a political one), and avoid assumptions about shared worldviews 
and remain in the concrete. Finally, do not expect to create converts to your perspective focus on the 
shared goal of the project. We need to develop a common language, to be sure, but it would be discouraging 
to see multidisciplinary synergism turn into yet another monolithic discipline where membership hinges 
on adherence to dogma. 8. Rehal, S., Communication of Insights in Early Stages of Collective Design Processes. 
in Work Life 2000, (Brussels, 1998). 9. Salen, K. and Zimmerman, E. Rules of play : game design fundamentals. 
MIT Press, Cambridge, Mass., 2004. 10. Sengers, P., How-To Tips for Interdisciplinary Communication. 
in Society for Literature and Science, 1996, (Atlanta, Georgia, 1996). 11. Shaw, M.L.G. and Gaines, 
B. Comparing Conceptual Structures: Consensus, Conflict, Correspondence and Contrast., 1989 retrieved 
from: http://pages.cpsc.ucalgary.ca/~gaines/reports/PSYCH/COCO/ COCO.pdf on Sept 12, 2004 12. Sutton-Smith, 
B. The ambiguity of play. Harvard University Press, Cambridge, Mass., 1997. 13. Whorf, B.L. Language, 
thought, and reality; selected writings. MIT Press, Cambridge, 1956.    
			]]></ft_body>
		</fulltext>
		<article_type art_type="short_paper" />
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2007</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>1328247</article_id>
		<sort_key>450</sort_key>
		<display_label>Pages</display_label>
		<pages>4</pages>
		<article_publication_date>11-14-2007</article_publication_date>
		<seq_no>10</seq_no>
		<title><![CDATA[NDNWN]]></title>
		<subtitle><![CDATA[designing games with aboriginal stories using the Aurora Toolset]]></subtitle>
		<page_from>233</page_from>
		<page_to>236</page_to>
		<doi_number>10.1145/1328202.1328247</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1328247</url>
		<abstract>
			<par><![CDATA[<p>Video games can provide an interactive digital space for the retelling of Aboriginal stories as interpreted by players. This project explores the Aurora Toolset from BioWare's <i>Neverwinter Nights</i>---a computer role-playing game based largely around text branching conversations and quests---as a game engine for modifying Aboriginal content into game space.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[aboriginal]]></kw>
			<kw><![CDATA[game design]]></kw>
			<kw><![CDATA[game modification]]></kw>
			<kw><![CDATA[storytelling]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>A.0</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10002944.10011122</concept_id>
				<concept_desc>CCS->General and reference->Document types</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002944.10011122</concept_id>
				<concept_desc>CCS->General and reference->Document types</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Experimentation</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P925220</person_id>
				<author_profile_id><![CDATA[81342493039]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Beth]]></first_name>
				<middle_name><![CDATA[A.]]></middle_name>
				<last_name><![CDATA[Dillon]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Simon Fraser University, Vancouver, BC]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Engeli, M. 2005, June. Playful Play with Games: Linking Level Editing to Learning in Art and Design. Paper presented at Digital Games Research Association Conference: Changing Views: Worlds in Play, Vancouver, BC. DOI = http://www.digra.org/dl/db/06276.54243.pdf.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Flanagan, M., Howe, D. C., and Nissenbaum H. 2005, June. New design methods for activist gaming. Paper presented at Digital Games Research Association Conference: Changing Views: Worlds in Play, Vancouver, BC. DOI = http://www.digra.org/dl/db/06278.19337.pdf.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Guglietti, M. V. 2005. Can you hear the virtual drumbeats? Native new media art and the myth of the virtual community. <i>Institute for Comparative Studies in Literature, Art and Culture.</i> Tavel, P. 2007 Modeling and Simulation Design. AK Peters Ltd.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Hopkins, Candice (2006). Making Things Our Own: The Indigenous Aesthetic in Digital Storytelling. <i>MIT Press Journals</i> 39(4): 341--344.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Magnussen, R., Misfeldt, M., &amp; Buch, T. 2003, November. Participatory design and opposing interests in development of educational computer games. Paper presented at Digitial Games Research Association Conference: Level Up, Utrecht, Netherlands.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Singer, B. R. 2001. <i>Wiping the War Paint Off the Lens: Native American Film and Video.</i> Minneapolis: University of Minnesota Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 NDNWN: Designing Games with Aboriginal Stories Using the Aurora Toolset Beth A. Dillon Simon Fraser 
University 1611 E 10th Ave. Vancouver, BC V5N 1X6 604.782.0051 bdillon@sfu.ca ABSTRACT Video games can 
provide an interactive digital space for the retelling of Aboriginal stories as interpreted by players. 
This project explores the Aurora Toolset from BioWare s Neverwinter Nights a computer role-playing game 
based largely around text branching conversations and quests as a game engine for modifying Aboriginal 
content into game space.  Categories and Subject Descriptors A.0 [GENERAL]: Conference proceedings. 
 General Terms Design, Experimentation.  Keywords Aboriginal, Storytelling, Game Design, Game Modification. 
 1. INTRODUCTION This project takes a leap into video games to continue the work of new media artists 
and scholars such as Skawennati Tricia Fragnito, Jason Lewis, and Loretta Todd, whose projects challenge 
definitions of Aboriginal traditions as static [3]. The design and development of video games, particularly 
the act of game modification, can expand on Native efforts found on the Internet: Cyberspace has been 
occupied, transformed, appropriated, and reinvented by native people in ways similar to how we've always 
approached real space. Like video, digital technologies have become a medium for speaking and telling 
our stories [4]. Before Internet, film served as the new medium for reinterpreting Aboriginal storytelling 
and reclaiming media rampant with stereotypes [6]. Similar to film, commercial video games also rely 
on numerous Native stereotypes. Characters often lose tribal Permission to make digital/hard copy of 
part of this work for personal or classroom use is granted without fee provided that the copies are not 
made or distributed for profit or commercial advantage, the copyright notice, the title of the publication, 
and its date of appear, and notice is given that copying is by permission of the ACM, Inc. To copy otherwise, 
to republish, to post on servers, or to redistribute to lists, requires prior specific permission and/or 
a fee. FuturePlay 2007, November 15-17, 2007, Toronto, Canada. Copyright 2007 ACM 978-1-59593-943-2/07/0011...$5.00 
 identity and are seen strictly as Indian with cultural characteristics drawn from different Nations 
and Tribes. From the half-breed male heroes in Red Dead Revolver and GUN to the stoic full-blood heroes 
battling dinosaurs and aliens in Turok and Prey, stories of Aboriginal characters are being told through 
commercial game industry, and we re not the ones telling them. However, video games as a media are promising 
for cultural sovereignty, a movement of bringing tradition into the present for self-representation [6]. 
Video games share aspects with both film and the Internet for a combination of a unique interactive media 
experience. The player becomes an author through play [1], a process embraced by Aboriginal storytelling. 
Stories are at once individualized and communal, original and replicated, authored and authorless, points 
out Candice Hopkins [4]. 2. FROM STORY TO GAMEPLAY Since integrating Aboriginal values through story 
content in game design can be considered a form of activism in the form of cultural sovereignty, this 
project incorporated iterative design methods targeted at activist game development [2]. These game modifications 
focus strictly on the transformation of Aboriginal stories to text and character actions in a game space. 
2.1 Discovery Choosing the Stories Stories are told in many ways, and build on each other over time. 
One story in my family is a story within a story within a story, so that by the time the central story 
is told, anyone listening is woven into the experience of the storytelling. Whether by campfire, out 
in the woods, in a room, on the streets, in a car, or while watching television, stories arrive to be 
told in many contexts. It is these stories I remember best, the ones I retold myself, the ones I interacted 
with and repeated from storytellers such as Ed Edmo at the Native American Student and Community Center 
in Oregon. As Irish, Anishinaabe (also known as Ojibwe stateside), and Métis, I have many stories. Nanaboozhoo, 
Rougarou, Weendigo, Zagime. Stories of why things are the way they are, how they came to be, lessons 
about how to live life well. There are certain stories, such as those of Weendigo, which I have decided 
not to bring into game form out of respect for my memories and the experiences of many others. Stories 
are as much sacred as they are common place in my life, and this project put me in a place in which I 
had to make decisions about what stories to tell. Although Weendigo is very much in my mind, and those 
stories are clawing to get out some day when I am ready, I decided to work with a Métis story, an intertextualized 
story, and a story within a story from Skawennati Tricia Fragnito in a collaborative project with the 
Aboriginal Territories in Cyberspace research group.  2.2 Translation Remaking the Stories Avoiding 
the pitfalls of appropriation was the most important concern in transforming the stories to game text 
and character interactions. Lines from stories were not put into game text directly from remembered oral 
stories and Skawennati s script from her story, but rather revised to fit the context of an interactive 
game where the player is speaking to other characters and receiving information about these stories in 
the space of the game. The Aurora Toolset includes the Conversation Editor, which is unique to a text 
branching gameplay mechanic. Text branching refers to a style of game writing in which a player interacts 
with other characters by way of conversation with multiple response options for the player. The player 
may be able to change the direction of the game s story or their own character s development by making 
unique choices in responses, thus creating a branching effect in the gameplay. Visual aesthetics were 
limited to what was available from the Aurora Toolset, which contains art and audio assets inspired by 
the medieval fantasy genre for BioWare s Neverwinter Nights. As such, the environment and music was largely 
limited, but basic settings such as forests, farm land, and other open landscapes were possible. Character 
models were not representative of appropriate body types, hair styles, and clothing, but rather served 
as placeholders for future work that will explore creating and importing outside assets to the Aurora 
Toolset. 2.3 Verification Playing the Stories First Nations friends played through the game mods to 
offer opinions and catch bugs, errors in the game design. Although the designer can repeatedly test and 
revise within the Aurora Toolset, part of the iterative process involves seeking other users to perfect 
the gameplay fluidity and intuitiveness. Finding unique experiences and reactions to the game content 
is another advantage to including player feedback. After asking a friend to play a particular mod, I 
observed them during gameplay and took note of their verbal reactions. I also watched for bugs and the 
different methods of gameplay from each player, such as their way of discovering which direction to go 
next. Afterwards, I asked for opinions and then immediately returned to the Aurora Toolset to edit the 
game mods based on responses. In essence, I used a real-time iterative design loop for testing and retesting. 
  3. MOD EXAMPLES The following examples offer insight into the possibilities of using the Aurora Toolset 
to create Neverwinter Nights game mods with Aboriginal stories. Each is unique in gameplay and integration 
of stories, which points to the multiplicity of options within set constraints when modding with the 
Aurora Toolset. 3.1 Noir Noir is based on Métis stories of rougarou, also known as werewolves. My mother 
has told me that when the French came to the woodlands, stories of the Ojibwe Weendigo merged with stories 
of large wolves, which in turn created new stories of the upright wolves that dominated the night and 
the woods the rougarou. I have always been very fascinated with the rougarou, and they fill many of my 
fiction stories and past scripts. The game mod, then, became largely based on the visuals of the werewolf 
and wolf models available in the Aurora Toolset. The mod itself is a short Go Kill quest, in which the 
player must prove to the Non-Player Character (NPC), a man named Laponce (a reference to my own family), 
that the lead rougarou has been killed. The scripting for a Go Kill quest works much the same as a Go 
Fetch quest, since the action to prove the player has killed the designated enemy is actually centered 
around giving an item found on the body of the enemy to the quest-giving NPC. The player is immediately 
thrown into the action of the quest, since they spawn next to a small fire and tent in the middle of 
the woods. The wolves have already targeted both the player and the NPC Laponce as enemies to attack 
by the time the player loads. The player must then fight beside Laponce and attempt to talk with him. 
However, Laponce is often occupied engaged in battle. Different players responded to Laponce in different 
ways. Some continued to follow Laponce to the designated final rougarou enemy. Some struck out on their 
own (to either meet their own defeat or kill the wolves successfully). Some waited for Laponce to return 
after killing the majority of the wolves, and then went to find the rougarou. The lead rougarou must 
be led back to Laponce for it to be killed, since the player is too weak as a new character to defeat 
the enemy. In conversation, Laponce explains the situation and the story of the rougarou, which have 
taken over the woods and must be stopped. Further modification would include more locations, NPC interactions, 
and story branching. The player could possibly face becoming a rougarou as well to explore the stories, 
which would need to be scripted into the game. Figure 1: Noir in the Aurora Toolset tileset view.  
  3.2 World of Neverwinter World of Neverwinter (WoN) is a spoof on World of Warcraft (WoW), which has 
a race called Tauren, loosely based on Native stereotypes. Tauren open conversations with how and reference 
the Earthmother. Physically, they are actually inspired by the fantasy race Minotaur, but their appearance 
is softened by the cartoon style of WoW. In contrast, in Neverwinter, the Minotaur race is beastly and 
intended as intimidating monsters. Figure 3: WoN in the Aurora Toolset tileset view. To intertextualize 
the Tauren from WoW, I used a Minotaur as the main character in a short Go Fetch quest. The Go Fetch 
quest is an action of sending the player on a quest to retrieve and deliver an item. The player has to 
speak with the Tauren (in the form of a Neverwinter Nights Minotaur) and find his map of Ashenvale, a 
location reference to WoW. The conversation is riddled with WoW-related references and humor, such as 
the Tauren consistently asking the player to join his guild, an occurrence often found to be an annoyance 
between players in WoW. Although not based on Aboriginal stories, this game mod points out the inappropriateness 
of the fantasy genre Minotaur representing the perceived Native race in WoW. The imagery in WoW harkens 
back to the savage and animal representations of Aboriginals. Future work in this direction involves 
a more complex game mod with multiple quests that directly intertextualize the beginning Tauren quests 
(with references to visions and spirits ) found in WoW.  3.3 TimeTraveller: 1862 Skawennati Tricia 
Fragnito wrote a film script about a Mohawk named Hunter who owns the TimeTraveller , a device which 
creates holodeck experiences. Hunter interacts with moments in history that he can t change, such as 
the start of the Dakota Uprising. Figure 6: 1862 in the Aurora Toolset tileset view. While Skawennati 
and Research Assistants at Concordia University are working on the modification of Second Life for the 
scenes related to the year 2121, the overall time setting for Hunter, I worked with the portion of the 
script when Hunter visits 1862. The game mod is not strictly quest-based, but more explorative and intuitive, 
as the player can choose to speak to NPCs or not. Since players in Neverwinter Nights always get to create 
their own characters, making the player Hunter was not an option. Hunter then became a NPC who provides 
information about the TimeTraveller properties, the time, and the setting. The story about the first 
incident that led to the Dakota Uprising went through an interesting transformation from historical fact 
to fictional script to game text. The script itself calls for a holodeck experience, which became a struggle 
in the context of a fully interactive game space where the player has more control. The Aurora Toolset 
constrained some aspects of the script, such as the placement of the farmer NPCs, which the player and 
the Dakota Sioux NPCs have a confrontation with. The farmers, in the script, shoot at the Dakota Sioux 
through the window of the farmhouse. However, the game physics for Neverwinter Nights don t allow actions 
through buildings. Instead, the farmer was placed by the door outside of the farmhouse and the farmer 
s cousins were placed beside the farmhouse behind hay bails. Although parts of the script and thus also 
the historical story, which has different accounts, had to change to fit into the Aurora Toolset, Skawennati 
and I met regularly by long distance communication to ensure the game version could be as close to the 
script as possible. Changes mainly meant a different approach from the player s viewpoint. Even so, the 
political commentary from Hunter s voiceovers about the history remained a strongpoint in the game text, 
which for me was the most important piece. Although the environment, including the farmland and farmhouse, 
is representative, future improvements with this game mod rely heavily on creating and importing external 
assets for properly representing the Dakota Sioux traditional appearance and Hunter s 2121 appearance. 
Currently the mod uses the Neverwinter Nights Elk Tribesman and Tiger Tribesman models, which are certainly 
not tribally distinctive or historical.  4. CONCLUSION AND NEXT STEPS Figure 7: Neverwinter Nights Uthgard 
Elk Tribesman. By using specific stories that each had unique ways of transforming in game space, this 
research shows promise for continuing larger scale game mods with the Aurora Toolset. These experiences 
cannot be generalized to all Aboriginal stories, and in essence, this is a strong point of this research. 
Each story is different, as are Tribes and Nations, and each deserve the time and respect for individual 
interpretation. While this project focused on game text and character interactions, further work should 
integrate the modification of art and audio. These assets are external to the Aurora Toolset, so that 
other technology must be used for creating art and audio, which can then be imported into the Aurora 
Toolset. Properly representing visual aesthetics is an enormous piece for accomplishing cultural sovereignty. 
Until such creation of external assets, the Aurora Toolset on its own offers a game engine with a narrowed 
focus to emphasize text and storytelling. The creation of a full-scale game with modified art and audio 
is necessary to further explore the use of the Aurora Toolset as a space for Aboriginal storytelling 
in video games.  5. REFERENCES [1] Engeli, M. 2005, June. Playful Play with Games: Linking Level Editing 
to Learning in Art and Design. Paper presented at Digital Games Research Association Conference: Changing 
Views: Worlds in Play, Vancouver, BC. DOI = http://www.digra.org/dl/db/06276.54243.pdf. [2] Flanagan, 
M., Howe, D. C., and Nissenbaum H. 2005, June. New design methods for activist gaming. Paper presented 
at Digital Games Research Association Conference: Changing Views: Worlds in Play, Vancouver, BC. DOI 
= http://www.digra.org/dl/db/06278.19337.pdf. [3] Guglietti, M. V. 2005. Can you hear the virtual drumbeats? 
Native new media art and the myth of the virtual community. Institute for Comparative Studies in Literature, 
Art and Culture.Tavel, P. 2007 Modeling and Simulation Design. AK Peters Ltd. [4] Hopkins, Candice (2006). 
Making Things Our Own: The Indigenous Aesthetic in Digital Storytelling. MIT Press Journals 39(4): 341-344. 
[5] Magnussen, R., Misfeldt, M., &#38; Buch, T. 2003, November. Participatory design and opposing interests 
in development of educational computer games. Paper presented at Digitial Games Research Association 
Conference: Level Up, Utrecht, Netherlands. [6] Singer, B. R. 2001. Wiping the War Paint Off the Lens: 
Native American Film and Video. Minneapolis: University of Minnesota Press.  
			]]></ft_body>
		</fulltext>
		<article_type art_type="short_paper" />
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2007</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>1328248</article_id>
		<sort_key>460</sort_key>
		<display_label>Pages</display_label>
		<pages>4</pages>
		<article_publication_date>11-14-2007</article_publication_date>
		<seq_no>11</seq_no>
		<title><![CDATA[Interactive community simulation environment for community health nursing]]></title>
		<page_from>237</page_from>
		<page_to>240</page_to>
		<doi_number>10.1145/1328202.1328248</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1328248</url>
		<abstract>
			<par><![CDATA[<p>The majority of nursing curriculums continue to relate experiences and examples of nursing to the more familiar role of "nurse clinician". Specifically, the use of simulation and technology has been used in the undergraduate nursing program to assist learners in developing nursing skills and knowledge for treating individual patients with acute and chronic conditions. Nursing students are now able to apply learned concepts of nurse clinician when treating virtual patients and while engaging in simulation-based education. The use of such simulation in undergraduate nursing education allows learners to readily apply skills and knowledge within a safe learning environment; however, the use of such technology has not been widely adopted to address the learning needs of today's community health nursing students. In fact, despite its importance, the role and process of community health nursing is often unknown to many undergraduate nursing students. This paper presents a strategy-based, interactive community simulation environment that addresses the learning needs of millennial students within a community health nursing curriculum.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[community health nursing]]></kw>
			<kw><![CDATA[game-based learning]]></kw>
			<kw><![CDATA[interactive learning environment]]></kw>
			<kw><![CDATA[serious games]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.8</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010405.10010497.10010504.10010507</concept_id>
				<concept_desc>CCS->Applied computing->Document management and text processing->Document capture->Graphics recognition and interpretation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010497.10010504.10010507</concept_id>
				<concept_desc>CCS->Applied computing->Document management and text processing->Document capture->Graphics recognition and interpretation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Human Factors</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P925260</person_id>
				<author_profile_id><![CDATA[81342497549]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Michelle]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Hogan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Ontario Institute of Technology, Oshawa, Ontario, Canada]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P882835</person_id>
				<author_profile_id><![CDATA[81331502931]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Hamed]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Sabri]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Ontario Institute of Technology, Oshawa, Ontario, Canada]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP36038922</person_id>
				<author_profile_id><![CDATA[81331495944]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Bill]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kapralos]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Ontario Institute of Technology, Oshawa, Ontario, Canada]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>983348</ref_obj_id>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[J. P. Gee. <i>What Video Games Have to Teach Us About Learning and Literacy.</i> Palgrave MacMillan, New York, NY. USA, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[D. A. Lieberman. Interactive video games for health promotion: Effects on knowledge, self-efficacy, social support and health. In R. L. Gold and T. Manning, editors, <i>Health Promotion and Interactive Technology</i>, pages 103--120. Lawrence Erlbaum Associates, Norwell, NJ. USA, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[K. Mangold. Educating a new generation: Teaching baby boomer faculty about millennial students. <i>Nurse Educator</i>, 32(1):21--23, 2007.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Public Health Agency of Canada. Core competencies for publc health (draft 2). Technical report, Ottawa, Ontario, Canada, October 5 2006.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1051239</ref_obj_id>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[D. Michael and S. Chen. <i>Serious Games: Games That Educate, Train and Inform.</i> Thomson Course Technology, Boston, MA. USA, 2006.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[A. Mitchell and Savill-Smith. The use of computer and video games for learning: A review of the literature. www.LSDA.org.uk, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[M. Prensky. Computer games and learning: Digital game-based learning. In J. Raessens and J. Goldstein, editors, <i>Handbook of Computer Game Studies</i>, pages 97--122. MIT Press, Cambridge, MA. USA, 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>337709</ref_obj_id>
				<ref_obj_pid>337694</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[B. D. Ruben. Simulations, games, and experience-based learning: The quest for a new paradigm for teaching and learning. <i>Health Education Research, Theory and Practice</i>, 30(4):498--505, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[B. Sibbald. 2020 vision of nursing. <i>Canadian Nurse</i>, 91(3):33--36, 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[A. J. Stapleton. Serious games: Serious opportunities. In <i>Proceedings of the 2004 Australian Game Developers' Conference</i>, pages 1--6, Melbourne, Australia, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[P. A. Stout, J. Villegas, and H. Kim. Enhancing learning through use of interactive tools on health-related websites. <i>Health Education Research, Theory and Practice</i>, 16(1):721--733, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[T. Susi, M. Johannesson, and P. Backlund. Serious games - an overview. Technical Report HS-IKI-TR-07-001, School of Humanities and Informatics, University of Skovde, Sweden, February 2007.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[R. Thomas, J. Cahill, and L. Santilli. Using an interactive computer game to increase skill and self-efficacy regarding safer sex negotiation: Field test results. <i>Health Education and Behavior</i>, 24(1):71--86, 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[M. Villeneuve and J. MacDonald. Toward 2020: Visions for nursing. Technical Report ISBN 1-55119-818-5, Canadian Nurses Association, Ottawa, Ontario, Canada, 2006.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Interactive Community Simulation Environment for Community Health Nursing Michelle HoganHamed Sabri 
and Bill KapralosFaculty of Health Sciences, Faculty of Business and Information Technology, University 
of Ontario Institute of Technology. University of Ontario Institute of Technology. Oshawa, Ontario, Canada. 
L1H 7K4. Oshawa, Ontario, Canada. L1H 7K4. michelle.hogan@uoit.ca bill.kapralos@uoit.ca ABSTRACT The 
majority of nursing curriculums continue to relate expe­riences and examples of nursing to the more familiar 
role of nurse clinician . Speci.cally, the use of simulation and tech­nology has been used in the undergraduate 
nursing program to assist learners in developing nursing skills and knowledge for treating individual 
patients with acute and chronic con­ditions. Nursing students are now able to apply learned con­cepts 
of nurse clinician when treating virtual patients and while engaging in simulation-based education. The 
use of such simulation in undergraduate nursing education allows learners to readily apply skills and 
knowledge within a safe learning environment; however, the use of such technology has not been widely 
adopted to address the learning needs of today s community health nursing students. In fact, despite 
its importance, the role and process of community health nursing is often unknown to many undergraduate 
nursing students. This paper presents a strategy-based, interactive community simulation environment 
that addresses the learn­ing needs of millennial students within a community health nursing curriculum. 
 Categories and Subject Descriptors I.3.8 [Computer Graphics]: Three-Dimensional Graphics and Realism 
Applications General Terms Human Factors  Keywords Community health nursing, serious games, interactive 
learn­ing environment, game-based learning. 1. INTRODUCTION The role of community health nursing can 
be traced back to the origin of nursing practice. The ever changing needs of our communities, emerging 
social and health issues, and Permissionto make digital/hardcopy of part ofthis work for personal or 
classroom useis grantedwithoutfeeprovided thatthecopies are not made ordistributedfor profitorcommercialadvantage, 
the copyright notice, the title ofthe publication, and itsdateofappear,and noticeis giventhat copyingis 
by permission ofthe ACM, Inc. To copy otherwise, to republish,to post on servers, or to redistribute 
tolists,requires prior specific permissionand/or afee. FuturePlay 2007, November 15-17, 2007, Toronto, 
Canada. Copyright 2007 ACM 978-1-59593-943-2/07/0011...$5.00 current and future demands on our health 
care system have created a much needed shift in health care delivery from that of hospital to community. 
Currently, approximately 70% of nurses work in hospitals as nurse clinicians [9]. By 2020, it is estimated 
that 75% of nurses will work in and with the community, thus creating a greater need for quali.ed, competent 
community health nurses [9]. Unlike a nurse clinician, the role and practice of commu­nity health nursing 
is very di.erent. Whereas nurse clini­cians are concerned with caring for the health of individuals, 
community health nurses are concerned with caring for, and promoting the health of entire communities. 
Their target of practice, the strategies they use, and the desired out­comes are all very di.erent and 
therefore, require di.erent skills, training, and education. Community health nurses must be competent 
in critical thinking abilities and core public health sciences, the foundational knowledge necessary 
to practice e.ectively [4]. Application of these basic public health sciences involves the use of techniques 
such as surveil­lance, monitoring, analysis, investigation, health promotion, capacity building, healthy 
public policy, research, develop­ment, evaluation, and innovation [4]. They must also be competent in 
assessment and analysis, the ability to collect, assess, analyze and apply health information in improving 
the health of their communities [4]. This competency pro­vides the foundation to establish evidence-based 
priorities, make decisions, budget, develop policy and plan programs [4]. Community health nurses must 
be pro.cient in policy development and program planning, including the ability to identify, assess and 
choose appropriate policy options, and to plan, implement, monitor, and evaluate policy [4]. When working 
with the community as a patient, community health nurses must also be competent in their ability to work 
with others. Partnership and collaboration are the cornerstones of community health nursing and will 
optimize performance through shared resources and responsibilities [4]. Commu­nity health nurses should 
be competent in communication, including: internal, external, written, verbal, non-verbal, lis­tening 
skills, providing information appropriate to di.erent audiences, use of media and social marketing techniques 
[4]. Community health nurses are required to interact e.ectively with a diversity of individuals, groups 
and communities and demonstrate e.ective leadership skills [4]. Unlike the skills required for that of 
a nurse clinician, much of these skills and their application cannot be carried out within newly devel­oped 
and highly innovative practice lab facilities where the focus of patient care is the individual. Therefore, 
developing innovative ways to teach the approach and process of com­munity health nursing is very challenging. 
For this reason, community health nursing curriculums have predominantly relied on traditional teaching-and-learning 
approaches where the application and practice of such skills is often quite dif­.cult.  1.1 The Millennial 
Student Traditional teaching-and-learning environments are often quoted by millennial students (the generation 
raised in the sensory-.ooded environment of digital technology and mass media e.g., the internet generation 
, or as designated by Prensky [7], the digital natives) as boring and do not ad­dress the unique learning 
needs of this generation. Millenni­als are very technologically literate and see technology as a necessity, 
both in life and in learning [3]. The fact that the millennial generation has always been digitally connected 
has led to a mindset unlike any that nursing faculty have ever seen. Understanding this mindset is an 
important aspect of educational planning and course development. Speci.­cally, according to Villeneuve 
[14], this generation does not remember a time without e-mail, internet, cell-phones or lap-top computers. 
This lived experience and their unique way of being and knowing has largely in.uenced the learning needs 
of this generation of nursing students. It is not surpris­ing that this generation highly regards doing 
rather than knowing , making interactive, experiential learning a neces­sity for their educational success. 
This generation prefers, expects and appreciates the use of technology in learning. In order for knowledge 
and skills to become fully under­stood, integrated and accessible for future situations, millen­nial 
students require reinforcement, application, repetition, and often practice in a variety of settings 
and contexts [8]. Virtual environments and video games o.er that opportu­nity, whereby students can practice 
their skills and abilities within a safe learning environment, leading to a higher level of self-e.cacy 
when faced with real life situations where such skills and knowledge are required [2]. 1.2 Serious Games 
In contrast to traditional teaching and learning environ­ments whereby the teacher controls the learning 
(e.g., teacher centered), video games present a learner centered ap­proach to learning whereby the player 
controls the learning through interactivity and allows the player to learn via ac­tive, critical learning 
[10]. Video games provide students the opportunity to learn to appreciate the inter-relationship of complex 
behaviors, sign systems, and the formation of social groups [1]. In addition to these bene.ts, the advantages 
of video games to other applications have not gone unnoticed. In fact, video game technology has been 
adopted and applied to applications whose primary purpose is not entertainment. These are referred to 
as serious games. Although no par­ticularly clear de.nition of the term is currently available, serious 
games usually refer to games that are used for train­ing, advertising, simulation, or education and are 
designed to run on personal computers or video game consoles [12] (se­rious games have also been more 
loosely de.ned as games that do not have entertainment, enjoyment, or fun as their primary purpose [5]). 
Serious games leverage the power of computer games to captivate and engage players for a spe­ci.c purpose 
such as to develop new knowledge or skills . Speci.cally, serious games support the development of ana­lytical 
and spatial, strategic, recollection, and psychomotor as well as visual selective attention skills [6]. 
Further bene­.ts of serious games include improved self-monitoring, prob­lem recognition and solving, 
improved short-and long-term memory, increased social skills, and increased self-e.cacy [6, 13]. Serious 
games have been employed in a number of learning­based applications including educational, national, 
secu­rity, corporate management, military, government, and in the training of emergency personnel/.rst 
responders and healthcare workers. The application of serious games can be broadly categorized into four 
categorize: i) military, ii) government, iii) education, and iv) corporate. Recently, there has been 
a great e.ort in the development of appli­cations related to health and healthcare. The number of po­tential 
applications within the healthcare category is large and includes, amongst others, physical .tness, education 
in health/self-directed care, recovery and rehabilitation, and diagnosis and treatment of mental illness/mental 
conditions [12].  1.3 Goal of this Work Despite the relevance and importance to millennial students, 
the use of technology has not been widely adopted to ad­dress the learning needs of today s community 
health nurs­ing students. The use of simulation and technology has been widely applied in nursing curriculums 
to address the skills and competency of nurse clinicians while little to no inno­vative technology has 
been developed to address the skills and competency of community health nurses. Speci.cally, the use 
of simulation and technology is frequently used in the undergraduate nursing program to assist learners 
in de­veloping nursing skills and knowledge for treating individ­ual patients with acute and chronic 
conditions. The use of such simulation allows learners to readily apply skills and knowledge within a 
safe learning environment, an oppor­tunity not formerly available to community health nursing students. 
This current project will address this large gap in community health nursing curriculums while simultane­ously 
addressing the educational needs of millennial students through the use of video game-based technology. 
Research on education has consistently found that the use of video games for educational purposes helps 
increase variables like skill and feelings of self-e.cacy [13]. This paper presents a strategy based, 
interactive community simulation environment whereby a learner centered approach to learning is taken, 
engaging students while allowing them to control their own learning through interactivity. Students are 
able to engage in discovery learning where the instruc­tor is no longer the primary source of information 
but a facilitator of their learning. This strategy based, interac­tive simulation environment allows 
students to explore and practice repeatedly, the role of community health nursing within a safe learning 
environment. Students move through the nursing process; conducting a nursing assessment of a virtual 
community, determining community diagnoses and implementing strategies within the virtual community to 
ad­dress the identi.ed health issues. The goals of this cognitive development are to assist students 
to:  Engage in the community health nursing process-as­sessment, diagnosis, analysis, planning, intervention, 
and evaluation.  Develop critical and re.ective thinking skills.  Explore models of community health 
nursing practice.  Reinforce key learning concepts.  Enhance competency and feelings of self-e.cacy 
  2. SIMULATION OVERVIEW The strategy-based, interactive, simulation environment supports various learning 
modules. The initial module focuses on the application of the nursing process with community-as-patient. 
The simulation begins with an overview of the community (see Figure 1(a)). The view of this community 
gives the student information pertaining to: location (geographic boundaries, climate, plants, and percentage 
of urban and rural life), housing (type, condi­tion, slum areas, sanitation, adequacy, crowding, etc.), 
wa­ter supply, and sanitation (sewage and waste disposal). The student can choose to investigate a speci.c 
part of the com­munity further (see Figure 1(b)).  (b) Focusing on one part of the community. Figure 
1: Community View. The student is then able to navigate through the commu­nity and interact with characters 
and objects he/she may encounter. Interactions include choosing any of the objects (e.g., school, churches, 
police stations and other institutes), or characters (e.g., people such as police o.cers, home­less, 
etc.) within the community overview. This interac­tion provides the students with information speci.c 
to the  (b)Interacting with a homeless person. Figure 2: Interacting with the community. object/character 
they are interacting with. For example, by choosing to interact with a homeless person, informa­tion 
pertaining to the homeless (e.g., location of homeless shelters, estimated number of homeless in the 
community, etc.) is presented to the student. Information is presented in either a caption bubble , within 
the user interface, or through audio. Two examples are illustrated in Figure 2. In Figure 2(a), the student 
has encountered an obese child and chooses to interact with them. This provides the user with information 
regarding obesity and diet with respect to the community. In Figure 2(b), the student has encountered 
a homeless character and chooses to interact with them. As a .nal example, in Figure 3, the student has 
entered the pub­lic health building where he/she encounters a public health nurse who provides information 
regarding public health ser­vices o.ered in the community. The student continues navigating through the 
environment while gathering information as they do so. As part of the total experience, the student is 
able to retrieve and exam­ine resources within a virtual book repository to assist them in their assessment. 
Once the student feels they have com­pleted a thorough assessment of the community, the student can then 
analyze the data and input a community health diagnosis . As several community health issues/problems 
exist, students will have to determine which problem they feel is a priority given their assessment and 
analysis. How­ever, the path they follow in the simulation is determined by the health issue/problem 
they choose.  Figure 3: Interacting with a public health nurse. Following the identi.cation of a community 
health issue, stu­dents must then identify various strategies that could be used to address the health 
issue/problem. Students must identify resources required to implement such strategies be­fore the actual 
implementation takes place. The implemen­tation of these strategies alters the health of the commu­nity 
and is directly observable within the virtual community. This provides an opportunity for students to 
re.ect on and evaluate the impact of his/her role and the strategies chosen and to develop higher order 
thinking skills. Following the completion of the nursing process, a report is produced to examine the 
thoroughness of the student s assessment, areas missed, other possible diagnoses and interventions. This 
re­port provides the means for educators to evaluate a student s success and allows the educator to provide 
the student feed­back. Students are able to re-enter the community as often as necessary to practice 
skills, identify di.erent health prob­lems/issues and implement di.erent strategies to address the issues. 
Students have control over the information gathered, strategies implemented and the frequency of which 
they re­visit the community. According to Stout, et al. [11], learner control is an important element 
for successful learning ex­periences because it can have a positive impact on students performance, improve 
attitudes toward learning and reduces teaching time. This teaching-and-learning tool o.ers true interactivity 
for the students and experience-based learning.  3. CONCLUSIONS In this paper, the application of gaming-based 
technology to the community health nursing curriculum was introduced. The strategy based interactive 
community simulation envi­ronment addresses the learning needs of millennial students while bridging 
the large gap between the use of innovation and technology in learning and community health nursing curriculums. 
Future work includes the development of vari­ous learning modules to complement the existing ones. New 
modules that will be developed include the following: Surveillance/Epidemiology Students will examine 
the con­ trol and management of a variety of communicable dis­ ease outbreaks using sound principles 
of epidemiology. Emergency Preparedness Students will be able to prac­ tice and develop the skills and 
critical thinking neces­ sary to plan and act during an emergency situation. Research/Evaluation Students 
will examine and actively evaluate a variety of interventions/programs based on health issues/problems 
identi.ed and strategies imple­mented in previous modules. Future work also includes greater, more extensive 
evaluation that includes user testing. In particular, the simulation will be incorporated into an existing 
undergraduate community health nursing curriculum at the University of Ontario Insti­tute of Technology. 
Here, its applicability and e.ectiveness will be evaluated and in-course corrections and iterations will 
be made accordingly. Finally, evaluation will also ex­amine the developed application s e.ectiveness 
in meeting millennial students learning needs, and in increasing the skills, knowledge and competence 
required to function as a community health nurse, as well as feelings of self-e.cacy.  4. REFERENCES 
[1] J.P.Gee. What Video Games Have to Teach Us About Learning and Literacy. Palgrave MacMillan, New York, 
NY. USA, 2003. [2] D. A. Lieberman. Interactive video games for health promotion: E.ects on knowledge, 
self-e.cacy, social support and health. In R. L. Gold and T. Manning, editors, Health Promotion and Interactive 
Technology, pages 103 120. Lawrence Erlbaum Associates, Norwell, NJ. USA, 1997. [3] K. Mangold. Educating 
a new generation: Teaching baby boomer faculty about millennial students. Nurse Educator, 32(1):21 23, 
2007. [4] Public Health Agency of Canada. Core competencies for publc health (draft 2). Technical report, 
Ottawa, Ontario, Canada, October 5 2006. [5] D. Michael and S. Chen. Serious Games: Games That Educate, 
Train and Inform. Thomson Course Technology, Boston, MA. USA, 2006. [6] A. Mitchell and Savill-Smith. 
The use of computer and video games for learning: A review of the literature. www.LSDA.org.uk, 2004. 
 [7] M. Prensky. Computer games and learning: Digital game-based learning. In J. Raessens and J. Goldstein, 
editors, Handbook of Computer Game Studies, pages 97 122. MIT Press, Cambridge, MA. USA, 2005. [8] B. 
D. Ruben. Simulations, games, and experience-based learning: The quest for a new paradigm for teaching 
and learning. Health Education Research, Theory and Practice, 30(4):498 505, 1999. [9] B. Sibbald. 2020 
vision of nursing. Canadian Nurse, 91(3):33 36, 2005. [10] A. J. Stapleton. Serious games: Serious opportunities. 
In Proceedings of the 2004 Australian Game Developers Conference, pages 1 6, Melbourne, Australia, 2004. 
[11] P. A. Stout, J. Villegas, and H. Kim. Enhancing learning through use of interactive tools on health-related 
websites. Health Education Research, Theory and Practice, 16(1):721 733, 2003. [12] T. Susi, M. Johannesson, 
and P. Backlund. Serious games ­an overview. Technical Report HS-IKI-TR-07-001, School of Humanities 
and Informatics, University of Skovde, Sweden, February 2007. [13] R. Thomas, J. Cahill, and L. Santilli. 
Using an interactive computer game to increase skill and self-e.cacy regarding safer sex negotiation: 
Field test results. Health Education and Behavior, 24(1):71 86, 1997. [14] M. Villeneuve and J. MacDonald. 
Toward 2020: Visions for nursing. Technical Report ISBN 1-55119-818-5, Canadian Nurses Association, Ottawa, 
Ontario, Canada, 2006.   
			]]></ft_body>
		</fulltext>
		<article_type art_type="short_paper" />
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2007</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	</section>
	<section>
		<section_id>1328249</section_id>
		<sort_key>470</sort_key>
		<section_seq_no>10</section_seq_no>
		<section_type>POSTER SESSION</section_type>
		<section_title><![CDATA[Posters]]></section_title>
		<section_page_from>241</section_page_from>
	<article_rec>
		<article_id>1328250</article_id>
		<sort_key>480</sort_key>
		<display_label>Pages</display_label>
		<pages>2</pages>
		<article_publication_date>11-14-2007</article_publication_date>
		<seq_no>1</seq_no>
		<title><![CDATA[Wildfire Wally]]></title>
		<subtitle><![CDATA[a volunteer computing game]]></subtitle>
		<page_from>241</page_from>
		<page_to>242</page_to>
		<doi_number>10.1145/1328202.1328250</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1328250</url>
		<abstract>
			<par><![CDATA[<p>Online casual games can be used to significantly enhance the productivity of volunteer computing. We call games which perform volunteer computing <i>volunteer computing games.</i> We introduce <i>Wildfire Wally</i>, a volunteer computing game capable of solving the maximum clique problem.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[casual games]]></kw>
			<kw><![CDATA[distributed algorithms]]></kw>
			<kw><![CDATA[distributed computing]]></kw>
			<kw><![CDATA[human computing]]></kw>
			<kw><![CDATA[online games]]></kw>
			<kw><![CDATA[volunteer computing]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>G.2.1</cat_node>
				<descriptor>Combinatorial algorithms</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>H.5.3</cat_node>
				<descriptor>Web-based interaction</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>G.4</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10003120.10003121.10003124.10010868</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)->Interaction paradigms->Web-based interaction</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003705</concept_id>
				<concept_desc>CCS->Mathematics of computing->Mathematical software</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003624.10003625.10003628</concept_id>
				<concept_desc>CCS->Mathematics of computing->Discrete mathematics->Combinatorics->Combinatorial algorithms</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Algorithms</gt>
			<gt>Human Factors</gt>
			<gt>Performance</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P925233</person_id>
				<author_profile_id><![CDATA[81474642862]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Evan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Peck]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Gordon College]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P925258</person_id>
				<author_profile_id><![CDATA[81342509038]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Maria]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Riolo]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[California Institute of Technology]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P925224</person_id>
				<author_profile_id><![CDATA[81100327757]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Charles]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Cusack]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Hope College]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Anderson, D. P., "Public Computing: Reconnecting People to Science," in <i>Proceedings of the Conference on Shared Knowledge and the Web</i>, November 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Justiniano, C., "Tapping the Matrix: Revisited," ChessBrain Project, <i>BoF Linux Forum in Copenhagen</i>, October 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Anderson, D. P. and J. McLeod VII, "Local Scheduling for Volunteer Computing." <i>Parallel and Distributed Processing Symposium</i>, 2007. <i>IPDPS 2007. IEEE International.</i> pages 1--8.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Cusack, C. A., C. Martens, and P. Mutreja, "Volunteer Computing Using Casual Games," presented at <i>FuturePlay 2006 International Conference on the Future of Game Design and Technology</i>, London, Ontario, Canada, October 10--12, 2006. Published in Conference Proceedings.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Wildfire Wally: A Volunteer Computing Game Evan Peck Maria Riolo Charles Cusack Gordon College California 
Institute of Technology Hope College Computer Science Mathematics Computer Science evan.peck@gordon.edu 
riolo@caltech.edu cusack@hope.edu ABSTRACT Online casual games can be used to significantly enhance 
the productivity of volunteer computing. We call games which perform volunteer computing volunteer computing 
games. We introduce Wildfire Wally, a volunteer computing game capable of solving the maximum clique 
problem. Categories and Subject Descriptors G.2.1 [Discrete Mathematics]: Combinatorics Combinatorial 
algorithms; G.4 [Mathematical Software]: Parallel and vector implementations; H.5.3 [HCI]: Group and 
Organization Interfaces Web-based interaction General Terms Algorithms, Performance, Human Factors 
 Keywords Casual games, online games, distributed algorithms, volunteer computing, distributed computing, 
human computing 1. INTRODUCTION As scientists have become more frequently confronted by increasingly 
complex problems, research teams have turned to computers to aid in the exploration of these challenges. 
Unfortunately, technology has simply not kept pace. A single processor is no longer adequate for the 
problems researchers now encounter on a daily basis. Consequently, a research team may not receive tangible 
results from a problem for weeks, months, or even years. An increasingly popular solution to this problem 
is volunteer computing. Volunteer computing is a process that allows people from across the globe to 
donate their computer resources in a joint effort, effectively creating a powerful supercomputer. To 
illustrate the potential for volunteer computing, consider that as of 2004, approximately 150 million 
personal computer were connected to the internet a number that is estimated to exceed one billion by 
2015 [1]. Of these machines, consider further that many are idle for nearly ninety percent of each day. 
Even active computer users typically use less than ten percent of their machine s CPU [2]. Volunteer 
computing is a wonderful opportunity to take advantage of this enormous source of unused computation 
and refocus it Permission to make digital/hard copy of part of this work for personal or classroom use 
is granted without fee provided that the copies are not made or distributed for profit or commercial 
advantage, the copyright notice, the title of the publication, and its date of appear, and notice is 
given that copying is by permission of the ACM, Inc. To copy otherwise, to republish, to post on servers, 
or to redistribute to lists, requires prior specific permission and/or a fee. FuturePlay 2007, November 
15-17, 2007, Toronto, Canada. Copyright 2007 ACM 978-1-59593-943-2/07/0011...$5.00 back towards the research 
community. Unfortunately, volunteer computing falls short of its potential. While the world s largest 
contributor to volunteer computing, the Berkeley Open Infrastructure for Network Computing (BOINC), contains 
approximately 400,000 users, this number pales in comparison to the total number of available online 
computers [3]. We believe that by combining online casual gaming with volunteer computing creating volunteer 
computing games some of the problems plaguing volunteer computing can be solved. Therefore, we present 
Wildfire Wally, a prototype volunteer computing game that explores combining the accessibility and entertainment 
of online casual games with the effectiveness of volunteer computing. 2. MOTIVATION Since the success 
of volunteer computing is entirely dependent on participation, it is a problem that deserves special 
attention. Currently, there are at least four distinct barriers to participation in volunteer computing: 
lack of awareness, lack of broad appeal, a limited demographic, and lack of technical savvy [4]. We believe 
that casual online gaming is capable of breaking all of these barriers. As a medium, gaming immediately 
overcomes barriers of awareness and broad appeal. Casual gaming websites such as AddictingGames, MiniClip, 
and Yahoo! Games have experienced remarkable success as of late. Moreover, casual games appeal to a more 
balanced demographic, and can be catered even further to different people groups. Finally, since, online 
casual games are by definition simple, the final barrier of technical savvy is broken.  3. WILDFIRE 
WALLY 3.1 The Game In Wildfire Wally, players play as Wally, a red-bearded wilderness personality who 
is desperately trying to protect his forest from a raging fire. Wally extinguishes the flames by either 
dousing blazing trees with water, or by creating fire lines that isolate a burning area of the forest. 
As players progress from level to level, wind gusts and dropping humidity make containing the fire increasingly 
difficult. If a certain number of trees are not conserved, the player loses. But Wildfire Wally is more 
than a casual game it actually helps solve instances of the maximum clique problem. Wildfire Wally uses 
a distributed search tree algorithm, with each move in the game corresponding to a decision in the search 
tree. This allows individual players to exhaust a portion of the enormous search tree. In addition to 
gameplay contributing to the solution, players may contribute their spare computing cycles as well. Hence, 
by playing a game, people from across the globe simultaneously work on the same problem.  3.2 Game 
Features Although general design principals apply to any computer or video game, particular decisions 
become even more critical when designing volunteer casual games. A few of these design goals include 
simplicity, rapid decision-making, showing progress, and replayability. Wildfire Wally helps illustrate 
design decisions that can dictate the success of a volunteer computing game. To promote simplicity, Wildfire 
Wally was designed with easy-to­learn instructions and controls. The entire game can be played using 
nothing but the mouse. Also, as a web-based java applet, Wildfire Wally is made accessible to anyone 
who is familiar with basic internet browsing. To promote rapid decision-making, the game is based on 
trying to extinguish a fire as quickly as possible, forcing the player into quick actions to protect 
their forest. Furthermore, the game is broken into short levels to minimize stress. Progress is demonstrated 
in two different ways in Wildfire Wally. One score represents the player s score within the context of 
the game, while a second score represents the player s total contribution towards solving the maximum 
clique problem. Wildfire Wally s replayability hinges on its variation from game to game. We introduced 
a random element into gameplay by creating randomly generated forests and random lightning strikes that 
sparks the initial fire. Also, variables such as wind and humidity effect gamplay, and are adjusted from 
level to level. Finally, extending the game is relatively simple. We can introduce new objectives or 
twists in gameplay with minimal programming effort. 3.3 Adaptation Since our foremost goal is to attract 
as many participants as possible, it was important for us to make our application as flexible as possible. 
In Wildfire Wally, the only communication between the game and the problem solving portion of the application 
is a list of choices and decisions. This allows our implementation to utilize different game ideas with 
minimal programming effort (in this case, substituting only one java class). As long as a player makes 
decisions in a game, his or her gameplay will work seamlessly with our search tree solving algorithm. 
Hosting a variety of games gives us the opportunity to appeal to players of a wide array gaming genres. 
As a result, we could theoretically construct an entire gaming website of casual online games that caters 
to numerous demographics, with their cumulative game actions being used to solve the same problem On 
the other hand, our implementation of Wildfire Wally can also solve any problem mapped to a search tree. 
Once again, only one java class needs to be substituted one that is tailored to the specific problem. 
However many games and problems we implement, each game will be able to solve each problem. We could 
even allow the player to decide which problem they are contributing to as they play the game. 3.4 Future 
Possibilities Whereas Wildfire Wally takes steps in harnessing the average internet user s time and effort 
playing games, we similarly believe we can use the public s ingenuity to solve problems in more intelligent 
ways. Future progress can be made in constructing games that generate visual representations of problems 
 allowing players to have a more direct interaction with them.  4. CONCLUSION Merging online casual 
games with volunteer computing merely takes advantage of an engaging and rapidly growing leisure activity. 
Casual gaming very nearly has universal appeal. By refocusing the actions of casual gamers towards volunteer 
computing, we are increasing the processing power available to researches and improving their research 
efficiency. The pursuit of this vision can have profound effects on volunteer computing efforts. 5. 
ACKNOWLEDGMENTS We would like to thank Chris Martens and Priyanshu Mutreja for previous work done on 
the topic, and Hope College for housing our research. This work was partially supported by the National 
Science Foundation (NSF) grant CNS-0353566.  6. REFERENCES [1] Anderson, D.P., Public Computing: Reconnecting 
People to Science, in Proceedings of the Conference on Shared Knowledge and the Web, November 2003. [2] 
Justiniano, C., Tapping the Matrix: Revisited, ChessBrain Project, BoF Linux Forum in Copenhagen, October 
2005. [3] Anderson, D.P. and J. McLeod VII, Local Scheduling for Volunteer Computing. Parallel and Distributed 
Processing Symposium, 2007. IPDPS 2007. IEEE International. pages 1­ 8. [4] Cusack, C.A., C. Martens, 
and P. Mutreja, Volunteer Computing Using Casual Games, presented at FuturePlay 2006 International Conference 
on the Future of Game Design and Technology, London, Ontario, Canada, October 10-12, 2006. Published 
in Conference Proceedings.   
			]]></ft_body>
		</fulltext>
		<article_type art_type="poster" />
		<article_sponsors>
			<funding_agency>National Science Foundation (NSF)</funding_agency>
			<grant_numbers>
				<grant_number>CNS-0353566</grant_number>
			</grant_numbers>
		</article_sponsors>
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2007</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>1328251</article_id>
		<sort_key>490</sort_key>
		<display_label>Pages</display_label>
		<pages>2</pages>
		<article_publication_date>11-14-2007</article_publication_date>
		<seq_no>2</seq_no>
		<title><![CDATA[Creativity techniques in game design]]></title>
		<page_from>243</page_from>
		<page_to>244</page_to>
		<doi_number>10.1145/1328202.1328251</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1328251</url>
		<abstract>
			<par><![CDATA[<p>Innovation and novelty are seen as important elements in game design but systematic tools and methods for producing creative ideas may be little known or poorly available, and creativity itself can be seen as something mystical [2] that cannot be methodologically enhanced. However, modern creativity research claims that creativity is in the scope of learning and techniques for generating ideas are argued to give competitive advantage [1,2,6]. This may be an important message to designers, but also to the creative leaders.</p> <p>Even the most creative mind can commit the crime of repetition. This is because it is natural for the mind to create patterns [1]. Usually these patterns are helpful, but seeking new and innovative solutions as in product design, one should be able "to think outside" the common practices. Designers are required to be creative on demand, yet the procedures and methods for breaking the common approaches are often based on intuitive belief systems rather than on empirically validated theory [9].</p> <p>One of the solutions to enhance creativity in game design is to use idea generation techniques that help designers to be creative on demand. Studies from other industries suggest that there is a strong relationship between the number of idea generation techniques and the number of successful products [8,10]. However, brainstorming, the best known technique, does not necessarily lead to innovation [5], which is also acknowledged in game design [3]. Even though brainstorming is useful in some cases, no single creativity technique can provide the ultimate solution for innovation in general: different techniques are needed [10].</p> <p>Idea generation may seem a relatively easy task. However, while anybody can come up with some ideas, applicable and novel ideas do not come easily [9]. This is well established in those studies showing that one of the characteristics of companies successful in development is their ability to generate ideas [3]. In a successful ideating session, the generation of ideas is separated from idea evaluation and early criticism may be seen as harmful to the overall process[6].</p> <p>Whereas vertical thinking targets the one and only solution, lateral thinking targets quantity [1] as a tool for quality [6]. Additionally, since idea generation is not a random process governed solely by an individual's personal traits, but a relatively structured process that can be explained [8], a methodological approach is indeed possible.</p> <p>Since we believe that game ideas have their special characteristics, and that and general idea generation techniques may not be so very supportive of the nature of game design processes, we designed several experimental game-specific techniques in the GameSpace project (http://gamelab.uta.fi/GameSpace). These techniques are based on game-related stimuli and structural modules for ideating casual, multiplayer and mobile games. During the project, computer programs and other tools were created to help documenting, game analysis, randomization of stimuli and communicative aspects. These techniques are easy to approach from their functional aspects: the activity of idea generation is based on playing specific board games, card games, using small computer applications or other tools and toys.</p> <p>In light of our workshop experiences with Finnish game professionals in 2006 and 2007, these idea generation techniques can be successfully utilized and help designers to create applicable and novel game ideas that they would not otherwise come up with. Hence these techniques can be seen as a successful way to help "creativity on demand" in game design practices. Some of these techniques have already been fruitfully adopted by the Finnish mobile game industry. While we have already documented several positive user experiences and know that our techniques work, we are conducting a more extensive user study in autumn 2007 and spring 2008 to gain a systematic understanding of game specific idea generation techniques and game idea generation processes.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[brainstorming]]></kw>
			<kw><![CDATA[creativity]]></kw>
			<kw><![CDATA[game design]]></kw>
			<kw><![CDATA[ideas]]></kw>
			<kw><![CDATA[techniques]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.2.1</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10002951.10003227</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003241.10003243</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Decision support systems->Expert systems</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003241.10003243</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Decision support systems->Expert systems</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Human Factors</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P925218</person_id>
				<author_profile_id><![CDATA[81342501070]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Annakaisa]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kultima]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Tampere]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P925242</person_id>
				<author_profile_id><![CDATA[81342506587]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Janne]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Paavilainen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Tampere]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[de Bono, E. (1970) Lateral Thinking. Creativity Step by Step, New York: Harper and Row.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Couger J. D. (1995) Creative Problem Solving and Opportunity Finding, Boyd &amp; Fraser Publishing Co., Danvers, MA.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Gabler K., et al. (2005) "How to Prototype a Game in Under 7 Days: Tips and Tricks from 4 Grad Students Who Made Over 50 Games in 1 Semester" Gamasutra October 26, 2005 Retrieved from http://www.gamasutra.com/features/20051026/gabler_01.shtml]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Mandry, G. D., (1973) New Product Development in the UK Grocery, Research Paper No. 2, Retail Outlets Research Unit, Manchester Business School.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[McFadzean, Elspeth (2000) "Techniques to enhance creative thinking" Team Performance Management: An International Journal. 6 (3/4), 62--72. MCB University Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Mumford, M. D., &amp; Gustafson, S. B. (1988). "Creativity syndrome: Integration, application, and innovation". Psychological Bulletin, 103, 27--43.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Osborn, A. F. (1957) Applied Imagination, rev. ed., Scribner, New York, NY.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Parnes, S. (1961) "Effects of extended effort in creative problem solving". Journal of Educational psychology 52.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Perttula, M. K. (2006), Idea Generation in Engineering Design: Application of a Memory Search Perspective and Some Experimental Studies. Doctoral Dissertation. Helsinki University of Technology, Department of Mechanical Engineering, Machine Design. Otamedia Oy, Espoo.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Sowrey, T. (1989) "Idea Generation: identifying the most useful techniques". European Journal of Marketing 24 (5), 20--29.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Creativity Techniques in Game Design Annakaisa Kultima University of Tampere Kanslerinrinne 1 FIN-33014 
University of Tampere +358 504 437 258 annakaisa.kultima@uta.fi ABSTRACT Innovation and novelty are 
seen as important elements in game design but systematic tools and methods for producing creative ideas 
may be little known or poorly available, and creativity itself can be seen as something mystical [2] 
that cannot be methodologically enhanced. However, modern creativity research claims that creativity 
is in the scope of learning and techniques for generating ideas are argued to give competitive advantage 
[1,2,6]. This may be an important message to designers, but also to the creative leaders. Even the most 
creative mind can commit the crime of repetition. This is because it is natural for the mind to create 
patterns [1]. Usually these patterns are helpful, but seeking new and innovative solutions as in product 
design, one should be able to think outside the common practices. Designers are required to be creative 
on demand, yet the procedures and methods for breaking the common approaches are often based on intuitive 
belief systems rather than on empirically validated theory [9]. One of the solutions to enhance creativity 
in game design is to use idea generation techniques that help designers to be creative on demand. Studies 
from other industries suggest that there is a strong relationship between the number of idea generation 
techniques and the number of successful products [8,10]. However, brainstorming, the best known technique, 
does not necessarily lead to innovation [5], which is also acknowledged in game design [3]. Even though 
brainstorming is useful in some cases, no single creativity technique can provide the ultimate solution 
for innovation in general: different techniques are needed [10]. Idea generation may seem a relatively 
easy task. However, while anybody can come up with some ideas, applicable and novel ideas do not come 
easily [9]. This is well established in those studies showing that one of the characteristics of companies 
successful in development is their ability to generate ideas [3]. In a successful ideating session, the 
generation of ideas is separated from idea evaluation and early criticism may be seen as harmful to the 
Permission to make digital/hard copy of part of this work for personal or classroom use is granted without 
fee provided that the copies are not made or distributed for profit or commercial advantage, the copyright 
notice, the title of the publication, and its date of appear, and notice is given that copying is by 
permission of the ACM, Inc. To copy otherwise, to republish, to post on servers, or to redistribute to 
lists, requires prior specific permission and/or a fee. FuturePlay 2007, November 15-17, 2007, Toronto, 
Canada. Copyright 2007 ACM 978-1-59593-943-2/07/0011...$5.00 Janne Paavilainen University of Tampere 
Kanslerinrinne 1 FIN-33014 University of Tampere +358 400 473 650 janne.paavilainen@uta.fi overall process[6]. 
Whereas vertical thinking targets the one and only solution, lateral thinking targets quantity [1] as 
a tool for quality [6]. Additionally, since idea generation is not a random process governed solely by 
an individual s personal traits, but a relatively structured process that can be explained [8], a methodological 
approach is indeed possible. Since we believe that game ideas have their special characteristics, and 
that and general idea generation techniques may not be so very supportive of the nature of game design 
processes, we designed several experimental game-specific techniques in the GameSpace project (http://gamelab.uta.fi/GameSpace). 
These techniques are based on game-related stimuli and structural modules for ideating casual, multiplayer 
and mobile games. During the project, computer programs and other tools were created to help documenting, 
game analysis, randomization of stimuli and communicative aspects. These techniques are easy to approach 
from their functional aspects: the activity of idea generation is based on playing specific board games, 
card games, using small computer applications or other tools and toys. In light of our workshop experiences 
with Finnish game professionals in 2006 and 2007, these idea generation techniques can be successfully 
utilized and help designers to create applicable and novel game ideas that they would not otherwise come 
up with. Hence these techniques can be seen as a successful way to help creativity on demand in game 
design practices. Some of these techniques have already been fruitfully adopted by the Finnish mobile 
game industry. While we have already documented several positive user experiences and know that our techniques 
work, we are conducting a more extensive user study in autumn 2007 and spring 2008 to gain a systematic 
understanding of game specific idea generation techniques and game idea generation processes. Categories 
and Subject Descriptors I.2.1 [Applications and Expert Systems]: Games  General Terms Design, Human 
Factors  Keywords Game Design, Creativity, Techniques, Brainstorming, Ideas.  ACKNOWLEDGMENTS GameSpace 
techniques are being developed by the GameSpace team including Janne Paavilainen, Annakaisa Kultima, 
Jussi Kuittinen and Johannes Niemelä and tested in the GameSpace workshops during autumn 2006 and spring 
2007 by our industry partners, Nokia, TeliaSonera, Veikkaus, Sulake and Sumea/Digital Chocolate.  REFERENCES 
[1] de Bono, E. (1970) Lateral Thinking. Creativity Step by Step, New York: Harper and Row. [2] Couger 
J.D. (1995) Creative Problem Solving and Opportunity Finding, Boyd &#38; Fraser Publishing Co., Danvers, 
MA. [3] Gabler K., et al. (2005) How to Prototype a Game in Under 7 Days: Tips and Tricks from 4 Grad 
Students Who Made Over 50 Games in 1 Semester Gamasutra October 26, 2005 Retrieved from http://www.gamasutra.com/features/ 
20051026/gabler_01.shtml [4] Mandry, G.D., (1973) New Product Development in the UK Grocery, Research 
Paper No. 2, Retail Outlets Research Unit, Manchester Business School. [5] McFadzean, Elspeth (2000) 
Techniques to enhance creative thinking Team Performance Management: An International Journal. 6 (3/4), 
62-72. MCB University Press. [6] Mumford, M.D., &#38; Gustafson, S.B. (1988). Creativity syndrome: Integration, 
application, and innovation . Psychological Bulletin, 103, 27-43. [7] Osborn, A.F. (1957) Applied Imagination, 
rev.ed., Scribner, New York, NY. [8] Parnes, S. (1961) Effects of extended effort in creative problem 
solving . Journal of Educational psychology 52. [9] Perttula, M.K. (2006), Idea Generation in Engineering 
Design: Application of a Memory Search Perspective and Some Experimental Studies. Doctoral Dissertation. 
Helsinki University of Technology, Department of Mechanical Engineering, Machine Design. Otamedia Oy, 
Espoo. [10] Sowrey, T. (1989) Idea Generation: identifying the most useful techniques . European Journal 
of Marketing 24 (5), 20-29.  
			]]></ft_body>
		</fulltext>
		<article_type art_type="poster" />
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2007</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>1328252</article_id>
		<sort_key>500</sort_key>
		<display_label>Pages</display_label>
		<pages>2</pages>
		<article_publication_date>11-14-2007</article_publication_date>
		<seq_no>3</seq_no>
		<title><![CDATA[Playing for knowledge]]></title>
		<page_from>245</page_from>
		<page_to>246</page_to>
		<doi_number>10.1145/1328202.1328252</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1328252</url>
		<abstract>
			<par><![CDATA[<p>This paper focuses on the applicability of on-line games in pedagogy and social science research. The on-going experiements examine emerging virtual worlds, migratory practices, and developing markets.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[emerging markets]]></kw>
			<kw><![CDATA[viritual immigration]]></kw>
			<kw><![CDATA[virtual colonization]]></kw>
			<kw><![CDATA[virtual worlds]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>J.4</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010405.10010455</concept_id>
				<concept_desc>CCS->Applied computing->Law, social and behavioral sciences</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010455</concept_id>
				<concept_desc>CCS->Applied computing->Law, social and behavioral sciences</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Economics</gt>
			<gt>Experimentation</gt>
			<gt>Human Factors</gt>
			<gt>Verification</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P925227</person_id>
				<author_profile_id><![CDATA[81342497250]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Dana]]></first_name>
				<middle_name><![CDATA[R.]]></middle_name>
				<last_name><![CDATA[Herrera]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[St. Mary's College of California, Moraga, CA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P925216</person_id>
				<author_profile_id><![CDATA[81342503670]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Andr&#225;s]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Margitay-Becht]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Budapest University of Technology and Economics, Hungary]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>1076839</ref_obj_id>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Castronova, E. 2005 Synthetic Worlds: The Business and Culture of Online Games. The University of Chicago Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Bernard, H. Russell. 2006 Research Methods in Anthorpology. Alta Mira Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1076617</ref_obj_id>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Salen, K., Zimmerman, K. 2006 The Game Design Reader: A Rules of Play Anthology. The MIT Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Playing for knowledge Dana R. Herrera, PhD St. Mary s College of California 1928 St. Mary s College 
Road Moraga, CA 94575 +1-925-631-8289 dherrera@stmarys-ca.edu ABSTRACT This paper focuses on the applicability 
of on-line games in pedagogy and social science research. The on-going experiements examine emerging 
virtual worlds, migratory practices, and developing markets. Categories and Subject Descriptors J.4 
[Computer Applications]: Social and Behavioral Sciences anthropology and economics.  General Terms Economics, 
Experimentation, Human Factors, Verification.  Keywords Virtual Worlds, Emerging Markets, Virtual Colonization, 
Viritual Immigration 1. INTRODUCTION This study defines virtual worlds as computer-based simulated environments 
inhabited by individuals through avatars. The worlds themselves can be two or three-dimensional, the 
avatars can be text-based or graphic, and the content can be thematized (e.g. in the case of games). 
These computer-based simulated environments are the new conduits for increased, intensive social interaction 
with millions of international computer users networking with one another on a daily basis.[1] The research 
will incorporate two, distinct levels. In the pedagogical level, students will use theoretical and conceptual 
frameworks to examine, in an academically rigorous way, the cultural and economic significance of these 
virtual spaces. The research level, however, targets the students themselves: how will they interact 
with a new virtual reality, how will they react to the new economic and social realities encountered. 
 2. CLASS BASICS The Culture and Economy of Virtual Worlds, an intensive four- Permission to make digital/hard 
copy of part of this work for personal or classroom use is granted without fee provided that the copies 
are not made or distributed for profit or commercial advantage, the copyright notice, the title of the 
publication, and its date of appear, and notice is given that copying is by permission of the ACM, Inc. 
To copy otherwise, to republish, to post on servers, or to redistribute to lists, requires prior specific 
permission and/or a fee. FuturePlay 2007, November 15-17, 2007, Toronto, Canada. Copyright 2007 ACM 978-1-59593-943-2/07/0011...$5.00 
András Margitay-Becht, MA, MSc, PhD(c) Budapest University of Technology and Economics 2 Stoczek u. Budapest 
H-1111 Hungary +1-925-395-3307 margitay@gmail.com week course at St. Mary s College of California asks, 
How does the persistent renegotiation of identity markers and capital (social, human, and cultural) in 
virtual worlds reinterpret, but not necessarily reproduce, inequalities present in the real world ? Initially, 
students are trained in appropriate anthropological methods and theoretical frameworks of cultural analysis. 
Students and instructors then engage in simultaneous gameplay within an emerging virtual world. As participant 
observers, students will be asked to engage in ethnographic fieldwork that encompasses the completion 
of in-game quests as well as virtual observations of other avatars. Their observations will form the 
basis of a behavior pattern analysis that reveals the developing cultural norms and values of their online 
world. Rather than entering a cultural milieu with well-established gamer constructed social structures, 
students engage a world that is in the early stages of player migration. Initially, students are trained 
in appropriate anthropological methods and theoretical frameworks of cultural analysis. Students and 
instructors then engage in simultaneous gameplay within an emerging virtual world. As participant observers, 
students will be asked to engage in ethnographic fieldwork and economic analysis that encompasses the 
completion of in-game quests, engaging in virtual trade, as well as observations of other avatars. Their 
observations will form the basis of a behavior pattern analysis that reveals the developing cultural 
norms and values of their online world.[2] Rather than entering a cultural milieu with well-established 
gamer constructed social structures, students engage a world that is in the early stages of player migration. 
 3. EXAMINED SOCIAL PHENOMENA 3.1 Virtual Immigration The real world students migrate through to virtual 
space where the boundaries of time, space, and place blur to include other transnational citizens. These 
virtual immigrants might be gaming neophytes to both gaming and the synthetic world. Or, the immigrants 
may also be players who bring their own cultural capital from other preexisting persistent world. These 
second, third, or fourth generation migrants, enculturated into a specific virtual world traditions and 
style of gameplay, bear the social markers of these other worlds.[3] As the authors own participant observation 
suggests, for example, rivalries often erupt when two groups of gamers who had previously inhabited separate 
worlds migrate to the same virtual environment. As participant observers, students can therefore immediately 
apply anthropological theoretical analysis of real world immigrant populations to the community building 
of virtual migrants. Possible avenues of exploration include, but are not limited to  the liminal spaces 
in-between the inhabitation of the real and virtual  in-game globalization and transnational relationships 
of multiple synthetic worlds  holistic analysis of developing cultural groups navigation of linguistic 
and communication norms  the development of virtual and real gender identities as individuals navigate 
a new virtual reality with preset rules of character development  in-game class structures as they are 
constructed parallel to real life hierarchies   3.2 Emerging markets The virtual world used in the 
experiment is a newly developed, freshly opened reality. This gives us the unique opportunity, to both 
experience the development of trade and economy in a new world, and also analyze the insertion of a loosely-knit 
colony of immigrants to this new world. The pedagogical level of the experiment will aim at teaching 
the students the role and workings of the marketplace. The easy analogy between the in-game kill-loot-trade 
cycle and the organic reality s design-produce-trade cycle will be introduced and explored, and through 
the flat learning curve of gameplay, they will gather useful experience in basics of trading, price mechanism, 
supply-demand, and most importantly, arbitrage. Because the explored virtual world will have existed 
only for two months by that time, the price mechanism will not be perfect, allowing for possible exploitation. 
 4. EXPERIMENT The experiment stage of our research will focus on the interaction of the group with 
the already established population of the virtual reality. We are going to focus on the social and economic 
behaviour of our students versus the rest of the world, and see how their performance compares to the 
"average" user. 4.1 Colony structure The explored virtual world will provide infrastructural support 
for organized communities, i.e. guilds. We are interested whether the class as a whole will form a guild 
or not? If they do, do they use it for in-game advantage in playing? In combat scenarios versus other 
groups? Will they utilize the easier communication channels in the organic reality to organize more efficient 
in-world operations either against synthetic or organic entities and organizations? Will the trading 
power of a guild be utilized? So in essence, will our new immigrants to the existing but young virtual 
reality act as a whole, as a community, or as scattered individuals? Will those individuals not taking 
part in a possibly emerging class-oriented guild perform better or worse than the guild members? Will 
immigrants of other societies notably members of guilds of other virtual realities keep their allegiance 
to their virtual peers, or form new alliances with members of their class, maybe even strike out on their 
own? 4.2 Economic implications and approach Through working closely together with the virtual reality 
s creator and maintainer, we will have access to detailed data about the actions of the student s characters. 
This data will be used to evaluate and compare their economic performance to that of the other participants 
of the virtual world. The authors will participate in the world from it s onset, charting the development 
of the economy, analyzing trends in trade value of various products, and the emergence of an in-game 
currency (which may or may not be the actual currency of the game current pre-release tests seem to 
indicate that the medium of exchange will be different than the in-game legal tender.) This data, and 
the accumulated data will be used in creating an economic model, and the students and guild(s) performance 
will be analyzed and compared according to this. The eventual result will be an in-depth analysis of 
the economic outcome of cultural structures in an economy placed on the borders of an emerging virtual 
world and an existing real-life social structure  5. REFERENCES [1] Castronova, E. 2005 Synthetic Worlds: 
The Business and Culture of Online Games. The University of Chicago Press. [2] Bernard, H. Russell. 2006 
Research Methods in Anthorpology. Alta Mira Press. [3] Salen, K., Zimmerman, K. 2006 The Game Design 
Reader: A Rules of Play Anthology. The MIT Press.   
			]]></ft_body>
		</fulltext>
		<article_type art_type="poster" />
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2007</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>1328253</article_id>
		<sort_key>510</sort_key>
		<display_label>Pages</display_label>
		<pages>2</pages>
		<article_publication_date>11-14-2007</article_publication_date>
		<seq_no>4</seq_no>
		<title><![CDATA[mygamestudies.com]]></title>
		<subtitle><![CDATA[building a community for game design students]]></subtitle>
		<page_from>247</page_from>
		<page_to>248</page_to>
		<doi_number>10.1145/1328202.1328253</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1328253</url>
		<abstract>
			<par><![CDATA[<p>The author is about to defend his Ph.D. on methods of game studies and design. The major results of the study are methods with which to analyze game play from the perspectives of game design and player experience. The methods will be implemented online as a community service for teaching game studies and design. <i>mygamestudies.com</i> will be a site with community features that is open for contributions from students, educators, researchers, and game designers.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[game analysis methodology]]></kw>
			<kw><![CDATA[game curriculum]]></kw>
			<kw><![CDATA[game design]]></kw>
			<kw><![CDATA[web 2.0]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.2.1</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10002951.10003227</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003241.10003243</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Decision support systems->Expert systems</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003241.10003243</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Decision support systems->Expert systems</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Human Factors</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P697938</person_id>
				<author_profile_id><![CDATA[81100104941]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Aki]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[J&#228;rvinen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Goffman, E. Encounters. Two Studies in the Sociology of Interaction. Bobbs-Merrill Educational Publishing, Indianapolis, 1961.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[J&#228;rvinen, A. "Introducing Applied Ludology: Hands-on Methods for Game Studies". DiGRA 2007 Situated Play. International Conference of the Digital Games Research Association, September 24th to 28th, 2007, Tokyo, Japan.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 mygamestudies.com Building a Community for Game Design Students Aki Järvinen http://www.gameswithoutfrontiers.net 
+358 40 504 1367 aki@gameswithoutfrontiers.net ABSTRACT The author is about to defend his Ph.D. on methods 
of game studies and design. The major results of the study are methods with which to analyze game play 
from the perspectives of game design and player experience. The methods will be implemented online as 
a community service for teaching game studies and design. mygamestudies.com will be a site with community 
features that is open for contributions from students, educators, researchers, and game designers. Categories 
and Subject Descriptors I.2.1 [Applications and Expert Systems]: Games General Terms Design, Human Factors 
Keywords Game analysis methodology, game design, game curriculum, Web 2.0 1. INTRODUCTION The author 
s Ph.D. study Games without Frontiers: Theories and Methods for Game Studies and Design attempts to formulate 
a general ludological theory of game structures and of a theory of player experience, i.e. psychology 
of play behavior. The theoretical basis of the thesis is highly multi-disciplinary, as it draws from 
cognitive psychology and theory of emotions, social psychology, study of human abilities, psychology 
of goals, and various studies of games, players, and game design. For an introduction to the analysis 
methods and their theoretical background, see [2]. 1.1 100+ Games Project The theoretical findings, such 
as categorizations of different game mechanics, types of goals, and human cognitive abilities, are put 
to practice in a set of analysis methods. The author s aim has been to formulate tools applicable to 
various different gaming encounters , a term coined by sociologist Erwin Permission to make digital or 
hard copies of all or part of this work for personal or classroom use is granted without fee provided 
that copies are not made or distributed for profit or commercial advantage and that copies bear this 
notice and the full citation on the first page. To copy otherwise, or republish, to post on servers or 
to redistribute to lists, requires prior specific permission and/or a fee. FuturePlay 2007, November 
15-17, 2007, Toronto, Canada. Copyright 2007 ACM 978-1-59593-943-2/07/0011...$5.00 Goffman [1], in order 
to understand better what makes games engaging, both in general fashion, and in case of particular games 
with particular features. The methods have been developed iteratively through analyzing a sample of over 
100 games, including computer, board, card, and sports games. This sample and the consequent analysis 
tasks the author has carried out under the 100+ Games Project. The methods seek to provide analysis recipes 
and thus systematic commensurability between the results. Thus structurally and/or experientially similar 
games can be identified, and subsequent new categorizations and design drivers could rise from that. 
Moreover, the methods are meant to enable exploration of further and possibly more complex research questions 
and game design solutions. For example, by identifying the core dynamics of game play in a popular game 
of a certain genre, the premises for designing games into the same genre can be set in a more analytic 
fashion. Ideally this means that communicating design goals to fellow designers and developers becomes 
more fluent. The individual methods are meant to be combined in an analysis of a game, because the findings 
that one method yields often build up on the findings of another. For instance, it is easy to continue 
to an analysis of goals once the game elements are identified, and so on. An analysis that employs all 
the methods bridges different perspectives to the game both as a formal structure and as a psychological, 
emotional play experience for the player.  2. TAKING THE METHODS ONLINE These possibilities gave birth 
to the concept of an online database which would grow from analyses conducted by students, scholars, 
and practitioners. The database functions as an archive and from which queries with certain criteria 
can be made. This enables identifying similarities and differences between games, i.e. a resource for 
conducting background research for new concepts or further studies. In addition, this kind of study activity 
could be leveraged to facilitate a community of people interested in game analysis in education, research 
and design contexts. Hence the idea for mygamestudies.com was born. 2.1 Alpha Phase in 2007 mygamestudies.com 
will go into alpha in October 2007. The alpha phase will consist of teaching sessions where the author 
employs the online tools as teaching aides. The alpha version of the online tools will include three 
of the methods and a database of analyses based on the 100+ games sample. It will function as a demonstration 
of analysis results and a seed for future analyses.  2.2 Announcing Beta for 2008 Next phase of the 
project will include analyzing the results from the alpha, and consequently implementing improvements 
for the next version of the tools and the site. The following release will take mygamestudies.com on 
to its beta phase, starting in early 2008. In the beta version, mygamestudies.com will include community 
functionalities and features, such as grading and commenting analyses by fellow users, etc. These will 
be implemented gradually, and overall the concept will evolve iteratively through the author s teaching 
assignments and experiences gathered from them. The alpha and beta phases will also serve as a validation 
and iteration process for the methods themselves.  3. GAME STUDIES IN THE AGE OF WEB The outcome and 
success of the concept is unknown at the time of writing, but the alpha phase will give a chance to draw 
tentative conclusions: Is it possible to leverage the social nature of Web 2.0 for the purposes of developing 
and sharing knowledge about game studies and design? mygamestudies.com attempts to achieve this goal 
in the context of ludological game analysis. The author hopes to have a chance to engage more insights 
and users for the concept from the community of academics and practitioners participating in the Future 
Play conference. During the alpha phase, the site can be accessed through the author s site: http://www.gameswithoufrontiers.net. 
 4. REFERENCES [1] Goffman, E. Encounters. Two Studies in the Sociology of Interaction. Bobbs-Merrill 
Educational Publishing, Indianapolis, 1961. [2] Järvinen, A. Introducing Applied Ludology: Hands-on Methods 
for Game Studies . DiGRA 2007 Situated Play. International Conference of the Digital Games Research Association, 
September 24th to 28th, 2007, Tokyo, Japan.  
			]]></ft_body>
		</fulltext>
		<article_type art_type="poster" />
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2007</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>1328254</article_id>
		<sort_key>520</sort_key>
		<display_label>Pages</display_label>
		<pages>2</pages>
		<article_publication_date>11-14-2007</article_publication_date>
		<seq_no>5</seq_no>
		<title><![CDATA[Making players laugh]]></title>
		<subtitle><![CDATA[the value of humour in computer games]]></subtitle>
		<page_from>249</page_from>
		<page_to>250</page_to>
		<doi_number>10.1145/1328202.1328254</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1328254</url>
		<abstract>
			<par><![CDATA[<p>Humour is an important aspect of human communication and interaction, and it has cognitive, social, and affective functions. Yet there seems little humour in videogames, even while Machinima draws strongly on comical principles. Humour seems to be an important source of pleasure for game players, and its importance in videogames should be re-evaluated. This brief paper introduces our study of the experience of humour in videogames, and explores the value of humour for design.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[emotion]]></kw>
			<kw><![CDATA[game design]]></kw>
			<kw><![CDATA[humour]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>K.8.0</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010405.10010476.10011187</concept_id>
				<concept_desc>CCS->Applied computing->Computers in other domains->Personal computers and PC applications</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010476.10011187</concept_id>
				<concept_desc>CCS->Applied computing->Computers in other domains->Personal computers and PC applications</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP43124408</person_id>
				<author_profile_id><![CDATA[81100307740]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Claire]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Dormann]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Carleton University, Ottawa, Canada]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P244169</person_id>
				<author_profile_id><![CDATA[81100135223]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Robert]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Biddle]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Carleton University, Ottawa, Canada]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[H. Bergson. Le rire essai sur la signification du comique. In <i>Oeuvres</i>, pages 382--485. Presse Universitaire de France, 1970.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1183329</ref_obj_id>
				<ref_obj_pid>1183316</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[C. Dormann, P. Barr, and R. Biddle. Humour theory and videogames: Laughter in the slaughter. In <i>ACM SIGGRAPH Videogame Symposium</i>, Boston, Massachusetts, 2006. ACM.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[C. Dormann and R. Biddle. Humour in game-based learning. <i>Learning, Media, and Technology</i>, 31(4):411--424, 2006.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>336354</ref_obj_id>
				<ref_obj_pid>336296</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[J. Y. Douglas and A. Hargadon. The pleasure principle: Immersion, engagement, and flow. In <i>Hypertext 2000.</i> ACM, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[S. Freud. <i>Jokes and their relation to the unconscious.</i> Routledge and Kegan Paul, London, 1960.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Gamespot.com. <i>A brief history of video game humour.</i> http://www.gamespot.com/features/6114407/, 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[B. G. Glaser. <i>Basics of grounded theory analysis: Emergence vs. forcing.</i> Sociology Press, Mill Valley, CA, USA, 1992.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Making players laugh: the value of humour in computer games Claire Dormann and Robert Biddle Human-Oriented 
Technology Lab Carleton University, Ottawa, Canada cdormann@connect.carleton.ca ABSTRACT Humour is an 
important aspect of human communication and interaction, and it has cognitive, social, and a.ective functions. 
Yet there seems little humour in videogames, even while Machinima draws strongly on comical principles. 
Humour seems to be an important source of pleasure for game players, and its importance in videogames 
should be re-evaluated. This brief paper introduces our study of the experience of humour in videogames, 
and explores the value of humour for design. Categories and Subject Descriptors K.8.0 [Personal Computing]: 
Games  General Terms Design  Keywords game design, humour, emotion 1. INTRODUCTION People engage in 
the exchange of jokes and humorous ex­ploits in order to provoke laughter and bring about its plea­sure. 
Humour is an important aspect of human communi­cation and interaction, and it has cognitive, social, 
and af­fective functions. It would seem to have an obvious place in games. And in some gameworlds, it 
does: in The Sims , for example, humour is part of the relationships and situations shared by characters, 
and symbols appear in their speech bubbles while characters share jokes and laugh. Yet in gen­eral there 
seems little humour explicit in videogames. This seems especially surprising, for example, because in 
Machin­ima, .lms made from editing captured video from gameplay, humour is the primary focus and it is 
common to draw on comical principles. In our earlier work, we have addressed how theories of hu­mour 
might relate to the patterns we see in the design of Permissiontomakedigital/hardcopy of part of this 
workfor personal or classroomuseisgranted without fee provided thatthecopies are not made or distributedforprofit 
or commercialadvantage, thecopyrightnotice,the titleofthepublication,and itsdate of appear,andnoticeisgiven 
that copying is by permission of the ACM, Inc. To copy otherwise, to republish,to poston servers, or 
toredistributetolists, requires prior specificpermission and/ora fee. FuturePlay 2007, November15-17, 
2007,Toronto,Canada. Copyright 2007 ACM 978-1-59593-943-2/07/0011...$5.00 commercial games [3], and how 
humour can play a role in game-based learning [2]. We are now turning to the experi­ence of players themselves: 
humour seems to be an impor­tant source of pleasure for game players, and its importance in videogames 
should be re-evaluated. In this brief paper we introduce our study of the experi­ence and the value of 
humour in the design of computer games. We .rst review theories of humour, then describe our study to 
investigate the experience of humour in com­puter gameplay, and .nally present some preliminary results 
of our study. We hope that gaining a better understanding of the utilization of humour in games will 
help us to design more engaging games and create new game concepts. For simplicity we are using humour 
as a generic term, for all kinds of comical devices, including wit and comedy.  2. HUMOUR THEORY The 
study of humour theories and humour applications in a variety of contexts and .elds show us some of the 
potential of humour for the design of computer games. Humour has a great entertainment capacity, but 
can also be used to as­sist other aims. For example, enhancing dialogue and other verbal or textual game 
elements with humour can be used for sustaining interest and arousing curiosity. Also, engag­ing in humour 
and laughter increases energy and a sense of well-being. Humour can also have an important relief func­tion 
in game play, and this might be speci.cally important for novice players, where it can compensate for 
repetitive failures and reward e.ort. To understand how these a.ects might be used, we .nd it useful 
to consider the main theories of humour. Superior­ity theory is an early theory of humour and laughter, 
and suggests that we laugh about the misfortunes of others, so laughter occurs at the expense of other 
people with oneself as superior or triumphant. Bergson [1] proposed this kind of humour has a social 
function like censure or control in enforcing the norm of a group or culture. Alternatively, af­fective 
mechanisms linked to Freud s relief theory [5] can be seen as a safety valve for forbidden feelings, 
and so is linked to healthy adaptive behaviour. Relief theory suggests that humour comes from this release 
of nervous energy. There is also a cognitive approach, and such mechanisms are the foundation of incongruity 
theory. In this approach, humour depends on playing with hidden meanings that are suddenly revealed in 
unexpected ways.  3. EXPERIENCE OF HUMOUR IN GAMES In order to understand more of the experience and 
value of humour in videogames, we are investigating through in­depth interviews what makes players laugh 
when they play. We want to .nd out what kind game elements, designs, situ­ations, or events players are 
.nding funny, comical or hilar­ious. We are gathering information on the type of humour used, what types 
of function the humour has (social, cogni­tive or emotional), and if humour was scripted or acciden­tal. 
We are also interested in humour resulting from players pushing and manipulating the boundaries of the 
games. Al­though humour can obviously be scripted within the rules and interactive possibilities of the 
game, it can also be in­troduced by players to amuse themselves. For example by transgressing reality 
and social rules. In The Sims , burn­ing the house down while cooking a meal, killing your Sims, or having 
your married Sim .irt with the neighbor: all these can be seen as funny and can make players laugh. 
We are conducting qualitative research through semi-structured interviews. We are essentially asking 
players to describe, in as much detail as possible, instances of computer game events and situations 
that made them laugh, were humorous or comical. We are analyzing our .ndings using the quali­tative method 
of grounded theory , an emergent method­ology by which a theoretical account of a topic is developed 
through examination and grounding in empirical data [7]. We use in-depth open coding and axial coding, 
with codes being added and modi.ed as appropriate. We present be­low some preliminary results stemming 
from the sample in­terviews that have been conducted so far. Analysis of the data illuminated the importance 
of the social dimension of humour, and especially the two patterns that we describe below. 4. TEXTURE 
It has been suggested that trying to squeeze humour into games that are primarily in genres other than 
comedy is a key problem [6]. However, our study has highlighted that many people enjoying humour scripted 
in games not as a primary focus, but as part of the texture of the gameplay. Humor can be embedded in 
this way as part of inciden­tal dialog. For example, one participant recalled playing a golf game and 
mentioned that during the tournament, de­pending on your moves, the computer would generate funny comments; 
the caddies would say something; or your own avatar would behave in a certain funny ways. Some of the 
comments were quite snarky and made her laugh as she had not anticipated these sort of comments. Another 
way of introducing humour reported was even less direct. For ex­ample, a participant reporting that while 
playing a spying game, the player s avatar overhears two non-player charac­ters (NPCs) making derogatory 
and humorous comments about another NPC: it was again funny as it was completely unexpected. However, 
players also noted that they especially appreciate this type of humour when the funny dialogue also provides 
clues and hints that can be used to gain an advantage in the game. Thus, added to the humour value of 
the dialogues, another important factor is the cleverness that the players then feel when they realize 
the presence of the clues. 5. SELF-REFERENCE The second theme we are able to identify in our interviews 
involves the use of self-reference within games. For example, players reported enjoying characters momentarily 
stepping out of their roles, making remarks about the game as a game, rather than as their world. Similarly, 
great humour was seen in explicit acknowledgment of the use of the game interface to interact with the 
game world. For example, in a war strategy game, a player reported wanting to maneuver units and so clicked 
many times on one of them. To his surprise, the unit then said something like stop clicking me, you are 
bothering me and the player found that hilarious. A similar pattern was reported involving a kind of 
intertextuality. In particular, players found it very funny when games or char­acters made mocking references 
to characters or actions in older versions of games, or to other games entirely. As Douglas [4] discussed 
in relation to hypertext, the plea­sure of humour in games seems related to immersion within the gameplay. 
In one way, humour further enhances the enjoyment of the game plot and player absorption within the game 
world. Alternatively, humour can also further en­gage players by playing with game conventions or the 
game mechanics by breaking the rules , such as acknowledging players or using game references. 6. CONCLUSION 
In all walks aspects of life, people share laughter and ex­change jokes. Why should games be di.erent? 
While realis­tic 3D graphics have been emphasized in game development and evaluation, there are many 
other forms of realism, and humour is one. Moreover, humour plays a powerful role in life, and has many 
consequences. The value of humour and comedy could also lie in creating a strong emotional simu­lation, 
a di.erent aspect of realism that has been under­valued in game design. We hope that research in humour 
and comedy in videogames, besides providing valuable in­sight into how players play computer games and 
what they .nd fun, will lead to the design of more playful, humorous and human-oriented games.  7. REFERENCES 
[1] H. Bergson. Le rire essai sur la signi.cation du comique. In Oeuvres, pages 382 485. Presse Universitaire 
de France, 1970. [2] C. Dormann, P. Barr, and R. Biddle. Humour theory and videogames: Laughter in the 
slaughter. In ACM SIGGRAPH Videogame Symposium, Boston, Massachusetts, 2006. ACM. [3] C. Dormann and 
R. Biddle. Humour in game-based learning. Learning, Media, and Technology, 31(4):411 424, 2006. [4] J. 
Y. Douglas and A. Hargadon. The pleasure principle: Immersion, engagement, and .ow. In Hypertext 2000. 
ACM, 2000. [5] S. Freud. Jokes and their relation to the unconscious. Routledge and Kegan Paul, London, 
1960. [6] Gamespot.com. A brief history of video game humour. http://www.gamespot.com/features/6114407/, 
2005. [7] B.G.Glaser. Basics of grounded theory analysis: Emergence vs. forcing. Sociology Press, Mill 
Valley, CA, USA, 1992.   
			]]></ft_body>
		</fulltext>
		<article_type art_type="poster" />
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2007</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	<article_rec>
		<article_id>1328255</article_id>
		<sort_key>530</sort_key>
		<display_label>Pages</display_label>
		<pages>2</pages>
		<article_publication_date>11-14-2007</article_publication_date>
		<seq_no>6</seq_no>
		<title><![CDATA[AudiOdyssey]]></title>
		<subtitle><![CDATA[an accessible video game for both sighted and non-sighted gamers]]></subtitle>
		<page_from>251</page_from>
		<page_to>252</page_to>
		<doi_number>10.1145/1328202.1328255</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1328255</url>
		<abstract>
			<par><![CDATA[<p>Despite the growing number and demographics of video game players, most games are still completely inaccessible to disabled populations. To study the issue of gaming accessibility, we created AudiOdyssey, a prototype video game designed to be usable by both sighted and non-sighted audiences. Featuring multiple input control schemes, rhythm based game play, and fully accessible menus and play levels, the prototype allows all individuals to share a common gaming experience, regardless of level of vision.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[accessible design]]></kw>
			<kw><![CDATA[accessible user interface]]></kw>
			<kw><![CDATA[accessible video game]]></kw>
			<kw><![CDATA[experimental game design]]></kw>
			<kw><![CDATA[human computer interaction]]></kw>
			<kw><![CDATA[sight impaired]]></kw>
			<kw><![CDATA[vision impaired]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.2.1</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10002951.10003227</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003241.10003243</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Decision support systems->Expert systems</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003241.10003243</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Decision support systems->Expert systems</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Human Factors</gt>
			<gt>Management</gt>
			<gt>Theory</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>PP43128877</person_id>
				<author_profile_id><![CDATA[81332500974]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Eitan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Glinert]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Cambridge Center, Cambridge, MA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>PP43135262</person_id>
				<author_profile_id><![CDATA[81100059161]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Lonce]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wyse]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[National University of Singapore, Singapore]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Winegarner, Beth. 2005. Game sales hit record highs. Gamespot Article. http://www.gamespot.com/news/2005/01/28/news_611743 8.html]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Essential Facts about the Computer and Game Industry. 2006. Sales, Demographic and Usage Data. Entertainment Software Association. http://www.theesa.com/archives/files/Essential%20Facts% 202006.pdf]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[United States Census Disabilities Information. 2000. http://www.census.gov/hhes/www/disability/disabstat2k/ta ble2.html]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[American Legislation Section 508 Standards. http://www.section508.gov/]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Grammenos D., A. Savidis, C. Stephandis. 2004. UA-Chess: A Universally Accessible Board Game. http://dmt.fh-joanneum.at/kd3/objects/application_pdf/1650_UA_accessible_chess_game.pdf]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[The Eye Diseases Prevalence Research Group. 2004. Causes and Prevalence of Visual Impairment Among Adults in the United States. http://archopht.ama-assn.org/cgi/content/abstract/122/4/477]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Klopfer, E. and A. Begel. 2005. StarLogo TNG. An Introduction to Game Development. In Press for the Journal of E-Learning.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Klopfer, E. and K. Squire. 2005. Environmental Detectives - The Development of an Augmented Reality Platform for Environmental Simulations. In Press for Educational Technology Research and Development.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Wyse, L. 2003. A Sound Modeling and Synthesis System Designed for Maximum Usability. International Computer Music Conference. http://www.zwhome.org/~lonce/Publications/Publications_files/WyseICMC2003Paper.zip]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1043567</ref_obj_id>
				<ref_obj_pid>1042444</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Wyse, L. 2005. Generative Sound Models. IEEE Multimedia Modeling Conference. http://www.zwhome.org/~lonce/Publications/Publications_files/Wyse_MMM_GenerativeSoundModels_IEEE.pdf]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1272538</ref_obj_id>
				<ref_obj_pid>1272516</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Kelly, H., K. Howell, E. Glinert, L. Holden, C. Swain, A. Burrowbridge, M. Roper. How to Build Serious Games. 2007. Communications of the ACM, Vol. 50, No. 7. http://delivery.acm.org/10.1145/1280000/1272538/p44-kelly.html?key1=1272538&key2=7758742911&coll=GUIDE&dl=GUIDE&CFID=3127304&CFTOKEN=7709991]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 AudiOdyssey: An Accessible Video Game for Both Sighted and Non-Sighted Gamers Eitan Glinert Graduate 
Student, Singapore-MIT GAMBIT Game Laboratory 5 Cambridge Center, Suite 300 Cambridge, MA 02139 (+01)-617-416-6863 
 glinert@mit.edu ABSTRACT Despite the growing number and demographics of video game players, most games 
are still completely inaccessible to disabled populations. To study the issue of gaming accessibility, 
we created AudiOdyssey, a prototype video game designed to be usable by both sighted and non-sighted 
audiences. Featuring multiple input control schemes, rhythm based game play, and fully accessible menus 
and play levels, the prototype allows all individuals to share a common gaming experience, regardless 
of level of vision. Categories and Subject Descriptors I.2.1 [Applications and Expert Systems]: Games 
 General Terms Design, Human Factors, Theory, Management.  Keywords Human Computer Interaction, Accessible 
User Interface, Accessible Video Game, Accessible Design, Experimental Game Design, Sight Impaired, Vision 
Impaired. 1. INTRODUCTION Video games (used here to refer to both computer games and console games) have 
become a driving force in the entertainment market. In 2004, video game sales in the United States topped 
$7.3 billion, with over 200 titles selling more than 250,000 units [1]. These numbers are growing every 
year, and more tellingly, the user demographics are expanding as well [2]. Despite their increasing and 
widespread appeal, video games remain inaccessible to many people with disabilities, who are frequently 
unable to succeed at or even play the very same games their friends enjoy. This affects a significant 
portion of the population, as roughly 18.6% of persons aged 16 to 64 in America have some form of disability 
[3]. These range from cognitive challenges, to physical disabilities, to technological deficiencies, 
and other medical conditions. Indeed, the range is so wide and varied that the US government has recently 
passed Permission to make digital/hard copy of part of this work for personal or classroom use is granted 
without fee provided that the copies are not made or distributed for profit or commercial advantage, 
the copyright notice, the title of the publication, and its date of appear, and notice is given that 
copying is by permission of the ACM, Inc. To copy otherwise, to republish, to post on servers, or to 
redistribute to lists, requires prior specific permission and/or a fee. FuturePlay 2007, November 15-17, 
2007, Toronto, Canada. Copyright 2007 ACM 978-1-59593-943-2/07/0011...$5.00 Lonce Wyse Associate Professor, 
National University of Singapore Communications and New Media Programme National University of Singapore 
 11 Law Link, Singapore 117570 cnmwll@nus.edu.sg legislation requiring all federally funded software 
research to meet certain accessibility requirements to help address the issue [4]. Despite this, with 
the exception of a few notable attempts [5], games which address these issues are in short supply. One 
of the more common forms of disabilities among the general population are visual impairments, with 2.76% 
of America having some form of visual impairment [6]. However, as of the writing of this paper there 
are fewer than 300 publically available games that are accessible to blind and low vision individuals. 
Many of the games that do exist are derivative from existing genres, instead of being designed from the 
ground up for this audience. They do not take advantage of some of the more recent advances in audio 
and haptic technology to create novel and compelling experiences for the visually impaired, that could 
also engage the broader gaming market. We believe there would be a strong interest in innovative designs 
and best practices that demonstrate the potential of games accessible to both the visually impaired as 
well as the sighted. Such research would also benefit the field of accessible user interfaces. Furthermore, 
we believe the creation of such games will likely have social benefit by allowing disabled people to 
play together in ways previously unfeasible. Therefore, the goal of our collaborative effort is to create 
a prototype visually impaired accessible video games that is also designed for the mainstream market, 
and associated best practice guidelines  2. AUDIODYSSEY AudiOdyssey is our first such prototype game, 
developed at the Singapore-MIT GAMBIT Game Laboratory. Released in August 2007, the game is designed 
around several research goals: Implementing a game design that allows visually impaired and sighted 
users to play the game in the same way, with the same level of challenge, and share a common gaming experience. 
 Designing online multiplayer that allows for identity masking, at least in the sense that users in 
remote locations should not be aware of the visual status of their gaming counterpart.  Designing alternative 
control schemes for improved accessibility to the visually impaired.  Creating a fun, engaging game 
that relies on audio more than visuals to simulate an exciting experience.   AudiOdyssey is a rhythm 
game in which the user takes the role of Vinyl Scorcher, an up and coming DJ new to the club scene. Using 
a keyboard or a Nintendo Wiimote as input, the user overlays tracks to create songs in an effort excite 
the audience on the dance floor. During special freestyle sections, one can play dynamically generated 
sound effects to the beat of the song. Coded in flash, the game is currently only for the PC, however 
future variants may be created for Mac and Linux operating systems as well. The game employs many innovations 
to achieve the projects research goals. By using the Wiimote as input, blind individuals are able to 
use this popular new device in a video game for the first time, and the game has a more natural and intuitive 
user interface. Spatial sound cues from stereo speakers tell the user where and how to swing the Wiimote. 
The focus on music ensures that both sighted and non­sighted users will have a similar gaming experience, 
while keeping the difficulty of the game the same for both groups. Finally, the multiplayer aspect allows 
visually impaired users to play with others using an abnormally high level of interactivity, regardless 
of their lack of sight. AudiOdyssey was developed at MIT by a group of seven Singaporean and MIT undergraduates 
working together in a scrum management team, under the author s supervision. The finished prototype is 
available for free download at http://gambit.mit.edu/loadgame/index.php. Deliverable materials such as 
best practice guidelines and journal articles serve as the basis for future game creation, and will be 
distributed to industry via conference presentations and journal publications to further the development 
of visually impaired accessible games.  3. OUTCOMES AND APPLICATIONS AudiOdyssey will be formally tested 
with statistically significant numbers of both sighted and non-sighted groups in November 2007. Individuals 
will be asked to evaluate the game based on usability, frustration and challenge levels, and overall 
play experience. AudiOdyssey s development has yielded several notable outcomes. To create a game that 
is accessible to the visually impaired yet compelling enough for sighted individuals, we have devised 
an intuitive and engaging Wiimote and keyboard based user interface that is easy for both parties to 
use. The lessons learned during this UI development will be applicable in the development of future games. 
Likewise, while socially based multiplayer games are wildly successful in the mainstream arena, accessible 
versions are extremely rare. Future derivative versions of AudiOdyssey will demonstrate new techniques 
for the creation of such components, encouraging similar future efforts both in academia and in industry. 
Best practice guidelines based on this research will have further benefit, as they will be available 
to future game development teams. We expect that these materials will help show others not only how to 
make games for the visually impaired, but methodology for making games based on compelling research. 
Finally, it is our hope that by demonstrating the creation of a fun and accessible game, others groups, 
especially in industry, will follow suit with the development of similar games. 4. COLLABORATIONS This 
project is a joint effort between Prof. Eric Klopfer at MIT and Prof. Lonce Wyse at the National University 
of Singapore. Klopfer is a co-founder of the Education Arcade, a research laboratory at MIT that is dedicated 
to making novel educational video games. He has lead research on the game development tool Starlogo and 
in augmented reality games 7, 8]. Wyse heads the Arts and Creativity Lab at the NUS Interactive and Digital 
Media Institute pursuing research in interactive sound synthesis [9], musical networks, sound models 
[12], and music cognition. Eitan Glinert, a graduate student at MIT working under Prof. Klopfer, is the 
research manager for the project. He has worked on the educational video game Immune Attack at the Federation 
of American Scientists [11], and has background in computer science, biology, and project management. 
 5. REFERENCES [1] Winegarner, Beth. 2005. Game sales hit record highs. Gamespot Article. http://www.gamespot.com/news/2005/01/28/news_611743 
8.html [2] Essential Facts about the Computer and Game Industry. 2006. Sales, Demographic and Usage Data. 
Entertainment Software Association. http://www.theesa.com/archives/files/Essential%20Facts% 202006.pdf 
[3] United States Census Disabilities Information. 2000. http://www.census.gov/hhes/www/disability/disabstat2k/ta 
ble2.html [4] American Legislation Section 508 Standards. http://www.section508.gov/ [5] Grammenos D., 
A. Savidis, C. Stephandis. 2004. UA-Chess: A Universally Accessible Board Game. http://dmt.fh­joanneum.at/kd3/objects/application_pdf/1650_UA_accessi 
ble_chess_game.pdf [6] The Eye Diseases Prevalence Research Group. 2004. Causes and Prevalence of Visual 
Impairment Among Adults in the United States. http://archopht.ama-assn.org/cgi/content/abstract/122/4/477 
[7] Klopfer, E. and A. Begel. 2005. StarLogo TNG. An Introduction to Game Development. In Press for the 
Journal of E-Learning. [8] Klopfer, E. and K. Squire. 2005. Environmental Detectives The Development 
of an Augmented Reality Platform for Environmental Simulations. In Press for Educational Technology Research 
and Development. [9] Wyse, L. 2003. A Sound Modeling and Synthesis System Designed for Maximum Usability. 
International Computer Music Conference. http://www.zwhome.org/~lonce/Publications/Publications_ files/WyseICMC2003Paper.zip 
[10] Wyse, L. 2005. Generative Sound Models. IEEE Multimedia Modeling Conference. http://www.zwhome.org/~lonce/Publications/Publications_ 
files/Wyse_MMM_GenerativeSoundModels_IEEE.pdf [11] Kelly, H., K. Howell, E. Glinert, L. Holden, C. Swain, 
A. Burrowbridge, M. Roper. How to Build Serious Games. 2007. Communications of the ACM, Vol. 50, No. 
7. http://delivery.acm.org/10.1145/1280000/1272538/p44­kelly.html?key1=1272538&#38;key2=7758742911&#38;coll=GUI 
DE&#38;dl=GUIDE&#38;CFID=3127304&#38;CFTOKEN=7709991   
			]]></ft_body>
		</fulltext>
		<article_type art_type="poster" />
		<ccc>
			<copyright_holder>
				<copyright_holder_name>ACM</copyright_holder_name>
				<copyright_holder_year>2007</copyright_holder_year>
			</copyright_holder>
		</ccc>
	</article_rec>
	</section>
</content>
</proceeding>

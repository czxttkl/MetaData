<?xml version="1.0" encoding="ISO-8859-1"?>
<!DOCTYPE proceeding SYSTEM "proceeding.dtd">
<proceeding ver="6.0" ts="04/10/2010">
<conference_rec>
	<conference_date>
		<start_date>08/09/2008</start_date>
		<end_date>08/10/2008</end_date>
	</conference_date>
	<conference_loc>
		<city><![CDATA[Los Angeles]]></city>
		<state>California</state>
		<country></country>
	</conference_loc>
	<conference_url></conference_url>
</conference_rec>
<series_rec>
	<series_name>
		<series_id>SERIES11411</series_id>
		<series_title><![CDATA[ACM Siggraph Video Game Symposium]]></series_title>
		<series_vol></series_vol>
	</series_name>
</series_rec>
<proceeding_rec>
	<proc_id>1401843</proc_id>
	<acronym>Sandbox '08</acronym>
	<proc_desc>Proceedings of the 2008 ACM SIGGRAPH symposium</proc_desc>
	<conference_number>2008</conference_number>
	<proc_class>symposium</proc_class>
	<proc_title>Video games</proc_title>
	<proc_subtitle></proc_subtitle>
	<proc_volume_no></proc_volume_no>
	<isbn13>978-1-60558-173-6</isbn13>
	<issn></issn>
	<eissn></eissn>
	<copyright_year>2008</copyright_year>
	<publication_date>08-09-2008</publication_date>
	<pages>183</pages>
	<plus_pages></plus_pages>
	<price><![CDATA[]]></price>
	<other_source></other_source>
	<abstract>
		<par><![CDATA[<p>We are excited to introduce papers from the third annual Sandbox Symposium! This is our second year of printed proceedings, which features a compelling blend of papers on topics such as artificial intelligence, game design, education, and development techniques and tools. We had over 50 high-quality submissions and chose 23 papers to be presented at the conference. In addition to the papers, we also have three panels, one on gamer communities, another on character animation, and one featuring representatives from the International Game Developers Association (IGDA). An addition this year includes morning workshops on a variety of timely game topics, including ethics in games, transmedia storytelling, new business practices and models, acting, new techniques, and women and games. Katie Salen and Raph Koster will provide the keynote addresses.</p> <p>This year's symposium features papers on both the theoretical and practical aspects of game development and design, and includes proofs of concept, case studies, critiques and explorations. The authors of these papers show a diversity of expertise and breadth of experiences that echoes the games community itself. They come from both academia and industry, or bridge the gap between; they have backgrounds in film theory, AI, education, philosophy, robotics, business, music, psychology, physics, narrative, programming, and cinematography. The genres of games evaluated and developed also vary: papers investigate first-person shooters, MMOs, mixed-reality games, 2-D platformers, and educational games, to name just a few. We hope to continue to serve as a site of scholarship on all aspects of games---practice, theory, design and participation.</p> <p>The symposium begins with an evening keynote address from Raph Koster that bridges the interests of the Sandbox and Web3D communities. The next morning features a full day of sessions. It begins with a series of workshops that bring together people on timely topics in game design, community, business, and development, and invites participants to collaboratively compose a takeaway that can be shared with the rest of the conference.</p> <p>The first paper session is "Secret Agents: AI, Game Agents and Databases," which presents three papers that highlight novel techniques to further develop the AI, game agent, and database capabilities of games. Opposite this is "Meaning, Metaphor and Mediation," with three papers that explore the philosophical and aesthetic sides of game design.</p> <p>The panel discussion, "Gamer Communities, Design, and Learning," involves looking at the way communities of games interact online and how feedback informs game design. The three papers in "Architecting Navigation and Behavior" discuss game development and design from navigational, robotics and artificial intelligence perspectives.</p> <p>"Learning Through Games: Four Exemplars" presents four models of using games in educational settings and for teaching purposes. "New Tools, Techniques, and Technologies" showcases four different development and design tools.</p> <p>The panel, "Four Views of Procedural Character Animation for Computer Games," illustrates four distinct aspects of procedural animation technology. Opposite this is an IGDA panel titled, "In the Production Trenches: Developers Tackle Roadblocks," which features game industry leaders.</p> <p>The final paper session features "The Game Mechanics Shop," with three papers that reveal insights into game mechanics and play. "3-D and Cinematography: Making Games Come Alive" brings together three papers on cutting-edge cinematography, camera, and 3-D techniques in game development.</p> <p>Finally, the event ends with a keynote address from Katie Salen, followed by the presentation of the "best paper award."</p> <p>We hope this program helps connect you with the latest trends, theories, scholarship and insights in the game community. We look forward to many more years of playing in the Sandbox!</p>]]></par>
	</abstract>
	<publisher>
		<publisher_id>PUB27</publisher_id>
		<publisher_code>ACMNY</publisher_code>
		<publisher_name>ACM</publisher_name>
		<publisher_address>2 Penn Plaza, Suite 701</publisher_address>
		<publisher_city>New York</publisher_city>
		<publisher_state>NY</publisher_state>
		<publisher_country>USA</publisher_country>
		<publisher_zip_code>10121-0701</publisher_zip_code>
		<publisher_contact>Bernard Rous</publisher_contact>
		<publisher_phone>212 869-7440</publisher_phone>
		<publisher_isbn_prefix></publisher_isbn_prefix>
		<publisher_url>www.acm.org/publications</publisher_url>
	</publisher>
	<sponsor_rec>
		<sponsor>
			<sponsor_id>SP932</sponsor_id>
			<sponsor_name>ACM Special Interest Group on Computer Graphics and Interactive Techniques</sponsor_name>
			<sponsor_abbr>SIGGRAPH</sponsor_abbr>
		</sponsor>
	</sponsor_rec>
	<categories>
		<primary_category>
			<cat_node/>
			<descriptor/>
			<type/>
		</primary_category>
	</categories>
	<chair_editor>
		<ch_ed>
			<person_id>P1100674</person_id>
			<author_profile_id><![CDATA[81365593292]]></author_profile_id>
			<orcid_id></orcid_id>
			<seq_no>1</seq_no>
			<first_name><![CDATA[Karen]]></first_name>
			<middle_name><![CDATA[]]></middle_name>
			<last_name><![CDATA[Schrier]]></last_name>
			<suffix><![CDATA[]]></suffix>
			<affiliation><![CDATA[Scholastic/Columbia University]]></affiliation>
			<role><![CDATA[Program Chair]]></role>
			<email_address><![CDATA[]]></email_address>
		</ch_ed>
		<ch_ed>
			<person_id>P1100675</person_id>
			<author_profile_id><![CDATA[81100281811]]></author_profile_id>
			<orcid_id></orcid_id>
			<seq_no>2</seq_no>
			<first_name><![CDATA[Chris]]></first_name>
			<middle_name><![CDATA[]]></middle_name>
			<last_name><![CDATA[Swain]]></last_name>
			<suffix><![CDATA[]]></suffix>
			<affiliation><![CDATA[USC School of Cinematic Arts]]></affiliation>
			<role><![CDATA[Program Chair]]></role>
			<email_address><![CDATA[]]></email_address>
		</ch_ed>
		<ch_ed>
			<person_id>P1100676</person_id>
			<author_profile_id><![CDATA[81320496107]]></author_profile_id>
			<orcid_id></orcid_id>
			<seq_no>3</seq_no>
			<first_name><![CDATA[Michael]]></first_name>
			<middle_name><![CDATA[]]></middle_name>
			<last_name><![CDATA[Wagner]]></last_name>
			<suffix><![CDATA[]]></suffix>
			<affiliation><![CDATA[Danube University Krems]]></affiliation>
			<role><![CDATA[Program Chair]]></role>
			<email_address><![CDATA[]]></email_address>
		</ch_ed>
		<ch_ed>
			<person_id>P1100677</person_id>
			<author_profile_id><![CDATA[81320494325]]></author_profile_id>
			<orcid_id></orcid_id>
			<seq_no>4</seq_no>
			<first_name><![CDATA[David]]></first_name>
			<middle_name><![CDATA[]]></middle_name>
			<last_name><![CDATA[Schwartz]]></last_name>
			<suffix><![CDATA[]]></suffix>
			<affiliation><![CDATA[Rochester Institute of Technology]]></affiliation>
			<role><![CDATA[Conference Chair]]></role>
			<email_address><![CDATA[]]></email_address>
		</ch_ed>
	</chair_editor>
</proceeding_rec>
<content>
	<section>
		<section_id>1401844</section_id>
		<sort_key>10</sort_key>
		<section_seq_no>1</section_seq_no>
		<section_type>SESSION</section_type>
		<section_title><![CDATA[Artificial intelligence]]></section_title>
		<section_page_from>7</section_page_from>
	<article_rec>
		<article_id>1401845</article_id>
		<sort_key>20</sort_key>
		<display_label>Pages</display_label>
		<pages>8</pages>
		<article_publication_date>08-09-2008</article_publication_date>
		<seq_no>1</seq_no>
		<title><![CDATA[Using genetically optimized artificial intelligence to improve gameplaying fun for strategical games]]></title>
		<page_from>7</page_from>
		<page_to>14</page_to>
		<doi_number>10.1145/1401843.1401845</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1401845</url>
		<abstract>
			<par><![CDATA[<p>Fun in computer games depends on many factors. While some factors like uniqueness and humor can only be measured by human subjects, in a strategical game, the rule system is an important and measurable factor. Classics like chess and GO have a millennia-old story of success, based on clever rule design. They only have a few rules, are relatively easy to understand, but still they have myriads of possibilities. Testing the deepness of a rule-set is very hard, especially for a rule system as complex as in a classic strategic computer game. It is necessary, though, to ensure prolonged gaming fun.</p> <p>In our approach, we use artificial intelligence (AI) to simulate hours of beta-testing the given rules, tweaking the rules to provide more game-playing fun and deepness. To avoid making the AI a mirror of its programmer's gaming preferences, we not only evolved the AI with a genetic algorithm, but also used three fundamentally different AI paradigms to find boring loopholes, inefficient game mechanisms and, last but not least, complex erroneous behavior.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[fun]]></kw>
			<kw><![CDATA[genetic algorithm]]></kw>
			<kw><![CDATA[strategic games]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.2.1</cat_node>
				<descriptor>Games</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>K.8.0</cat_node>
				<descriptor>Games</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.2.m</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10002951.10003227.10003251.10003258</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Multimedia information systems->Massively multiplayer online games</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010476.10011187.10011190</concept_id>
				<concept_desc>CCS->Applied computing->Computers in other domains->Personal computers and PC applications->Computer games</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10011007.10010940.10010941.10010969.10010970</concept_id>
				<concept_desc>CCS->Software and its engineering->Software organization and properties->Contextual software domains->Virtual worlds software->Interactive games</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003251.10003258</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Multimedia information systems->Massively multiplayer online games</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010476.10011187.10011190</concept_id>
				<concept_desc>CCS->Applied computing->Computers in other domains->Personal computers and PC applications->Computer games</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10011007.10010940.10010941.10010969.10010970</concept_id>
				<concept_desc>CCS->Software and its engineering->Software organization and properties->Contextual software domains->Virtual worlds software->Interactive games</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010070.10010099</concept_id>
				<concept_desc>CCS->Theory of computation->Theory and algorithms for application domains->Algorithmic game theory and mechanism design</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<person_id>P1100678</person_id>
				<author_profile_id><![CDATA[81365598242]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Christoph]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Salge]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University Hertfordshire]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1100679</person_id>
				<author_profile_id><![CDATA[81365598480]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Christian]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Lipski]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[TU Braunschweig]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1100680</person_id>
				<author_profile_id><![CDATA[81365597647]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Tobias]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Mahlmann]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Braunschweig School of Arts]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1100681</person_id>
				<author_profile_id><![CDATA[81317497542]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Brigitte]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Mathiak]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[TU Braunschweig]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>1082648</ref_obj_id>
				<ref_obj_pid>1082473</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Andrade, G., Ramalho, G., Santana, H., and Corruble, V. 2005. Automatic computer game balancing: a reinforcement learning approach. In <i>AAMAS</i>, ACM, F. Dignum, V. Dignum, S. Koenig, S. Kraus, M. P. Singh, and M. Wooldridge, Eds., 1111--1112.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Demasi, P., and de O. Cruz, A. J. 2003. Online Coevolution for Action Games. <i>International Journal for Intelligent Games and Simulation 2</i>, 2, 80--88.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>534133</ref_obj_id>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Goldberg, D. E. 1989. <i>Genetic Algorithms in Search, Optimization and Machine Learning.</i> Kluwer Academic Publishers, Boston, MA.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Hill, T., Lundgren, A., Fredriksson, R., and Schith, H. 2005. Genetic algorithm for large-scale maximum parsimony phylogenetic analysis of proteins. <i>Biochimica et Biophysica Acta</i>, 19--29.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Juul, J. 2003. The game, the player, the world: looking for a heart of gameness. In <i>DIGRA Conf.</i>
]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1207478</ref_obj_id>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Koster, R. 2005. <i>A theory of fun for game design.</i> Paraglyph press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Koza, J. R. 1991. Genetic evolution and co-evolution of computer programs. In <i>Artificial Life II</i>, C. T. C. Langton, J. D. Farmer, and S. Rasmussen, Eds., vol. X. Addison-Wesley, Santa Fe Institute, New Mexico, USA, 1990, 603--629.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1557446</ref_obj_id>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Pereira, F. C. 2006. <i>Creativity and Artificial Intelligence: A Conceptual Blending Approach, Applications of Cognitive Linguistics.</i> Amsterdam: Mouton de Gruyter.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1620106</ref_obj_id>
				<ref_obj_pid>1620092</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Ponsen, M. J. V., Munoz-Avila, H., Spronck, P., and Aha, D. W. 2005. Automatically Acquiring Domain Knowledge For Adaptive Game AI Using Evolutionary Learning. In <i>AAAI</i>, AAAI Press / The MIT Press, M. M. Veloso and S. Kambhampati, Eds., 1535--1540.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2100144</ref_obj_id>
				<ref_obj_pid>2100099</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Yannakakis, G. N., and Hallam, J. 2006. Towards Capturing and Enhancing Entertainment in Computer Games. In <i>Proceedings of the Hellenic Conference on Artificial Intelligence</i>, 432--442.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Using Genetically Optimized Arti.cial Intelligence to improve Gameplaying Fun for Strategical Games 
 Christoph Salge* Christian Lipski Tobias Mahlmann Brigitte Mathiak§ Adaptive Systems Group TU Braunschweig 
Braunschweig School of Arts TU Braunschweig University Hertfordshire  While human beta-testers instinctively 
try to .nd a balanced gaming style, an AI implementation is able to quickly .nd exploits in the game 
system. Abstract Fun in computer games depends on many factors. While some fac­tors like uniqueness and 
humor can only be measured by human subjects, in a strategical game, the rule system is an important 
and measurable factor. Classics like chess and GO have a millennia-old story of success, based on clever 
rule design. They only have a few rules, are relatively easy to understand, but still they have myriads 
of possibilities. Testing the deepness of a rule-set is very hard, espe­cially for a rule system as complex 
as in a classic strategic computer game. It is necessary, though, to ensure prolonged gaming fun. In 
our approach, we use arti.cial intelligence (AI) to simulate hours of beta-testing the given rules, tweaking 
the rules to provide more game-playing fun and deepness. To avoid making the AI a mir­ror of its programmer 
s gaming preferences, we not only evolved the AI with a genetic algorithm, but also used three fundamentally 
different AI paradigms to .nd boring loopholes, inef.cient game mechanisms and, last but not least, complex 
erroneous behavior. CR Categories: I.2.1 [Arti.cial Intelligence]: Applica­tions and Expert Systems Games; 
I.2.m [Arti.cial Intelligence]: Miscellaneous Genetic Algorithm; K.8.0 [Personal Computing]: General 
Games Keywords: fun, strategic games, genetic algorithm *e-mail: c.salge@rise-of-atlantis.de e-mail:c.lipski@cg.cs.tu-bs.de 
e-mail:t.mahlmann@tu-bs.de §e-mail:mathiak@gmail.com  1 Introduction 1.1 Motivation Developing a state 
of the art computer game today requires the in­vestment of a lot of money and time. To minimize the risks 
of such an investment it is necessary to evaluate the possible success of the product at an early stage. 
Aside of factors that are not controlled by the developers, such as marketing, one wants to ensure that 
the game is attractive to the players, that it creates fun. This again depends on a combination of several 
factors, one being the actual game, or to be more precise: the game mechanics. If the game appears to 
be unbalanced, or unfair, it might not be well received. One way to avoid this problem is to copy existing 
game mechan­ics and then obfuscate that by moving them to a different theme setting. Another way, to 
ensure the quality of innovative game me­chanics, normally involves a lot of game testers, thus costing 
time and money. Copyright &#38;#169; 2008 by the Association for Computing Machinery, Inc. Permission 
to make digital or hard copies of part or all of this work for personal or classroom use is granted without 
fee provided that copies are not made or distributed for commercial advantage and that copies bear this 
notice and the full citation on the first page. Copyrights for components of this work owned by others 
than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, to republish, to post 
on servers, or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions 
from Permissions Dept, ACM Inc., fax +1 (212) 869-0481 or e-mail permissions@acm.org. Sandbox Symposium 
2008, Los Angeles, California, August 9 10, 2008. &#38;#169; 2008 ACM 978-1-60558-173-6/08/0008 $5.00 
 1.2 Idea mainly developed as a case study for a different question, but serves us as a tool to interface 
with the game. Our case study evaluates a different approach, where AIs are used to evaluate the game 
mechanics for critical errors. AIs are fast and cheap to operate, and they do not need a graphical representation, 
if a well de.ned interface exists. So, they can be used on early non­graphical prototypes. The costs 
are minimal as most games require the development of an AI anyway to serve as an opponent for the player. 
Our idea is to employ a genetic algorithm to adapt the AI and then analyze their winning strategies to 
.nd .aws in the game mechanics. The aim is not to show that AIs are able to determine if a game is actual 
fun to play, but if they are capable of .nding .aws in the games that would ruin the game for human players. 
 1.3 Related Work AI research shows, that it is possible to use genetic algorithms to improve the performance 
of AIs in computer games [Ponsen et al. 2005]. Several works exist, that explore the different strategies 
in designing and adapting AIs, such as reinforcement learning [An­drade et al. 2005], or coevolution 
[Demasi and de O. Cruz 2003]. These works also illustrates that AIs can be applied to different game 
mechanics, such as action games or real time strategy games. Also, the underlying model or paradigm of 
their approaches varies from the control of single units to high level decision making, sim­ilar to our 
approach of using and comparing several models. But unlike us, they solely focus on improving the game 
play of the AIs, to make them more challenging, or human like opponents. The question of what makes a 
game fun is also discussed in [Koster 2005], although it does not introduce a formalism to approach it 
systematically. A good overview and synthesis of the current game de.nitions is presented in [Juul 2003]. 
Metric measurements of game fun were also attempted by [Yannakakis and Hallam 2006], introducing psychological 
qualities such as curiosity into an AI, and measuring it s satisfaction. Our approach now tries to combine 
the evolution of better AIs with the measurement game features related to fun. 1.4 Overview For a systematic 
analysis it is necessary .rst to de.ne what a com­puter game actually is, which parameters it has, and 
how they can be measured. This will be done in the .rst section, where we also discuss how those parameters 
correlate with the player having fun. We focus especially on the negative cases, since it is more con­vincing 
to argue, what a player will de.nitely not enjoy. This idea was tested during the development of Rise 
of Atlantis 1, a turn based strategy game developed at the TU Braunschweig to investi­gate several questions 
related to game development. The following three sections introduce the key aspects of the game, and 
how those are important to our project. First, an overview of the game mechanics is given. The game was 
designed to reach a level of complexity that makes it impossible to .nd an optimal strategy, both by 
mathematical analysis and by evaluation of an experienced player. For space constraints only the key 
aspects are explained in more detail. The next section describes the general program structure of the 
game, describing how to interface the AI with the game server with­out using a graphical representation. 
The advantages of a client­server approach in combination with our method are discussed, and we show 
that the AIs are only able to get the same amount of in­formation that a player would receive. The graphical 
interface was 1http://www.rise-of-atlantis.de The AI section presents the three types of AIs that were 
used to evaluate the game mechanics of Rise of Atlantis . It describes in detail how the AIs were evolved 
with genetic algorithms, and how we determined the .tness of the resulting AIs. We then take a look at 
the resulting strategies and examine them to .nd the critical .aws in the game mechanics of Rise of Atlantis 
. Several errors of different types are presented and discussed. The paper closes with some conclusions. 
  2 Theory of Games This section will provide some of the theoretical background needed to analyze 
a game. The Encyclopaedia Britannica de.nes games as a universal form of recreation generally including 
any activity engaged in for diversion or amusement and often establish­ing a situation that involves 
a contest or rivalry . We use a less holistic de.nition from Juul [Juul 2003], that not only de.nes what 
a game is, but does so by naming several features a game has. 2.1 De.nition Juuls de.nition [Juul 2003] 
identi.es games by six parameters. 1. Fixed Rules: A game has to be described by a set of unam­biguous 
rules. This is also an absolute necessity, if a game is programmed on a computer, since everything has 
to be sys­tematically described before implementation. 2. Variable and Quanti.able Outcome: A game has 
to have more then one possible ending, which are distinguishable by the players. 3. Valorisation of 
the Outcome: Some of the outcomes have to be better then others. 4. Players Effort: The actions of the 
player have an effect on the game, usually it is harder to achieve a more positive outcome. 5. Attachment 
of the player to the outcome: The player wants to achieve the better outcome. If he does, it makes him 
feel good 6. Negotiable consequences: The game itself should not have consequences on the world, apart 
from winning or loosing. Even so, consequences can be assigned to the different ends of the game, by 
betting.   2.2 Strategy Games on Computers This de.nition also includes the special case of a turn 
based strat­egy computer game. The .xed and unambiguous rules, which are necessary to implement a game 
on a computer, also determine the other .ve factors of this de.nition. They are normally split into three 
groups of rules, regarding the interaction between players, be­tween the player and the game and describing 
the inner workings of the game. The .rst set of rules, which governs the interaction between the players 
is neglected, our focus lies on the second two groups. The rules that govern the interaction between 
player and world are equivalent to the interface on a computer game. To formalize this, we assume that 
every turn the player picks an action from a .nite number of options. If this is extended to assume that 
several choices per round are made, and that not doing anything can be an option, this formalism is able 
to describe most interactions with turn based computer games. But for the case of a strategic game, this 
for­malism appears natural, since it is the skill of decision making that dominates this game, rather 
then agility or fast reactions. The third set of rules that governs the inner workings of the game is 
associated with the game mechanics. It determines most of the games features, and improving its quality 
is our goal.  2.3 Measurable Parameters Since the player is attached to the outcome, most games are 
played in order to win the game, meaning to achieve one of the better out­comes for the players. In many 
cases, this is dif.cult because the valorisation of the different outcomes if different for the players, 
and thereby a con.ict is generated. Overcoming this con.ict and still being able to win in spite of non 
favourable opponents creates a feeling of ful.lment and fun, and is therefore desirable when cre­ating 
a game. The goal here is to determine those parameters that would spoil this process. Naturally, a player 
tries to use a strategy that would increase his chances of winning. So .rst of all, such a strategy has 
to exist. That means, some of the actions the player take have to be better then other, at least for 
the given situation. If this is not the case, or if the player never has the necessary information to 
do so, the game becomes completely random and the player is not able to put any effort into the game, 
since his actions don t really change anything. So some actions have to be better then others. But if 
one action, or a certain combination of actions is always better then others, the player will eventually 
learn of this, and always pick this action. We will call this a dominant strategy. This is also adverse 
to the idea of a player effort, because the player will realize, that he is not really making smart decision 
during the game in order to win it, but is just executing a strategy that leaves him no choice. His actions 
are again without effect, the outcome is predetermined. A similar problem poses an action, which is never 
bene.cial. This inferior choice is not as problematic as a dominant strategy, but it also limits the 
choices a player can make. Therefore all actions should at least be useful in certain circumstances. 
Every game fea­ture should be part of a successful strategy. Therefore game designers should avoid dominant 
strategies and in­ferior choices. If the inner workings of the game are kept secret, it is harder for 
the player to discover such strategies. But if they are eventually found, the game is still spoiled. 
Complex games make it hard, even if the player knows the rules, to determine what a dom­inant strategy 
is, but it also makes it hard for the game designer to check if those strategies exist. Finding such 
strategies is a multidimensional search problem, which genetic algorithms are able to approximate. So 
a genetically evolved AI, whose .tness function is de.ned by how well it plays the game, would consider 
a dominant strategy a local maximum. So if several AIs adapt a certain strategy and are then always able 
to beat the other AIs, their strategy can be considered dominant. Even if a certain game feature or action 
is chosen much more frequent then others a strong hint exist that this action might be to powerful. Respectively, 
if AIs never use a certain game feature, this feature is an inferior choice. Another parameter that can 
be measured is the time a game would last if played by a human player. Since the game should not infringe 
upon the real life of the player, this time should be limited to a manageable length. Figure 1: Both 
units were ordered to move. The green unit is faster and thereby escapes the attack.  3 Game Mechanics 
To test our theories we designed a case study that was conducted during the development of the game Rise 
of Atlantis . This section will present a short overview of the game mechanics and its basic features. 
The main goals here are to show that the game is too complex to .nd an optimal strategy with a simple 
mathematical analysis, and to explain some of the details that we will refer to in the results section. 
Rise of Atlantis is a turn-based strategy game set in a pre­industrial world with some fantasy elements. 
The game world is represented as a grid of game tiles, each game tile being of a cer­tain terrain, and 
possibly containing resources and local population. The player s goal is to hire people, explore the 
territory, amass re­sources and increase his power in order to either complete the goals set by the storyline, 
or to overcome his opponents. 3.1 Concurrent Turn Execution The idea of a turn based game was in our 
case inspired by letter games that were common in the last century. Players would send in their turn 
to a game master, who would then evaluate them and send reports out to the players. In our game, every 
turn the player chooses the actions his troops should undertake, and those are then send to the server. 
The server evaluates the commands, places them in an order determined by the kind of action and the properties 
of the agent performing them, and then tries to execute them. Nor­mally, there is no uncertainty, if 
an order can be executed, only when other players are involved the agents might fail. If, for exam­ple, 
a troop is send to attack an enemy unit but this unit was moved away in the same turn and is faster, 
the attack can not take place (cf. Fig. 1).  3.2 Interaction with the world The interaction of the player 
with the world happens only through his agents, either single heroes, or troops of people he commands. 
All the actions the player can take are actions one of his agents can perform. There are two kinds of 
agents, heroes and regular troops. Regular troops are used for gathering resources, building structures, 
.ghting enemies, processing goods and other tasks that are more ef.cient with several people (cf. Fig. 
2). They can consist of a different amount of people and can be hired in villages. Heroes are single 
individuals that can do all the things troops of people can do, but do so less ef.ciently, since they 
are alone. How­ever, they have additional abilities that allow them to hire people, prospect for new 
resources, lead armies into battle, perform various kinds of magic and rally villages so they join your 
side. Since all  Figure 2: The player interacts with the world through his units. Each turn they consume 
money and food, but they can perform var­ious actions such as harvesting and .ghting. the action in the 
world are performed as orders given to the units, all a player has to do is to give an order of what 
to do in the next round to every unit. This is very convenient for our AI testing, since it allows us 
to offer a limited amount of choices (the set of possible orders) for a .nite set of agents to the AI 
to decide.  3.3 Unit Skill System There are only two basic types of units, heroes and troops, but with 
time they can specialize by developing their skills. Both types gain skills in two ways by executing 
an activity that is related to that skill, or by practicing it in a school. Heroes learn faster and also 
have a higher skill cap. There are two main advantages of higher skills. First, all actions performed 
with that skill are increased in ef.ciency. While a group of people harvests wood, they gain skill points 
in the category wood, which increases their productivity. At certain point levels, they also gain additional 
bonuses and extras, such as the ability to plant trees and a bonus for using axes in battle. Since heroes 
have a higher skill cap, some abilities and bonuses can only be reached by them. Also, some abilities 
require a high skill in more than one category. To avoid having too many skills, several actions are 
grouped under the same skill. A unit skilled in gathering wood is also a good carpenter. The main result 
of this is that as the game progresses, and the units gain more and more experience, the options for 
the player and the commands he can give grow more complex. There is also a trade-off to be considered: 
does the player want to have only few skilled units, or rather a large mass of cheap troops. 3.4 Resources 
There is a wide range of resources available in the game world, which can be harvested. Some like wheat 
or wood grow back, while other, such as ore and gems will eventually be depleted. Some, such as ore, 
also have to be discovered .rst and then the player has to build a special building, a mine, to harvest 
them. The resources are used for either building new structures that enhance the players abilities, give 
his agents new options or are used to produce tools and weapons, that have similar effects. In general, 
all goods can also be traded to the local villagers to gain some money, which is one of the two basic 
resources. Money and food is used every turn by the agents, and if they do not receive enough they get 
unhappy or unhealthy respectively. Every person uses up one unit of food and troops uses up one piece 
of gold per person, while heroes demand 100 pieces of gold. So, to have a lot of people under you command, 
you would need a lot of food, while someone who wants to have a lot of heroes would need a lot of gold 
income. 3.5 Settlements Settlements, even though they can not be built, play an important part in the 
game. Players can either persuade them with diplomati­cally skilled heroes to join sides, or take them 
by force. The second option will then create a .ght and part of the population will be diminished. Either 
way, if the player gains control, the villagers will then allow him to recruit troops and heroes from 
its people, construct buildings in the settlement, and pay taxes every turn. The settlements thereby 
create a steady stream of income needed to sup­port the troops. The player can also sell and buy goods 
in settlement, where prices depend on local supply and demand. The settlements have an inven­tory of 
goods, just like the agents, and every turn they use up goods and produce others, depending on the local 
environment they are situated in and what their needs are. So a settlement in the middle of the forest 
might not be the best place to sell wood. Even if allied with the player, the settlements still have 
a high grade of autonomy. The agents can take actions to in.uence the settlements, but there is no complete 
control. Especially if the player takes actions the villagers dislike, such as sending their people to 
battle where they die, or not paying their salary. The settlement will become unhappy and eventually 
will stage a revolt. Then the player is faced with the choice of suppressing his settlements or keeping 
them happy. 3.6 Asynchronous Diplomacy When playing with other human players a direct diplomatic ex­change 
is not possible due to the turn based nature of the game. So, as another feature, all diplomatic exchange 
is conducted in a matter of offers and responses. The game offers several levels of diplomatic relations 
one can declare toward another player. The best one is being allied, where another player is able to 
use other player s facilities like his own. The levels then decent from neutral, to trade embargo, to 
closed borders and war. In the state of war, all your units attack the units of your enemy. Since you 
can change your status with the execution of your turn, it is possible to change you status to war, with 
a player that has another status toward you. So, your units will attack his, and he will be ambushed. 
The same goes for peace, once two players are at war. Both sides have to change back to peace, otherwise 
the .ghting will continue. In the late game, another powerful group will appear, that is suppos­edly 
a common enemy of the players. Some of the players will then get the offer to betray their allies, and 
win together with this fac­tion. The element of asynchronous diplomacy adds to the suspense, because 
allies can betray one another at every turn.  4 Program Structure Genetic evolution demands the AIs 
to play thousands of games as fast as possible. In order to do so, they have to interface with the game, 
or more speci.cally the game mechanics. This section de­scribes how the game program is structured, and 
how that allows the AIs to interface with the program. In a turn based strategy game the interaction 
with the game can be formalized as choosing an action from a given set of actions at every  Figure 3: 
UML package diagram of the game s internal structure, showing how both clients for AI and human players 
interact with the server. turn. In our game those decisions are the speci.c orders given to all units 
under the player s control. Note, that the order to do nothing is also an order, and will be assumed 
as the default order if no other is given. The diagram in Figure 3 shows the basic modularization. The 
game was realized as a client server application. The module World-Data on the server side contains all 
game data about the world and the players. The server module called GameLogic represents the rules, and 
is responsible for the evaluation of each turn. When all players hand in their turns, it executes their 
effects on the model in WorldData . Two kinds of clients were created, graphical ones for the human players, 
and non-graphical for the AIs. In both cases, they receive their data from the Parser module that encodes 
the relevant game data in an XML .le that would then in turn be used to update the world data on the 
clients. The module Parser only encodes the data accessible to the player through his units, so the AI 
does not receive more information than a normal player. The AIs and the players then give orders to their 
units in their WorldData Module after examining the game situation. Those are transmitted back to the 
server, again in the form of an XML File. This modularization has several advantages. First, the AI as 
well as players can be constricted from viewing the complete world state of the game, thus preventing 
cheating. The communication of the orders in the form of a speci.ed XML .le makes it possible to play 
by TCP, email or any other kind of communication that is able to transport that .le. It also gives a 
well speci.ed format for the AI to express their decisions. It is also possible to completely omit the 
graphical representation, if only AIs are playing; accelerating the game in order to speed up the evolution 
process. A genetic evolution of that complexity takes a lot of time. A high number of complete games 
have to be played to evolve even a sin­gle generation. Several generations are necessary to achieve even 
a basic level of evolution. All this takes considerable time, and it is not only the decision making 
of the AIs that slows down the pro­cess. Also the speed in which that decision can be transmitted and 
processed must be taken in account. Having a fast implementation of all factors included should not be 
neglected either.  5 Graphics Although a graphical client does not necessarily belong to the basic requirements 
of the game, such a client was implemented at an early stage of the development process. The graphical 
client ensures that all programmers can easily inspect the current game state and com­pete with the AI. 
We also used the graphical game client to conduct a before-and-after comparison of the game with human 
players. To do so, some of the game mechanics that were designed to make the game accessible to AIs now 
had to be visualized to human players. In another project that was part of the development of Rise of 
At­lantis a concept was created that allows ef.cient data representa­tion, which also addresses the two 
most troublesome aspects of its game mechanic. The need to visualize the concurrent turn execu­tion of 
orders, and the presentation of the different orders a unit can execute. To address the .rst issue, we 
switched between two distinct screen layouts. The .rst layout presented the actual game state and allowed 
interaction with the game entities, such as giving orders. The sec­ond layout contains a wide screen 
display of the game world and shows the game progress in between rounds by following an auto­matically 
compiled timeline. The player can jump back and forth in this timeline layout to inspect all visible 
in-game events and he may even return to this timeline view when he entered the interac­tion layout. 
In order to present all possible orders in a single, coherent view, the amount of information displayed 
was linked to the position of the camera. When the player zooms out and overlooks several game tiles 
in a birds-eye view, only very basic orders, such as movement, are possible. When viewed from a closer 
distance, the camera au­tomatically changes its viewing angle, so that a single game tile is presented 
in an almost isometric view. More details of the scene are revealed and thus, the orders where the unit 
would interact with them are accessible by clicking the corresponding objects. By do­ing so it was ensured, 
that the player would have access to the same amount of possible orders the AIs had, without getting 
confused.  6 Genetic Optimization Genetic algorithms are optimization of search algorithms that have 
been inspired by biological evolution [Goldberg 1989]. The idea is to have a genome space that is equivalent 
to the search space. Indi­vidual solutions are assessed by an evaluation function, also called .tness 
function. Fit individuals are allowed to procreate and are changed either through mutation or recombination. 
Much of the terminology used with genetic algorithms is taken from biology as its historical roots are 
in the simulation of evolutionary processes. Today they are used in many areas including arti.cial creativity 
[Pereira 2006], bioinformatics [Hill et al. 2005] and all general op­timization problems without a clear 
direct approach. 6.1 Mathematical De.nition A genetic algorithm belongs to the category of random-walk 
al­gorithms. Given a multi-dimensional search space and a .tness function f (xx) the goal of the random-walk 
algorithm is to .nd the global maximum of the function f. A classic random-walk algo­rithm starts at 
a randomly determined point in the search space and from there on tries to .nd higher ground (e.g. the 
hill-climbing al­gorithm). Genetical algorithms vary this theme by starting at mul­tiple places at once 
and sharing information on the heights glob­ally, randomly trying to .nd even higher grounds. The point 
in the search space is represented through a set of chromosomes carried by each individual. The genetic 
algorithm can be split into four phases: initialization, selection, reproduction and termination. In 
the initialization phase, random individuals are generated as the .rst generation. Next, for each of 
these individuals, the .tness function is calculated and the less .t individuals are removed from the 
process. There are two ways to create new genomes, mutation or recombina­tion (crossover). Mutation is 
modelled by randomly picking chro­mosomes and changing them. Recombination takes at least two .t individuals. 
Their genomes are split randomly and the pieces are recombined to form a new individual. Selection and 
reproduction are then repeated until the termination criterion is met, which might be anything from a 
target number of generations or .tness over lack in .tness increase to computational time constraints. 
 6.2 Using Genetic Algorithms to Train the AIs The main problem in applying this method to our game 
it that the .tness function cannot be calculated directly. There is no explicit function that gives a 
.tness value for each individual. For the se­lection process, however, that is not exactly necessary. 
The .tness function is only used to compare the .tness of two individuals, but that can be done just 
as well by letting them compete against each other. This method of indirectly determining the .tness 
of the in­dividuals is called coevolution and is one of the main advantages of genetic algorithms over 
classical search algorithms [Koza 1991]. Our implementation of the genetic algorithm with coevolution 
works as follows. Let G be the maximum generation size and S be the minimum generation size. During initialization, 
G individu­als are build randomly. The individuals are randomly pitted against each other in a match. 
The losing individual is deleted. When the generation size reaches its minimum S, the reproduction be­gins. 
From the survivors again two are chosen randomly. They are crossed, using a random one-point-crossover 
and mutated at a rate of 1/numberofgenes, which on average results in one muta­tion per generation. We 
stopped the process after about 24 hours of computation time, with S = 32 and G = 128. When mapping behavior 
to a vector space, the naive approach is to give the reaction to all possible input possibilities. For 
Rise of At­lantis , this approach would be fatal as even the map has more than trillions of variations. 
Instead of dictating the reactions to the input, we chose to use AI behavior models, for which the genetic 
algo­rithm provides the parameters. The three behavior models, we used, are introduced in section 7. 
All three follow a different paradigm.  7 AI paradigms When building an AI, basic design questions have 
to be answered, before even considering implementation, optimization and integra­tion. While studying 
typical decision-making processes in human players, we noticed that there are different paradigms concerning 
strategical and tactical play. In the next three sections, we will discuss the AI paradigms we used for 
optimization of the game and their advantages and disad­vantages. 7.1 Swarm AI The most basic paradigm 
is that of swarm behavior. Every entity is seen independently and tries to perform best from its limited 
point of view. Their decisions are based on primitive motivations like hunger, loneliness, curiosity, 
fear and anger. It is randomly decided what motivation to pursuit. As you can see in .gure 4, the motiva­tions 
give motivation points toward the different actions, which add  Figure 5: Organisational chart for the 
Councillor AI up to the probability distribution of the actions. The precise param­eters are determined 
by the genetic code. While most motivations are determined individually, like hunger and loneliness, 
others are set as global parameters like anger and fear. Although each entity decides on their own, their 
behavior does not have to be egoistic. In fact, entities may give food away when meet­ing another entity 
with fewer resources. Each individual s prime goal is to win the game. They do not do, however, explicitly 
plan or coordinate on a global level. We did, however, notice emergent behavior that did bene.t the whole 
group. The individual s aversion to loneliness, leads to mov­ing clusters like unit groups, which proved 
to be very effective in both war scenarios and resource management. Other advantages where more technical 
in nature. The implemen­tation of a motivation system is very simple. New actions and even new motivations 
can be added quickly, when the game logic is ex­tended or changed. In our test games, the swarm AI usually 
beat its opponents, not only because its implementation is simpler, hence more robust, but also because 
it learned much faster. Since, we re­stricted learning time and the swarm AI could play faster due to 
its simplicity and could thus run through more generations.  7.2 Councillor AI The Councillor AI acts 
similarly to a Cabinet. The Councillors are specialized in topics like war, infrastructure, expansion 
and re­source gathering. Each of the Councillors has a wish list of sec­ondary goals, like build workshop 
or more soldiers . The exact  Figure 6: Work.ow of the Reactive AI content and priorization of these 
wishes is determined by the ge­netic makeup and some situational markers. Also, the Councillors are prioritized 
based on situation and genes, which in.uences the global priority of their wishes. According to the priority 
of each wish, needed resources are dis­tributed, missing resources are set on the resources gathering 
list or transported. Unlike the swarm AI, resources can be allocated even when the goal is not reachable 
in the current turn. That way, resources can be saved for more expensive buildings. Besides resources, 
wishes need units to be ful.lled. They are as­signed jobs to units like gathering and exploring. When 
redistribut­ing the jobs according to the priorization, the algorithm tries to maximize the units staying 
in a job to take full bene.t of the learn­ing system of Rise of Atlantis . Unlike the swarm AI, this 
system needs a lot of handicraft, by for­mulating the wishes and splitting them into jobs intelligently. 
The main advantage is that decisions are easy to understand for humans and predictable. It makes a nice 
opponent and could easily be used as a recommender system for new players. The main disadvantage is that 
many crucial decisions are made hard-coded, without in.u­ence of genes, which seriously hampers the .exibility 
needed in the play testing phase, when rules are still changing. Tactically, we noticed occasional micro-management 
mistakes that were not cov­ered through the jobs and wishes. The gameplay worked very well for building 
quickly an infrastructure, but did not cope well with sudden changes, rare situations and attacks.  
7.3 Reactive AI Much like the Councillor AI, the Reactive AI decides globally on how to proceed. Unlike 
the Councillors, it focuses much more on reacting to situations, than following its own plans. As you 
can see in .gure 6 the decision process is split into four steps. The Commander analyzes the game report 
and looks for certain pat­terns, called situations. Typical situations are enemies on the bor­der, resource 
scarcity and lacking exploration. From the detected situations, the Consultant generates general solutions 
or hints by consulting the genes, together with an alarm level of the situation. Next, the Commander 
sorts the hints by the weights given to them in the gene and their alarm level. The Micromanager converts 
the hints greedily into actual commands. Unused resources are given standard tasks that do not require 
much movement. Again, the main problem is the amount of hard-coded intelligence required to make this 
AI run. This increases calculation time and decreases .exibility. The Reactive AI did a much better job 
of re­acting to attacks and tactical micro-management than the Council­lor AI.  8 Results and Discussion 
In this section we will present the general results of the case study and discuss some of the .ndings 
in more detail. The AIs adapted well to the game mechanics and already twenty generations after the initialization 
the genomes would perform signi.cantly better then the randomly initialized genomes. This suggests that 
the hard coded parts of the AIs were well chosen, giving the AIs enough .exibility to adjust, but also 
restricting them enough so they can evolve successfully. It also shows, that the game mechanics, as a 
minimum, are not com­pletely random itself, and that certain strategies improve the odds of winning. 
The next step is to look for dominant strategies, inferior choices and bugs. 8.1 Dominant Strategies 
One example for a dominant strategy was the overproduction of grain. One of the AIs found a strategy 
in which it would hire as much troops as possible, and use all of them to harvest grain, an openly available 
and regrowing resource. The grain was then partly eaten, and the rest was sold for money at the closest 
settlement. The resulting money was enough to hire more troops, and the AI was thus able to increase 
its troops exponentially. The mechanism that adjusted the prices in settlements depending on supply and 
demand should have prevented this. Selling increasingly huge amounts of grain to the villagers, which 
would never use them up, should have decreased the prices dramatically and made this unpro.table. Un­fortunately, 
the regular price for grain was only two gold units, and a price for anything could never fall below 
one gold piece. A change of this lower bound made the strategy disappear completely. This illustrates, 
how a somewhat complex dominant strategy that involves several different actions (hiring troops, harvesting 
grain, transporting it to the settlement, selling it) could be successfully identi.ed. An experienced 
player could have found that strategy as well, but might then have been forced to repeat those rather 
boring actions over and over, and control an exponentially large amount of troops. It was decided that 
this strategy is not bene.cial for game­playing fun and it was thus removed from the game. In a later 
evolution, many AIs decided to hire more troops in the beginning than they could sustain in the long 
term to gain a short term bene.t in resources and protection. Since that strategy was not essential to 
win a game and actually seemed like a fun strategy for players, giving them more to do in the beginning, 
it was left as a viable possibility in the game.  8.2 Inferior Choices The AIs where also able to identify 
several choices as inferior, and did not use them at all. For example, after additional cost and re­quirement 
for the production of iron where introduced, most AIs dropped the production of those good depending 
on iron completely from their strategies. Even so they where capable to produce iron goods, as was seen 
before the cost of the ore processing steps were increased. Something similar happened to the use of 
horses. In one version, their training depended on building a stable and the AI stopped to produce horses, 
because it was not pro.table anymore. Apart from that, the statistics could be used to investigate which 
features of the AI used. For most options, it could even be deter­mined to what extend or frequency a 
certain feature was used. Most of the AIs, for example, settled for a moderate approach to explo­ration. 
No exploration appears as an obviously bad choice, since it limits the player s options heavily. But 
a maximum of exploration also proves to be bad, since it entails the risk of loosing several units due 
to the lack of support form the main troops, and early contact to the enemy. A different factor of the 
game mechanics that could be determined was the actual time it would take a player to play a game. On 
aver­age it took the AIs 300 turn to complete a game. This is too long, considering that a player would 
need 2 minutes for a turn the game would last 10 hours. It also revealed that especially the early build­ings 
and tools took way to long to produce.  8.3 Bug Detection Another interesting result we discovered during 
the case study was the ability of the AIs to identify bugs in the game mechanics mod­ule. Since the AIs 
were more likely to get killed if they lost a game, being able to crash the game was an advantage for 
the genetic selection process. Therefore, several AIs developed ways to crash the game. One was particular 
memorable, because it involved the combination of several complex actions to crash the game. These would 
have been hard to .nd by conventional beta testing, since it involved several phenomena human players 
would instinctively avoid. Every troop unit has an integer number that represents the number of people 
in that troop. If, for any reason such as combat or bad health, a person in that unit dies, that number 
is decreased, if the number of people reaches zero in that way, the unit is erased. The problem was that 
if a unit was created as a troop of zero people, the reduction of one person put the counter to -1, and 
the unit would not be erased. So zombie units where created, which produced food and gold every turn, 
could not die and caused the game to crash in battle simulations. Naturally, units of that size should 
no be possible to produce, but the AI found a way. By not giving a hero food for a longer time, the unit 
gets very close to death, and its ef.ciency in different tasks suffers. When this hero hires a troop 
unit in a settlement, the amount of hired people is calculated in regard to the hero s general ef.ciency, 
which could yield a result of zero people.  9 Conclusions In this paper, we studied the usefulness of 
using genetically opti­mized AIs as playtesters. More speci.cally, we compared the per­formance of three 
different AI paradigms in this situation. Each AI was designed and programmed by 6 to 7 undergraduate 
students over a time period of three months. As discussed in section 8, the evolving AIs where able to 
develop winning strategies, revealing both dominant and inferior strategies. None of those strategies 
were obvious in super.cial human play test, we conducted before training. It fact, many of those strategies 
used rather boring and repeated moves, or neglected certain aspects of the game. Human beta-testers usually 
try to avoid both. Degrad­ing the value of those strategies made the game more interesting, by not forcing 
the players to use them in order to be effective. Implementing the genetic algorithm was relatively fast 
and easy, given that the AI had been designed for it from the start. Since an AI had to be developed 
for the game anyway, the additional cost of making it optimisable was relatively low. Working with an 
un­.nished and changing game logic was quite a challenge, though. While the SwarmAI could be changed 
relatively easy, both groups with more complex AIs had a hard time adjusting their AIs to the changes. 
To our surprise, the simplest AI became also the most ef­fective, both in terms of .nding strategies 
and bug detection, simply because they could run more and faster than the more complex AIs. Also, it 
turned out, that the most important ability of AIs is not to have the most ef.cient micro-management, 
but to react to threats and actions from the opponent and the surrounding area. In conclusion, we believe 
this case study to be convincing proof of concept for our initial thesis. The human play tests we conducted 
before and after the modi.cations actually show the game is now more fun to play.  References ANDRADE, 
G., RAMALHO, G., SANTANA, H., AND CORRUBLE, V. 2005. Automatic computer game balancing: a reinforcement 
learning approach. In AAMAS, ACM, F. Dignum, V. Dignum, S. Koenig, S. Kraus, M. P. Singh, and M. Wooldridge, 
Eds., 1111 1112. DEMASI, P., AND DE O. CRUZ, A. J. 2003. Online Coevolution for Action Games. International 
Journal for Intelligent Games and Simulation 2, 2, 80 88. GOLDBERG, D. E. 1989. Genetic Algorithms in 
Search, Opti­mization and Machine Learning. Kluwer Academic Publishers, Boston, MA. HILL, T., LUNDGREN, 
A., FREDRIKSSON, R., AND SCHITH, H. 2005. Genetic algorithm for large-scale maximum parsi­mony phylogenetic 
analysis of proteins. Biochimica et Biophys­ica Acta, 19 29. JUUL, J. 2003. The game, the player, the 
world: looking for a heart of gameness. In DIGRA Conf. KOSTER, R. 2005. A theory of fun for game design. 
Paraglyph press. KOZA, J. R. 1991. Genetic evolution and co-evolution of computer programs. In Arti.cial 
Life II, C. T. C. Langton, J. D. Farmer, and S. Rasmussen, Eds., vol. X. Addison-Wesley, Santa Fe Institute, 
New Mexico, USA, 1990, 603 629. PEREIRA, F. C. 2006. Creativity and Arti.cial Intelligence: A Conceptual 
Blending Approach, Applications of Cognitive Lin­guistics. Amsterdam: Mouton de Gruyter. PONSEN, M. J. 
V., MUNOZ-AVILA, H., SPRONCK, P., AND AHA, D. W. 2005. Automatically Acquiring Domain Knowledge For Adaptive 
Game AI Using Evolutionary Learning. In AAAI, AAAI Press / The MIT Press, M. M. Veloso and S. Kambham­pati, 
Eds., 1535 1540. YANNAKAKIS, G. N., AND HALLAM, J. 2006. Towards Captur­ing and Enhancing Entertainment 
in Computer Games. In Pro­ceedings of the Hellenic Conference on Arti.cial Intelligence, 432 442.  
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
	</article_rec>
	<article_rec>
		<article_id>1401846</article_id>
		<sort_key>30</sort_key>
		<display_label>Pages</display_label>
		<pages>8</pages>
		<article_publication_date>08-09-2008</article_publication_date>
		<seq_no>2</seq_no>
		<title><![CDATA[A spatial awareness framework for enhancing game agent behaviour]]></title>
		<page_from>15</page_from>
		<page_to>22</page_to>
		<doi_number>10.1145/1401843.1401846</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1401846</url>
		<abstract>
			<par><![CDATA[<p>We describe a framework for providing game agents with awareness of the intrinsic spatial qualities of the virtual worlds that they inhabit. We develop a novel data structure based on a modified medial axis, which establishes a mapping between the medial axis and world structures. This data structure can be used to perform queries about the width, curvature and connectivity of a space within a virtual world. Additional information, such as sampled visibility can also be integrated with this framework. An agent-based crowd simulation is adapted to make use of the sensory information provided by this data structure and the success of using this information within two game scenarios is evaluated.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[agents]]></kw>
			<kw><![CDATA[games]]></kw>
			<kw><![CDATA[spatial analysis]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.2.10</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>I.4.7</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>I.4.8</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010225.10010227</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Computer vision tasks->Scene understanding</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010382</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Image manipulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010245</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Computer vision problems</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010245</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Computer vision problems</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010225.10010227</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Computer vision tasks->Scene understanding</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<person_id>P1100682</person_id>
				<author_profile_id><![CDATA[81538664856]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Simon]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Perkins]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Cape Town]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1100683</person_id>
				<author_profile_id><![CDATA[81339506852]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[David]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Jacka]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Cape Town]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1100684</person_id>
				<author_profile_id><![CDATA[81100417619]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[James]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Gain]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Cape Town]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1100685</person_id>
				<author_profile_id><![CDATA[81100148618]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Patrick]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Marais]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Cape Town]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>280947</ref_obj_id>
				<ref_obj_pid>280814</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Amenta, N., Bern, M., and Kamvysselis, M. 1998. A new voronoi-based surface reconstruction algorithm. In <i>SIGGRAPH '98: Proceedings of the 25th annual conference on Computer graphics and interactive techniques</i>, ACM Press, New York, NY, USA, 415--421.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>235821</ref_obj_id>
				<ref_obj_pid>235815</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Barber, C., Dobkin, D., and Huhdanpaa, H. 1996. The quickhull algorithm for convex hulls. <i>ACM Transactions on Mathematical Software 22</i>, 4 (Dec), 469--483.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>361007</ref_obj_id>
				<ref_obj_pid>361002</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Bentley, J. 1975. Multidimensional binary search trees used for associative searching. <i>Communications of the ACM 18</i>, 509--517.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1271513</ref_obj_id>
				<ref_obj_pid>1270397</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Bhattacharya, P., and Gavrilova, M. L. 2007. Voronoi diagram in optimal path planning. In <i>ISVD '07: Proceedings of the 4th International Symposium on Voronoi Diagrams in Science and Engineering</i>, IEEE Computer Society, Washington, DC, USA, 38--47.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>199412</ref_obj_id>
				<ref_obj_pid>199404</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Chrysanthou, Y., and Slater, M. 1995. Shadow volume bsp trees for computation of shadows in dynamic scenes. In <i>SI3D '95: Proceedings of the 1995 symposium on Interactive 3D graphics</i>, ACM Press, New York, NY, USA, 45--50.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1263307</ref_obj_id>
				<ref_obj_pid>1263130</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Cornea, N. D., and Min, P. 2007. Curve-skeleton properties, applications, and algorithms. <i>IEEE Transactions on Visualization and Computer Graphics 13</i>, 3, 530--548. Member-Deborah Silver.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>807481</ref_obj_id>
				<ref_obj_pid>800250</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Fuchs, H., Kedem, Z. M., and Naylor, B. F. 1980. On visible surface generation by a priori tree structures. In <i>SIGGRAPH '80: Proceedings of the 7th annual conference on Computer graphics and interactive techniques</i>, ACM Press, New York, NY, USA, 124--133.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Guibas, L., Holleman, C., and Kavraki, L. 1999. A probabilistic roadmap planner for flexible objects with a workspace medial axis. In <i>Proceedings of the IEEE International Conference on Intelligent Robots.</i>
]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Holleman, C., and Kavraki, L. 2000. A framework for using the workspace medial axis in prm planners. In <i>Proceedings of the International Conference on Robotics and Automation</i>, 1408--1413.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>234347</ref_obj_id>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Klir, G. J., and Yuan, B., Eds. 1996. <i>Fuzzy sets, fuzzy logic, and fuzzy systems: selected papers by Lotfi A. Zadeh.</i> World Scientific Publishing Co., Inc., River Edge, NJ, USA.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Lid&#233;n, L. 2000. The integration of autonomous and scripted behaviour through task management. In <i>Artificial Intelligence and Interactive Entertainment, AAAI Spring Symposium.</i>
]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Mizumoto, M. 1998. Defuzzification. In <i>Handbook of Fuzzy Computation.</i> IOP Publishing Ltd.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Morgan, D. 2003. Algorithmic approaches to finding cover in three-dimensional, virtual environments. Masters thesis, MOVES Institute.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Ogniewicz, R. 1994. A multiscale mat from voronoi diagrams: The skeleton-space and its application to shape description and decomposition. <i>Aspects of Visual Form Processing</i>, 430--439.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Ogniewicz, R. 1994. Skeleton-space: a multiscale shape description combining region and boundary information. In <i>1994 IEEE Computer Society Conference on Computer Vision and Pattern Recognition</i>, 746--751.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[O'Neill, J. 2002. Efficient navigation mesh implementation. <i>Journal of Game Development.</i>
]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Pottinger, D. 2000. Terrain analysis in realtime strategy games. In <i>Proceedings of Computer Game Developer Conference.</i>
]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>122725</ref_obj_id>
				<ref_obj_pid>127719</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Teller, S. J., and S&#233;quin, C. H. 1991. Visibility preprocessing for interactive walkthroughs. <i>Computer Graphics 25</i>, 4, 61--68.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[van der Sterren, W. 2001. Terrain reasoning for 3d action games. <i>Game Programming Gems 2</i>, 307--316.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[van Waveren, J.-P. 2001. The quake iii arena bot. Masters thesis, Delft University of Technology.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Voronoi, G. 1907. Nouvelles applications des param&#232;tres continus &#224; la th&#233;orie des formes quadratiques. <i>Journal f&#252;r die Reine und Angewandte Mathematik 133</i>, 97--178.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>234379</ref_obj_id>
				<ref_obj_pid>234347</ref_obj_pid>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Zadeh, A. 1996. A rationale for fuzzy control. In <i>Fuzzy sets, fuzzy logic, and fuzzy systems: selected papers by Lotfi A. Zadeh.</i> World Scientific Publishing Co., Inc., River Edge, NJ, USA, 123--126.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 A Spatial Awareness Framework for Enhancing Game Agent Behaviour Simon Perkins* David Jacka Patrick 
Marais University of Cape Town University of Cape Town University of Cape Town James Gain§ University 
of Cape Town (a) (b) (c) (d) Figure 1: Starting with the geometry de.ning a virtual world in 1a, information 
on connectivity, width and curvature is extracted in 1b. This information is used by agents to enhance 
their behaviour within the virtual world. In 1b and 1c the beige and blue agents use this enhanced behaviour 
to defeat their red opponents. Abstract We describe a framework for providing game agents with awareness 
of the intrinsic spatial qualities of the virtual worlds that they inhabit. We develop a novel data structure 
based on a modi.ed medial axis, which establishes a map­ping between the medial axis and world structures. 
This data structure can be used to perform queries about the width, curvature and connectivityof a space 
within a virtual world. Additional information, such as sampled visibility can also be integrated with 
this framework. An agent-based crowd simulation is adapted to make use of the sensory in­formation provided 
by this data structure and the success of using this information within two game scenarios is eval­uated. 
CR Categories: I.2.10 [Arti.cial Intelligence]: Vision and Scene Understanding [Representations, data 
struc­tures and transforms, Perceptual reasoning] I.4.8 [Image Processing andComputerVision]:SceneAnalysis 
[I.4.7]: Image Processing and Computer Vision Feature Measure­ment Keywords: spatial analysis, agents, 
games 1 Introduction *e-mail: sperkins@cs.uct.ac.za e-mail: djacka@cs.uct.ac.za e-mail: patrick@cs.uct.ac.za 
§e-mail: jgain@cs.uct.ac.za Copyright &#38;#169; 2008 by the Association for Computing Machinery, Inc. 
Permission to make digital or hard copies of part or all of this work for personal or classroom use is 
granted without fee provided that copies are not made or distributed for commercial advantage and that 
copies bear this notice and the full citation on the first page. Copyrights for components of this work 
owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, to 
republish, to post on servers, or to redistribute to lists, requires prior specific permission and/or 
a fee. Request permissions from Permissions Dept, ACM Inc., fax +1 (212) 869-0481 or e-mail permissions@acm.org. 
Sandbox Symposium 2008, Los Angeles, California, August 9 10, 2008. &#38;#169; 2008 ACM 978-1-60558-173-6/08/0008 
$5.00 Arti.cial Intelligence Agents are actors within a virtual world, such as a game environment or 
training simulation. They are important components in the creation of these worlds as they contribute 
to the realism of a virtual experi­ence. Humans modify their behaviour based on their environ­ment. Straight 
and gently curving corridors of space are ap­propriate for running, while sharply curving spaces are 
not. Wide-open spaces provide good vantage points for trying to spot other objects, but are bad spaces 
to hide in. Dimly lit spaces, however, are good to lurk in. Sincehumansstrategisetheirbehaviourbasedontheiren­vironment, 
designers of AI agents may wish to do the same to create compelling agent behaviour. It would be appro­priate 
to design a bird agent to .y in wide-open spaces, but hop or walk in narrow, enclosed spaces. A designer 
trying to make an agent behave in a sneaky manner may wish the agent to favour dimly lit areas with poor 
visibility from other areas. To provide this spatial information to agents, it is necessary to perform 
spatial analysis on the virtual en­vironment. Path.ndingisatypeofspatial analysisthatisspeci.cally designed 
to assist the navigation of agents within a world. However, other types of spatial information are extracted 
during the creation and preprocessing of a virtual world, and while suchinformation may notbe speci.cally 
extracted with agents in mind, it may still be useful to them. For ex­ample the visibility between di.erent 
points in a world al­lows onetoavoid rendering invisibleworld structures[Teller andS´equin 1991]. Thisinformationmayalsobeuseful 
to an agent wishing to strategise about the suitability of a vantage point. Similarly, the lighting in 
various areas of a virtual world iscalculated toimprovetherealism ofarenderedimage,but this information 
may also be useful if agents are designed to reacttolightinginformation. Some agentsmay seebetterin the 
dark and should favour dark areas to gain an advantage over opponents with poor vision. These .elds 
have been well researched, but less work has beendone onprovidinginformationabouttheintrinsicqual­ities 
of a space. For example, the way a space curves is useful to an agent when planning when to accelerate 
and decelerate, especially if its turning behaviour is physically modelled. The width or openess of a 
space is also a useful measure for evaluating proximity to world structures and strategising about wide 
or narrow spaces. We present a novel data structure that provides useful data on higher-order connectivity, 
curvature and width. We also describe the process for automatically generating this structure from a 
world de.ned by 2D polyons. The data from this structure can be combined with data extracted from othersources,such 
asvisibility andlighting.Weimple­ment simple agents and demonstrate how their e.ectiveness can be improved 
by utilising this data in two di.erent sce­narios. In the .rst, racing car agents use data about track 
curvature to improve their racing line. In the second, battle robots use data about path intersections 
to orientate them­selves towards areas of high tra.c. The agents use almost no planning capability since 
the intention of our work is not to improve agent design, but to assist it. Our work has been developed 
in 2D as a preliminary to a full3Dimplementation. Itisworthnotingthatwhilecurrent games are largely rendered 
in 3D, much of the strategy is based on 2D and 2.5D evaluation of worlds. This paper is structured as 
follows: We describe previous work in Section 2 and discuss background material relevent to our work 
in Section 3. Section 4 describes our general approach totheproblem and thecreationof ourdatastruc­ture. 
Section 5 describes the agents that we use to test our work. Section 6 describes our testing and results 
and we conclude in Section 7.  2 Previous Work Navigations Graphs are commonly used to enable agents 
to navigate within a virtual world by providing perception of paths within the world. They provide a 
simpli.ed represen­tation of the spatial areas that an agent may occupy. This reducesthetimeneeded tosearch 
throughpositionsin order toplanroutes and makedecisions. At.rstdesignerscreated navigation graphsby manuallyplacing 
waypointsinthe vir­tual world [Lid´en 2000]. As virtual worlds increase in size and complexity, this 
task became more time-consuming and a candidate for automation. TheQuakeIIIbot[van Waveren 2001]is an 
example of the automation of navigation graph creation. It extracts a navigation graph from a Binary 
Space Partition (BSP) Decomposition of a 3D world. The traversability of the con­vex BSP leaf nodes are 
examined and are linked together to create the graph. The Navigation Mesh [O Neill 2002]sim­pli.es navigation 
graph creation by taking advantage of the fact that 3D games are often set on earthlike terrain with 
humanoid agents. Since it is only possible for these agents to walk on the ground, the navigation mesh 
is constructed by connecting the agent-accessible polygons. As noted by [van der Sterren 2001], such 
navigation algorithms are use­ful for calculating the shortest path between two locations, but they do 
not assist agents in understanding the terrain around them. Pottinger[Pottinger 2000]discusses in.uence 
maps which are created by applying terrain in.uences to a 2D array to determine the best position to 
site a game object. He also discusses grouping logical areas together for AI use via area decomposition 
and the importance of establishing connec­tivity between such areas for path.nding purposes. How­ever, 
this information is derived from features external to theterrain and notfromtheterrainitself. Morgan[Morgan 
2003]evaluatesanumber of algorithmsfordetermining suit­able locations for a soldier to take a cover within 
a virtual world including using Shadow BSP Trees [Chrysanthou and Slater 1995] to detect regions of concealment. 
For reasons of e.ciency, he decides to use a sensor grid which evaluates visibility around an agent at 
di.erent heights to decide if a location may be used for cover. Van der Sterren [van der Sterren 2001] 
discusses terrain reasoning by examining the relationship between waypoints in a navigation graph. The 
connectivity and visibility be­tween waypoints is used to make estimates about the e.ec­tivenessofawaypoint 
asa.ringposition. Thise.ectiveness is then modi.ed by the actual performance of agents at the waypoint. 
Van Der Sterren recognises the need for anno­tating waypoints with higher-order terrain information such 
as visibility and lighting. However, the focus on waypoints inherentlydiscardsintrinsic geometricdatathatmaybeuse­ful 
to agents and introduces resolution issues. For example, the curvature of a section of space would be 
di.cult to re­construct from waypoints and resolution issues would com­plicate the matter further. It 
also di.cult to reason about higher-order connectivity because waypoints are distributed throughouttheworldin 
ordertoprovide agentswith sensory information. The proliferation of waypoints maybe obscure the fact 
that there is a single logical path that all the way­points in a region may belong to. In contrast our 
method focuses on retaining such information since it may be useful to agent designers.  3 Background 
BinarySpacePartition(BSP) Trees[Fuchs et al. 1980] are commonly used in spatial analysis. It is a binary 
tree that recursively divides a space using half-planes. They are typi­cally createdfromaset ofpolygons,usingthepolygonplanes 
as splitting half-planes. BSP trees are commonly used in virtual worlds as they are useful in calculating 
visibility and performing collision detection. Voronoi Diagrams [Voronoi 1907]are another useful tool 
for spatial analysis. Given a set of points S in a plane, a Voronoi diagram partitions the plane into 
convex polygons, each containing one point p . S and having the property that everypointinthepolygonis 
closerto p than any other point in S. Voronoi diagrams have various applications but the one that pertains 
to our work is their use in generating a Medial Axis. In 2D, the medial axis of a shape can be de.ned 
as a set of curves de.ned as the locus of points have have two closestpoints ontheboundaryofashape[Cornea 
andMin 2007]. It canbeusedforrepresenting theshapeof anobject, sinceit constitutesaset ofcurvesthatrunroughlydownthe 
centre of an object. Voronoi diagrams are frequently used to approximatethemedial axis[Ogniewicz 1994a]. 
Thisprocess isusedinpathplanning[Bhattacharya andGavrilova 2007] and roboticmotionplanning[Guibasetal. 
1999;Holleman and Kavraki 2000] to generate a medial axis, from which a navigation graph is derived. 
Amenta et. al [Amenta et al. 1998] use Voronoi Di­agrams to reconstruct surfaces from unorganised sample 
points. They use a process they call Voronoi .ltering to choose faces of the Delauney simplices to remove. 
Of inter­est here is their use of the medial axis to construct a metric that relates sampling density 
to surface curvature, and from which they can prove the accuracy and topological validity (a) Major 
Concavity (b) Minor Concavity Figure 2: Major concavities introduce signi.cant changes into the width 
and curvature of a space and therefore war­rant a skeleton extension into the space. The changes intro­duced 
by minor concavities do not. of their surface reconstructions.  4 Approach We aimtodevelopadatastructurerepresentingtheintrinsic 
qualities of a space, such as width, curvature and connectiv­ity. A medial axis or skeleton is usefulfor 
representing these qualities since in 2D it is a set of curves that run through centre of a space. From 
the skeleton, logical paths through the space can be identi.ed, providing connectivity informa­tion and 
allowing the path curvature to be used to identify the curvature of the surrounding space. We .rstperformaBSPdecomposition 
oftheworld. Since thisstructuresubdividestheworld usinghalf-planes, convex regions representing the solid 
areas of a world can conve­niently be determined and grouped together. The bound­aries of these grouped 
regions can then be identi.ed by traversing the outer boundary of the group. This approach means that 
aleveldesigner can conveniently construct world structures out of separate polygons. It also allows for 
world structures with holes. As we are dealing with geometric representations of vir­tual worlds, we 
adapt the popular geometric technique of extracting amedial axisfromaVoronoidiagram[Ogniewicz 1994a]. 
TheboundariesextractedfromtheBSPprocess are sampled and used asinputtothevoronoitesselationprocess. Medial 
axis transforms tend to overemphasise boundary details [Ogniewicz 1994b] and this leads to the creation 
of .ne vestigial elements that represent complex boundary in­formation. We do not wish to capture this 
structural data directly because it is too .ne: we are interested in capturing the general qualities 
of a space. Consider Figure 2a. The major concavity introduces sig­ni.cant changes to the width, curvature 
and connectivity of the space and should therefore be represented on the skele­ton. The minor concavity 
in Figure 2b does not and should therefore be left o. the skeleton. To this end, we prune sections of 
the skeleton that extend into minor concavities. While the curvature of a space can be easily measured 
from the curvature of the skeleton, it is not necessarily triv­ial to arrive at a de.nition of the width 
of a space. In most cases the shortest distance between the skeleton and world boundary su.ces. However, 
concavities again intro­duce problems, since the furthest point within a concavity can be the appropriate 
point to choose when measuring the width between the skeleton and the world. To deal with this issue, 
we develop a bi-directional mapping between the skeleton and world that ensures that sections of skeleton 
are associated with the correct sections of world boundary. Figure 3: Voronoi Tesselation created from 
orange input points, sampled from the boundary of the gray world struc­tures. The blue edges and vertices 
of this tesselation are linked together in a graph. 4.1 Skeleton Extraction We create a modi.ed medial 
axis from a Voronoi tesselation [Voronoi 1907] of virtual world objects. This medial axis is then pruned 
to .t our de.niton of the skeleton. Sampling polygons: Weperform aBinary SpaceParti­tion (BSP) [Fuchs 
et al. 1980] of the polygons describing the world and extract the convex regions de.ned by the BSP tree 
half-plane intersections. Solid regions represent­ing a distinct world structure are grouped together 
and the counter-clockwiseboundariesofthisstructure areextracted. This boundary is stored as a closed, 
parameterised line. Voronoi Tessellation and Initial Skeleton: Points are sampled on the the parameterised 
boundaries and are used as input points to the Voronoi tesselation process. We use qhull [Barberetal. 
1996]toperformthetesselation. For each input point, a voronoi facet is generated, consisting of a number 
of voronoi vertices. The vertices and the edges between them are linked together in a graph as shown 
in Figure 3. Initially, a voronoi vertex is labelled as o. the skeleton if it lies within a world structure, 
otherwise it is considered tobe ontheskeleton. Agraph edgeisconsidered to be on the skeleton if both 
it s starting and ending point are on the skeleton. Pruning the skeleton: According to our de.nition 
of the skeleton, skeletal sections extending towards minor re­gions of concavity represent too much detail 
and should be pruned. Skeletal sections that extend into major regions of concavity are orthogonal to 
sections of the world. We there­fore test the endpoints to see if the orthonality criterion is met. This 
is accomplished by examining the skeletal end­points, e, that only have one neighbour n on the skeleton. 
An endpoint e is considered strong if there exists at least one adjacent non-skeletal neighbour a such 
that the angle .. between the vectorsen-and -ea liesin theinterval[p 2 -o, p 2 +o] for some toleranceo. 
Otherwise the endpointis consideredto be weak. Weak endpoints areprunedfromtheskeleton. The process continues 
until no endpoints remain or only strongly supported endpoints remain. Figure 4 shows two examples of 
this process. Skeleton Parameterisation: Prior to creating a map­pingbetweenworldboundaries andtheskeleton,parameter­isation 
must be performed to facilitate the mapping. To ac­complish this, we need toparameteriseboth a worldbound­ 
 (a) Before (b) After (c) Before (d) After Figure 4: Two examples of skeleton pruning: 4a shows a number 
of skeletal endpoints with weak supporting neigh­bours. This results in recursive removal until no endpoints 
remain as shown in 4b. In 4c the two endpoints are re­cursively pruned to the con.guration in 4d, where 
only one endpoint remains supported by two strong neighbours. ary and a section of skeleton with the 
intent of creating a correspondencebetweenthetwo. Anintuitiveway ofvisual­ising this is to realise that 
each world boundary is enclosed by apart oftheskeleton. Parameterising aboundary issim­ple since we can 
extract a closed counter-clockwise sequence of points from the BSP tree to describe it. However, our 
skeleton at this point exists as a graph -a set of vertices connected by edges -with no implied direction 
and no way to choose which path to take at intersecting points. To parameterise the section of skeleton 
surrounding a world boundary, we utilise the Voronoi facets derived from the tesselation process. By 
sampling the parameterised world boundaries, a sequence of points is extracted that is input to the voronoi 
tesselationprocess. The tesselationpro­duces a facet for each input point and therefore produces a corresponding 
sequence of facets that intersect the parame­terised boundary. Facets that do not have skeleton vertices 
can be safely ignored. Once the facet ordering has been es­tablished, the ordering of the skeleton points 
lying on the facets can also be established. This sequence of points is then parameterised. This relation 
between the voronoi in­put points and the skeleton points is shown in Figure 5. At the end of the parameterisation 
process a parame­terised world boundary Pb(tb), and a section of parame­terised skeleton Ps(ts), that 
correspond to each other are produced, with 0.0 = tb,ts = 1.0.  4.2 Mapping Generation Once a skeleton 
has been derived from the world structure, and parameterisations for sections of skeleton and world boundaries 
have been established, we create a mapping be­tween the skeleton and world boundaries. The aim of this 
mapping isto establish thebestpossible correspondencebe­tweenpoints ontheskeleton andpoints ontheworldbound­ary 
in order to accurately represent the width of the space. Once again, this is accomplished by examining 
the Voronoi facets that intersect the world boundaries and have an edge Figure 5: Skeleton Parameterisation: 
The orange input points to the Voronoi tesselation process produce the blue voronoi facets, which have 
edges and vertices that lie on the skeleton and are marked in red. The ordering of the input points produces 
a corresponding voronoi facet order­ing, which allows us to establish an ordering of the skeleton points 
surrounding the world structure. on the skeleton. We use these facets to categorise sections of world 
boundary and skeleton into three classes as shown in Figure 6. Perpendicular Sections: Consist of one 
or more con­secutively ordered Voronoi facets which have edges that all intersect the world boundary 
at the same angle. The inter­secting edges are perpendicular to each other. Folded Out Sections: Consist 
of one Voronoi facet that fans outward from the world boundary. The intersecting edges diverge from each 
other as they move from the world boundary towards the skeleton. Folded In Sections: Consist of one or 
more consecutively ordered Voronoi facets which have had weak skeleton end­points pruned away. These 
facets fan in towards skeleton endpoints that have been removed. These sections are used to establish 
local mappings be­tween world and skeleton boundaries and form the building block of the .nal mapping. 
Each section is assigned param­eterised values for the starting and ending skeleton points (tss and tse) 
and starting and endingboundarypoints(tbs and tbe). Two section lists are maintained, a skeleton or­dered 
section list ordered by the tss of each section and a boundary ordered section list, ordered by tbs. 
When performing a mapping from the parameterised skeleton onto the parameterised boundary for some param­eterised 
skeleton value ts, the skeleton ordered section list is used to look up a section such that tss = t = 
tse. Linear interpolation is then performed to derive a corresponding parameterised value tb for the 
boundary. (ts - tss)(tbs - tbe) tb = tss - tse Folded in sections converge onasingleskeletonpoint such 
that tss = tse and linear interpolation fails in this case. To tbs -tbe deal with this we simply map 
tss and tse to 2 . Map­pingfromtheboundary ontotheskeletoncanbeperformed by reversing the process, with 
no special cases needing to be dealt with, since sections never converge onto a single boundary point. 
 Figure 6:Classifying sections:Sections ofspacebetweenthe world boundary and skeleton are classi.ed into 
Folded Out, Folded In and Perpendicular sections, based on the Voronoi facets found within the space. 
  5 Agent Implementation In order to test the spatial awareness framework, we imple­mented an agent-based 
crowd simulation system. The sim­ulation consists of world geometry represented as a set of polygons 
and a crowd of autonomous, embodied agents. Us­ing forward Euler integration, the agents update their 
state at each time step based on their perception of the world as well as constraints imposed on them. 
The autonomous agentsinteractwiththeworld(as well as other simulated agents) through a set of senses 
as shown in Figure 7. These senses take information from the world (suchas world geometry or enemy agent 
positions), as well as information about the local agent (such as turn rate or movement speed), and produce 
a two dimensional output according to the sense interface. This output is used by the agent to steer. 
Thesenses aretailoredforaparticulartypeofagent. Ex­amples include distance to friends, the distance to 
each friendlyagentintheworld, andgeom vision x, the amount of area obscured by world geometry measured 
along the agent s x-axis. The senses may be customised to allow the agentsagreaterorlesserknowledgeoftheworld 
ortoallowa certaintype ofbehaviour. Forexample,the geom vision x sense may be used for navigation purposes 
and the an­gle to friend sense for tactical decision purposes. Figure 7: A visual overview how an agent 
s brain interacts with the world. The input from the senses are grouped into a perception module and 
used as input to the agent s brain. This brain then alters control values for the agent which are in 
turn used to update the agent s internal state. An agent s brain is a collection of fuzzy rules, well 
docu­mentedinthe.eldofcontrolsystems[Zadeh 1996]. These rules may be visualised as a network of fuzzy 
logic nodes. Each rule, of a standard if a then b form, operates onfuzzy variables which, in contrast 
to the standard boolean variety, take onavalueintherange[0,1]. Forafull explanationof fuzzy variable 
and fuzzy inference, the reader is referred to standardtexts[Klir andYuan 1996]. A fuzzi.cation step 
takes the two dimensional input from the agent s senses and determines the values of the fuzzy variables 
used by the brain. This is done in a number of di.erent ways, depending on the properties required, usu­ally 
involving a scaling step followed by a summation or maximum operation. Once the fuzzy inference has been 
conducted, a defuzzi.cation step is required in order to de­termine the real values for the agent s controls 
as well as combine rules that act upon the same control. We use the heightmethodforthisdefuzzi.cation[Mizumoto 
1998]due its computational e.ciency.  6 Results To demonstrate the usefulness of the spatial awareness 
framework, we created two simple games using the crowd simulation agentsdesigned toplay the games atabasiclevel. 
We then created a new group of agents based on the original agents, but with additional rules making 
use of extra sen­sory information provided by the spatial awareness frame­work. By observing theperformanceofthemodi.ed 
agents, we evaluated whether or not the framework has enhanced their behaviour. 6.1 Racing Car Scenario 
The racing car game involves the agents moving around a simple track as e.ciently as possible while avoiding 
the walls. We observed that the basic agent, with inter-agent and wall avoidance behaviour, did not take 
an optimal line around corners. This is due to the agent being purely reac­tive with no knowledge or 
recollection of the way in which the track turns. (a) Racetrack 1 (b) Racetrack 2 (e) Racetrack 5 (f) 
Robot War 1 Figure 8: The virtual worlds used in testing and their skeletons. and the last three for 
testing the robot war scenario. We created a sense which provided information on the curvature of the 
upcoming section of track by considering the angle changes along upcoming sections of skeleton. To accomplish 
this, the polygonal boundaries of the local map­ping sections in the skeleton ordered section list wereplaced 
in a quadtree. During the game, the quadtree was used to lookup thelocalmapping sectioncontaining the 
agent spo­sition. A binary search was performed within the mapping to calculate the skeleton t value 
corresponding to the agent s position. Thechangesinskeletoncurvature afterthe t value werethenprovided 
tothe agent. Using thisinformation,the agent was able to keep the inside wall of the track in view, hugging 
the walls and taking a better line around corners. Wecreated .veracing tracks(SeeFigure 8ato 8e) totest 
theperformanceofthe agents. Eight racingagentstookpart in each race, four of which were normal agents 
and the other four being enhanced with curvature awareness. The agents startingpositionswere arrangedinthetraditionalstaggered, 
two column con.guration, with the curvature aware agents placed at the back. In allof the .ve tracks, 
the spatiallyaware agents overtook all the normal agents by the second lap. Taking the inside line on 
the track shortened the distance they travelled and gave them a better line making it more di.cult for 
normal agents to pass. The four spatially aware agents queried the framework in realtime. The complexity 
of this query is O(logN) since it involves a quadtree lookup followed by a binary search. (c) Racetrack 
3 (d) Racetrack 4 (g) Robot War 2 (h) Robot War 3  The .rst .ve were used for testing the racetrack 
scenario,  6.2 Robot War Scenario To test the use of the spatial awareness framework in a set­ting somewhat 
similar to a .rst-person shooting game, we created a robot war simulation. Each agent was able to shoot 
in the direction that they are facing with some degree of randomness in their accuracy. The basic behaviour 
for a robot agent is the standard agent-and wall-avoidance, as well as a targetting behaviour in which 
an agent turns to face any enemy agent that it sees. In this scenario, the improved agents were given 
a sense of how many skeleton intersection points -locations where three or more skeleton sections connected 
-were visible to them. The rationale for knowledge of these areas being ad­vantageous is that places 
where paths intersect are likely to have a lot of tra.c. This sense is therefore a combination of the 
intrinsic quality of connectivity provided by the frame­work and the secondary quality of visibility. 
To this end, we generated a strategy map from the spatial awareness framework. The strategy map is generated 
by traversing the skeleton and sampling points on it and to either side of it. At each point, we compute 
the number of visible skeleton intersection points and two sense values, best vis angle and position 
goodness. best vis angle is set to the angle at which the most skeleton intersection points can be seen 
in a 30. arc. position goodness is set to the number of intersection points in the 30. divided by the 
number of visible skeleton intersection points. Thus, if a point has many intersection skeleton points 
visible in a single 30. arc, it will have a high position goodness, representing the advantage of being 
able to see many areas of high tra.c. The sample points were placed in a kd-tree Table 1: The outcomes 
of the agent contests. The number of kills for each type of agent are listed for each contest. Contest 
Smart Agent Normal Agent Kills Kills Map 1 Team 5 3 Map 2 Team 5 0 Map 3 Team 5 1 Map 1 Team Reversed 
5 0 Map 2 Team Reversed 5 2 Map 3 Team Reversed 5 0 Map 1 1v1 1 0 Map 2 1v1 1 0 Map 3 1v1 1 0 Map 1 1v1 
Reversed 1 0 Map 2 1v1 Reversed 1 0 Map 3 1v1 Reversed 1 0 [Bentley 1975] to facilitate a fast lookup. 
The .rst sense, best vis angle, was used by adding two rulestothebrainwhich turnthe agenttoward thebest 
angle if there are no enemies currently visible. The second sense, position goodness wasusedtodirectthe 
agenttostop and waitforenemiesinalocation(alsoknown as camping )if it has a high position goodness and 
is not too close to other friendly agents (to stop agents grouping together in one spot). The combination 
of these two behaviours results inthe agentsoccasionallycampinginastrategically valuable area while facing 
in the direction from which an enemy is most likely to come. The contests between the agents took place 
in three vir­tualworlds(SeeFigure 8fto 8h). Sincewewishedtoeval­uate the e.ect of one environmental variable 
or sense at a time, we constructed worlds which did not give an undue advantage to the normal agents. 
For example, we broke up outer circuits on the edge of the world since normal agents tended to congregate 
on them and surprise the more spa­tially aware agents looking inward. While it would be easy enough to 
use additional environmental variables to elimi­nate this advantage, our intention was to assess the 
utility of the extra spatial information to agent behaviour, not to design an optimal agent. For each 
world two di.erent contests took place: A team contest were a groupof .ve smart agents competedagainst 
a group of .ve normal agents and a one-on-one con­test where one smart agent competed against one normal 
agent. Each contest was then repeated with the starting positions reversed in order to ensure that the 
virtual worlds did notundulyfavour oneside. Theresultsofthesecontents are listed in Table 1. In each 
case, the agents with awareness of path intersec­tionpoints won the contest. Additionally, the more spatially 
aware agents camped near positions with a high posi­tion goodness sense, managing to surprise normal 
agents who wandered across areas of high tra.c. Since the agents reactto sensory information,theyhavenohigher-levelplan­ning 
behaviour besides camping.  6.3 Complexity of Data Structure Queries Ineach scenario,themorespatially 
aware agentsqueried the framework in realtime. To lookup curvature information for a racing agent, a 
quadtree lookup was performed followed by a binary search, yielding an O(logN) complexity. To lookup 
up a point sample for the warring agents, a nearest neighbour search was performed on a kd-tree, which 
again produces O(logN)complexity.  7 Conclusion The spatial awarenessframeworkpresentedinthispaperin­troduces 
a new system which allowing agents to query the geometric qualities of the space that they are operating 
in, namely width, curvature and connectivity. To our knowl­edge, this is the .rst system which automatically 
extracts such qualitative geometric information from the environ­ment. An agent crowd simulation system 
was implemented to test whether awareness of these qualities could improve the performance of agents 
within a virtual world. Even though the agents were primarily designed to react tosensoryinformation 
and onlyimplemented themostbasic of planning capabilities, their e.ectiveness was increased by providing 
geometric information. We also showed how the connectivity information derived from our spatial awareness 
framework could be combined with the commonly used vis­iblity information. 8 Acknowledgements This research 
was funded by the National Research Foun­dation of South Africa under grants GUN2053402 and GUN66423. 
 References Amenta, N., Bern, M., and Kamvysselis, M. 1998. A new voronoi-based surface reconstruction 
algorithm. In SIGGRAPH 98: Proceedings of the 25th annual confer­ence on Computer graphics and interactive 
techniques, ACM Press, New York, NY, USA, 415 421. Barber, C., Dobkin, D., and Huhdanpaa, H. 1996. The 
quickhull algorithm for convex hulls. ACM Transactions on Mathematical Software 22,4(Dec), 469 483. Bentley, 
J. 1975. Multidimensional binary search trees used for associative searching. Communications of the ACM 
18, 509 517. Bhattacharya, P., and Gavrilova, M. L. 2007. Voronoi diagram in optimal path planning. In 
ISVD 07: Pro­ceedings of the 4th International Symposium on Voronoi Diagrams in Science and Engineering, 
IEEE Computer Society, Washington, DC, USA, 38 47. Chrysanthou, Y., and Slater, M. 1995. Shadow volume 
bsp trees for computation of shadows in dynamic scenes. In SI3D 95: Proceedings of the 1995 symposium 
on In­teractive 3D graphics, ACM Press, New York, NY, USA, 45 50. Cornea, N. D., and Min, P. 2007. Curve-skeleton 
prop­erties, applications, and algorithms. IEEE Transactions on Visualization and Computer Graphics 13, 
3, 530 548. Member-Deborah Silver. Fuchs, H., Kedem, Z. M., and Naylor, B. F. 1980. On visible surface 
generation by a priori tree structures. In SIGGRAPH 80: Proceedings of the 7th annual conference on Computer 
graphics and interactive techniques, ACM Press, New York, NY, USA, 124 133. Guibas, L., Holleman, C., 
and Kavraki, L. 1999. A probabilistic roadmap planner for .exible objects with a workspace medial axis. 
In Proceedings of the IEEE Inter­national Conference on Intelligent Robots. Holleman, C., and Kavraki, 
L. 2000. A framework for using theworkspacemedial axisinprmplanners. In Pro­ceedings of the International 
Conference on Robotics and Automation, 1408 1413. Klir, G. J., and Yuan, B., Eds. 1996. Fuzzy sets, fuzzy 
logic,andfuzzy systems: selectedpapersby Lot.A.Zadeh. World Scienti.c Publishing Co., Inc., River Edge, 
NJ, USA. Lid´en, L. 2000.Theintegrationof autonomous and scripted behaviour through task management. 
In Arti.cial Intelli­gence and Interactive Entertainment, AAAI Spring Sym­posium. Mizumoto, M. 1998. 
Defuzzi.cation. In Handbook of Fuzzy Computation. IOP Publishing Ltd. Morgan, D. 2003. Algorithmic approaches 
to .nding cover in three-dimensional, virtual environments. Masters the­sis, MOVES Institute. Ogniewicz, 
R. 1994. A multiscale mat from voronoi di­agrams: The skeleton-space and its application to shape description 
and decomposition. Aspects of Visual Form Processing, 430 439. Ogniewicz, R. 1994. Skeleton-space: a 
multiscale shape description combining region and boundary information. In 1994 IEEE Computer Society 
Conference on Computer Vision and Pattern Recognition, 746 751. O Neill, J. 2002. E.cient navigation 
mesh implementa­tion. Journal of Game Development. Pottinger, D. 2000. Terrain analysis in realtime strat­egy 
games. In Proceedings of Computer Game Developer Conference. Teller, S. J., and S´Visibility prepro­equin, 
C. H. 1991. cessing for interactive walkthroughs. Computer Graphics 25, 4, 61 68. van der Sterren, W. 
2001.Terrainreasoningfor3d action games. Game Programming Gems 2, 307 316. van Waveren, J.-P. 2001.Thequakeiii 
arenabot.Masters thesis, Delft University of Technology. Voronoi, G. 1907. Nouvelles applications des 
param`etres continus `eoriedesformesquadratiques. Journal f¨ ala th´ur die Reine und Angewandte Mathematik 
133, 97 178. Zadeh, A. 1996. A rationaleforfuzzy control. In Fuzzy sets, fuzzy logic, and fuzzy systems: 
selected papers by Lot. A. Zadeh. World Scienti.c Publishing Co., Inc., River Edge, NJ, USA, 123 126. 
 
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
		<article_sponsors>
			<funding_agency>National Research Foundation of South Africa</funding_agency>
			<grant_numbers>
				<grant_number>GUN2053402GUN66423</grant_number>
			</grant_numbers>
		</article_sponsors>
	</article_rec>
	<article_rec>
		<article_id>1401847</article_id>
		<sort_key>40</sort_key>
		<display_label>Pages</display_label>
		<pages>8</pages>
		<article_publication_date>08-09-2008</article_publication_date>
		<seq_no>3</seq_no>
		<title><![CDATA[Declarative processing for computer games]]></title>
		<page_from>23</page_from>
		<page_to>30</page_to>
		<doi_number>10.1145/1401843.1401847</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1401847</url>
		<abstract>
			<par><![CDATA[<p>Most game developers think of databases as nothing more than a persistence solution. However, database research is concerned with the wider problem of <i>declarative processing.</i> In this paper we demonstrate how declarative processing can be applied to computer games. We introduce the <i>state-effect</i> pattern, a design pattern that allows game developers to design parts of their game declaratively. We present SGL, a special scripting language which supports this design pattern and which can be compiled to a declarative language like SQL. We show how database techniques can process this design pattern in a way that improves performance by an order of magnitude or more. Finally, we discuss some design decisions that developers must make in order to adopt this pattern effectively.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[databases]]></kw>
			<kw><![CDATA[games]]></kw>
			<kw><![CDATA[scripting]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>D.3.2</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10011007.10011006.10011008.10011009</concept_id>
				<concept_desc>CCS->Software and its engineering->Software notations and tools->General programming languages->Language types</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10011007.10011006.10011008.10011009</concept_id>
				<concept_desc>CCS->Software and its engineering->Software notations and tools->General programming languages->Language types</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<person_id>P1100686</person_id>
				<author_profile_id><![CDATA[81100616621]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Walker]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[White]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Cornell University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1100687</person_id>
				<author_profile_id><![CDATA[81365594225]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Benjamin]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Sowell]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Cornell University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1100688</person_id>
				<author_profile_id><![CDATA[81452607023]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Johannes]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Gehrke]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Cornell University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1100689</person_id>
				<author_profile_id><![CDATA[81100529925]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Alan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Demers]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Cornell University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>1376739</ref_obj_id>
				<ref_obj_pid>1376616</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Albright, R., Demers, A., Gehrke, J., Gupta, N., Lee, H., Keilty, R., Sadowski, G., Sowell, B., and White, W. 2008. SGL: A scalable language for data-driven games (demonstration paper). In <i>Proc. SIGMOD.</i>
]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>597051</ref_obj_id>
				<ref_obj_pid>597007</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Bohannon, P., Lieuwen, D., Rastogi, R., Silberschatz, A., Seshadri, S., and Sudarshan, S. 1997. The architecture of the Dal&#237; main-memory storage manager. <i>Multimedia Tools Appl 4</i>, 2, 115--151.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Boncz, P., and Kersten, M. 1995. Monet: An impressionist sketch of an advanced database system. In <i>Proc. BIWIT.</i>
]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1287389</ref_obj_id>
				<ref_obj_pid>1287369</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Carney, D., &#199;etintemel, U., Cherniack, M., Convey, C., Lee, S., Seidman, G., Stonebraker, M., Tatbul, N., and Zdonik, S. 2002. Monitoring streams --- a new class of data management applications. In <i>Proc. VLDB.</i>
]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Demers, A., Gehrke, J., Panda, B., Riedewald, M., Sharma, V., and White, W. 2007. Cayuga: A general purpose event monitoring system. In <i>CIDR</i>, 412--422.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>627398</ref_obj_id>
				<ref_obj_pid>627276</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Dewitt, D., Ghandeharizadeh, S., Schneider, D., Bricker, A., Hsiao, H., and Rasmussen, R. 1990. The gamma database machine project. <i>IEEE Trans. on Knowledge and Data Engineering 2</i>, 1, 44--62.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Dunki, Q. 2008. Streaming open world pathfinding. In <i>Proc. GDC.</i>
]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Ensemble Studios. 2000. <i>Computer Player Strategy Builder Guide, AI Expert Documentation for Age of Empires II: The Age of Kings.</i> Ensemble Studios.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Fu, D., Houlette, R., and Jensen, R. 2003. A visual environment for rapid behavior definition. In <i>Proc. Conference on Behavior Representation in Modeling and Simulation.</i>
]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1007594</ref_obj_id>
				<ref_obj_pid>1007568</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Govindaraju, N., Lloyd, B., Wang, W., Lin, M., and Manocha, D. 2004. Fast computation of database operations using graphics processors. In <i>Proc. SIGMOD.</i>
]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Kruszewski, P., and van Lent, M. 2007. Not just for combat training: Using game technology in non-kinetic urban simulations. In <i>Proc. Serious Game Summit, GDC.</i>
]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Liebgold, D. 2008. Adventures in data compilation and scripting for uncharted: Drake's fortune. In <i>Proc. GDC.</i>
]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1025210</ref_obj_id>
				<ref_obj_pid>1025115</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[McNaughton, M., Cutumisu, M., Szafron, D., Schaeffer, J., Redford, J., and Parker, D. 2004. ScriptEase: Generative design patterns for computer role-playing games. In <i>Proc. ACE.</i>
]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>872855</ref_obj_id>
				<ref_obj_pid>872757</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Motwani, R., Widom, J., Arasu, A., Babcock, B., Babu, S., Datar, M., Manku, G. S., Olston, C., Rosenstein, J., and Varma, R. 2003. Query processing, approximation, and resource management in a data stream management system. In <i>Proc. CIDR.</i>
]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Nguyen, H., Ed. 2007. <i>GPU Gems</i>, vol. 3. Addison-Wesley.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[O'Brien, J., and Stout, B. 2007. Embodied agents in dynamic worlds. In <i>Proc. GDC.</i>
]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1239658</ref_obj_id>
				<ref_obj_pid>1239655</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Pike, R., Doward, S., Griesemer, R., and Quinlan, S. 2005. Interpreting the data: Parallel analysis with Sawzall. <i>Scientific Programming Journal 13</i>, 4, 227--204.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Posniewski, S. 2007. Massively modernized online: MMO technologies for next-gen and beyond. In <i>Proc. Austin GDC.</i>
]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Reynolds, C. 1999. Steering behaviors for autonomous characters. In <i>Proc. GDC.</i>
]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>671803</ref_obj_id>
				<ref_obj_pid>645915</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Stonebraker, M., Katz, R., Patterson, D., and Ousterhout, J. 1988. The design of XPRS. In <i>Proc. VLDB.</i>
]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1247486</ref_obj_id>
				<ref_obj_pid>1247480</ref_obj_pid>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[White, W., Demers, A., Koch, C., Gehrke, J., and Rajagopalan, R. 2007. Scaling games to epic proportions. In <i>Proc. SIGMOD</i>, 31--42.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1007617</ref_obj_id>
				<ref_obj_pid>1007568</ref_obj_pid>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Zhu, Y., Rundensteiner, E., and Heineman, G. 2004. Dynamic plan migration for continuous queries over data streams. In <i>Proc. SIGMOD.</i>
]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Declarative Processing for Computer Games Walker White Benjamin Sowell Johannes Gehrke Alan Demers 
Cornell University Cornell University Cornell University Cornell University wmwhite@cs.cornell.edu sowell@cs.cornell.edu 
johannes@cs.cornell.edu ademers@cs.cornell.edu Abstract Most game developers think of databases as nothing 
more than a persistence solution. However, database research is concerned with the wider problem of declarative 
processing. In this paper we demonstrate how declarative processing can be applied to computer games. 
We introduce the state-effect pattern, a design pattern that allows game developers to design parts of 
their game declaratively. We present SGL, a special scripting language which supports this design pattern 
and which can be compiled to a declarative language like SQL. We show how database techniques can process 
this de­sign pattern in a way that improves performance by an order of magnitude or more. Finally, we 
discuss some design decisions that developers must make in order to adopt this pattern effectively. CR 
Categories: D.3.2 [Programming Languages]: Language Classi.cations [Specialized application languages] 
Keywords: Games, Scripting, Databases 1 Introduction Scalability is a fundamental problem in the development 
of com­puter games. Players constantly demand more be it more poly­gons, more physics particles, more 
AI behaviors, or, in the case of massively multiplayer online games (MMOs), more players. Scalability 
has long been a focus of the database community. How­ever, the game development industry has done little 
to exploit database research in this area. Most developers think of databases as a persistence solution, 
designed to store and read game objects from disk. As such, almost all database usage in games design 
has been within the development of MMOs. However, the advantages of databases are not limited to persistence. 
It is true that commercial databases focus on persistence, but that is because this is what their customers 
have demanded. Database research has dealt with the much larger issue of processing declara­tive languages. 
Declarative languages, such as SQL, transform one collection of data to another without specifying the 
exact side ef­fects in-between. Because the query optimizer is free to process the transformation however 
it wants, operations written declaratively can be highly optimized and parallelized, often with orders 
of mag­nitude improvement in performance. It would be both dif.cult and unnatural to write all of a game 
in a declarative language. However, there are large subsystems of com­puter games that are amenable to 
being processed declaratively. For example, game developers have designed algorithms to parallelize Copyright 
&#38;#169; 2008 by the Association for Computing Machinery, Inc. Permission to make digital or hard copies 
of part or all of this work for personal or classroom use is granted without fee provided that copies 
are not made or distributed for commercial advantage and that copies bear this notice and the full citation 
on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting 
with credit is permitted. To copy otherwise, to republish, to post on servers, or to redistribute to 
lists, requires prior specific permission and/or a fee. Request permissions from Permissions Dept, ACM 
Inc., fax +1 (212) 869-0481 or e-mail permissions@acm.org. Sandbox Symposium 2008, Los Angeles, California, 
August 9 10, 2008. &#38;#169; 2008 ACM 978-1-60558-173-6/08/0008 $5.00 physics simulations with GPUs 
[Nguyen 2007]. Much of this work involves custom pipelines that are very similar to techniques devel­oped 
decades ago by the database community. However, instead of a general pipeline model that can be reused 
over and over again, game developers come up with a distinct solution every time they encounter a new 
algorithm. With a more principled approach, the time spent engineering this pipeline could be freed up 
for more time improving game play. Declarative processing opportunities are not just limited to physics 
algorithms. The authors have published work demonstrating how declarative processing can improve the 
computational performance of scripted character AI by an order of magnitude [White et al. 2007]. We believe 
there are many other possibilities for declara­tive processing in games. By providing game developers 
with tools to design declaratively, we can help them overcome many of the dif.culties in game scalability. 
The aim of this paper is to introduce our work on declarative pro­cessing to the game design community. 
In doing so, we explore the design decisions necessary to adequately leverage this processing model. 
In this paper, we make the following contributions: In Section 2 we show how declarative processing 
can be ap­plied to games using a novel design pattern, which we call the state-effect pattern.  In Section 
3 we present SGL, a custom scripting language for the state-effect pattern. SGL allows designers to bene.t 
from database-style optimizations without any knowledge of SQL or other query languages.  In Section 
4 we provide an overview of the optimization tech­niques that a query processor can apply to the state-effect 
pat­tern. These techniques can result in orders of magnitude im­provement in performance.  In Section 
5 we identify and discuss some of the challenges that designers may face in adopting the state-effect 
pattern.  In Section 6 we give an overview of related work. Finally, we con­clude with some directions 
for future work in Section 7.  2 The Declarative Processing Model One of the main ways in which declarative 
processing achieves per­formance gains is by intentionally limiting expressiveness. In other words, some 
declarative languages are not as expressive as tradi­tional programming languages, but they can be more 
ef.ciently op­timized. A canonical example of this is the relational algebra, a popular declarative language 
implemented by SQL. The relational algebra does not support arbitrary iteration: it does not have for 
or while loops and does not support recursion. The only type of iteration that it does support is the 
for-each loop, which iterates through the elements in a list. This specialized type of iteration called 
a join in the database literature has been heavily researched and highly optimized. As we show throughout 
this paper, this weaker form of iteration is still capable of expressing a wide range of com­plex and 
interest behavior. Furthermore, restricting ourselves to this form of iteration can result in substantial 
performance bene.ts. To provide games with these performance bene.ts, we need to iden­tify and separate 
joins from arbitrary iteration in the game logic. In general, this is a very dif.cult problem. A better 
solution is to identify design patterns that are adaptable to our optimizations and to provide tools 
for processing these patterns. In this section we present a basic design pattern that allows for extensive 
declarative optimizations. In addition, we illustrate this pattern with several examples showing its 
wide range of applicability. 2.1 The State-Effect Design Pattern We call our design pattern the state-effect 
pattern. In practice, this pattern is applied to part or all of the game simulation loop (i.e. the part 
of the game that processes object behavior and updates the game state). In this pattern, we separate 
the attributes of the game objects into two disjoint types: states and effects. Naively, states are values 
that change only at the end of the simulation time step, but which remain constant during the main computational 
phase. Effects, on the other hand, are ephemeral values that can change within the simulation loop as 
the object interacts with other objects in the game. In addition to separating states and effects, we 
put restrictions on how these two types of object attributes can interact with one another. Before we 
outline the pattern in detail, we .rst consider an example that is already familiar to most game developers: 
a particle system. In its simplest form, the attributes of an object of a particle system are mass, volume, 
position, velocity and (possibly) acceleration. In addition, during a single simulation time step, each 
particle has a force attribute which represents the interactions with all of the other objects in the 
particle system. The simulation loop computes this force attribute, and uses it to update the other particle 
attributes in the following way: (1) It sums up all of the forces acting upon each particle. (2) From 
these forces, it computes the new acceleration and/or velocity for each particle. (3) It tentatively 
moves the particles each to their new position according to the acceleration and/or velocity. (4) Finally, 
it searches for any collisions that occurred during the process, and backs them out as necessary.  Ignoring 
for now the collision detection and resolution phase in step (4), we can easily separate this process 
into states and effects. The force attribute is an effect that is computed from interactions with other 
objects. It can be computed using a join, as we just loop over all the other game objects with a for-each 
and sum the results together. The other attributes position, velocity, acceleration are only updated 
at the end of the loop and therefore may be clas­si.ed as state. Furthermore, state values are updated 
using only a simple mathematical calculation from the force attribute and the existing state values; 
no further iteration is required. A powerful feature of this design is that, because the state is not 
up­dated until the end of the simulation loop, the force calculations can all be isolated from one another. 
We can evaluate the game objects in any order, or even in parallel, and still get the same answer. This 
feature has been heavily utilized by game engineers to parallelize physics computations on modern GPUs 
[Nguyen 2007]. The abil­ity to do order-independent processing is the crucial property that allows us 
to optimize this calculation with database techniques. Given the particle system as our motivation, we 
now outline the state-effect pattern in more detail. It consists of the following parts: Separation of 
object attributes into states and effects. State attributes remain unchanged for the majority of a sim­ulation 
time step, only changing at the end. Effect attributes, on the other hand, support intermediate computation. 
They can change within the simulation loop, but are reset at the beginning of every time step. In those 
cases where we want an attribute to be both a state and an effect, we make a separate attribute for each 
role. In the particle system example, force is an effect while all other attributes are state. Rules 
for combining effects within a single time step. Intuitively, effects represent actions that a game object 
can perform either on itself or on other objects. These effects can include actions from intelligent 
agents, such as the result of a magic spell, or actions from inanimate objects, such as the force exerted 
by one particle on another. As all actions in a single time step are applied simultaneously, we need 
order­independent rules for combining these effects to produce a single net effect. In our particle system 
example, summation is the rule for combining individual force effects. This rule is independent of order 
since summation is associative and commutative. (Query Phase) Speci.cation of object interactions. For 
each game object, we need instructions specifying what effects it either generates or incurs. If we were 
to use a scripting language to implement our pattern, these instruc­tions would be scripts attached to 
the individual game objects. These instructions have one major restriction; the query phase may not have 
any form of iteration other than a join (e.g. a for-each loop). In our particle system example, the query 
phase consists of the mathematical formulae computing the force between pairs of particles. (Post-processing 
Phase) Speci.cation for updating state. At the end of the simulation loop, we need instructions for how 
to compute the new state from the effects that we have. For ef.ciency, we would prefer that the instructions 
be simple calculations done in straight-line code. However, to make it easier to integrate this pattern 
into the rest of the game, we place no restrictions on this part of the pattern; it may even include 
instructions that cannot be computed declaratively. In our particle system example, steps (2) and (3) 
are examples of simple post-processing which updates the state from the effect. Furthermore, since there 
are no restrictions on what we do in the post-processing phase, we can include step (4), which may involve 
unsafe iteration. The names query phase and post-processing phase are chosen to re.ect the ways in which 
we process these steps. Suppose that each of our game objects were a row in a database table. Because 
of our restrictions on the query phase, we could process it as a single database query that returns a 
new table of effects on each of these objects. The post-processing phase then uses a standard program­ming 
model to update these objects using the values in this effect table. As we show in Section 4, the bene.ts 
of using traditional database techniques to speed up the query phase can be enormous. The primary dif.culty 
with this design pattern is that we have to be careful with what we put in the post-processing step; 
it can easily become a catch-all step for parts that are hard to separate. There is little advantage 
for our pattern in the post-processing phase, as it is handled normally without declarative optimizations. 
Hence, if we put too much in this phase, the cost of this phase can dominate the optimizations described 
in Section 4. We discuss this issue in more detail in Section 5.2.  2.2 An Illustrative Example While 
particle systems is a natural example of the state-effect pat­tern, the pattern is by no means restricted 
to physics applications. For a more sophisticated example, we consider the case of scripted character 
AI. We apply the state-effect pattern to design a real-time strategy game in which every unit is individually 
scripted. First we de.ne the state and effects. While our units have many attributes, the important ones 
for our example are as follows: State: player, unit type, health, x position, y position  Effects: 
damage, healing, x velocity, y velocity,  We use sum as our rule to combine the damage effects. That 
way, if the unit is attacked by multiple opponents, all the damage effects stack on on another. Similarly, 
we use sum as the combination rule for the velocity components. On the other hand, we use a different 
rule for healing. which we model after the healing auras from War­craft III. These auras do not stack 
with one another; at each time step, a unit receives healing only from the active aura of the great­est 
power. Hence our combination rule for healing is maximum, not sum. This gameplay feature illustrates 
why we separated dam­age and healing into two separate effects, even though they are both used to update 
the health state. Next we specify the query phase. To keep our example simple, we limit ourselves to 
two unit types, healers and archers. We assign them the following simple behavior as part of the query 
phase: If the unit is an archer, search for the weakest enemy unit (e.g. the one with the least health) 
within .ring range.  If no such unit is found, set the velocity effects to move towards some prede.ned 
location (e.g. the enemy base, the mouse click location, etc.).  If a unit is found, assign some .xed 
amount of damage to the enemy unit.   If the unit is a healer, apply a .xed amount of healing to all 
units in range of the healing aura.  Finally our post-processing stage updates the game state in the 
ob­vious way. That is, we add the velocity to the position to get the new position. Furthermore, we subtract 
the total damage from the health, but add the healing. Because we have used the state-effect pattern, 
we can express the query phase as a database query. Figure 1 illustrates how to repre­sent our simple 
example as a nested query in SQL (for this example, DIST() and IN RANGE() are prede.ned functions introduced 
to simplify the query). This query demonstrates a serious issue with our design pattern: the query is 
unreadable to anyone without extensive SQL experience. Moreover, the SQL query expresses the behavior 
for all types of units, making it dif.cult for the game developer to program indi­vidual character behavior. 
In order to use this design pattern ef­fectively, game designers will need tools to specify character 
and object behavior individually, but then compile all this behavior into a single declarative expression 
for optimization.  3 The SGL Scripting Language The simplest type of tool that we can provide to game 
developers is a scripting language. Developers have a long history of creating highly specialized and 
restricted scripting languages. Sometimes these restrictions are imposed to make processing ef.cient, 
such as Microsoft s rule speci.cation language in Age of Kings [Ensem­ble Studios 2000]. Other times 
limitations are imposed in order to SELECT U.PLAYER, U.TYPE, U.HEALTH, U.X, U.Y, SUM(E.DAMAGE), MAX(E.HEAL), 
SUM(E.VX), SUM(E.VY) FROM Units U, (SELECT T.KEY, 0 as DAMAGE, HAMOUNT AS HEAL, 0 as VX, 0 as VY FROM 
Units T, Units H WHERE H.TYPE="Healer" AND H.PLAYER = T.PLAYER AND IN_RANGE(T,H) UNION SELECT T.KEY, 
0 as DAMAGE, 0 as HEAL, (GOAL_X-T.X)/DIST(T.X,GOAL_X) AS VX, (GOAL_Y-T.Y)/DIST(T.Y,GOAL_Y) AS VY FROM 
Units T, Units A WHERE NOT EXISTS (SELECT * FROM Units T WHERE IN_RANGE(T,A) ) UNION SELECT MIN(T.KEY), 
DAMOUNT as DAMAGE, 0 as HEAL, 0 as VX, 0 as VY FROM Units T, Units A WHERE IN_RANGE(T,A) AND A.TYPE = 
"Archer" AND A.PLAYER <> T.PLAYER AND T.HEALTH = ANY(SELECT MIN(S.HEALTH) FROM Units S WHERE IN_RANGE(S,A) 
AND A.PLAYER != S.PLAYER ) ) as E WHERE U.KEY = E.KEY GROUPBY U.KEY Figure 1: SQL Expression for the 
RTS Query Phase keep designers from introducing unsafe behavior: Cryptic Studios removed iteration from 
one of the scripting languages for City of Heroes/City of Villains after designers repeatedly introduced 
in.­nite loops into the game [Posniewski 2007]. In our case, the script­ing language is introduced to 
help the game engine recognize uses of the state-effect pattern and optimize them accordingly. We call 
our scripting language the Scalable Games Language (SGL), because of its ability to process large numbers 
of game ob­jects. SGL consist of two types of .les data .les and script .les. The data .les de.ne the 
data types ( classes ) in our lan­guage, while the script .les de.ne the behavior for a given data type 
during the query phase. Every game object accessed by a script must have an associated data .le in order 
to make its attributes accessible. The list of at­tributes need only include those that are accessed 
by the scripting language; game objects may have other attributes that are used by the game engine proper, 
but are not visible to the scripting language. Figure 2 shows an example of a data .le for the RTS example 
in Section 2.2. The format is similar to a C++ class. The data type comprises several .elds, which are 
explicitly separated into states and effects. While later versions of SGL will support a wider array 
of .eld types, currently a .eld may either be a number, another data type speci.ed by a data .le, or 
an (unordered) set of values (e.g. Set(Unit)). For state .elds, the data .le speci.es initial values 
for new objects allocated by the script. Effect .elds, on the other hand, specify only a combination 
function. Currently SGL supports only built­in combination rules: sum, minimum, maximum, and average 
for numbers, and union for set types. Object types are combined by priority functions, which take a set 
of objects and select a unique element from the set according to speci.ed rules. The most basic priority 
function is priority; this function uses an opaque priority value built into the system. Custom priorities 
are introduced using the functions argmin and argmax. These func­ class Unit { state: number player 
= 0; number type = 0; number x = 0; number y = 0; number health = 0; Unit target = null; effects: number 
vx : avg; number vy : avg; number damage : sum; number healing : max; Unit acquired : priority; update: 
x = x + vx; y = y + vy; health = health -damage; target = (acquired != null ? acquired : target); } Figure 
2: Sample Datatype Declaration tions take an expression (EXP) and a set of objects. The expres­sion is 
evaluated on each object in the set, and the function returns the one with the minimum (or maximum) value. 
For example, we could use argmin to chose the enemy unit that is closest to our character; we simply 
provide the expression computing distance to the function argmin. In those cases where there is more 
than one minimum (or maximum), these functions use the built-in priority value to break ties. In addition 
to attributes, the data .le also speci.es update rules. The update rules are expressions de.ned in terms 
of the effect and state .elds. They are used to de.ne the new value of each state .eld at the end of 
the post-processing stage. For example, in Fig­ure 2, the update rules use the velocity effects to adjust 
the position state. Therefore SGL can handle very simple post-processing in­structions, like steps (2) 
and (3) in our particle system example. For more complicated post-processing operations, we rely on the 
integration between SGL and the game engine. The game engine invokes SGL by calling a function which 
processes a single step of the query phase, followed by an application of the update rules. The game 
engine is free to do whatever operations it wants to the game objects before invoking the script again. 
Thus we can safely ignore more complex post-processing examples such as step (4) in our particle system 
example. The script .les are structured to look like an imperative program­ming language, even though 
they are processed declaratively. This is intended to make the scripting language more accessible to 
de­signers who have no experience with declarative languages. Each script .le is associated with a data 
type, and all of the .elds of that data type may be accessed in that script without a dot. In addition, 
.elds of other objects are accessed using the traditional dot selec­tion found in most object-oriented 
languages. For example, in a script associated with a unit type, x is the x position of the unit executing 
the script, while target.x is the x position of the current combat target of the script executor. The 
scripting language has many features common to scripting lan­guages, such as if-else conditionals. Furthermore, 
it has ex­pressions for manipulating numbers, objects, and sets of objects. For brevity, we focus on 
the most important parts of the script. The primary purpose of the script is to assign values to the 
effect .elds. A script may assign a value to an effect .eld of the object executing the script, or to 
an effect .eld of another object. In order to process the script as ef.ciently as possible, there is 
no guarantee on the order in which the values are assigned to the effect .elds; let (number dist = (x-target.x)*(x-target.x)+ 
(y-target.y)*(y-target.y)) in { if (dist < ATTACK_RANGE) { // If in range, attack. target.damage <-DMG_AMOUNT; 
} else { // Else move closer (use unit velocity) vx <-(target.x-x)/dist; vx <-(target.y-y)/dist; } } 
Figure 3: Assigning Effect Values if more than one value is assigned to an effect value, then these values 
are combined using the rules speci.ed in the data .le. Addi­tionally, in order to prevent hazardous side 
effects such as reading effects assigned out of order, effect .elds may never be read they are write-only. 
In essence, our effect .elds work like the aggregate variables found in Sawzall, Google s highly parallelizable 
data pro­cessing language [Pike et al. 2005]. Indeed, our notation for writing to an effect .eld, <- 
, is the same as Sawzall s. SGL provides local variables to store and access the results of inter­mediate 
computation. However, as in a functional language, these variables may never be reassigned after they 
are de.ned. As long as there is no iteration in the script, this does not actually place any restrictions 
on the designer. Furthermore, since we handle itera­tion specially, we believe this is an acceptable 
trade-off in language expressiveness to make processing simpler. To introduce an intermediate variable 
in a SGL, we use the syntax let (TYPE)(identifer) = (EXP) in {(BLOCK)} The scope of this variable is 
the code block surrounded by the braces. Figure 3 shows the use of a let declaration to represent a unit 
choosing between two actions, depending on the distance between it and its combat target. SGL supports 
multiple variable assignments in a single let statement; they must all be part of a comma-separated list. 
In addition to let statements, SGL supports a limited form of iter­ation. Again, in order to improve 
our ability to optimize the execu­tion of a script, we wish to avoid variables that can be both read 
and written arbitrarily. Therefore, our design of this iteration loop itself follows the state-effect 
pattern. We call our iteration accum-loops, and they have the syntax accum (TYPE)(identifier)1 with (COMBINATOR)over 
(TYPE)(identifier)2 from (EXP){ (BLOCK)1 } in {(BLOCK)2 }Naively, this loop uses the .rst code block, 
(BLOCK)1, to iterate over the elements in the set (EXP), and then makes the results of that iteration 
available to the second code block, (BLOCK)2. Within the .rst code block, the variable (identi.er)1 is 
treated as an effect .eld. We make no guarantees on the order in which the accumu­lation loop is processed; 
the elements in (EXP) can be processed in any order, or even in parallel. Therefore, within (BLOCK)1, 
the variable (identi.er)1 may never be read, and values are assigned to it using the same <- operator 
as effect .elds. At the completion of (BLOCK)1, the accum-loop combines all of the values assigned to 
(identi.er)1 using the combination func­tion (COMBINATOR). This combinator function can be any of the 
functions we used for effect .elds. Once these values are com­bined, they may be read from the variable 
in the second code block, (BLOCK)2. As with a let statement, the variable (identi.er)1 may never be reassigned 
in (BLOCK)2; it is read-only. // Compute the minimum health of a possible target accum number healthvalue 
with min over Unit u from UNIT { let (number dist = (x-u.x)*(x-u.x)+ (y-u.y)*(y-u.y)) in { // Only select 
enemies in range if (u.player != player &#38;&#38; dist < ARCHER_RANGE) { healthvalue <-u.health; } } 
in { // Find the unit with that health. accum Unit weakest with priority over Unit w from UNIT { let 
(number dist = (x-w.x)*(x-w.x)+ (y-w.y)*(y-w.y)) in { // Be sure to select with same rules if (w.player 
!= player &#38;&#38; dist < ARCHER_RANGE &#38;&#38; w.health = healthvalue) { weakest <-w; } } } in { 
if (weakest != null) { acquired <-weakest; } } } Figure 4: Accum-Loop Speci.cation of Target Acquisition 
Figure 4 illustrates the use of two accum-loops to specify the target acquisition behavior of our archers 
in Section 2.2. The .rst accum­loop .nds the minimum health of an acceptable target in range, and the 
second searches for a target with that health. This is not the most ef.cient way to express this particular 
behavior a more ef.cient way would use the argmin priority function but it is a simple example showing 
how accum-loops can be coordinated to produce interesting behavior. Furthermore, a typical query optimizer 
can recognize that these two accum-loops have similar structure and combine them automatically. All of 
our language structures have been designed so that they can be compiled into the relational algebra, 
the declarative language used by SQL. As a result, the SGL compiler can gather all of the script .les 
and compile them into a single database query. As we show in the next section, this allows us to improve 
script perfor­mance by orders of magnitude. Thus while SGL does have some very unusual language features 
 such as the accum-loops the performance enhancements make their adoption worthwhile.  4 Advantages 
of Declarative Processing The advantage of representing the query phase by a database query is that we 
can apply query optimization technology to process it ef.ciently. While no commercial query optimizer 
is targeted at pre­cisely the kind of workload found in computer games, there is a substantial body of 
research on in-memory databases [Boncz and Kersten 1995; Bohannon et al. 1997], and more recent research 
has focused on optimizing queries over streams of data [Carney et al. 2002; Motwani et al. 2003; Demers 
et al. 2007]. When combined with traditional database query optimization techniques, this work can be 
directly applied to game processing. In this section we explain a few ways in which known database technology 
can be used to process the state-effect design pattern ef­.ciently. These techniques are not new; indeed, 
one of the strengths of the state-effect pattern is that we have so many existing optimiza­tion techniques 
to choose from. We present them here just to give the reader a sense of the advantages of adopting this 
pattern. 4.1 Aggregate Indexing A well-known dif.culty encountered in the design of computer games is 
the n 2-problem . This occurs when one game object needs to iterate over most or all of the other game 
objects in order to determine its behavior. For example, suppose we want to design a game character that 
runs in fear if it encounters a large number of marching skeletons. The probability that the character 
runs is deter­mined by the number of skeletons it sees, so the character needs to count skeletons. In 
a naive implementation, the game engine would take each character and enumerate all the game objects 
visible to that character, incrementing a counter for each skeleton encoun­tered. If a character can 
see most of the other game objects, this process requires O(n) steps. Thus, in a situation where there 
are O(n) skeleton-phobic characters, each of which can see most of the other game objects, the total 
processing time is O(n 2). This cannot be remedied by computing the number of skeletons only once, as 
different characters may have different .elds of vision resulting in different skeleton counts. Examples 
like this arise frequently in practice. Military simula­tions, in particular, often encounter cases in 
which everyone sees everyone else [Kruszewski and van Lent 2007]. Database tech­nology can help us here. 
In the state-effect pattern, enumeration is done using accum-loops, and at the end of an accum-loop the 
effect results are combined into a single value using an aggregate function like sum or max. Databases 
have developed aggregate pro­cessing techniques that are often much faster than the naive O(n) per query. 
One common solution is the aggregate index, which ef­fectively pre-computes the aggregate on subsets 
of the data in such a way that the result for any query can be computed by combining a small number of 
the pre-computed aggregates. In many instances, an aggregate index can reduce the cost of our accum-loop 
compu­tation from O(n 2) to O(n log n). A good query optimizer can usually infer when to use an aggre­gate 
index by static analysis of a database query. Thus, the game designer does not need to worry about building 
and maintaining a custom index for each new application; the query optimizer handles it automatically. 
In an early prototype of SGL, the authors developed a battle simula­tion in a simple RTS that demonstrated 
the advantages of aggregate indexing [White et al. 2007]. The simulation was designed to have very complex 
behavior, with each unit interacting with large numbers of other units. For example, armies of archers 
continually polled the locations of both enemy units and allied knights, so that they were always able 
to hide behind the knights for cover. In addi­tion, healing units distributed themselves among allied 
units so that their healing auras had maximum effectiveness. A large number of aggregate indices were 
required to implement this behavior. For exact details, we refer the reader to our original paper. Timing 
results for this simulation are shown in Figure 5. This graph plots the number of simulated units against 
total processing time for 500 simulation steps, comparing the naive algorithm to the use of aggregate 
indexing. Figure 5 clearly demonstrates the value of aggregate indexing. The overhead of building and 
maintaining all the aggregate indices is not noticeable even when the number of units is small; and the 
indices enable the system to scale to an order of magnitude more units using a reasonable simulation 
time step of 100 ms.  4.2 Dynamic Optimization Aggregate indexing is not always the most ef.cient way 
to process iteration. If it is not true that everyone sees everyone else, it may  Figure 6: Comparison 
of Aggregate Indexing versus Pruning be better just to prune the search space and iterate over the pruned 
objects normally. This solution is commonly used in games, and it often yields excellent results. The 
problem is that the choice between aggregate indexing and sim­ple pruning depends on the current state 
of the game. For example, consider a game in which we want to distribute healers for max­imum effectiveness. 
A simple algorithm assigns to each healer a healing priority. At each time-step, each healer searches 
its visible range for wounded allies whose health is below this prior­ity. With uniformly distributed 
priority values, this algorithm drives healers to congregate in areas with the most wounded. Obviously, 
if there are few wounded units, we can process this behavior very ef.ciently by just pruning out the 
healthy allies. However, in a pitched battle with large numbers of wounded, we need a different technique 
(like aggregate indexing) to avoid the n 2 problem. Figure 6 shows the results of simulating the healer 
behavior de­scribed above over several hundred time steps. This simulation uses the same prototype as 
the previous aggregate index simula­tion [White et al. 2007], but we have isolated the performance to 
the healer behavior only. The graph compares the cost of building and maintaining an aggregate index 
to that of simple pruning. The simulation begins at the end of major battle. All allied units are wounded, 
and so pruning is not very effective. Over time, the wounded allies are gradually healed until eventually 
no more wounded remain. As the number of wounded decreases, the cost of pruning decreases, overtaking 
the cost of the aggregate index and eventually outperforming it by another order of magnitude. Ideally, 
we would like to keep statistics that enable us to predict which of pruning or aggregate indexing will 
be more ef.cient on the current game state, so we can switch between these query plans as necessary. 
This technique is called dynamic query optimization. There has been substantial research on dynamic query 
optimization, particularly on streaming data [Zhu et al. 2004]. In a simulation environment, we can theoretically 
achieve the performance of the optimal query plan at each time step with a constant (multiplicative) 
overhead. In practice we can often do much better than this.  4.3 Other Optimizations While our early 
work on SGL has focused on index optimization, there are other other known optimization techniques that 
should ap­ply to the state-effect pattern. Two that are of particular interest for games are pipelining 
and parallelization. While we have not applied these techniques speci.cally to SGL, there has been some 
recent work on adapting them to in-memory systems. Pipelining in database processing works much the same 
way that it does in computer graphics. A database query plan consists of a number of simple operators 
connected together in a graph. With pipelined evaluation, rather than materializing the entire output 
re­lation of each operator and storing it in memory, we instead gen­erate output values incrementally, 
on demand. This can greatly reduce the amount of memory required for query processing: in­stead of allocating 
memory for all intermediate results, we provide only small input and output buffers for each operator. 
Large mem­ory blocks are required only for aggregate indices and for certain blocking operators (such 
as sorting). This is particularly useful for effect .elds, which exist only during the query phase and 
update rules, and thus need to be materialized only in the input and output buffers of the pipeline. 
Game designers sometimes develop custom streaming algorithms such as path.nding [O Brien and Stout 2007; 
Dunki 2008] or GPU physics simulations [Nguyen 2007]. In our approach, pipelining comes for free when 
we compile the query phase into a declara­tive format. Thus the game developer can focus on designing 
the behavior without having to construct custom pipelines. Another class of optimizations relevant to 
games is parallelization. Because database queries have no side effects (they take streams of data as 
input and produce new streams of data as output) they are embarrassingly parallel [Dewitt et al. 1990; 
Stonebraker et al. 1988]. Indeed, there has even been recent work on processing database queries with 
GPUs [Govindaraju et al. 2004]. In the case of SGL, it is obvious how to parallelize our query phase. 
As effect variables can never be read, we can isolate the objects in the query phase from one another 
and process them separately. We can also parallelize any accum-loop for exactly the same reason.  5 
Game Design Issues While the state-effect pattern provides several performance advan­tages, it is unusual 
and does require that the game designer structure the game logic appropriately. While our formalization 
of the state­effect pattern is still very new, we have already identi.ed two major design challenges 
from our initial prototypes. 5.1 Designing Effects The most obvious challenged is the design of effects. 
Very often, games update the state of an object in the middle of the simulation loop. In order to take 
advantage of the state-effect pattern, the game developer must design effects that appropriately delay 
the update until the end of the simulation loop. Fortunately, game designers already do work with effects. 
They are particularly common in RPGs; these games have paralyzation effects, poison effects, performance 
enhancing effects, and so on. Designing a single effect is usually straightforward. The game de­signer 
introduces a .eld for the effect, and speci.es rules for han­dling those cases when the effect is produced 
more than once in a single time step. While this may result in a large number of .elds, the pipelining 
process mentioned in Section 4.3 can minimize the amount of memory necessary to process them. A greater 
challenge is managing the interplay between different ef­fects. For game balance purposes we may not 
want certain effects to stack with one another. For example, we may want a character to receive a strength 
enhancement effect or a speed enhancement effect, but not both. One way to implement this would be to 
model strength and speed enhancements as separate effect .elds, but write update rules so that only one 
of them is used at a time. However, this becomes unwieldy as we introduce more incompatible effects. 
An alternate solution is to use an object to represent a performance enhancement effect. Then, in order 
to choose the single effect that takes effect, we use a priority function, such as argmin or argmax 
 to choose among them. For example, in model­ing performance enhancement, we may want an object with 
three .elds: the enhancement type, the enhancement strength, and the rank of that enhancement, where 
enhancements of higher rank are give higher priority over those of lower rank. When we assign an enhancement 
to a character via an effect .eld, we use argmax to select the enhancement of greatest rank. Another 
interesting example is the use of effects for object acqui­sition. In Section 3 our unit type had a .eld 
to represent its cur­rent combat target, and we used an object effect .eld with a pri­ority function 
to update this value. Another example would be the use of an object effect to assign loot to characters 
after a success­ful boss kill. Loot assignment presents an interesting challenge, since we want to ensure 
that only one character gets the object. Typically this is not an issues, as the game processes each 
player separately in turn. However, when we use the state-effect pattern, players may processed simultaneously, 
so we cannot check whether another player has received the loot in the same time step. The solution to 
this problem is to understand what our semantic constraints are. While players may have multiple items 
of loot, each loot may have only one player. Because the uniqueness constraint applies to the loot and 
not the player, the correct design in this case is to make the owner an effect .eld in the loot object. 
That way the loot has a priority function for choosing its unique owner in the case of ties. Once the 
owner has been determined, the object can be added the character s inventory either by the update rules 
(SGL supports expressions for manipulating sets of objects) or in a subsequent iteration of the update 
loop. With some practice, our current formulation of the state-effect pat­tern can express a wide range 
of effect interactions. As we continue to explore the uses of this pattern, we may .nd ways to extend 
it to other types of effect interactions. This is an interesting area for future work.  5.2 Integrating 
the State-Effect Pattern Another challenge with the state-effect pattern is in integrating it with other 
parts of the game engine. First of all, we must iden­tify what parts, if any, of the game engine are 
amenable to the state-effect pattern. Some subsystems are very easy to model in this framework, while 
others cannot be modeled at all. The most signi.cant limitation is that we cannot use this pattern search 
over the transitive closure of a graph. This means that it cannot support path.nding algorithms like 
A* which crawl over a terrain graph. On the other hand, steering algorithms [Reynolds 1999] are similar 
to force calculations in a particle systems and are quite amenable to the state-effect pattern. The .rst 
step in the design process is to identify all instances of iter­ation, such as for-loops or while-loops. 
Any iteration which can be expressed as a for-each loop, or unrolled as a constant num­ber of iterations, 
is a candidate for the query phase. However, we must also examine the variable assignments within each 
iteration loop. These assignments must all be expressible as effect variables; otherwise they will be 
lost when the iteration is done. Obviously we can do this when the iteration is simple aggregation (e.g. 
summing, averaging, building up sets of objects). With greater pro.ciency in effect design, we are capable 
of doing more. For cases such as path.nding, which cannot be modeled by this pattern, we still may be 
able to improve performance through more sophisticated use of the state-effect pattern. The state-effect 
pattern assumes that it is part of the main simulation loop. However, there is nothing preventing us 
from embedding the state-effect pattern in other iteration loops as well. In SGL, a call from the game 
engine only performs a single query phase and update, allowing us to po­sition it where ever we want. 
Thus we can apply the state-effect pattern to the internals of these algorithms, and then iterate over 
this pattern externally in the game engine. However, this type of design may require that we reorder 
the ap­plication of iteration. For example, path.nding iterates over all of the characters searching 
for a path, and, for each character, uses A* to perform a search of the terrain graph. The outside iteration 
is acceptable, while the inner iteration is not. We can extend our state-effect pattern to path.nding 
if we swap the order of iterations. In this case, we use the query phase to pipeline the processing of 
all of the characters at once, and iterate over the steps in the A* algo­rithm outside in the post-processing 
phase. It is not clear whether this gives any performance bene.t over existing high-performance algorithms, 
but it does illustrate the basic principle. An alternative to this extension of the state-effect pattern, 
is to sim­ply separate troublesome calculations and integrate them into the post-processing phase. Once 
again, path.nding is an excellent ex­ample, as most game engines implement it in a separate subsystem 
which communicates the set of computed waypoints to the steering algorithms [O Brien and Stout 2007]. 
As SGL supports set .elds, we can easily pass this information from the path.nding system to the steering 
algorithms in the query phase. Furthermore, as it is a separate subsystem, we can either process the 
path.nding during the post-processing phase, or asynchronously in a separate thread. The right design 
choice in each of these instances depends upon the application. While we should always be reluctant to 
move work out of the declarative query phase, sometimes it is the right thing to do. Again, as we develop 
more pro.ciency with the state-effect pattern, we will begin to learn more about the appropriate design 
choices in this case.  6 Related Work There has been some work in the academic community on special 
purpose scripting languages for games, such as the ScriptEase lan­guage [McNaughton et al. 2004]. However, 
much of this work has focused on tools that make design accessible to inexperienced pro­grammers. The 
work in this paper is different in that our scripting language is developed for the sole purpose of processing 
complex game behavior ef.ciently. While there are other special purpose languages designed for improving 
game performance, such as Sim­bionic [Fu et al. 2003] or Naughty Dog s GOAL [Liebgold 2008], our approach 
is the .rst one to leverage database processing tech­niques. Some of the work presented in this paper, 
particular the optimiza­tions in Section 4, have been presented previously in the context of early SGL 
prototypes [White et al. 2007]. These prototypes sup­ported only one type of game object and could not 
perform iteration without some working knowledge of SQL. The purpose of this pa­per has been present 
a much more advanced version of SGL that does not require SQL. In addition, our aim has been to make 
this material accessible to a non-database audience, as well as to discuss some of the issues that arise 
when attempting to use our design pat­tern for developing games.  7 Conclusions The state-effect pattern 
is a very powerful technique for ef.ciently scaling the interactions between game objects. It allows 
game de­signers to use a design pattern already familiar to them, albeit infor­mally, to leverage decades 
of research in declarative processing and optimization. It removes the burden of designing custom pipelines 
and optimization, as this is all handled by the compiler, and allows the developer to focus more on the 
design process. In addition to the obvious research opportunities in game-speci.c database processing, 
the state-effect pattern offers many interesting research opportunities in design. SGL is still a fairly 
simple script­ing language because the authors have focused their research on formalizing the semantics 
and optimizing the query phase [White et al. 2007; Albright et al. 2008]. Higher level design tools would 
make it easier to visualize the design process and leverage this de­sign pattern. The design of effects 
and their combination rules are interesting even by themselves. As we showed in Section 5.1, we can use 
them to enforce semantic constraints like each loot object has one owner . Since cheats in MMOs are often 
some violation of semantic constraints, we would like to develop tools that allow game designers to specify 
other types of constraints. Declarative processing in games presents an excellent opportunity for database 
researchers and the game designers to collaborate with one another. We believe that continued work in 
this area will greatly enrich both communities, and allow us to create more complex and immersive worlds. 
 Acknowledgements This work is supported by the National Science Foundation under Grant IIS-0725260, 
the Air Force under Grant FA9550-07-1-0437, and a grant from Microsoft Corporation. Any opinions, .ndings, 
conclusions or recommendations expressed herein are those of the author(s) and do not necessarily re.ect 
the views of the sponsors.  References ALBRIGHT, R., DEMERS, A., GEHRKE, J., GUPTA, N., LEE, H., KEILTY, 
R., SADOWSKI, G., SOWELL, B., AND WHITE, W. 2008. SGL: A scalable language for data-driven games (demon­stration 
paper). In Proc. SIGMOD. BOHANNON, P., LIEUWEN, D., RASTOGI, R., SILBERSCHATZ, A., SESHADRI, S., AND 
SUDARSHAN, S. 1997. The archi­tecture of the Dal´i main-memory storage manager. Multimedia Tools Appl 
4, 2, 115 151. BONCZ, P., AND KERSTEN, M. 1995. Monet: An impressionist sketch of an advanced database 
system. In Proc. BIWIT. CARNEY, D., C¸ ETINTEMEL, U., CHERNIACK, M., CONVEY, C., LEE, S., SEIDMAN, G., 
STONEBRAKER, M., TATBUL, N., AND ZDONIK, S. 2002. Monitoring streams a new class of data management 
applications. In Proc. VLDB. DEMERS, A., GEHRKE, J., PANDA, B., RIEDEWALD, M., SHARMA, V., AND WHITE, 
W. 2007. Cayuga: A general pur­pose event monitoring system. In CIDR, 412 422. DEWITT, D., GHANDEHARIZADEH, 
S., SCHNEIDER, D., BRICKER, A., HSIAO, H., AND RASMUSSEN, R. 1990. The gamma database machine project. 
IEEE Trans. on Knowledge and Data Engineering 2, 1, 44 62. DUNKI, Q. 2008. Streaming open world path.nding. 
In Proc. GDC. ENSEMBLE STUDIOS. 2000. Computer Player Strategy Builder Guide, AI Expert Documentation 
for Age of Empires II: The Age of Kings. Ensemble Studios. FU, D., HOULETTE, R., AND JENSEN, R. 2003. 
A visual envi­ronment for rapid behavior de.nition. In Proc. Conference on Behavior Representation in 
Modeling and Simulation. GOVINDARAJU, N., LLOYD, B., WANG, W., LIN, M., AND MANOCHA, D. 2004. Fast computation 
of database operations using graphics processors. In Proc. SIGMOD. KRUSZEWSKI, P., AND VAN LENT, M. 2007. 
Not just for combat training: Using game technology in non-kinetic urban simula­tions. In Proc. Serious 
Game Summit, GDC. LIEBGOLD, D. 2008. Adventures in data compilation and scripting for uncharted: Drake 
s fortune. In Proc. GDC. MCNAUGHTON, M., CUTUMISU, M., SZAFRON, D., SCHAEF-FER, J., REDFORD, J., AND 
PARKER, D. 2004. ScriptEase: Generative design patterns for computer role-playing games. In Proc. ACE. 
MOTWANI, R., WIDOM, J., ARASU, A., BABCOCK, B., BABU, S., DATAR, M., MANKU, G. S., OLSTON, C., ROSENSTEIN, 
J., AND VARMA, R. 2003. Query processing, approximation, and resource management in a data stream management 
system. In Proc. CIDR. NGUYEN, H., Ed. 2007. GPU Gems, vol. 3. Addison-Wesley. O BRIEN, J., AND STOUT, 
B. 2007. Embodied agents in dynamic worlds. In Proc. GDC. PIKE, R., DOWARD, S., GRIESEMER, R., AND QUINLAN, 
S. 2005. Interpreting the data: Parallel analysis with Sawzall. Sci­enti.c Programming Journal 13, 4, 
227 204. POSNIEWSKI, S. 2007. Massively modernized online: MMO tech­nologies for next-gen and beyond. 
In Proc. Austin GDC. REYNOLDS, C. 1999. Steering behaviors for autonomous charac­ters. In Proc. GDC. 
STONEBRAKER, M., KATZ, R., PATTERSON, D., AND OUSTER-HOUT, J. 1988. The design of XPRS. In Proc. VLDB. 
WHITE, W., DEMERS, A., KOCH, C., GEHRKE, J., AND RA-JAGOPALAN, R. 2007. Scaling games to epic proportions. 
In Proc. SIGMOD, 31 42. ZHU, Y., RUNDENSTEINER, E., AND HEINEMAN, G. 2004. Dy­namic plan migration for 
continuous queries over data streams. In Proc. SIGMOD.  
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
		<article_sponsors>
			<funding_agency>National Science Foundation</funding_agency>
			<grant_numbers>
				<grant_number>IIS-0725260</grant_number>
			</grant_numbers>
		</article_sponsors>
		<article_sponsors>
			<funding_agency>Air Force</funding_agency>
			<grant_numbers>
				<grant_number>FA9550-07-1-0437</grant_number>
			</grant_numbers>
		</article_sponsors>
	</article_rec>
	<article_rec>
		<article_id>1401848</article_id>
		<sort_key>50</sort_key>
		<display_label>Pages</display_label>
		<pages>4</pages>
		<article_publication_date>08-09-2008</article_publication_date>
		<seq_no>4</seq_no>
		<title><![CDATA[Gamer communities, design, and learning]]></title>
		<subtitle><![CDATA[panel proposal]]></subtitle>
		<page_from>31</page_from>
		<page_to>33</page_to>
		<doi_number>10.1145/1401843.1401848</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1401848</url>
		<abstract>
			<par><![CDATA[<p>Though much of the study of games and learning has understandably emphasized the interaction of game players with specific games (e.g., Gee [2003]), recent work has shifted to the understanding the social sphere around games and communities of engaged gamers (e.g., Squire and Giovanetto [2008]; Wright et al [2002]). In particular, online discussions around and supporting games are an increasingly ubiquitous feature of popular games, providing venues for passionate gamers to discuss games, critique each other's work, and interact with game designers. We argue that the ways that <i>communities</i> of gamers interact on the Internet show the inextricable nature of a variety of design activities and approaches to learning in contemporary gamer cultures, across a wide range of game genres.</p>]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1100690</person_id>
				<author_profile_id><![CDATA[81100536791]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Kurt]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Squire]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Wisconsin-Madison]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1100691</person_id>
				<author_profile_id><![CDATA[81467661622]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Sean]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Duncan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Wisconsin-Madison]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1100692</person_id>
				<author_profile_id><![CDATA[81365598282]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Ben]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[DeVane]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Wisconsin-Madison]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1100693</person_id>
				<author_profile_id><![CDATA[81365597882]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Moses]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Wolfenstein]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Wisconsin-Madison]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1100694</person_id>
				<author_profile_id><![CDATA[81365593297]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Rik]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Hunter]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Wisconsin-Madison]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Benkler, Y. <i>The Wealth of Networks.</i> Yale University Press, New Haven, CT, 2006.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Devane, B. and Squire, K. The Meaning of Race and Violence in <i>Grand Theft Auto: San Andreas. Games &amp; Culture</i>, in press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Duncan, S. C. and Gee, J. P. The Hero of Timelines: Argumentation and Epistemology in Zelda Chronology Debates. In <i>The Legend of Zelda and Philosophy</i>, L. CUDDY, Ed. Open Court, Chicago, in press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Gee, J. P. <i>Social Linguistics and Literacies: Ideology in Discourses.</i> Falmer, New York, 1990.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>983348</ref_obj_id>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Gee, J. P. <i>What Video Games Have to Teach Us About Learning and Literacy.</i> Palgrave, New York, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Hobler, M. Games, Gender, and Digital Culture: An Analysis of Three Communities. University of Oregon theses, School of Journalism and Communication, M.S., June 2007.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Jenkins, H. <i>Convergence Culture: Where Old and New Media Collide.</i> New York University Press, New York, 2006a.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Jenkins, H. <i>Fans, Bloggers and Gamers: Exploring Participatory Culture.</i> New York University Press, New York, 2006b.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Lankshear, C. and Knobel, M. <i>New Literacies.</i> Open University Press, Berkshire, UK, 2006.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Morris, S. WADs, Bots and Mods: Multiplayer FPS Games as Co-creative Media. Level Up, Digital Games Conference. Retrieved from http://www.digra.org/dl/db/05150.21522.pdf, 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Nieborg, D. B. Am I Mod or Not? - an Analysis of First Person Shooter Modification Culture. Paper presented at Creative Gamers Seminar - Exploring Participatory Culture in Gaming. Hypermedia Laboratory (University of Tampere), 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Sherry J. L. The effects of violent video games on aggression: A meta-analysis. <i>Human Communication Research</i>, 27, 3, 409--431, 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Squire, K. Video games literacies. In <i>Handbook of Research on New Media Literacies</i>, M. KNOBEL, D. LEU, &amp; C. LANKSHEAR. New York: MacMillan, in press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Squire, K. and Giovanetto, L. The Higher Education of Gaming. <i>E-Learning</i>, V. 5, #1, 2008.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Wright, T., Briederbach, P. and Boria, E. Creative Player Actions in FPS On-Line Video Games: Playing Counter-Strike. <i>Game Studies: The International Journal of Computer Game Research.</i> V. 2, #2, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Panel Proposal: Gamer Communities, Design, and Learning Kurt Squire Sean Duncan Ben DeVane Moses Wolfenstein 
Rik Hunter University of University of University of University of University of Wisconsin-Madison Wisconsin-Madison 
Wisconsin-Madison Wisconsin-Madison Wisconsin-Madison kdsquire@education.wisc.edu scduncan@wisc.edu devane@wisc.edu 
wolfenstein@wisc.edu rlhunter@wisc.edu 1 Statement of Purpose Though much of the study of games and 
learning has understandably emphasized the interaction of game players with specific games (e.g., Gee 
[2003]), recent work has shifted to the understanding the social sphere around games and communities 
of engaged gamers (e.g., Squire and Giovanetto [2008]; Wright et al [2002]). In particular, online discussions 
around and supporting games are an increasingly ubiquitous feature of popular games, providing venues 
for passionate gamers to discuss games, critique each other's work, and interact with game designers. 
We argue that the ways that communities of gamers interact on the Internet show the inextricable nature 
of a variety of design activities and approaches to learning in contemporary gamer cultures, across a 
wide range of game genres. For this panel, we propose to discuss online "gamer communities" [Squire in 
press] from a number of game genres turn-based strategy games (Civilization III), massively-multiplayer 
online games (World of Warcraft), console and handheld adventure games (The Legend of Zelda series), 
sandbox-style console action games (Grand Theft Auto: San Andreas), and first-person shooter games (Team 
Fortress 2). Through the creation of new knowledge (be it in the form of written text; e.g., "Zelda timelines" 
or a collaborative website such as WoWWiki), the development of game design skills (e.g., Civilization 
III scenarios or Team Fortress 2 level design), or means of representing one's identity (e.g., models 
of rappers using Grand Theft Auto: San Andreas), we aim to show how gamers are productive in their relationship 
with games, and why. We will draw implications for how game design influences the nature of online discussions 
around games as well as how discussions in gamer communities feed back into game design. Our overarching 
goal is to shine a light on "gamer communities" as productive arenas of learning and literacy, and show 
the ways that common gamer activities involve practices of value (for both the participants and game 
designers). For, while the term "gamer" is often used in the popular press as a pejorative, we will highlight 
the ways that productive activities meaning-making, new literacies, argumentation, and the design of 
creative artifacts (stories, models, databases, and new games) are part and parcel of engagement in 
gamer communities. 2 Kurt Squire -Shaping Players into Designers: Civilization III and Apolyton University 
To gamers, online forums have often been productive spaces, where players can debate stories and mechanics 
of games, teach each other how to play games, and collaborate to develop new revisions (e.g., maps, mods, 
add-ons) for existing games. In this presentation, I will discuss a specific case: An online ethnography 
of Civilization III players at "Apolyton University" (AU). AU is an informal online "university" of gamers, 
created to enhance one another s pleasure from the game experience, teach one another how to play the 
Civilization games, and facilitate players' changes of the game's standard rule set [Squire and Giovanetto 
2008]. I will focus on the key participant structures that scaffold learning in this environment, as 
well as the way that participation in these "gamer communities" [Squire in press] may result in transformative 
experiences whereby gamers enter as players but leave as designers (as seen through game play practices, 
as well as the career paths of several participants who were hired by game companies as a result of their 
participation in AU). The ways that these communities have facilitated moving from player to designer 
will be shown in the Apolyton University case, but is not limited to just this instance. Rather, I argue 
that AU illustrates the ways that online gamer forums may in general provide valuable venues for players 
to learn the ability to lead, to design, and to shape gaming communities for learning goals.  3 Sean 
Duncan -The Hero of Time(lines): Gamers, Designers, and The Legend of Zelda The ways that gamers relate 
to and manipulate the storylines of long-running series of games can illustrate the complex relationships 
contemporary gamers have with the "texts" of games, game designers, and each other. I argue that the 
"timeline debates" [Duncan and Gee in press] around Nintendo's The Legend of Zelda series are cases of 
online discussions in which gamers have collaboratively re-appropriated and re-structured commercial 
game narratives, explicitly justified their theories, and repeatedly vetted designs in a public forum. 
I argue for the consideration of these debates as "informal design communities," illustrating the ways 
that productive fan interaction with games can contain embedded literacy practices traditional textual 
literacies as well as "new literacies" (e.g. argumentation, remixing, and design; Lankshear and Knobel 
[2006]). Additionally, I propose that a featural analysis of a game can help to explain the ways that 
games' designs both afford and constrain the informal, yet iterative design of narrative artifacts around 
the game (in this case, the Zelda "timelines"). That is, there is utility in constructing a taxonomy 
of the Zelda series' narrative and ludic constraints, and the potential influence of these constraints 
on the form of the design activities around the games (as seen in the online discussions). By understanding 
how design activities evolve in communities of passionate gamers, we may be able to address larger issues 
of motivation in learning, while also better understanding the intertwined ways that the online interaction 
of gamers and game designers increasingly shapes the evolution of popular game series.  4 Ben DeVane 
-Building Digital Literacies Through Hip Hop Culture: Fan Modding PracticesWith Grand Theft Auto: San 
Andreas Violent videogames such as Grand Theft Auto: San Andreas (GTA:SA) have often been characterized 
as mindless digital spaces that transmit aggression, indolence, and other negative values to young players. 
While studies suggests that young people have much more sophisticated interpretations (and critiques) 
of these games' narratives than is commonly thought [DeVane and Squire in press], little research has 
sought to understand what players do with these games in naturalistic settings and how they understand 
them [Jenkins 2006b; Sherry 2001]. In this presentation, I will investigate the practices that enthusiasts 
of these games engage in beyond play and the reasons fans find these practices so compelling. This study 
looks at an online GTA:SA fan community and examines the interaction of popular culture and hip hop-affiliated 
identities with productive digital literacies. I will consider how identity operates in this social space 
as fans create, share and critique "mods," or game modifications. I contend fan-modders draw heavily 
on the discursive identity kits [Gee 1990] of popular media and hip hop culture as they painstakingly 
build 3-D models of their favorite rappers for peer critique or redesign the game to resemble other hip 
hop-affiliated titles. I argue that this kind of interactive relationship with the design of a videogame 
has consequences for the development of understandings of how games facilitate learning and the identities 
enacted in fan communities influence players' practices with commercial games. 5 Moses Wolfenstein -"Sentry 
Down! : Valve's Team Fortress 2 and Player Based Production Traditionally, investigation on communities 
of first-person shooter (FPS; e.g., Counter Strike, Call of Duty) gamers has been limited to niche topics 
[Nieborg 2005; Hobler 2007], and research focused on design and media production activities around this 
genre has been even more limited [Morris 2003]. While this is understandable given the long stream of 
bad press as well as political and legal action these games and their players have received, it is problematic 
in that players of FPSs have created long standing communities in which active production and participation 
(both inside and outside of actual game play) are highly valued [Wright et al 2002]. In this presentation, 
I will address how FPS players engage in productive participation, focusing on online forums around recent 
the recent FPS game Team Fortress 2 (TF2). Valve's 2007 release of The Orange Box has seen new iterations 
of production communities within the FPS genre. User communities around TF2 offer particularly intriguing 
groups for analysis. On one hand, the highly original cartoon/Cold War aesthetics of the game have given 
rise to a wide variety of exceptionally creative machinima and other original productions. At the same 
time, members of the TF2 community have taken to extremely active level design and game mechanic critique, 
offering the games creators suggestions on ways to improve the game s mechanics, and giving each other 
critical feedback on these topics. Analyzing the forms of discourse and activities within the official 
Valve forums as well as unofficial gamer forums (e.g., minedog.com), I will address how communities of 
FPS players engage in productive critical and design activities within this genre. 6 Rik Hunter -Fusing 
the Community: WoW as Cultural Activator Videogames such as World of Warcraft act as cultural activators 
[Jenkins 2006]; indeed, the large-scale WoW community has several channels through which to commune, 
address emerging needs or problems through cooperation, and accomplish shared goals --all of which can 
occur outside the game. Communion and collective action, then, can result in fusion. If game developers 
wish to take advantage of fusion strengthening player engagement and loyalty they might seek out ways 
to not only encourage players emotional connectedness to the game and in­game communities but also both 
individual and collaborative meaning-making activities outside the game. For example, established in 
2004, "WoWWiki" is a user-editable database of information made up entirely of user contributions. An 
example of an online, informal, and recreational learning community, what Gee [2003] calls an affinity 
space, the central task of the highly-engaged members of WoWWiki is to write hypertextual encyclopedic 
articles in order to compile information regarding the game World of Warcraft, official Warcraft lore, 
information from previous Warcraft RTS games, table-top role­playing games, novels, comics, and graphic 
novels. In this presentation, I will argue that WoWWiki is a significant fan community representing commons-based 
peer-production [Benkler 2006] where participation takes form in collective networks brought together 
by shared interests in a particular topic as well as assessing how sites like this can be effectively 
used to foster fusion.  References BENKLER, Y. The Wealth of Networks. Yale University Press, New Haven, 
CT, 2006. DEVANE, B. and SQUIRE, K. The Meaning of Race and Violence in Grand Theft Auto: San Andreas. 
Games &#38; Culture, in press. DUNCAN, S. C. and GEE, J. P. The Hero of Timelines: Argumentation and 
Epistemology in Zelda Chronology Debates. In The Legend of Zelda and Philosophy, L. CUDDY, Ed. Open Court, 
Chicago, in press. GEE, J. P. Social Linguistics and Literacies: Ideology in Discourses. Falmer, New 
York, 1990. GEE, J. P. What Video Games Have to Teach Us About Learning and Literacy. Palgrave, New York, 
2003. HOBLER, M. Games, Gender, and Digital Culture: An Analysis of Three Communities. University of 
Oregon theses, School of Journalism and Communication, M.S., June 2007. JENKINS, H. Convergence Culture: 
Where Old and New Media Collide. New York University Press, New York, 2006a. JENKINS, H. Fans, Bloggers 
and Gamers: Exploring Participatory Culture. New York University Press, New York, 2006b. LANKSHEAR, C. 
and KNOBEL, M. New Literacies. Open University Press, Berkshire, UK, 2006. MORRIS, S. WADs, Bots and 
Mods: Multiplayer FPS Games as Co-creative Media. Level Up, Digital Games Conference. Retrieved from 
http://www.digra.org/dl/db/05150.21522.pdf, 2003. NIEBORG, D.B. Am I Mod or Not? -an Analysis of First 
Person Shooter Modification Culture. Paper presented at Creative Gamers Seminar -Exploring Participatory 
Culture in Gaming. Hypermedia Laboratory (University of Tampere), 2005. SHERRY J. L. The effects of violent 
video games on aggression: A meta-analysis. Human Communication Research, 27, 3, 409-431, 2001. SQUIRE, 
K. Video games literacies. In Handbook of Research on New Media Literacies, M. KNOBEL, D. LEU, &#38; 
C. LANKSHEAR. New York: MacMillan, in press. SQUIRE, K. and GIOVANETTO, L. The Higher Education of Gaming. 
E-Learning, V. 5, #1, 2008. WRIGHT, T., BRIEDERBACH, P. and BORIA, E. Creative Player Actions in FPS 
On-Line Video Games: Playing Counter-Strike. Game Studies: The International Journal of Computer Game 
Research. V. 2, #2, 2002.  Biographies Kurt Squire is an Associate Professor at the University of Wisconsin-Madison 
in the Educational Communications and Technology division of the Department of Curriculum and Instruction. 
Squire is the director of the Games+Learning+Society Initiative and his current research interests center 
on the impact of contemporary gaming practices on learning, schooling and society. Sean Duncan is a doctoral 
student in the Department of Curriculum and Instruction and member of the Games+Learning+Society Initiative 
at the University of Wisconsin-Madison. His research deals with digital media literacy and learning, 
focusing on the evolution of design practices in online gaming communities. Ben DeVane is a doctoral 
student in the Department of Curriculum and Instruction and member of the Games+Learning+Society Initiative 
at the University of Wisconsin-Madison. His research investigates the use of youth culture and popular 
media in games for learning. Moses Wolfenstein is a doctoral student in the Department of Educational 
Leadership and Policy Analysis and member of the Games+Learning+Society Initiative at the University 
of Wisconsin-Madison. His doctoral research deals with leadership in online games, as well as game based 
learning tools for school leaders, virtual schools and the potential they hold for housing next level 
interactive platforms for teaching and learning. Rik Hunter is a PhD candidate in the University of Wisconsin's 
Composition and Rhetoric program. His research interests include new media, fan production, collective 
intelligence, and collaborative writing and learning. Rik's dissertation, titled "Writing WoWWiki: Wiki-Mediated 
Collaborative Composition &#38; Social Interaction," develops an understanding of how the wiki and goals 
of a fan community shape collaborative composition in an online environment (i.e., the ways in which 
technologies shape and are shaped by discourse communities).  
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
	</article_rec>
	</section>
	<section>
		<section_id>1401849</section_id>
		<sort_key>60</sort_key>
		<section_seq_no>2</section_seq_no>
		<section_type>SESSION</section_type>
		<section_title><![CDATA[Education and learning]]></section_title>
		<section_page_from>35</section_page_from>
	<article_rec>
		<article_id>1401850</article_id>
		<sort_key>70</sort_key>
		<display_label>Pages</display_label>
		<pages>8</pages>
		<article_publication_date>08-09-2008</article_publication_date>
		<seq_no>1</seq_no>
		<title><![CDATA[Body music]]></title>
		<subtitle><![CDATA[physical exploration of music theory]]></subtitle>
		<page_from>35</page_from>
		<page_to>42</page_to>
		<doi_number>10.1145/1401843.1401850</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1401850</url>
		<abstract>
			<par><![CDATA[<p>Music is appreciated by people from all walks of life. Music fits into our daily schedules in many ways, from casual listening to cultural events or movies. At a deeper level, the mechanics of music are not usually known to most lay people and learning the components of music theory can be a lengthy and difficult process. We present a new paradigm of social musical exploration and creation system using the physical body as an interface. We have created a physical mixed reality interactive game which enables people from all walks of life to interact in a physical space and learn fundamentals of music theory through experimentation. The initial prototype teaches pitch, time signature and dynamics in music. Initial player studies were conducted to refine the prototype to improve the usability, playability, and to ensure that the learning objectives are accomplished. We provide an evaluation of the research project and assess the usefulness of the system in the classroom setting as well as an interactive museum setting. Future plans for development are discussed in the conclusion of the paper to provide for the future development direction.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[music]]></kw>
			<kw><![CDATA[physical computing]]></kw>
			<kw><![CDATA[serious games]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>H.5.5</cat_node>
				<descriptor>Signal analysis, synthesis, and processing</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>J.5</cat_node>
				<descriptor>Literature</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010405.10010469</concept_id>
				<concept_desc>CCS->Applied computing->Arts and humanities</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010583.10010750.10010762.10010767</concept_id>
				<concept_desc>CCS->Hardware->Robustness->Hardware reliability->Signal integrity and noise analysis</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010583.10010588.10003247</concept_id>
				<concept_desc>CCS->Hardware->Communication hardware, interfaces and storage->Signal processing systems</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<person_id>P1100695</person_id>
				<author_profile_id><![CDATA[81311485601]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Eng]]></first_name>
				<middle_name><![CDATA[Tat]]></middle_name>
				<last_name><![CDATA[Khoo]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[National University of Singapore]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1100696</person_id>
				<author_profile_id><![CDATA[81363592872]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Timothy]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Merritt]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[National University of Singapore]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1100697</person_id>
				<author_profile_id><![CDATA[81365597870]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Victor]]></first_name>
				<middle_name><![CDATA[Lim]]></middle_name>
				<last_name><![CDATA[Fei]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[National University of Singapore]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1100698</person_id>
				<author_profile_id><![CDATA[81325489384]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Wei]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Liu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[National University of Singapore]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1100699</person_id>
				<author_profile_id><![CDATA[81100454187]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Hafizur]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Rahaman]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[National University of Singapore]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1100700</person_id>
				<author_profile_id><![CDATA[81365595385]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>6</seq_no>
				<first_name><![CDATA[Janaka]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Prasad]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[National University of Singapore]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1100701</person_id>
				<author_profile_id><![CDATA[81320492462]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>7</seq_no>
				<first_name><![CDATA[Timothy]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Marsh]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[National University of Singapore]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[AsiaOne, 2008. Now you can 'draw' music. AFP. May 26, 2008. Retrieved 31.05.2008, from http://digital.asiaone.com/Digital/News/Story/A1Story20080526-67053.html.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Bogost, I. 2005. The rhetoric of exergaming. In <i>Proceedings of the Digital Art &amp; Culture Conference (DAC'05), Copenhagen, Denmark, November 30th - December 3rd 2005.</i>
]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Camurri, A. 1995. Interactive dance/music systems. In <i>Proceedings of the International Computer Music Conference (ICMC'95), Banff, Canada</i>, 245--252.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1279829</ref_obj_id>
				<ref_obj_pid>1279740</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Castellano, G., Bresin, R., Camurri, A., and Volpe, G. 2007. Expressive control of music and visual media by full-body movement. In <i>Proceedings of the 7th international conference on New interfaces for musical expression (NIME'07)</i>, New York, USA, 390--391.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Chen, S., and David, M., 2007. Proof of learning: Assessment in serious games. Gamasutra. Retrieved 01.24.2007, from http://www.gamasutra.com.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Gunter, G., Kenny, R., and Vick, E. 2006. A case for a formal design paradigm for serious games. <i>The Journal of the International Digital Media and Arts Association 3(1)</i>, 93--105.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Machover, T., and Chung, J. 1989. Hyperinstruments: Musically intelligent and interactive performance and creativity systems. In <i>Proceedings of International Computer Music Conference (ICMC'89), Columbus, USA</i>, 186--190.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Marsh, T. 2007. Informing design and evaluation methodologies for serious games for learning. In <i>Proceedings of Learning with Games 2007, Sofia Antipolis, France</i>, 479--485.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>642709</ref_obj_id>
				<ref_obj_pid>642611</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Mueller, F., Agamanolis, S., and Picard, R. 2003. April 2003. Exertion interfaces: sports over a distance for social bonding and fun. In <i>Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (Ft. Lauderdale, Florida, USA, April 05 - 10, 2003)</i>, 561--568.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Steiner, R. 2008. <i>Eurythmy Forms for Tone Eurythmy.</i> Steiner-books.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Thompson, C., 2007. Halo 3: How microsoft labs invented a new science of play. Wired. Retrieved 31.05.2008, from http://www.wired.com/gaming/virtualworlds/magazine/15-09/ff_halo, 2007.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Yamaha, 2007. Tenori-on. Retrieved 31.05.2008, from http://www.global.yamaha.com/tenori-on/index.html.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Body Music: Physical Exploration of Music Theory Eng Tat Khoo*, Victor Lim Fei , Janaka Prasad!, Timothy 
Marsh**, Timothy Merritt ,Wei Liu§,Ha.zur Rahaman¶National University of Singapore Abstract Music is 
appreciated by people from all walks of life. Music .ts into our daily schedules in many ways, from casual 
listening to cul­tural events or movies. At a deeper level, the mechanics of music are not usually known 
to most lay people and learning the compo­nents of music theory can be a lengthy and dif.cult process. 
We present a new paradigm of social musical exploration and creation system using the physical body as 
an interface. We have created a physical mixed reality interactive game which enables people from all 
walks of life to interact in a physical space and learn fundamen­tals of music theory through experimentation. 
The initial prototype teaches pitch, time signature and dynamics in music. Initial player studies were 
conducted to re.ne the prototype to improve the us­ability, playability, and to ensure that the learning 
objectives are ac­complished. We provide an evaluation of the research project and assess the usefulness 
of the system in the classroom setting as well as an interactive museum setting. Future plans for development 
are discussed in the conclusion of the paper to provide for the future development direction. CR Categories: 
H.5.5 [Information Interface and Presentation]: Sound and Music Computing Signal analysis, synthesis, 
and pro­cessing; J.5 [Computer Applications]: Arts and Humanities Literature Keywords: serious games, 
physical computing, music 1 Introduction In this digital age, new interfaces for musical expression 
provide much broader musical possibilities than have ever existed before. There is a constant quest to 
be in harmony with ones instrument so that music can .ow freely from the imagination and take form effortlessly. 
This sparks an interest to achieve more .uid methods for creating music, particularly in the use of the 
human body as the direct interface with music. There are many new digital musical interfaces, but most 
are based on traditional musical instruments or are at least designed as a tan­gible object. In the music 
computing community there is an in­ *e-mail: khooet@nus.edu.sg e-mail: timothy.merritt@nus.edu.sg e-mail: 
victorlimfei@nus.edu.sg §e-mail: idmliu@nus.edu.sg ¶e-mail: ha.zur@nus.edu.sg Ie-mail: idmijpw@nus.edu.sg 
 **e-mail: tmarsh@nus.edu.sg Copyright &#38;#169; 2008 by the Association for Computing Machinery, Inc. 
Permission to make digital or hard copies of part or all of this work for personal or classroom use is 
granted without fee provided that copies are not made or distributed for commercial advantage and that 
copies bear this notice and the full citation on the first page. Copyrights for components of this work 
owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, to 
republish, to post on servers, or to redistribute to lists, requires prior specific permission and/or 
a fee. Request permissions from Permissions Dept, ACM Inc., fax +1 (212) 869-0481 or e-mail permissions@acm.org. 
Sandbox Symposium 2008, Los Angeles, California, August 9 10, 2008. &#38;#169; 2008 ACM 978-1-60558-173-6/08/0008 
$5.00 creasing attention on identifying new paradigms of expressive in­teraction with machines. Camurri 
[Camurri 1995] argues that one of the most consolidated directions is that of interactive music sys­tems, 
i.e. systems able to process expressive gestures for generating and controlling musical signals, such 
as hyper and virtual musical instruments [Machover and Chung 1989]. Attention of the music community 
is focused on the development of interaction metaphors that take into account full-body move­ments and 
gestures at different levels of abstraction, and the inter­action with an active environment with evolution 
and dialogue ca­pabilities. This leads to Multimodal Environments enabling multi­modal player interaction 
by exhibiting real-time adaptive behaviour [Castellano et al. 2007]. In particular, immersive environments 
en­abling communication by means of full body movements, such as in dancing, singing, and playing. Movement 
and music are inter­twined for two reasons. Firstly, sounds are made when air vibrates at frequencies, 
which are sensed by the ear. In order to generate the vibration, a mechanical movement is necessary. 
Faster vibra­tions yield higher pitch and likewise, more pronounced vibration yields higher volume. The 
second aspect relating movement to mu­sic is the natural tendency for people to follow along with music 
by moving their bodies. Dance not only echoes the music, but helps the dancer understand the music in 
a more emotionally deep man­ner. Quite simply, sound is made by movements; people understand sound by 
moving. The goal of this research project is to blur the line between these two aspects, and open up 
an avenue for them to mingle more in­timately. Instead of dancing to music, it is now possible to create 
music by movement. This project is a tool, an interface between motion and music, a new musical instrument. 
It is designed to be highly con.gurable to allow the artist as free a form of expression as possible. 
It is also designed to be fun and comfortable to use. This is a powerful tool and a fun toy, stimulating 
for adults yet ac­cessible to a child. 2 Background Currently, children or adults who wish to learn 
music must do it through the traditional musical instrument such as the piano, violin or drums. However, 
it is helpful to remember that these musical in­struments are merely means in which a variety of sound 
or musical notes are produced. Though there are obvious bene.ts in the use of these instruments in facilitating 
the acquisition and sensitization to music, it often neces­sitates certain mastery, or at least an acceptable 
level of competence in the musical instruments in order to bring about an appreciation of music itself. 
Beyond this, each musical instrument is designed to produce its unique sound and therein foregrounds 
a distinctive as­pect of the musical score. Even though there is merit in this, there is nonetheless 
a certain reduction in capacity and constraint in full ex­pression for a musical score when a single 
particular instrument is used. For instance, the same tune will carry a different quality, and as a result 
a dissimilar feel, or emotional experience, when played by a guitar, organ or harmonica. While there 
could be indignant protests from traditionalists who might uphold the importance of learning music through 
musical in­struments, it is an undeniable fact that the technicalities and com­plexities involved in 
the mastery of a musical instrument could have put one too many potential music enthusiasts off. There 
are innu­merable individuals, who confronted by the challenge and seem­ingly insurmountable hurdle of 
mastering a musical instrument, simply gave up and gave in to the familiar reason that they are just 
not musically inclined. This, however, could not be further from the truth. Humans are musical beings. 
We make music all the time and apart from the sit­uation of silence in a vacuum created by an arti.cial 
void, sound is an indelible part of the human experience. It is a part of our lives. As such, there is 
an imperative to be sensitized to the nature of mu­sic, its frequency, pitch, volume, rhythm, and from 
there, cultivate an appreciation of music.  3 Related Work There is also a growing trend of playing 
music video games. Guitar Hero is a good example that has found its way into most popular game consoles 
like PlayStation 2 &#38; 3, Nintendo Wii, and Xbox 360. The game is notable for the introduction of a 
simpli.ed musical interface which is a scaled down version of a guitar. This interface offers a gentle 
learning curve and does not require knowledge of playing the real instrument. Commercial arcade games 
have recently seen a growing trend of games that require human physical movement as part of the inter­action. 
For example, dancing games such as Dance Dance Revolu­tion (DDR) and ParaParaParadise by Konami are based 
on players dancing in time with a musical dance tune and moving graphical objects. These dancing games 
introduce performance as a key ele­ment in the play experience. It is a new kind of entertainment where 
the game player also doubles as a performer. The dance movements introduced by the game have a performance 
element which attract the audiences attention and amusement. However, these games still force the person 
to stand in more or less the same spot and focus on a computer or TV screen in front of them. Our game 
promotes full body movement over a large space rather than restricting the player to a small area. This 
encourages the play­ers to explore the game space together with other players. We also maintained the 
performance play element of the above mentioned games. This is especially useful in classroom learning, 
for non players to be immersed in the game and to understand the game by watching others play. Recently, 
there are new musical interfaces that allow users to cre­ate and manipulate music through touch and drawing 
using tangi­ble musical interfaces [AsiaOne 2008]. One such example is the TENORI-ON by Yamaha [Yamaha 
2007]. TENORI-ON allows the user to create musical performances by touching and drawing patterns on the 
box-like interface. Our system extends the box-like interface to a full sized room space which allows 
users to utilize their bodies as an interface to create and manipulate music. Our research extends on 
the Eurythmy [Steiner 2008] concept of visualising language and music in a form of body movement. When 
performing Eurythmy with music (also called tone Eurythmy), el­ements of music for example melody, harmony 
and rhythm, are all expressed. We take the reverse approach to the Eurythmy con­cept by allowing players 
to explore the music theories through their body movements and interaction with the other players in 
a physical space.  4 Learning Objectives The objective of this research project is to transcend the 
limitations presented in the use of musical instruments as the essential interface for learning some 
core elements in music theory. The level of knowledge of the concepts of frequency, tempo, and volume 
among others are only learned after the student internal­izes the mechanics behind the concepts. Our 
learning objective is to provide an interactive experience in which the student gains an understanding 
not from learning in traditional methods or through hours of practice. Our objective is to more quickly 
break down some of the fundamental concepts of music theory and allow the student to touch and feel the 
variables much like pulling the levers of a machine and experimenting with the possible outcomes and 
therefore develop a deep appreciation and understanding. 4.1 Accomplishing the Learning Objectives Our 
research project endeavors to address and eliminate the hard to learn interface of traditional musical 
instruments. Our aim is to make the person one with the interface. We want people to experi­ence, interact 
and manipulate music directly, without the need for a steep learning curve. By allowing control and manipulation 
of musical notes through the human physiology, barriers to learning music are removed. The project promotes 
learning of music by al­lowing the individual to experience how music is created through their bodily 
movement and physical actions. This project aims to eliminate the physical instrument altogether. The 
sensor system enables the use of ones own body as a musical instrument through detection of movement, 
freeing the artist from the traditional requirements of producing live music. The ability to create and 
manipulate sound through movement provides the po­tential for immediate intuitive control of musical 
pieces. In this paper we describe a game, which allows players to use their full-body for controlling 
in real-time, the generation of an expres­sive audio-visual feedback.  5 System Description The system 
extracts expressive motion features from the players full-body movements and gestures in a room setting 
as shown in Figure 1. The values of these motion features are mapped both onto acoustic parameters for 
the real-time expressive rendering of a piece of music, and onto real-time generated visual feedback 
projected on a screen in front of the player. This intuitive way of exploring music provides a deeper 
sensitization of the nature of music itself, such as frequency, amplitude, tempo and time signature, 
and hence lowers the barriers in appreciating music. This can also inspire more peo­ple to learn music 
and music theory as well as develop newfangled approaches to music. Details explaining the proposed learning 
ob­jectives and the ways in which the system accomplishes these are provided in the following sections. 
5.1 System Architecture Our system consists of the following four components: playground, camera, speakers 
and visual output screen. A playground can be any .oor space that is within the camera viewing area. 
A normal web cam is used for tracking of the players activity in the play­ground. The system is developed 
using MAX/MSP programming platform and the video tracking is done using the Cyclops plugin. The MAX/MSP 
program developed is shown in Figure 2. The rea­son we chose MAX/MSP is due to its ease of reprogrammability 
which is one of the key design considerations for our system. Fig­ure 3 shows the system in operation 
with the video tracking and Max MSP program running on the laptop screen and the visual out­put on the 
right. Figure 4 shows the camera tracking matrix for the scenario of 2 people and with a resolution of 
5 levels for each Figure 1: Four players controlling the dynamics of four independent tracks of instrument 
music by moving their body music track for the Dynamics lesson. The overall system diagram is shown in 
Figure 5. We compare the difference of the grayscale value of each of the square in the matrix for the 
current and the pre­vious video frame to detect any person entering that square. In some scenarios where 
the ceiling height is low and absence of a wide an­gle camera lens, the person would occupy more than 
one square in the matrix of the video. We have written a tracking algorithm to comprise the above situations 
by identifying the square with a higher level and use it to trigger the events in the music lesson. For 
example in music dynamics lesson, if a person is occupying square 1, 2 and 3. The system will identify 
the maximum current value to be 3 and use it to trigger the dynamics level of the music.  Figure 3: 
System in operation: MAX/MSP program on the right and the visual output on the left  6 Music Lessons 
6.1 Frequency Frequency is related to the number of movements or vibrations per second represented in 
Hertz (Hz). Another way to describe this is cycles per second. The human ear can perceive the vibrations, 
which are from 15Hz and 20,000Hz. This means that a string mov­ing back and forth 15 times per second 
would be audible and would be the lowest pitch. At the other end of the spectrum, at 20,000Hz, the frequency 
would be the highest pitch and at the upper limit of perception. A string in this case would be moving 
back and forth 20,000 times per second. The concept of frequency and pitch are normally taught from the 
perspective of using pianos for pitch and wave diagrams for frequency. While these methods can be useful 
in teaching the concepts to students, our solution is to provide a map­ping of space between two people 
as the length of a virtual vibrating string. The larger the distance, the lower the frequency and lower 
pitch. The players see the virtual string on the wall-projected dis­play, which changes in length and 
vibration speed while the audible Tracking  Figure 4: Camera tracking matrix of 2x5 sound in the room 
changes accordingly. To enhance the mapping of the frequency and its translation to instruments, an accompany­ing 
animated image of a piano or guitar showing the .nger position is displayed along with the numerical 
frequency in Hz while the corresponding note appears on the staff diagram. While this ac­complishes the 
learning objective of teaching the basic concepts, it goes far beyond and allows for the learner to see 
the relative range of the various instruments and hear their sounds. Figure 6(a) shows that when players 
are standing far apart, they create a lower frequency sound. In Figure 6(b) players standing closer together 
creates a higher frequency sound. 38  (a) (b) Figure 6: (a) Users standing far apart creates a lower 
frequency sound (b) Users standing closer together creates a higher frequency sound 6.2 Time Signature 
The concept of basic tempo is often easily understood. With the aid of a metronome, students can hear 
the clicking sound, which provides a steady division of time and a pace for music. The more challenging 
concept beyond this is the concept of rhythm and me­ter. The time signature is most commonly used in 
Western notation systems to specify how many beats are in each measure and what note value constitutes 
one beat in the measure. Time signatures in­dicate meter, but the artist composing a piece of music is 
free to use another meter, provided that the measures contain the indicated number of beats. Generally, 
the time signature indicates the feeling of a piece of music. For example, waltzs are always in 3 / 4 
time and they give rise to the undulating feel which is most easily ex­pressed in the dance, or by saying 
outloud, 1,2,3 1,2,3. A change to the 6 / 8 time signature gives the feeling of a very fast waltz and 
the undulation can be felt by saying out loud, 1, and, 2, and, 3, and, 1, and, 2, and, 3, and. The standard 
western notation system displays the time signature by placing the beats per measure count above the 
indication of the note which constitutes one beat. In 3 / 4 time as shown in Figure 7, there are 3 beats 
per measure and the quarter note is the note which represents a single beat. Figure 7: Standard notation 
showing the 3 /4 time signature In order for the learner to get a grasp for this concept, our learning 
environment maps the number of players in the space to a particular time signature and plays a melody 
accordingly. As shown in Figure 8, having three people in the space triggers the melody to play in 3 
/ 4 time and the corresponding notes being heard are displayed on the projected wall display with each 
note being highlighted as its corresponding sound is heard. When another player enters the space, the 
game changes the time signature to the 4 / 4 time and the players can hear the difference, not in speed 
necessarily, but in the stresses of the notes and the natural cycle of the phrases. This scenario accomplishes 
the learning objective of demonstrating time signatures in an exploratory way while reinforcing what 
is heard with what is represented in the notation system. (a) (b) (c) Figure 8: (a) Three people in 
the space triggers the melody to play in 3 / 4 time (b) Four people in the space triggers the melody 
to play in 4 / 4 time (c) Six people in the space triggers the melody to play in6/ 8time  6.3 Dynamics 
Dynamics is a musical component associated with volume. In mu­sical terms, dynamics is expressed in notations 
such as p (piano, soft), mp (mezzo-piano, medium soft), mf (mezzo-forte, medium loud), f (forte, loud), 
etc. In music CDs and mp3s that we listen to today, rich dynamics conversation between different tracks 
of in­struments in a song are programmed and combined into a stereo track during the mixdown process, 
hence not allowing players to change the dynamics to their preference. In order for the learner to get 
a grasp for this concept, our learning environment maps the position of the player into the dynamic or 
volume level of a track of music. We have developed a human mixer game to teach music dynamics. Different 
players in the playground will each control the dynamic level of an instrument track. They move their 
body toward the screen or away from the screen in order to change the volume level. These changes are 
re.ected on the screen as well. In this way many players can move their body in the playground and controlling 
the mix of the dynamics of the music they are controlling. The game play scenario of the human mixer 
game is shown in the Figure 1. In this scenario, there are four players who each controls a saxophone, 
guitar, drum or violin music track dynamics level in­dependently. The dynamics level of the music tracks 
are shown on the projection screen in real time, which correspond to the position of the players. The 
.nal output music dynamics is a summation of the collaborative control effort from the players.  7 Evaluation 
The evaluation of the learner s progress in serious games in com­parison with traditional teaching materials 
is often dif.cult to as­sess [Marsh 2007]. We have seen many methods attempting to show the transfer 
of knowledge and others, which inform the de­sign using techniques from the entertainment games .eld 
[Thomp­son 2007]. Figuring out if somebody learned something is a very dif.cult task as mentioned by 
Jonathan Ferguson [Chen and David 2007], Robert Gagne and James Keller [Gunter et al. 2006]. In the context 
of our game, there may need to be an assortment of evaluation methods made available depending on the 
context of the game use and the target audience. For example, if the game is situated in a museum setting, 
it may be that the purpose of the game is to inspire creativity and interest in music theory without 
a hard and fast score of the student achievement. However, if the game is intended to accompany traditional 
classroom teaching of music theory, it may be necessary to have a way to show the mastery of the concepts 
and also demonstration of the ability to transfer the knowledge and skills to another setting. In either 
scenario, our game requires multiple people to create the interactive experience. This is similar to 
most music creation, which usually requires the various musical instruments to play their part and to 
fall together into a synchronized pattern, negotiating the transitions, and playing off of the actions 
of the others. Our game is best suited to inspire and allow students to explore as a group and build 
an understanding of musical concepts and get a taste for what sounds good with less focus on the traditional 
methods of single student testing. One possible way to assess the transfer of knowledge would be for 
the students to train other stu­dents after they have taken part in the game sessions and have mas­tered 
the concepts. The trainer students could follow a lesson plan provided to them, but they would also have 
some freedom to reveal the features of the game in a way of their choosing. This type of train the trainer 
exercise would ensure that the students can trans­fer the knowledge to others and that they can facilitate 
the learning session, which can be a delicate balance between story telling and conveyance of factual 
information. Borrowing from Papert s idea of soft and hard fun, we would like to present and test the 
knowledge in a way that provides an experience which is a balance between easy experiential rewards and 
the more lengthy exercises whereas the students build up to an understanding and reward for their ef­forts. 
It could be that the Ah ha moments of training the trainers could provide this hard fun and give the 
students a sense of empow­erment. 8 User Studies The re.nements to our interactive system were made 
possible through involvement of users at various stages. These re.nements focused on making the learning 
scenarios more effective, improv­ing the usability of the system, and increasing the motivation or playability 
of the users interacting with the system. This section describes the re.nements made to the system. 8.1 
Learning Scenario Re.nements The learning scenarios provide speci.c lessons about music theory using 
the physical space in various ways. With play testing of the scenarios with 6 players, we learned that 
the on-screen feedback of player position and the game state is critical for ensuring that the player 
understands the connection between their actions and re­sults, but it also gave us insights on improving 
the effectiveness of the game. The .oor was divided into 5 sections for each player for some of the scenarios, 
these were levels from high to low, or soft to loud, etc. Displaying the activated region and the signi.cance 
of that activated region on-screen helped to build more meaning­ful associations to the material. As 
was expected, the players took pride in pointing out what they believed to be the associated effects 
of movements and how these translated into changes in the sound. This learning process through group 
discovery and exploration was reported by the players as being a key feature in the game-based learning 
process; students would interact, test hypotheses, and then reach a shared conclusion about the interaction 
and then work to hone their skills as a group in creating sound events.  8.2 Usability Re.nements The 
interaction space is a large room-sized area which is de.ned by the .eld of view of the overhead camera. 
After the .eld of view is known, the calibration is then set inside the MAX/MSP program to divide the 
space into tracks made up of rectangular regions. When the content of any of the regions changes from 
the background im­age, it is registered as activated. The human form is .uid and takes up more than one 
rectangular section at a time. In addition to this, when the players are standing there is the problem 
of the registra­tion jumping from one to another setting. The players explained that they would lose 
the sense of connection between their actions and the sounds and animation. This led to awkward moments 
dur­ing the play experience which caused for a break in the .ow of the game. We looked at other ways 
to capture the players including having the players sit in chairs with wheels, rolling back and forth 
as a way to interact as shown in Figure 9. This made the pro.le of the human form much bigger, yet it 
slowed the movement of the players. We added the algorithm which assessed how many regions were considered 
activated and then of these regions, using the up­permost value as the truly activated region. With this 
algorithm, the stability of the registration improved the usability because the acti­vated regions became 
more stable and intuitive for the players. The players expressed that they enjoyed the ability to move 
around in different ways including the standing and seated positions. Spon­taneously, one of the players 
registered his movements by standing up and moving the chair back and forth with the arms. This showed 
us that more re.nements to the usability can be considered, but that the interactive experience is enjoyable 
enough that the players ac­tively experiment and seek out the movements that work best for them.  Figure 
9: Players sit in chairs with wheels, rolling back and forth as a way to interact 8.3 Playability Re.nements 
In our play testing we quickly noticed that facilitation of the activity was a critical component to 
the success and understanding by the players. Often, we had to direct the players to move to a speci.c 
spot on the .oor or to move slowly in order for them to understand the connection between their actions 
and the sounds being heard. This guided exploration gave the players moments of re.ection and activity 
which is common in other learning activities, but may be more necessary in our larger group oriented 
scenario. While this type of activity facilitation is possible in a classroom setting, or when directed 
by a facilitator, if this system is used in a museum setting, we may need to adapt the scenarios to be 
more user directed and .exible enough to be played with a varied number of users. Figure 10 shows that 
the players are having great time playing the game during the user study. The feedback gathered from 
the play testing con.rmed that the system is enjoyable and entertaining, but there were many suggestions 
for improvements to make the expe­rience even more enjoyable and exciting. One such example was the idea 
to allow the players to create the sound samples which are used in the scenarios. When this idea was 
explained by one player, the others became thrilled and excited about the possibility. An­other idea 
from a player involved introducing a timer to the game to give a sense of urgency to the scenarios and 
to build the excite­ment. These and other possibilities will be explored in the future prototypes to 
increase the fun factor of the game based learning system.   9 Discussion In the following, we discuss 
the possibilities for future develop­ments of the system including the game mechanics, body based in­teractions, 
and concepts for user research. 9.1 Game Mechanics As described earlier, the driving force in the system 
is to teach con­cepts of music. In order to accomplish this, we take the approach that physical, ludic 
interaction offers a powerful way to engage the players and to teach dif.cult concepts. By employing 
the game techniques of cooperation and competition, the users can become immersed in the game experience 
and share moments of excitement in the social setting. Rules for each scenario need to enhance the experience 
and excitement, but not detract from the goal of music exploration. There can be a time based system 
in which the play­ers have to complete the mini-tasks and lessons in order to score points. Additional 
points can be given for accuracy of the body movements as well. In this way, the style of interaction 
is similar to DDR, which has been successful in providing enjoyable game play. We are interested in ways 
in which the game play can be adjusted to individual players, in the shared space so that players of 
differing skill levels can still enjoy and play together.  9.2 Body Based Interactions All musical instruments 
require some degree of physical movement on the part of the musician. In the case of electronic and digital 
in­struments, this is still the case, however there is a much wider range of possibilities when using 
digital and electrical systems which are not bound to the same rules as traditional physical instruments. 
We would like to explore expanding the user tracking method to allow another dimension to the game experience. 
The body movements used when playing the theremin, for example, require the artist to use hand position 
in order to control volume and pitch. The player of the theremin and our system as well is somewhat bound 
to the sliding between the range of values and position. It is dif.cult to create the silent moments 
in between the notes which is a strength of traditional instruments. We will explore the use of gestures 
of the players arms or with handheld switches to allow the players to expand the interaction space. Not 
only will the location of the player serve as input, but the body gestures can be used to augment or 
modify the input as is the case with the sustain pedal in a piano, or the foot pedals used by the electric 
guitarist. The possibilities could include simple electronic switches to add silence or sustain, acceleration 
sensors for keeping the beat similar to maracas, higher de.nition camera based tracking for .ner position 
sensing, among others. Another avenue for exploration could be to explore the con­cept of Eurhythmics, 
borrow the movements and lessons and to­gether with the technological enhancements, make new forms of 
body based music.  9.3 User Research In order to re.ne the design of new lessons and game scenarios, 
we will focus on in depth user studies. Our focus will .rst look at the initial experience and to look 
for ways in which the player .g­ures out the connection between the movements and the effect on the sound 
and visual animation. We will also examine each of the scenarios with various age groups of players with 
various levels of knowledge of music. The system allows for a wide range of game scenarios from the very 
simple interaction and visuals to more com­plex scenarios illustrating the physics of sound and therefore, 
there may be ways in which the system can easily adapt to the user s level of knowledge and provide an 
appropriately matched experience to increase the amount of enjoyment from the game play.  10 Conclusion 
In this paper we present a new paradigm of social musical explo­ration and creation system using the 
physical body as an interface. We have created a physical mixed reality interactive game which enables 
people from all walks of life to interact in a physical space and learn fundamentals of music theory 
through experimentation. Using large physical body movements, players explored the con­cepts of music 
theory as a group with fun interaction. Our system presents to the players a game with mini scenarios 
each focused on a speci.c music lesson, with sound events which change according to the movements of 
the players. The performance and co-creation aspect of the game made the experience exciting and gave 
rise to unexpected events. The players became very immersed in the expe­rience and not only learned music 
concepts but enjoyed playing to­gether. One funny event happened when the players were carefully adjusting 
the volume of the instruments in the dynamics scenario and one player said, come on drums, you have to 
step up now! The other players were laughing at the metaphorical language used and the assumption of 
roles the player took. In future prototypes we will look at making advancements in the factors affecting 
playability and will work to re.ne the tracking mechanisms to make a tight coupling between natural user 
move­ments and the registration of the players. We will also expand the interactive scenarios to include 
new features as mentioned by the play testers in our search for making fun play opportunities that can 
facilitate the learning of music theory. References ASIAONE, 2008. Now you can draw music. AFP. May 
26, 2008. Retrieved 31.05.2008, from http://digital.asiaone.com/Digital/News/Story/A1Story20080526­67053.html. 
BOGOST, I. 2005. The rhetoric of exergaming. In Proceedings of the Digital Art &#38; Culture Conference 
(DAC 05), Copenhagen, Denmark, November 30th -December 3rd 2005. CAMURRI, A. 1995. Interactive dance/music 
systems. In Proceedings of the International Computer Music Conference (ICMC 95), Banff, Canada, 245 
252. CASTELLANO,G., BRESIN,R., CAMURRI,A., AND VOLPE,G. 2007. Expressive control of music and visual 
media by full-body movement. In Proceedings of the 7th international conference on New interfaces for 
musical expression (NIME 07),New York, USA, 390 391. CHEN,S., AND DAVID, M., 2007. Proof of learning: 
Assess­ment in serious games. Gamasutra. Retrieved 01.24.2007, from http://www.gamasutra.com. GUNTER,G., 
KENNY,R., AND VICK, E. 2006. A case for a formal design paradigm for serious games. The Journal of the 
International Digital Media and Arts Association 3(1), 93 105. MACHOVER,T., AND CHUNG, J. 1989. Hyperinstruments: 
Musi­cally intelligent and interactive performance and creativity sys­tems. In Proceedings of International 
Computer Music Confer­ence (ICMC 89), Columbus, USA, 186 190. MARSH, T. 2007. Informing design and evaluation 
methodologies for serious games for learning. In Proceedings of Learning with Games 2007, So.a Antipolis, 
France, 479 485. MUELLER,F., AGAMANOLIS,S., AND PICARD, R. 2003. April 2003. Exertion interfaces: sports 
over a distance for social bond­ing and fun. In Proceedings of the SIGCHI Conference on Hu­man Factors 
in Computing Systems (Ft. Lauderdale, Florida, USA, April 05 -10, 2003), 561 568. STEINER, R. 2008. Eurythmy 
Forms for Tone Eurythmy. Steiner­books. THOMPSON, C., 2007. Halo 3: How microsoft labs invented a new 
science of play. Wired. Retrieved 31.05.2008, from http://www.wired.com/gaming/virtualworlds/magazine/15­09/ff 
halo, 2007. YAMAHA, 2007. Tenori-on. Retrieved 31.05.2008, from http://www.global.yamaha.com/tenori-on/index.html. 
  
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
	</article_rec>
	<article_rec>
		<article_id>1401851</article_id>
		<sort_key>80</sort_key>
		<display_label>Pages</display_label>
		<pages>8</pages>
		<article_publication_date>08-09-2008</article_publication_date>
		<seq_no>2</seq_no>
		<title><![CDATA[User centered game design]]></title>
		<subtitle><![CDATA[evaluating massive multiplayer online role playing games for second language acquisition]]></subtitle>
		<page_from>43</page_from>
		<page_to>49</page_to>
		<doi_number>10.1145/1401843.1401851</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1401851</url>
		<abstract>
			<par><![CDATA[<p>Unlike recreational games, serious games do more than entertain the player. Serious games promote acquisition of information and skills that are valued in both the virtual world and the real world. The challenge is to design and develop serious games that simultaneously create an enjoyable experience for the player as the player develops or improves her skill set as a result of game play and applies these newly developed skills in a real world setting. Because transfer of learning represents the primary goal of serious games, it is crucial that game designers understand the interactions associated with game tasks and their impact on players prior to game development. Borrowing heavily from interaction design, we introduce the user centered game design methodology as the framework for serious game design and apply this technique to the evaluation of the social interactions between Player Characters in a commercial Massive Multiplayer Online Role Playing Game. Significant results from experimental studies suggest that this genre of games shows great promise as an unorthodox language learning tool for vocabulary acquisition and reveals the importance of social interactions in the virtual space of video games. Finally, we discuss the design implications for serious games that facilitate Second Language Acquisition.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[game design]]></kw>
			<kw><![CDATA[interaction design]]></kw>
			<kw><![CDATA[second language acquisition]]></kw>
			<kw><![CDATA[serious games]]></kw>
			<kw><![CDATA[user centered design]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>K.3.2</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10003456.10003457.10003527.10003531.10003536</concept_id>
				<concept_desc>CCS->Social and professional topics->Professional topics->Computing education->Computing education programs->Information science education</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003456.10003457.10003527.10003531.10003533</concept_id>
				<concept_desc>CCS->Social and professional topics->Professional topics->Computing education->Computing education programs->Computer science education</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003456.10003457.10003527.10003531.10003536</concept_id>
				<concept_desc>CCS->Social and professional topics->Professional topics->Computing education->Computing education programs->Information science education</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003456.10003457.10003527.10003531.10003533</concept_id>
				<concept_desc>CCS->Social and professional topics->Professional topics->Computing education->Computing education programs->Computer science education</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<person_id>P1100702</person_id>
				<author_profile_id><![CDATA[81554478556]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Yolanda]]></first_name>
				<middle_name><![CDATA[A.]]></middle_name>
				<last_name><![CDATA[Rankin]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Northwestern University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1100703</person_id>
				<author_profile_id><![CDATA[81365597782]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[McKenzie]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[McNeal]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Tennessee State University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1100704</person_id>
				<author_profile_id><![CDATA[81421596352]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Marcus]]></first_name>
				<middle_name><![CDATA[W.]]></middle_name>
				<last_name><![CDATA[Shute]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Clark Atlanta University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1100705</person_id>
				<author_profile_id><![CDATA[81100057328]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Bruce]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Gooch]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Victoria]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Abeele, V. V., Husson, J., Vandeurzen, L., and Desmet, S. 2007. A soft approach to computer science: Designing &amp; developing computer games for and with senior citizens. <i>Journal of Game Development 2</i>, 41--62.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Abt, C. C. 1970. <i>Serious Games.</i> Viking Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1212803</ref_obj_id>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Aldrich, C. 2005. <i>Learning by Doing:A comprehensive guide to simulations, computer games and pedagogy in e-Learning and other educational experiences.</i> Pfeiffer.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Allen, J., and Core, M. 1997. Draft of damsl: Dialogue act in several markup layers.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Backer, J. A. 1999. <i>Multi-user Domain Object Oriented as a High School Procedure for Foreign Language Acquisition.</i> PhD thesis, Nova Southeastern.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Beauvois, M. H., and Eledge, J. 1996. Personality types and megabytes: student attitudes toward computer-mediated communication (cmc) in the language classroom. <i>CALICO Journal 13</i>, 2, 27--45.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[C. Steinkuehler, C., and Williams, D. Where everybody knows your (screen) name: Online games as third places. <i>Journal of Computer-Mediated Communication 11</i>, 4.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Canale, M., and Swain, M. 1980. Theoretical bases of communicative approaches to second language teaching and testing. <i>Applied Linguistics 1</i>, 1, 1--47.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1272537</ref_obj_id>
				<ref_obj_pid>1272516</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Chatham, R. E. 2007. Games for training. <i>Communications of the ACM 50</i>, 7, 36--43.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1111301</ref_obj_id>
				<ref_obj_pid>1111293</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[El-Nasr, M., and Smith, B. 2006. Learning through game modding. <i>ACM Computers in Entertainment 4</i>, 1.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>994735</ref_obj_id>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Fullerton, T., Swain, C., and Hoffman, S. 2004. <i>Game Design Workshop: Designing, prototyping and playtesting games.</i> CMP Books.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>983348</ref_obj_id>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Gee, J. P. 2003. <i>What Video Games Have to Teach Us about Learning and Literacy.</i> Palgrave McMillian.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Hadley, O. M. 2001. Heinle and Heinle.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Horwitz, E., Horwitz, M., and Cope, J. 1986. Foreign language classroom anxiety. <i>The Modern Language Journal 70</i>, 2, 125--132.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Hudson, J., and Bruckman, A. A. 2002. Irc francais: The creation of an internet-based sla community. <i>Computer Assisted Language Learning Volume 15</i>, 2, 109--134.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Jakobson, M., and Taylor, T. 2003. The sopranos meets everquest: Social networking in massively multiplayer online games. In <i>Conference Proceedings of the 2003 Digital Arts and Culture (DAC) Conference</i>, ACM, 81--90.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[J. Payne, and Whitney, P. 2002. Developing 12 oral proficiency through synchronous cms: Output, working memory, and inter-language development. <i>CALICO Journal 20</i>, 1, 7--32.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1272538</ref_obj_id>
				<ref_obj_pid>1272516</ref_obj_pid>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Kelly, H., Howell, K., Glinert, E., Holding, L., Swain, C., Burrowbridge, A., and Roper, M. 2007. How to build serious games. <i>Communications of the ACM 50</i>, 7, 44--50.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Krashen, S. D. 1991. Pergamon Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1272536</ref_obj_id>
				<ref_obj_pid>1272516</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Mayo, M. J. 2007. Games for science and engineering education. <i>Communications of the ACM 50</i>, 7, 30--35.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>560143</ref_obj_id>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Preece, J., Rogers, Y., and Sharp, H. 2002. <i>Interaction Design: Beyond human-computer interaction.</i> R.R. Donnelley.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1179340</ref_obj_id>
				<ref_obj_pid>1179295</ref_obj_pid>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Rankin, Y., Gold, R., and Gooch, B. 2006. 3d role-playing games as language learning tools. In <i>In Conference Proceedings of EuroGraphics 2006</i>, vol. 25.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1202238</ref_obj_id>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[Rucker, R. 2003. <i>Software Engineering and Computer Games.</i> Addison-Wesley.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1215723</ref_obj_id>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[Salen, K., and Zimmerman, E. 2004. <i>Rules of Play: Game design fundamentals.</i> MIT Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[Squire, K. 2005. Changing the game: What happens when video games enter the classroom? <i>Innovate 1</i>, 6.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[Watts-Taffe, S., and Truscott, D. M. 2000. Using what we know about language and literacy development for esl students in the mainstream classroom. <i>Language Arts 77</i>, 3, 258--265.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 User Centered Game Design: Evaluating Massive Multiplayer Online Role Playing Gamesfor Second Language 
Acquisition Yolanda A. Rankin* McKenzie McNeal MarcusW. Shute Bruce Gooch§ Northwestern University Tennessee 
State University Clark Atlanta University UniversityofVictoria Abstract Unlike recreationalgames, seriousgames 
do more than entertain the player. Seriousgames promote acquisitionofinformation and skills that are 
valued in both the virtual world and the real world. The challengeistodesignanddevelop seriousgamesthat 
simulta­neously create an enjoyable experience for the player as the player developsorimprovesher skillsetasa 
resultofgameplayandap­plies these newly developed skills in a real world setting. Because transfer of 
learning represents the primary goal of seriousgames, it is crucial thatgame designers understand the 
interactions asso­ciated withgame tasks and their impact on players prior togame development. Borrowing 
heavily from interaction design, we intro­duce the user centeredgame design methodology as the framework 
for seriousgamedesignandapplythis techniquetotheevaluation of the social interactions between Player 
Characters in a commer­cial Massive Multiplayer Online Role Playing Game. Signi.cant results fromexperimental 
studies suggest that this genreofgames shows great promise as an unorthodox language learning tool for 
vocabulary acquisition and reveals the importance of social interac­tionsin the virtual spaceof videogames. 
Finally,we discuss the design implications for seriousgames thatfacilitate Second Lan­guage Acquisition. 
CR Categories: K.3.2 [Computers and Education]: Computer Uses in Education Collaborative Learning Keywords: 
Gamedesign, interaction design, secondlanguage ac­quisition, seriousgames, user centered design 1 Introduction 
Research suggests that video games effectively model the learn­ing process in that videogames require 
players to be active partic­ipants rather than passive observers, adapt toplayers capabilities, and give 
immediate feedback as a result of players decisions dur­inggame play [Gee 2003; Squire 2005]. Popular 
recreational video games successfully entice players to invest numerous hours play­ingvideogamesasplayerswork 
diligentlytoimprovetheirplaying abilities and progress from one game level to the next. Though videogames 
serve primarilyasa sourceof entertainment, recently theyhavebeguntofunctionas pedagogical tools, creatinga 
genre *e-mail: yrankin@northwestern.edu e-mail:mckenzie.mcneal@gmail.com e-mail:mwshute@shuteent.com 
§e-mail:brucegooch@gmail.com Copyright &#38;#169; 2008 by the Association for Computing Machinery, Inc. 
Permission to make digital or hard copies of part or all of this work for personal or classroom use is 
granted without fee provided that copies are not made or distributed for commercial advantage and that 
copies bear this notice and the full citation on the first page. Copyrights for components of this work 
owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, to 
republish, to post on servers, or to redistribute to lists, requires prior specific permission and/or 
a fee. Request permissions from Permissions Dept, ACM Inc., fax +1 (212) 869-0481 or e-mail permissions@acm.org. 
Sandbox Symposium 2008, Los Angeles, California, August 9 10, 2008. &#38;#169; 2008 ACM 978-1-60558-173-6/08/0008 
$5.00 of videogames known as seriousgames [Abt 1970; Aldrich 2005; Chatham 2007;Kelly et al. 2007; Mayo 
2007]. Seriousgames go beyond entertainment; theyattempt to educate players about tradi­tional classroom 
topics (e.g.physics, math, andbusiness) and non­traditional topics, including healthcare, and political 
issues in the Middle East [Mayo 2007]. Game designersof seriousgames strive to achieve the same level 
of engagement associated with recre­ational videogames with the caveat that players acquire knowledge 
and learn new concepts duringgame play that is useful in the real world. Successful integration of traditional 
learning objectives with the elements of entertainment, play, and fun becomes the goal for the design 
of seriousgames. However, few articles exist that re­port positive learning outcomes associated with 
seriousgames that demonstrate transfer of virtual skills to real world applications[Abt 1970; Aldrich2005; 
Chatham2007;Kellyetal.2007;Mayo2007]. To achieve this goal, we argue that the purpose for which we in­tend 
to use video games for educational purposes needs to be a crucial component of the design process. Athorough 
understand­ingofhow users interactin thegameworld de.nesa framework forgame design that contributes to 
both the design and evaluation of seriousgames. In response to these design constraints, we intro­duce 
user centeredgame design as the methodology for design and evaluationof seriousgames. We apply user centered 
design tech­niques, emphasizing observational studies ofgame play activities asthe.rstphaseofgamedesignforthe 
purposeofevaluatingMas­sive Multiplayer Online Role Playing Games (MMORPGs) as po­tential unorthodox 
second language (L2) pedagogical tools. Results from experimental studies indicate that MMORPGs provide 
suf.­cient motivation and opportunities for second language students to increase in pro.ciencyin a target 
language. Finally, we discuss the conceptualization phase, emphasizing design implications of seri­ousgames 
thatfacilitate Second LanguageAcquisition (SLA).  2 User Centered Game Design The typical game design 
process involves three phases of devel­opment: 1. conceptualization, 2. prototyping, and 3. playtesting 
[Fullerton et al. 2004]. Conceptualization describes the planning phase which involves brainstorming, 
identi.cation of formal (e.g. objectives, rules, possible outcomes,game controls, and mechan­ics) and 
dramatic (e.g. background story, characters, challenge, con.ict, and fun) elements ofgame design [Fullerton 
et al. 2004; Salen and Zimmerman 2004]. Game designers producegame spec­i.cations that demonstrate the 
initial look and feel of thegame in­terface, identify system behaviors for rules of interaction and pro­ceduresforgameplayandgame 
controlsthat userswillnavigatein the virtualworld [Rucker2003]. Prototyping allowsgame design­ersto quickly 
implementanAlphaversionofthegamethatgives players an opportunity to play thegame and collect feedback 
on thegame play experience [Fullerton et al. 2004; Salen and Zim­merman 2004]. Feedback from playtesting 
results in an iterative design process, forcinggame developers toprioritize changes and make tradeoffs 
between available features, quality and the sched­ule for .nal production [Rucker 2003]. While typicalgame 
design encompasses the iterative process described above, we posit that designersof seriousgames needadifferent 
design framework that interweaves social interactions, learningobjectives and elements of playifwehopeto 
design seriousgames thathaveapositive learn­ing impact on the player. The purpose for which we want to 
utilize games and the effect on the player determines the focus of user cen­tered design.We de.ne user 
centeredgame design to be:  Speci.c application  Affordancesofgame play  Effectsofgame play  We discuss 
each component below. 2.1 Speci.c Application Remembering that seriousgames createexperiences that promote 
the transfer of skills in the virtual to the real world, the .rst compo­nent of user centeredgame design 
requires agreement on the pur­pose of thegame. The speci.c application refers to whether the purpose 
of thegame is to acquire knowledge or develop skills for a speci.c task in preparation for real world 
scenarios [Abt 1970; Aldrich 2005]. Are we designingagame for educational purposes and if so, what are 
the learning objectives? Is thegame suppose to simulate a natural disaster that trains players to think 
quickly and respond to life threatening situations that save lives or does the seriousgame promotephysical 
interactionasan alternativeto car­diovascular activity? The answers to these questions identify the speci.c 
applications and objectivesof anyseriousgame. 2.2 Affordances ofGame Play Additionally,game designers 
need to understand the bene.ts that games provide the player in the role of the student. What does the 
game play experience afford theplayer that the same experience in the realworld does not? Isa particular 
genreof videogames better suited for the speci.c application and if so, how? User cen­tered game design 
recognizes the bene.ts of game play early in the design phase, allowinggamedevelopersto implement thesead­vantages 
into the core behaviors of the game system. Secondly, learningdoesnothappeninavacuum,butincludes social 
interac­tions that support the learningprocess. Previous research indicates thatgames are ideal for collaborative 
learning, creating opportuni­tiesforplayerstowork togetherto accomplishgame tasks [El-Nasr and Smith 
2006;C. SteinkuehlerandWilliams]. Game designers should consider bothface-to-face human interactions 
and social in­teractions in virtual spaces that support learning and designgames that enable players 
to emulate these interactions duringgame play [C. Steinkuehler andWilliams;Jakobson andTaylor 2003]. 
 2.3 Effects of Game Play While one can speculate about the bene.ts ofgames, we endorse methodology that 
provides substantialevidence thatgame play pro­duces positive learning outcomes. Equally important, designers 
needto strategicallybuildgamesthatprovidea pleasurableexperi­encefor players. This meansthat assessmentofthegameplayexpe­rienceis 
requiredto determinetheeffectsofgameplayon players. Whether this involves formal assessment (e.g. exams) 
or informal assessment (e.g. the players ability to completeagame task that mapstoa speci.c learningobjective), 
designersof seriousgames need to account for assessment early in the design process. The practice of 
measuring the effects ofgame play early in the design process increases the likelihood thatgame designers 
can actually createa seriousgame that producesa positiveexperience for the user and positive learning 
outcomes. Hence, the criticism is that assessment of the user experience must be continuously measured, 
be it quantitatively or qualitatively, and interwoven on multiple lev­els throughoutthedevelopment processof 
seriousgames.Ifwedo not incorporate assessment into the design process, then the result isa videogame 
that the designer hopes accomplishes a speci.ed goal that has meaning orvaluebeyond the contextofgame 
play. Loftygoalsandlackof assessmentdonotwarrantthe classi.cation of seriousgames, especially those seriousgames 
designed for ed­ucational purposes.Withoutunderstanding theeffectofgame play on theuser, thegame designer 
cannot justify the classi.cationof seriousgame. User centeredgame design consistsof one additionaldevelopmen­tal 
phase that initiates the design process for seriousgames. See .gure 1. The remainder of the paper will 
focus on the .rst two phasesofgamedevelopmentandits applicationtotheevaluationof MMORPGs thatfacilitate 
SLA. Figure 1: Model of User Centered Game Design.   3 Observational Studies: First Phase of User 
Centered Game Design In contrast to traditionalgame design, user centeredgame design begins with observational 
studies ofgame play activities, a form of playtesting, rather than the typical design activity of generating 
game ideas [Fullerton et al. 2004; Preece et al. 2002]. User centered game design shares similarities 
with human-centeredgame design in that both design approaches begin with observational studies of the 
user [Abeele et al. 2007]. However, there is a subtle difference between user centered game design differs 
and human-centered game design. Human-centeredgame design seeks to identify the appropriate social context 
in the real world to create meaningful experiences in the virtual world [Abeele et al. 2007]. User centered 
game design observes social interactions associated withgame play to identify and leverage the social 
interactions that support acquisi­tion and application of knowledge. Observational studies ofgame play 
activities provide insight into the learning process and iden­tify the cognitive processes that accompany 
these social interac­tions.Waiting untilthe playtestingphaseto determineifagame has met its objectives 
can lead to misappropriation of resources, disappointed players,andthe decisionto cancela videogame. 
In­stead, we advocate soliciting player input in the early stages of game design, beforea software-based 
prototypeisdeveloped,asan effective method forevaluating theplayer sexperience and driving thegame design 
process. In the early stages of seriousgame de­sign, low .delity prototypes such a paper-based prototypes, 
can be used for observational studies of players experiences [Preece et al. 2002]. Upon completionof 
observational studies,keystakeholders, includinggame designers and educators, identify potentiallearning 
opportunities relevant to a speci.c application or subject matter. These samelearning opportunities form 
the basis for the user model whichis based on human-to-human interactions thegame environ­ment naturally 
supports. The third aspect of user centeredgame design addressesthe impactoftheexperienceonthe user. 
Observa­tional studies that emphasize assessmentofgame playexperiences help to develop the overarching 
goal that designers hope players will achieveasa resultofgameplay.Nextwe conductexperimen­tal studies 
that demonstrate the importance of user centered design for seriousgames.  4 Characteristics of MMORPGs 
that Support Second Language Acquisition Though Standard American English remains the dominant language 
in the United States, 14% of its student population lives in homes where English is not the primary language 
[Watts-Taffe and Tr­uscott 2000]. Educators face the challenge of creating inclusive learning environments 
for students who possess different linguistic capabilities, emphasizing the need for secondlanguage pedagogi­cal 
supports in both mainstream classrooms and informal learning environments. Rather than relying solely 
on text as the means for providing critical information about the virtual environment, com­puter games 
leverage sophisticated graphics to generate images, sounds, gestures, and objects that take on different 
meanings rel­ativeto contextofthegame.Visual information becomesa crucial componentofgame play as players 
interpret visual representations and respond accordingly. In comparison to self-pace tutorials that focus 
on reading, writing, listening and writing skills, videogames require players to follow rules and process 
information to accom­plishgame tasks where languageisjusta meanstoanendandnot the end itself. Such activities 
overcome the lack of motivation at­tributed to text-based Multi-user Object Oriented (MOO) virtual environments 
[Backer 1999]. We identify three key components of MMOPRGs that accommodate SLA: virtual identity, social 
in­teractions andgame context. 4.1 Virtual Identity Typically, foreign language students struggle with 
developing tar­get language pro.ciencydue to inhibitions about using the newlan­guage, especially in 
the traditional classroom setting. Students be­come self-conscious,notwantingtomake mistakesin frontof 
their peers [Hadley2001; Horwitz et al. 1986]. Therefore, language in­structors seek ample opportunities 
to engage students in target lan­guage discourseasa meansof helping studentstobuild their con­.dence 
and develop language competencyand communicative per­formance, the ability to respond appropriately in 
the target language [?;Krashen 1991]. Research has shown that the use of computers (e.g. on-line chat 
rooms) to supplement language learning provides foreign language students with opportunities to practice 
their emer­gent language skillsina non-threatening environment orfaceless interaction that alleviates 
language anxiety or self-consciousness [Beauvois and Eledge 1996]. As a result, students produce more 
interactive conversations that resemble normalface-face conversa­tions in the target language. Foreign 
language students who inter­act online demonstrate an increase in their cognitive skills in the target 
language and perceived learning [Beauvois and Eledge 1996; Hudson and Bruckman 2002]. MMORPGs provide 
both extrinsic and intrinsic motivation in that players complete various quests of their choice to advance 
the development (e.g. skills, knowledge and power) of their chosen virtual character. Active learners 
who assume the role of the virtual characters make a commitment to the advancement of their chosen avatar 
in the virtual world. Simulta­neously, these virtual characters mask the true identity of foreign language 
students. This ability to mask foreign language students real identity reduces anxiety associated withface-face 
interactions with nativespeakers and creates an environment that is more forgiv­ing when foreign language 
students make mistakes during attempts to communicate with others [Rankin et al.2006]. 4.2 Social Interactions 
with Player Characters Video games such as Massive Multiplayer Online Role-Playing Games (MMORPGs) include 
social interactionsaspartofthegame play experience and become social spaces for people of different ethnicities, 
culture and languages to meet and communicate with one another, thus giving the L2 student accessibility 
to speakers in the target language [C. Steinkuehler andWilliams;Jakobson and Taylor 2003]. Social interactions 
in online chat rooms accelerate students reading, thinking and writing skills in the target language 
[J.Payne and Whitney2002] and support the theory that online so­cial interactions in MMORPGs willfacilitate 
SLA. Moreover, on­line social interactions promote a democratic learning environment thatis conducivetobothintrovertedandextroverted 
learners,evolv­ing into learner-centered environments in which students of differ­ent language levels 
accept more of the responsibility for develop­ing target language pro.ciency[Beauvois and Eledge 1996]. 
Be­cause MMORPGs attract a vast array of players from diverse back­grounds and require Player Characters 
(PCs) to develop strategic af.liations with other PCs, foreign language students will have am­ple opportunities 
to interact with speakers in the target language as theyseek assistance with dif.cult quests. Online 
social interactions during game play activities encourage foreign language students to continuously practice 
producing the target language and nego­tiating meaning with native speakers as foreign language students 
further develop communicative competence in the target language. MMORPGs supply chat windows that enable 
players to communi­cate with Non Player Characters (NPCs) as well as Player Char­acters (PCs) in the 
virtual world. Therefore, the practice of chat­ting with other PCs provides ample opportunities for interactions 
between non-native speakers and native speakers in the target lan­guage. These interactions support second 
language students ability to communicate effectively with native speakers.  4.3 Contextfor SecondLanguage 
Acquisition Interactive media in the form of video games offers an under­utilized, immersive environment 
for developing pro.ciency in a foreign language [Rankin et al. 2006]. MMORPGs utilize audio, graphical 
images to conveysemantic meanings of potential L2 vo­cabulary and phrases. MMOPRGs display dialogue between 
Non Player Characters (NPCs) and PCs to assist foreign language stu­dents with syntacticalstructure of 
the target language. Players se­lect a response to NPC questions which feature potential L2 vo­cabularyand 
informationrelevantquestsinthegame[Rankinetal. 2006]. Interactions between PCsfacilitate communicative 
perfor­mance as foreign language students develop an understanding of what constitutes an appropriate 
response while engaging in conver­sations with native speakers via the chat window. All of the infor­mation 
is displayed and heard in the target language, creating an immersive learning environment that reinforces 
communication in the target language. Thus, MMORPGs supply an immersive envi­ronment and opportunities 
to participate in social interactions with native speakers in the target language, creating an effective 
digi­tal learning environment for SLA. Next we conduct experimental studies that demonstrate the importance 
of user centered design for seriousgames.  5 Observational Studies of EverQuest II EverQuest II (EQ2) 
is a MMORPG that is a sequel to the original EverQuest MMORPG, both designed by Sony Online Entertain­ment.Priortoplayingthegame,playersselecta 
characterfrom16 races (e.g. dwarfs, barbarians, etc.) and5archetypes (e.g. mage, scout, artisan, priest, 
and .ghter) with each race and archetype hav­ing speci.c abilities. Players assume the role of their 
character, an avatarthat representstheplayer svirtualidentityinthegameworld. For example, if the player 
selects a cleric from the race of dwarfs who is a member of the priest class, then the player is represented 
as an avatar short in height and empowered with divine magic that banishes diseases. Players are immersedinafantasyworldof 
beau­tiful 3D graphics while journeying across various terrains, includ­ing rolling hills, barren deserts, 
dense forests, andbustling cities. Players advance from one level to another as theysuccessfully com­plete 
challenges/quests; EverQuest II contains 60 levels. Players may form groups known as guilds that work 
together to complete quests or choose to play as individuals. EverQuest II accommo­dates social interaction 
among players, allowing players to commu­nicatewithone anotherusingtextandaudiowhileplayingthegame and 
participating in player forums which serve as a useful resource for sharingand discussing effectivegame 
strategies, forming rela­tionships with other players, receiving assistance whenfaced with trouble, and 
learning how to play thegame. EverQuest II can be played in English, French, German, Russian, and Japanese 
and has an international player base. 5.1 First Observational Study To determine feasibility of MMORPGs 
as language learning tools, we conducted a between subjects experimental design to test the followinghypothesis: 
MMORPGsprovide adequate supportforL2 vocabulary acquisition. 5.2 Participants Twelve AdvancedEnglish 
as Second Language (ESL)Chinese stu­dents were randomly assigned to two conditions: 1. Six ESL stu­dents 
who attended three hours of class instruction; 2. Six ESL students who played EverQuest II (EQ2) for 
four hours. 5.3 Methods To accommodate the learning curve associated with understanding thegame objective 
and maneuvering thegame controls, ESL stu­dents spent anextra hour becomingfamiliar with EQ2. All twelve 
Advanced ESL students were enrolled in an Intensive English Pro­gram at a southern liberal arts college. 
Prior to participation in each condition, participants took an assessment that measured their priorknowledgeofL2vocabularywordsthat 
were modeledinNPC speech during game play. The assessment required ESL partici­pants to use the potential 
L2 vocabulary in a sentence demonstrat­ing prior knowledge. We purposefully selected L2 vocabulary that 
wasnotspeci.ctothegameand representedcollegelevel academic words (e.g. coagulated, coalesce, fervent, 
revive). ESL students who attended class participated in drill and rote exercises (e.g. de­.ne the L2 
vocabulary word and use it in a sentence) while the ESL students who played EQ2 were given the tasks 
of completing quests1 -8. Once both groups had completedthe designated hours for the study, each participants 
took three assessments. The .rst post test assessment asked students to use L2 vocabulary in sen­tences 
demonstrating understanding of the word. Sentences were evaluated for appropriate use of L2 vocabulary 
and not grammati­cal correctness. The second post-test assessment useda recognition task based ongame 
play scenarios where ESL participants selected the correct meaning from multiple choice options of L2 
vocabulary words. The third assessmentwasa rational cloze assessment which measured ESL participants 
semantic knowledge of L2 vocabulary words outside the context ofgame play in addition to their ability 
to select L2 vocabulary words based on contextual clues located in the clause, the sentence, and in the 
text. 5.4 Discussion of Results Theaverage pre-test score for all twelve participantswas 8.86 indi­catingknowledgeof 
approximatelytwoL2vocabularywords. One-Way AnalysisofVariance(ANOVA)of testofpost test assessment of 
sentence usage revealed a signi.cant difference, F(1, 9) = 8.94, p = 0.02. ESL students who participated 
in traditional classroom instruction had an average post test score of 54.78 (SD = 8.81) out of 100 compared 
to the average score 16.16 (SD = 9.65) for ESL students who played EQ2. No signi.cant differences were 
found for the post test forL2vocabularyin the contextof thegame and transfer of knowledge of L2 vocabulary 
outside the context of the game. See .gure 2. Figure 2: Results of post-test assessment of L2 vocabulary 
for .rst observational study.  6 Second Observational Study To determine feasibility of MMORPGs as 
language learning tools, Iconducteda secondbetween subjectsexperimentaldesignto test the following hypothesis: 
Social interactions between native and non native speakers in MMORPGs support L2 vocabulary acquisi­tion. 
 6.1 Participants Twelve AdvancedEnglish as Second Language (ESL) Chinese stu­dents were randomly divided 
into two groups of six each. Seven Native English Speakers (NES) of African American descent and enrolled 
in a southern university consented to participate in the study.  6.2 Methodology Each of the twelve 
ESL students were randomly assigned to one of the following conditions: 1. ESL students whoplayed EQ2 
alone and2. ESL studentswho formed teamsof4people(2NESand2 ESL) as they worked together to complete quests. 
Both groups se­lectedavirtual characterwhowasacitizenofQeynos(good charac­ter)andweretoldtocompletequests1 
-8.Theone additionalNES was to accommodate one game session when 1 NES participant couldnot attendandso 
anotherNES participantplayedthegamein this participant s absence. At the beginning of the study, the 
ESL students completed a pre tests which measured prior knowledge of potentialL2vocabularywords. Both 
groups(ESLEQ2soloplayers andEQ2ESLw/NES)engagedinfour hoursofgameplay,expos­ingbothgroupsto potentialL2vocabularyfoundinNPC 
dialogue. Upon completionof the study, three post tests weregiven. The .rst post test assessment asked 
students to use L2 vocabulary in sen­tences demonstrating understanding of the word. Sentences were evaluated 
for appropriate use of L2 vocabulary and not grammati­cal correctness. The second post-test assessment 
useda recognition task based ongame play scenarios where ESL participants selected the correct meaning 
from multiple choice optionsofL2vocabulary words. The third assessmentwasa rational cloze assessment 
which measured ESL participants semantic knowledge of L2 vocabulary words outsidethe contextofgameplayin 
additionto their abilityto selectL2vocabularywords basedon contextual clues locatedinthe clause, the 
sentence, and in the text. Results are discussed below. 6.3 Discussion ofResults ESL students who collaborated 
with NES participants performed signi.cantly higher (M = 55.56, SD = 5.06) than the ESL students who 
played EQ2 with no social interactions with NES (M = 82.22, SD = 5.54). An ANOVAof post test scores for 
L2 vocabulary in the context ofgame play indicate F(1,9) = 12.62 forp = 0.01. See .gure4.DespitethefactthattheESL 
studentspairedwiththeNES participants produced scores of zero for the post test assessment for L2vocabulary 
outside the contextof thegame, therewasno sig­ni.cant difference of low scores for the ESL students who 
played EQ2 alone. These results indicate that the social interactions be­tween ESL students and NES participants 
involved discussion of quests, including critical information that featured L2 vocabulary words. See 
.gure 5. These discussions made salient L2 vocabu­larywords andfacilitated ESL students increaseinL2vocabulary 
acquisition. Thus, results reinforce L2 pedagogy that emphasizes interactions with native speakers as 
the means in which second lan­guage students develop communicativecompetence (e.g. grammat­ical structure 
of language) and performance in the target language. See .gure 3. We predicted that thedrill and rote 
practices used forL2 pedagogy in the classroom instruction condition would prove bene.cial for post test 
assessment, especially since the ESL students de.ne the words and use them in sentences. Thus, the sentence 
usage post test was a near task of learning for this group of participants. Though the ESL students who 
played EQ2 did not improve signi.cantly, the majority of student participants in this group did increase 
their number of L2 vocabulary. Remember that the claim is MMORPGs canprovide adequate supportforL2 acquisition.Wedidnotexpect 
MMORPGsto outperform traditional classroom instruction,butwe want to evaluate MMORPGs ability to facilitate 
SLA. Therefore, results suggest that MMORPGs show great promise as a second language pedagogical tool, 
providedgame designers leverage the bene.ts of MMORPGs for SLA. Upon closer scrutiny, qualitative analysis 
revealed an interesting pattern of social dynamics between the NES players and ESL stu­dents. We developed 
a modi.ed version of the Dialogue Acts in Several Markup Layers applicable to social interactions between 
native English speakers and non-native English speakers in a vir­tual environment [Allen and Core 1997]. 
After achievingaCohen s Kappa of 80% inter-rater reliability, we coded 525 chat messages for the following 
four categories of speechacts: 1. request forgame or personal information; 2. assertive statements demonstrating 
knowledge of the game, self, or world; 3. conversational openings&#38;closings; 4. player s in.uence 
on other PCs future actions in the virtual world;  Though NES participants produced more chat messages 
for each of the categories, no signi.cant differences were found between the two groups. We assumed that 
there would be a signi.cant differ­enceinthe quantityof messages codedasassertivestatements since the 
ESL students were being introduced to EQ2 and in some cases thiswas their .rstexperience playing videogames. 
Results indicate that the lackofexperience playing videogames or the noveltyof EQ2 had small if anyimpact 
on their ability to communicate with NES participants. However, this suggests that the ESL students Advanced 
Level of Pro.ciencyin English may have contributed to their ability to match the communicative performance 
of their NES teammates. The question remains if we would see the same effect if Intermediate ESL students 
were conversing with NES players or would the communication patterns signi.cantly differ? These are questions 
to be explored in future research. Figure 3: Results of second observational study: One-Way ANOVA of 
post-test scores of L2 vocabulary.  7 Conceptualization of Serious Games for SLA Thegoalof seriousgamesisto 
creategameplayexperiences that develop knowledge and skills that have value in the virtual world and 
transfer to real world applications. The results of the .rst ob­servational study indicated that the 
effect of traditional L2 peda­gogy on post-test scoresfar outweighed the effect of ESL students playing 
EQ2. If we closely examine the practices involved in tradi­tional L2 instruction, we .nd that the instructor 
provides guided in­struction, repeatedly making salient thekeypoints of interest such as semantics of 
L2 vocabulary. In comparison, games represent open-ended exploration, giving the player the freedom to 
do as she wishes. This contradicts L2 classroom instruction and intro­ducesthe possibilityof studentsoverlooking 
important information suchas potentialL2vocabulary.Onedesign implicationfor serious games that lead to 
an increase in SLA is to incorporate experiences duringgame play that guide the player to relevant information 
in the target language. For example, the concept of intelligent NPCs that are capable of real-time multi-modal 
conversation that empha­sizesL2vocabulary canoffer guided instructionto second language students and 
enhance thegame playexperience.  Figure 4: Game dialogue between ESL students and NES partici­pants 
using L2 vocabulary word parchment. The results of both observational studies stronglysuggest that social 
interactions between native and non-native speakers in interactive and cooperativegameplay becomeanintegralfactorin 
contributing to second language acquisition. These results position user centered game designasaneffective 
methodologyfor designinggame inter­faces that capitalize on social interactions between players. The 
ability to leverage social interactions thatfacilitate SLA becomes a crucial requirement in the design 
of seriousgames that promote pro.ciency in the target language. Furthermore, our results iden­tify that 
MMORPGs accommodate the speci.c L2 learning objec­tives of vocabulary acquisition, reading comprehension 
skills, and conversational .uency. These same learning objectives become the speci.cations for the designofa 
seriousgame, speci.callygame tasks that creategame playexperiences that support thedevelop­ment of L2 
players pro.ciencyin the target language. Moreover, the qualitative analysis of native and non-native 
speak­ers chat logs collected during the second experimental study pro­vides valuable data that informs 
the prototype phase. This is more effective than the traditionalgame design process which does not include 
observational studies as the initial phase ofgame develop­ment. The four categories of speech acts used 
to code the subjects game logs serve the dual purpose of classifying the different types of social interactions 
between the NES players and the ESL stu­dents. Consequently, these four classi.cations of social interactions 
de.ne the conceptofa seriousgame thatfacilitates SLA. First,it supports communicative performance which 
is a SLA learning ob­jective. Secondly,itgivesthe second language studentthe abilityto communicate with 
other Player Characters whichisagame activity that supports the learning objective. The output of the 
conceptu­alization phase de.nes the speci.cations for the game prototype. Based on the results of observational 
studies, one iterative pass of user centered game design speci.es communication in the target language 
as one of the primary functions of the prototype. Using Sony sUI Builder,we implementanAlphaversionofagameplug­in 
that facilitates conversation in the target language by offering conversational prompts that assist L2 
students with social interac­tions associated withgame activities. See .gure4. Figure 5: Prototype of 
game plug-in that facilitates conversation with PCs.  8 Conclusion Results from both experimental studies 
indicate that MMORPGs can serve as unorthodox second language pedagogical tools. Fur­thermore, user centeredgame 
design identi.es learning opportuni­tiesin the initial stageofgamedevelopment. Futurework includes a 
prototypeofagame plug-in thatwill provide conversational sup­ports in the target for foreign language 
students. This will assist second language students attempts to meet and collaborate with na­tive speakers 
as theycompletegame tasks. Additional futurework includes usability testing of the prototype as part 
of the iterative design process for MMORPGs that supplement L2 pedagogy. 9 Acknowledgements We would 
like to acknowledge John Nordlinger for suggesting the idea that videogames could function as language 
learning tools and orchestrating a strategic meeting with John Smedleyof Sony On­line Entertainment. 
In addition, we express gratitude to Dr. Beth Stapleton, Demetria Rankin-Li, and Rodney Brown for giving 
us access to the students in the Mississippi College Intensive English Program. Finally, we thankScott 
Hartsman who has been one of our strongest advocates and mostfaithful supporters. None of this would 
be possible without him.  References ABEELE, V. V., HUSSON, J., VANDEURZEN, L., AND DESMET, S. 2007. 
A soft approach to computer science: Designing&#38; developing computergames for and with senior citizens. 
Journal of Game Development 2, 41 62. ABT,C.C. 1970. Serious Games. Viking Press. ALDRICH,C. 2005. Learning 
by Doing:A comprehensive guide to simulations, computer games and pedagogy in e-Learning and other educational 
experiences. Pfeiffer. ALLEN,J., AND CORE,M. 1997. Draftof damsl: Dialogue actin several markup layers. 
BACKER, J. A. 1999. Multi-user Domain Object Oriented as a High School Procedure for Foreign Language 
Acquisition. PhD thesis, Nova Southeastern. BEAUVOIS,M.H., AND ELEDGE,J. 1996. Personality types and 
megabytes: student attitudes toward computer-mediated com­munication (cmc) in the language classroom. 
CALICO Journal 13,2,27 45. C. STEINKUEHLER, C., AND WILLIAMS, D. Where everybody knows your (screen) 
name: Onlinegames as third places. Jour­nal of Computer-Mediated Communication 11, 4. CANALE,M., AND 
SWAIN,M. 1980. Theoretical basesof com­municative approaches to second language teaching and testing. 
Applied Linguistics 1, 1, 1 47. CHATHAM,R.E. 2007. Games for training. Communications of the ACM 50,7,36 
 43. EL-NASR,M., AND SMITH,B. 2006. Learning throughgame modding. ACM Computers in Entertainment 4, 1. 
FULLERTON,T.,SWAIN,C., ANDHOFFMAN,S. 2004. Game De­sign Workshop: Designing, prototyping and playtesting 
games. CMP Books. GEE, J. P. 2003. What Video Games Have to Teach Us about Learning and Literacy. Palgrave 
McMillian. HADLEY,O.M. 2001. Heinle and Heinle. HORWITZ,E.,HORWITZ,M., AND COPE,J. 1986.Foreign lan­guage 
classroom anxiety. The Modern Language Journal 70, 2, 125 132. HUDSON, J., AND BRUCKMAN, A. A. 2002. 
Irc francais: The creation of an internet-based sla community. Computer Assisted Language Learning Volume 
15, 2, 109 134. JAKOBSON, M., AND TAYLOR, T. 2003. The sopranos meets everquest: Social networking in 
massively multiplayer online games. In Conference Proceedings of the 2003 Digital Arts and Culture (DAC) 
Conference,ACM, 81 90. J.PAYNE,AND WHITNEY,P.2002.Developingl2 oralpro.ciency through synchronous cms: 
Output, workingmemory, and inter­language development. CALICO Journal 20,1,7 32. KELLY, H., HOWELL, 
K., GLINERT, E., HOLDING, L., SWAIN, C.,BURROWBRIDGE,A., AND ROPER,M. 2007.Howtobuild seriousgames. Communications 
of the ACM 50,7,44 50. KRASHEN,S.D. 1991. Pergamon Press. MAYO,M.J. 2007. Games for science and engineeringeducation. 
Communications of the ACM 50,7,30 35. PREECE, J., ROGERS, Y., AND SHARP, H. 2002. Interaction Design: 
Beyond human-computer interaction. R.R. Donnelley. RANKIN,Y.,GOLD,R., AND GOOCH,B. 2006. 3d role-playing 
games as language learning tools. InIn Conference Proceedings of EuroGraphics 2006, vol. 25. RUCKER, 
R. 2003. Software Engineering and Computer Games. Addison-Wesley. SALEN, K., AND ZIMMERMAN, E. 2004. 
Rules of Play: Game design fundamentals. MIT Press. SQUIRE,K. 2005. Changing thegame: What happens when 
video games enter the classroom? Innovate 1, 6. WATTS-TAFFE,S., AND TRUSCOTT,D.M. 2000. Using what we 
know about language and literacydevelopment for esl students in the mainstream classroom. Language Arts 
77, 3, 258 265.  
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
	</article_rec>
	<article_rec>
		<article_id>1401852</article_id>
		<sort_key>90</sort_key>
		<display_label>Pages</display_label>
		<pages>4</pages>
		<article_publication_date>08-09-2008</article_publication_date>
		<seq_no>3</seq_no>
		<title><![CDATA[GOGS]]></title>
		<subtitle><![CDATA[USC GamePipe Online Game Server]]></subtitle>
		<page_from>51</page_from>
		<page_to>53</page_to>
		<doi_number>10.1145/1401843.1401852</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1401852</url>
		<abstract>
			<par><![CDATA[<p>Massively multiplayer online games (MMO) are at the height of interest and growing in popularity in the commercial video game market. New development studios are vying for the position of top MMO, both in the number of users and market value. Recently, interest in online games has entered the realm of educational practitioners and researchers. It was as researchers, as well as game developers and designers in mind, that the USC GamePipe Laboratory has developed its initial version of the academic, open source USC GamePipe Online Game Server (USC GOGS).</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[massively multiplayer online games]]></kw>
			<kw><![CDATA[networked games]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>C.3</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010520.10010553</concept_id>
				<concept_desc>CCS->Computer systems organization->Embedded and cyber-physical systems</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010520.10010570</concept_id>
				<concept_desc>CCS->Computer systems organization->Real-time systems</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010520.10010553</concept_id>
				<concept_desc>CCS->Computer systems organization->Embedded and cyber-physical systems</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010520.10010570</concept_id>
				<concept_desc>CCS->Computer systems organization->Real-time systems</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<person_id>P1100706</person_id>
				<author_profile_id><![CDATA[81100549374]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Michael]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zyda]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[USC GamePipe Laboratory, Los Angeles, CA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1100707</person_id>
				<author_profile_id><![CDATA[81365593614]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Devin]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Rosen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[USC GamePipe Laboratory, Los Angeles, CA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1100708</person_id>
				<author_profile_id><![CDATA[81365598413]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Bharathwaj]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Nandakumar]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[USC GamePipe Laboratory, Los Angeles, CA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Ogre3d http://ogre3d.org]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Fmod http://fmod.org]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[RakNet -- http://www.jenkinssoftware.com/]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[USC GamePipe Laboratory web site http://gamepipe.usc.edu]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 GOGS: USC GamePipe Online Game Server Michael Zyda USC GamePipe Laboratory 941 W. 37th Pl., SAL 300 
Los Angeles, CA 90089-0781 +1-310-463-5774  zyda@usc.edu Devin Rosen USC GamePipe Laboratory 941 W. 
37th Pl., SAL 300 Los Angeles, CA 90089-0781 +1-310-463-5774  devinpro@usc.edu Bharathwaj Nandakumar 
USC GamePipe Laboratory 941 W. 37th Pl., SAL 300 Los Angeles, CA 90089-0781 +1-310-463-5774  nandakum@usc.edu 
ABSTRACT Massively multiplayer online games (MMO) are at the height of interest and growing in popularity 
in the commercial video game market. New development studios are vying for the position of top MMO, both 
in the number of users and market value. Recently, interest in online games has entered the realm of 
educational practitioners and researchers. It was as researchers, as well as game developers and designers 
in mind, that the USC GamePipe Laboratory has developed its initial version of the academic, open source 
USC GamePipe Online Game Server (USC GOGS). Categories and Subject Descriptors C.3 [Computer Systems 
Organization]: Special-purpose and application-based systems; real-time and embedded systems. General 
Terms Networked games  Keywords Networked games; massively multiplayer online games. 1. INTRODUCTION 
Online games provide new and exciting ways for educators to disseminate knowledge. Online education opens 
up new avenues of teaching by allowing customization of material tailored to the needs of students in 
a controlled fashion. By freeing the conventional, spatial boundaries of education, new forms of collaborative 
efforts are facilitated. Online digital communities allow new forms of interaction to emerge. In addition 
to provoking new forms of interaction in education, online games and communities open up new opportunities 
for the study of social behavior. The goal, with respect to new research, involves studying the patterns 
of established and emergent groups in online games. With an open MMOG, researchers would be able to create 
and test social models in the digital world that could lead to insight in the actual world. Copyright 
&#38;#169; 2008 by the Association for Computing Machinery, Inc. Permission to make digital or hard copies 
of part or all of this work for personal or classroom use is granted without fee provided that copies 
are not made or distributed for commercial advantage and that copies bear this notice and the full citation 
on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting 
with credit is permitted. To copy otherwise, to republish, to post on servers, or to redistribute to 
lists, requires prior specific permission and/or a fee. Request permissions from Permissions Dept, ACM 
Inc., fax +1 (212) 869-0481 or e-mail permissions@acm.org. Sandbox Symposium 2008, Los Angeles, California, 
August 9 10, 2008. &#38;#169; 2008 ACM 978-1-60558-173-6/08/0008 $5.00 The USC GamePipe Laboratory, in 
assessing these growing needs, while striving to educate the engineers pursuing the games industry, has 
developed an initial version of an open source, academic online game server. In the effort to develop 
an MMOG, we found that there currently are not any freely available, open source solutions to help bridge 
the technological gap between single player and large-scale networked games. The goal was to provide 
a simple to use, intuitive software toolkit to allow researchers and small independent designers and 
developers to create multiplayer networked games. The priority was to eliminate technical challenges, 
to allow developers to take new or single player games and easily bring them to the online multiplayer 
community. 2. The Technology In the USC GamePipe Laboratory, the majority of games are developed in 
C++. The libraries most-often used are OGRE (Object-Oriented Graphics Rendering Engine) [1] and the FMOD 
sound engine [2]. Development is done on Windows based PCs. During the course of an average semester 
about twelve unique games are produced to the point of being a functionally complete and entertaining 
demo. In addition to these original concepts, a few games are continued from the previous semester for 
further development. The combination of C++ and OGRE has been so successful that we have created the 
GamePipe Game Engine (GGE) based around OGRE. The primary target of users for GOGS is the student developer 
in GamePipe. By focusing on having the network package tightly integrate with the GGE, we chose to only 
support Windows based operating systems for both the network server and network databases. This decision 
may be expanded to support other platforms in future versions. All development of GOGS was in C++ using 
Microsoft Visual Studio and the database was Microsoft Access. All of the design choices for the engine 
were to support the Object Oriented design paradigm used in production in the lab.  3. The Design The 
design of GOGS is a multilayered pattern to help support the rapidly scaling requirements of networked 
games. The architecture consists of the Authentication Layer, Game State Layer, VOIP Layer, Client Layer, 
and Accounting Database, and a Player Persistence Database. Each layer was conceptualized to allow for 
simple horizontal scaling. The Authentication Layer is responsible for handling the initial connection 
of clients as well as verifying the clients. The Authentication Layer validates Clients. After correct 
validation, it sends both required player information from the Player Persistence Database and the current 
state of the game. The state sent takes into account the entry point of the player from the Game State 
Layer. This layer also allows a client to transfer from one Game State Server to another. This verification 
from the Authentication Layer to switch between servers was chosen to increase the security of the networked 
system.  The Game State Layer handles all game simulation calculations. The architecture of the system 
treats the clients as a proxy. This means the players make requests to the actual game characters being 
simulated on the server. The choice to use a proxy allows for stricter security policies to ensure the 
clients are limited from cheating the game. This method of control also allows for all game state inconsistencies 
between clients to be handled by the Game State Layer. By choosing to have a proxy system, we give up 
faster client side simulation speeds for the sake of having a consistent state of the game for all clients. 
The addition of the VOIP Layer was added after the initial design of the system. The decision to include 
VOIP in the engine was based on the observation that if an MMOG did not support verbal communication 
in the game, players would turn to outside software packages to facilitate group communication and collaboration. 
The VOIP Layer only supports direct communication and group communication. This decision was based on 
two pieces of information. The first mitigating factor was the amount of bandwidth required to support 
the constant flow of audio data. We wanted to limit the amount of data sent to clients in similar geographic 
regions within a game, so we did not provide the capability to transmit voice to general players in an 
area. The second reason for limiting the communication to individuals or groups was for the security 
of the players if the engine was to be used for an academic game or as an academic tool. This decision 
was based on the safety of the player. We limited verbal communication to players in the client's friend 
list or groups that were chosen by the client. The Client Layer was designed to be thin, lightweight, 
and easy to use by developers requiring network support. From the developers' standpoint, GOGS is an 
event-based system. This means that every object sent over the network is treated in the same fashion. 
All developers have to do to integrate networking is send and receive events. The decision to make all 
objects consistent was for ease of design. In order to use any object as an event, it just has to use 
the Event Interface and be serializable. In addition to simplifying the use of objects, we made the login 
process of clients easy by limiting the amount of code required connect to the engine. The Player Persistence 
Database is responsible for keeping a cached copy of the client status on disk in the event of a system 
failure. This database maintains persistence between client sessions. As a whole, GOGS features an event-based 
system with global time. Maintaining a global time eliminates any playback or packet flooding attacks. 
GOGS includes Lobby code that allows players to communicate by either text or verbal chat with other 
players in the lobby, as well as players in the current game.  4. Current State The current version 
of the GOGS system was designed and implemented over the course of one semester. A team of eight graduate 
level computer science students in the USC GamePipe Laboratory created it. In order to facilitate the 
rapid design and testing of GOGS in a condensed timeframe, we limited the scope of the project to a single 
server for each of the layers. Taking an existing, session based network game and replacing all network 
code with GOGS compliant code initially tested this version of the engine. This allowed the game to maintain 
state between sessions and also enabled easy integration of VOIP.  5. The Games The games developed 
using GOGS helped in determining the efficiencies and deficiencies of the initial design and Penguins 
is a multilayer snowball throwing game. The game revolves around groups of penguins engaging in a friendly 
snowball fight. Each player controls a group of matching penguins. The player controls one individual 
penguin in the group while the rest of the penguins on the team are there for supporting snowball attacks. 
The team penguins are controlled by AI to throw snowballs at the nearest threatening penguin or defend 
the player. During this snowball fight, no blood is shed, but rather penguins slowly turn into ice-cubes 
as opponents snowballs hit them. Originally the game was based on rounds in short individual sessions. 
It supported a maximum of four individual players during any given session. The particular challenge 
in designing the game was to minimize the number of packets sent while still allowing a large amount 
of data to be passed over the network. Every snowball thrown in the game generated data that needed to 
be sent to maintain a consistent state in the game. We had to primarily optimize the way snowball information 
was sent in order to allow players to throw snowballs as rapidly as they could click the mouse button. 
We intentionally did not want to place a limit on the number of snowballs created in any given game session. 
The reason for not limiting this was to see how far we could push the capability of the network software 
as well as maximize the level of fun in the game. This first version of the game was created using RakNet 
[3]. The second version of Penguins was converted to use the GOGS architecture. By switching over the 
network code, we were able to take advantage of several of the features that were built into the engine. 
The first noticeable benefit was the addition of player persistence and the Authentication Layer. After 
integration, we were able to create client accounts with passwords. In addition to these accounts, the 
player persistence database maintained the player preferences when re-entering the game. Players could 
maintain the costumes they had previously selected for their penguin squad. In the game, you could choose 
a hat and costume for your team to differentiate between the penguin groups. Statistics of the rounds 
were also collected on the player persistence database. Another benefit of GOGS that related to gameplay 
was the easy addition of VOIP. With the addition of verbal communication, we saw changes in the way alliances 
were formed during game sessions. The second version of Penguins included a lobby that supported both 
text and verbal chat between players in the lobby as well as in the game. The most significant improvement 
to the Penguins game was the increase in the number of supported Lockdown is currently in development 
in the USC GamePipe Laboratory. This game is a training simulation for first responders in hostile situations. 
The purpose of the simulation is to assess the players on their level of performance in handling threatening 
situations. The game is a squad-based game where multiple players are on a single team with the primary 
goal of securing a hostile environment. While the first objective of the game is to secure the environment, 
secondary goals include a triage mini­game in which players assess and classify any injured non-playing 
characters (NPC). Players are ranked based on their accuracy of classifying these NPCs in addition to 
the amount of time it takes them to perform the triage and to secure the environment. Lockdown was a 
prime candidate for GOGS due to the requirement of allowing the squad to have verbal communication during 
the simulation. One of the bigger challenges in Lockdown, which we did not have to address in Penguins 
was the size and scope of the terrain. Penguins took place in a relatively small piece of terrain that 
was essentially a flat, confined, outside area. Lockdown in contrast occurs in a building with multiple 
floors. Each floor contains a variety of rooms, doors, hallways, and stairs. The game also supports both 
interior and exterior gameplay in relation to the building. The diverse terrain had no immediate impact 
on the performance of GOGS. Lockdown also features more simultaneous clients than Penguins supported. 
Lockdown will support eight to sixteen human players in addition to countless NPCs that are controlled 
in the Game State Layer.  6. Conclusion As a team, we are thrilled about the successful use of GOGS 
in both of these games. The most important part is that the interest to continue to design and develop 
GOGS is spreading among graduate level students. These students realize the importance of having a successful 
open source solution to this challenging problem. There are a variety of technical improvements that 
will be made in the next iteration of GOGS. These improvements include a variety of optimizations. We 
plan to include increased threading support for buffering threads on both the client and server layers. 
Another step is to implement the horizontally scalable layers with a distributed server system that uses 
the publisher/subscriber model over TCP/IP channels. We would like to expand upon the level of packet 
compression and optimization. The next version will also include dynamic area-of-interest management 
(AOI). We plan to extend GOGS beyond the USC GamePipe Lab to the general game development community in 
order to promote creativity and community in game design and development [4]. 7. ACKNOWLEDGMENTS We 
wish to thank all the students involved in the development of GOGS, including Bharathwaj Nandakumar, 
Devin Rosen, Praveen Kansara, Balakrishnan Ranganathan, Apar Suri, Ivan Chen, Sunil Shenoy, Pravin Babar 
and Nathan Greenfield. We additionally thank the National Science Foundation for its support of this 
project through the USC Integrated Media Systems Center.  8. REFERENCES [1] Ogre3d http://ogre3d.org 
[2] Fmod http://fmod.org [3] RakNet http://www.jenkinssoftware.com/ [4] USC GamePipe Laboratory web 
site http://gamepipe.usc.edu  
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
	</article_rec>
	<article_rec>
		<article_id>1401853</article_id>
		<sort_key>100</sort_key>
		<display_label>Pages</display_label>
		<pages>6</pages>
		<article_publication_date>08-09-2008</article_publication_date>
		<seq_no>4</seq_no>
		<title><![CDATA[Using Greenfoot and games to teach rising 9th and 10th grade novice programmers]]></title>
		<page_from>55</page_from>
		<page_to>59</page_to>
		<doi_number>10.1145/1401843.1401853</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1401853</url>
		<abstract>
			<par><![CDATA[<p>In a two-week residential game camp we used the Greenfoot IDE to teach java programming to rising 9<sup>th</sup> and 10<sup>th</sup> graders. Students created their own computer games which required learning how to write java programs, create a game design, and create art assets. In this paper we focus on the computer science pedagogy used and describe the initial design of an augmented game development framework for the Greenfoot environment. This framework includes classes for the following useful game elements: Animation, Projectiles, Side Scrolling Worlds, Text Boxes, Clocks and Timers. We describe these classes, discuss the effectiveness of each, and describe potential improvements to their implementation and design. We also report the results of a survey conducted during each of the camps.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[computer science education]]></kw>
			<kw><![CDATA[game development]]></kw>
			<kw><![CDATA[game programming]]></kw>
			<kw><![CDATA[introductory programming]]></kw>
			<kw><![CDATA[novice programmers]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>K.3.2</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10003456.10003457.10003527.10003531.10003536</concept_id>
				<concept_desc>CCS->Social and professional topics->Professional topics->Computing education->Computing education programs->Information science education</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003456.10003457.10003527.10003531.10003533</concept_id>
				<concept_desc>CCS->Social and professional topics->Professional topics->Computing education->Computing education programs->Computer science education</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003456.10003457.10003527.10003531.10003536</concept_id>
				<concept_desc>CCS->Social and professional topics->Professional topics->Computing education->Computing education programs->Information science education</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003456.10003457.10003527.10003531.10003533</concept_id>
				<concept_desc>CCS->Social and professional topics->Professional topics->Computing education->Computing education programs->Computer science education</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Human Factors</gt>
			<gt>Languages</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P1100709</person_id>
				<author_profile_id><![CDATA[81436599351]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Mohammed]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Al-Bow]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Denver]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1100710</person_id>
				<author_profile_id><![CDATA[81436598171]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Debra]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Austin]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Denver]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1100711</person_id>
				<author_profile_id><![CDATA[81324489181]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Jeffrey]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Edgington]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Denver]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1100712</person_id>
				<author_profile_id><![CDATA[81317493521]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Rafael]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Fajardo]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Denver]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1100713</person_id>
				<author_profile_id><![CDATA[81436592970]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Joshua]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Fishburn]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Denver]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1100714</person_id>
				<author_profile_id><![CDATA[81100493882]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>6</seq_no>
				<first_name><![CDATA[Carlos]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Lara]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Denver]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1100715</person_id>
				<author_profile_id><![CDATA[81430603947]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>7</seq_no>
				<first_name><![CDATA[Scott]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Leutenegger]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Denver]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1100716</person_id>
				<author_profile_id><![CDATA[81100568896]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>8</seq_no>
				<first_name><![CDATA[Susan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Meyer]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Denver]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[The Greenfoot Programming Environment, www.greenfoot.org]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Bang, Molly, PICTURE THIS, How Pictures Work, SeaStar Books, 2000, ISBM 1-58717-030-2]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[The BlueJ Programming Environment, www.bluej.org]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1268820</ref_obj_id>
				<ref_obj_pid>1268784</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Distasio, Joseph, Way, Thomas, P., Inclusive Computer Science Education Using a Ready-made Computer Game Framework, ITiCSE'07, June 23--27, 2007, Dundee, Scotland, United Kingdom, ACM 2007.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Fajardo, R., Leutenegger, Scott T., "Programming, Pixels and Play: A University Summer Game Camp To Attract Under-represented Populations to Game Development and Computer Science", Proc. of Future Play, 2006.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1028701</ref_obj_id>
				<ref_obj_pid>1028664</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Henriksen, Poul, Kolling, Michael, greenfoot: Combining Object Visualisation with Interaction, OOPSLA'04, Oct 24--28, 2004, Vancouver, British Columbia, Canada, ACM.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[The Inkscape drawing tool, www.Inkscape.org.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Pixels, Play, Programming, and Pedagogy, www.p4games.org]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Salen, Katie, Zimmerman, Eric, Rules of Play, MIT Press, 2004, isbn 0-262-24045-9]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1203954</ref_obj_id>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Shaffer, David Williamson. How Computer Games Help Children Learn. Palgrave Macmillan. 2006]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1181905</ref_obj_id>
				<ref_obj_pid>1181901</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Wallace, Scott A., Nierman, Andrew, Addressing the Need for a Java Based Game Curriculum, Journal of Computing Sciences in Colleges, Volume 22, Issue 2 (December 2006), pp. 20--26.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Using Greenfoot and Games to Teach Rising 9th and 10th Grade Novice Programmers Mohammed Al-Bow2, Debra 
Austin4, Jeffrey Edgington2 Rafael Fajardo1,3, Joshua Fishburn3, Carlos Lara2, Scott Leutenegger2, Susan 
Meyer1 1Art and Art History, 2Computer Science, 3Digital Media Studies, 4Education University of Denver 
 ABSTRACT In a two-week residential game camp we used the Greenfoot IDE to teach java programming to 
rising 9th and 10th graders. Students created their own computer games which required learning how to 
write java programs, create a game design, and create art assets. In this paper we focus on the computer 
science pedagogy used and describe the initial design of an augmented game development framework for 
the Greenfoot environment. This framework includes classes for the following useful game elements: Animation, 
Projectiles, Side Scrolling Worlds, Text Boxes, Clocks and Timers. We describe these classes, discuss 
the effectiveness of each, and describe potential improvements to their implementation and design. We 
also report the results of a survey conducted during each of the camps. Categories and Subject Descriptors 
K.3.2 [Computers and Education]: Computer Science Education. D.m [Software]: Miscellaneous games. General 
Terms Design, Human Factors, Languages. Keywords Computer Science Education, Introductory Programming, 
Novice Programmers, Game Programming, Game Development.  1.INTRODUCTION During July 2007 we delivered 
two-week residential summer game camps for rising 9th and 10th graders supported by National Science 
Foundation grant ESI-0624767. One camp was for young men the other for young women. The goal of each 
camp was to use student interest in games to increase interest in Science, Technology, Engineering, and 
Math (STEM) disciplines. Our camps piloted a new interdisciplinary project-based learning approach drawing 
together art, design, and computer programming. Copyright &#38;#169; 2008 by the Association for Computing 
Machinery, Inc. Permission to make digital or hard copies of part or all of this work for personal or 
classroom use is granted without fee provided that copies are not made or distributed for commercial 
advantage and that copies bear this notice and the full citation on the first page. Copyrights for components 
of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy 
otherwise, to republish, to post on servers, or to redistribute to lists, requires prior specific permission 
and/or a fee. Request permissions from Permissions Dept, ACM Inc., fax +1 (212) 869-0481 or e-mail permissions@acm.org. 
Sandbox Symposium 2008, Los Angeles, California, August 9 10, 2008. &#38;#169; 2008 ACM 978-1-60558-173-6/08/0008 
$5.00 Each day included three 2.5 hour learning sessions: one in art, one in game design, and one in 
programming. The last 4 days were spent workshopping to realize the student games. These last few days 
also included some additional programming concepts driven by specific student need. A more modest camp 
using Flash/Actionscript was piloted in 2006 with results reported in a paper by Fajardo and Leutenegger 
[5]. During the art sessions, students were introduced to visual asset development using traditional 
and digital studio practices. The curriculum focused on the figure and the scene. First, students made 
three-dimensional wire figures. Using these figures, two-dimensional space was addressed and gesture 
drawing introduced, resulting in picture planes loosely depicting the illusion of space through line 
weight, proportional shifts, placement, and horizon line. Gesture drawings of the human figure followed, 
as a live model enacted short, multi-step action poses. A move to the digital realm resulted in jointed 
characters ready to be programmed in an animated sequence. Students then focused on the scene, using 
construction paper and scissors to create narrative compositions taken from Picture This [2]. Relying 
on shape, placement, proportion and color to depict narrative, the collages offered a model easily transferred 
to the digital environment. Instruction on the basics of one-point, two­point and three-point perspective 
followed. Studio work concluded with an introduction to value, light and shadow. In the game design sessions, 
we employed the rapid creation and iteration of paper-based games to teach fundamental skills. Students 
were given a working definition of games taken from Salen and Zimmerman [9] and then challenged to create 
a game in the first thirty minutes of the first design session. They were then introduced to the concept 
of critical and reflective play as a way to assess the quality of the play experience. Students were 
encouraged to develop helpful critical vocabularies by play testing and commenting on each others games. 
Students then were given opportunities to refine their games and have them replayed. Students were given 
a simple and clear set of quality standards so that good games could be identified. We also modeled and 
described the concepts behind Humane Games to encourage the broad exploration of kinds of games. In addition 
to the student camps, we also offered a two week Teacher Game Institute, a professional development program 
for high school teachers who will implement game development courses in their schools. Every day, teachers 
had 1.5 hours of instruction in each of art, design, programming, and pedagogical theory for delivering 
this interdisciplinary curriculum. The teachers read David Williamson Shaffer [10]. The pedagogy sessions 
focused on the changing context of teaching and learning; what it means to be educated in the 21st century; 
technology and information literacy standards; project­based learning and performance-based assessment; 
and fostering creativity in digital-age students.  2.USING GREENFOOT AND INKSCAPE Before choosing our 
tools we evaluated commercial, open source, and freeware tools. We decided the benefits of freeware tools 
outweighed any weaknesses. We chose tools for their functionality and facilitation of teaching introductory 
programming and game design, but also because the developers of both tools are committed to keeping the 
tools free. This allows schools and other institutions to begin implementing our program at very little 
to no cost. It also allows students to continue development of their games at home or at school, as well 
as design new games. For our programming IDE we chose to use Greenfoot [1]. Greenfoot is a free, cross-platform 
programming and simulation environment built on BlueJ environment [3]. The Greenfoot environment allows 
users to easily create and explore classes, instances, and members using a graphical interface. The latest 
version of Greenfoot (version 1.4.1 as of this writing) is compatible with any system that runs Java 
5 or later. A Greenfoot scenario (or program) divides user created classes into three categories: World, 
Actor, and Utility. Users customize the scenario by creating a subclass of the World class. Users then 
create subclasses of Actor for each type of game entity. Utility classes can be used to accomplish functionality 
such as specific mathematical calculations needed by several classes. When the Greenfoot scenario is 
executed, Greenfoot starts a main loop. Each iteration of the main loop invokes the act() method of every 
object instantiated from subclasses of the Actor class. For visual asset creation we chose the Inkscape 
drawing tool [7]. Inkscape is an open source, cross­platform vector graphics editor. Inkscape was also 
chosen for its ease of use and simplicity. 3. PROGRAMMING CONCEPTS TAUGHT The ultimate goal of the camp 
was to get students interested in pursuing studies in STEM disciplines. One way to do this is to give 
students a positive and fun experience where they felt empowered. Mastering elementary programming concepts 
is one way for students to feel empowered. During the camp students were taught many of the standard 
elementary programming concepts: control structures (if/else, for loops), classes, objects, members, 
methods, and arrays. Each of these concepts is illustrated in our Little Red example described below. 
Greenfoot s elegant design allows users to create new classes, objects, and invoke methods simply by 
clicking with the mouse. This greatly assists teaching the difference between classes and objects. The 
concepts of class, object instance, and methods were taught using the Actor class. A Greenfoot World 
is an invisible grid of cells. Each cell may contain one or more Actor objects. This grid corresponds 
exactly to a coordinate system already familiar to students from math classes but with the y-axis pointing 
down instead of up. We taught the grid/coordinate system two ways: via a kinesthetic exercise and using 
many simple Greenfoot scenarios. The kinesthetic exercise consisted of creating a real-world grid on 
the floor of the classroom. A grid of masking tape was placed on the floor with cells large enough to 
accommodate two students. Students were then created and added to the grid at specified grid locations. 
Each student was then moved about the grid by invoking methods on the student. This exercise was quite 
useful for teaching concepts of grid location, movement, velocity and the Greenfoot World class boundaries. 
This exercise also helped solidify the concepts of class, object instance, and method invocation. In 
conjunction with the kinesthetic exercise we also used our Little Red scenarios to demonstrate how Actor 
objects are located on the grid and how they are moved. Students were quickly able to create their own 
Actor classes with student created movement methods. The combination of both approaches seemed to result 
in a deeper understanding of the coordinate system. Many of the students exhibited that a-ha! moment 
as they moved their classmates around the grid with code .  4. LITTLE RED RIDING HOOD EXAMPLES To provide 
the students a complete learning example we created a game based on Little Red Riding Hood and informed 
by Molly Bang s excellent design principle book Picture This [2]. A goal was to use simple art so as 
to not intimidate the students and show them that fun games can be created with modest visual assets. 
A screen shot of the main play screen is in Figure 1. Little Red is the small triangle in the top left 
corner. We started the camp by having the students play the game. The game contains a splash screen with 
play instructions, static objects (apples) to be collected, dynamic objects (wolves) to be avoided, a 
goal (collect a certain number of apples) and appropriate end screens (success for collecting enough 
apples; failure for being eaten by a wolf). We separated the various game aspects such as keyboard events, 
collision detection, world position, and character animation into individual Greenfoot scenarios and 
corresponding programming lessons for the students. FIGURE 1: Little Red Screen By first playing the 
game students quickly learn the Greenfoot interface. Further, the example game sets the stage for a series 
of increasingly more complete Little Red Riding Hood scenarios to explain step-by-step how the game is 
created. The scenario progression matches the order we presented the programming lecture topics. The 
series of Little Red scenarios are as follows: 1. Little Red moving: to the right and left, back and 
forth, bouncing off world boundaries (both dimensions), and keyboard controlled. Keyboard control is 
made easy with the Greenfoot keyboard handling methods. The boundary reflection and direction changing 
necessitates if/else statements. 2. Add a background image and apples, which are static objects. Add 
collision detection code using the Greenfoot Actor s getOneIntersectingObject() method so Little Red 
can collect apples. 3. Add a populate() method to the World constructor to place apples in the world 
at fixed locations using the Greenfoot addObject() method. 4. Spell words with apples: Use for-loops 
to increment x or y-locations to place apples to spell out words like HI or IF . Although not part of 
the game the students like this example which helped explain for­loops and further reinforced their understanding 
of the grid cell ordering. 5. Use for loops and the Greenfoot getRandomNumber() method to place apples 
at random inside our populate()method (which is called by the World constructor). 6. Add wolves with 
a simple patrolling movement behavior. The wolves move 10 spaces forward and then change directions by 
90, 180, or 270 degrees with equal probability. This code requires keeping track of the direction a wolf 
is heading using a data member so that on the next movement the (x,y) location can be set correctly. 
This scenario also makes use of the setRotation() method to rotate the wolf image to face the direction 
it is headed. We also added an  intersection test between Little Red and a wolf so that if they collide, 
the game stops. 7. Modify the wolf to be a heat seeking wolf . The wolves have the same patrolling motion 
as above, but, if Little Red is within a certain distance, specified via a method parameter, the wolf 
then moves towards Little Red. This requires teaching students how to calculate the distance between 
two points thus making math they have been exposed to relevant. 8. Create data members to hold the number 
of apples collected so far and the number of apples needed to win. Update the number of collected apples 
and move to a win screen when a sufficient number is collected, or, move to a lose screen when a wolf 
gets Little Red. 9. Give Little Red a magic wand to make wolves disappear if they are close by. We store 
the wolf objects in an array and when Little Red uses the wand,  by pressing the W key, we loop through 
the array to calculate the distance to each wolf. If the distance is below a threshold value the wolf 
is removed from the game. This series of Little Red examples illustrates many of the concepts that most 
of the students would need to complete their own game. Of course many of the students came up with much 
more grandiose design ideas that necessitated more sophisticated programming. To make this possible we 
have added several classes for students to use and/or modify as described in the next section.  5. GAME 
DEVELOPMENT FRAMEWORK Since many games involve similar concepts: timers, projectiles, etc. we provided 
the students with classes which implement these ideas. This also helped mitigate the short time span 
of the camp itself. We wanted the students to concentrate on implementing their game rather than trying 
to implement details of projectiles for example. We also wanted to provide the students with as many 
examples as possible. This was important for two reasons: the students could study the examples during 
their own time and they could modify our examples rather than creating a new solution from scratch. The 
examples served two purposes: as samples of good coding practices and as foundations from which the students 
could build their games. A number of game frameworks have been developed using Java. We discuss two that 
we considered using rather than Greenfoot and creating our own framework. The Java Instructional Game 
Engine (JIGE) [11] met many of our requirements: it uses Java, it targets the development of two dimensional 
games, it is open source, and free to use. The only two drawbacks (from our perspective) are that it 
is somewhat complex for ninth and tenth grade students and would have required us to teach the students 
a development environment or how to use the command line interface to Java. The Labyrinth framework is 
also implemented in Java but is aimed at creating one particular genre of two dimensional game (i.e. 
a simple fantasy role-playing game with a torch bearing hero and a fire breathing monster ) [4]. We were 
concerned that many of our students might not be interested in this sort of game. Labyrinth also has 
the same complexity issues as JIGE. We ultimately decided to use Greenfoot and build our own game development 
framework. Our framework of example classes is quite simple because the Greenfoot environment provides 
much of the foundation required to implement many games and simulations [6]. We provided students with 
six main classes: Timer, Text Box, Projectile, Bounce Movement Actor, Animation, and Side Scrolling World. 
We also provided the students with color-coded class diagrams. We used different colors for the data 
member declarations, the act() method, any others methods, any any constructors. We purposely chose a 
separate color for the act() method to highlight it as the key method for Greenfoot Actor objects. We 
found that the color coding greatly helped students understand the parts and roles of the classes. All 
example Greenfoot scenarios, class implementations, documentation, and other materials are freely available 
from our project website [8]. 5.1 Bounce Movement Actor This new type of actor, allows a game object 
to move in either the x or y dimension according to data member velocities. The game object also respects 
the boundaries of the world by reflecting off of them. The class included only four methods: act(), atXboundary() 
which returns true if at the left or right-most boundary of the world, atYboundary() which checks for 
the top/bottom boundaries, and moveXY(). The class contains two data members: xVelocity and yVelocity. 
The moveXY() sets the new location of the object to its current location plus the x/y velocity values. 
The act() method simply checks if the object is at a boundary, and if so negates the corresponding velocity 
value, and then calls moveXY(). The Bounce Movement Actor class was provided in the first of the Little 
Red example scenarios. This class was used by many students to make (non-keyboard controlled) enemies 
or obstacles bounce around the world. 5.2 Timer Class The timer class is used in games that require 
a timed task by displaying a clock on the screen. The clock counts down at a rate based on number of 
acts specified by the student. Once an object of the timer class is created and added to the world, the 
timer can be started or paused using the methods start() and pause() respectively. The timer class was 
used in many of the female students games especially games involving mazes. 5.3 Text Object Class The 
text object class allows adding text to the world by specifying the location of a text object and it 
s contents. The changeText() method is used to set the contents of the text object. The text object class 
was used in almost all games during both the boys and girls camps. 5.4 Projectile Class The projectile 
class was used to facilitate the inclusion of projectiles such as bullets, balls, etc. The constructor 
allows the students to set the speed and the lifetime of the projectile where lifetime determines how 
long before the projectile expires and is removed. The projectile class provides three usage types: 1) 
launching of a projectile at a specified angle; 2) launching at a target object; or 3) launch a projectile 
that tracks a target as the target moves. The class includes methods: shootInDirection(int rotation), 
shootAtTarget(Actor Target), shootTracking(Actor Target). These methods will place the projectile object 
at the xy-coordinate of the shooting object and the projectile will move in the direction specified or 
towards the target as described above. This class was developed during the boys camp and was used in 
10 games (out of 17) during that camp. The projectile was also used in one game to compute line of sight. 
 5.5 Animation Class The Greenfoot Actor class provides methods for changing the location of the actor 
object and changing the actor s current image but does not provide a method for animating an actor (i.e. 
displaying a sequence of images). Since animation is a common element of computer games, we created a 
new simple class which provides this capability. The animation class stores a list of images. An Animation 
is constructed by passing the base name of a set of numbered image files. For example, if one creates 
an animation of a flying bird with 7 frames the image files could be name bird1, bird2, bird7 and the 
base name is bird . The class has four key methods: initAnimation(); startAnimation(), stopAnimation(), 
and animate() which gets the next frame of the animation. Many of the boy s games (13 out of 18) used 
this simple animation or side scrolling animation (described below) in their game. Few of the girls used 
this class (only 2 out of 17). We believe the low usage by the girls was due to the fact that this class 
was presented very late during their camp. Everybody that used this class thought it was easy to use. 
The Animation class is used by the Side Scrolling World class described below.  5.6 Side Scrolling World 
Many of the students wanted advanced features similar to side scrolling games (including multiple animation 
cycles such as walk, run, and jump triggered by different key strokes and health bars). To our knowledge 
Greenfoot does not support continuous scrolling of a world. Our initial design of the class was rather 
complicated to use because its methods combined movement, animation, and the scrolling of the world. 
Scrolling was implemented in a discrete way: a new background class holds an array of background images. 
Methods such as setNext() and setPrevious() allowed the change from the current background image to the 
specified background image. Nearly half of the student games used the Side Scrolling World class, but 
getting it to work correctly necessitated significant instructor assistance which was contrary to our 
goal of making the students feel empowered. We are in the process of simplifying this class to improve 
its utility and usability.  6. SURVEY RESULTS Seventeen students completed surveys both before and 
after the boys camp. The survey asked questions regarding attitudes toward attending college, computer 
science, the camp experience, and whether basic programming concepts were understood by the student. 
The questions and responses were: Q: How strong is your programming? (Asked first day of camp): none 
4, minimal 7, average 4, strong 1. Q: Rate your understanding of Classes and Objects: A little shaky 
2, okay 8, strong 6. Q: Give an example of an if/else statement: No Answer 7, Examples of if with incorrect 
code: 8 (?), 2 correct answers. Q: Rate your understanding of how to use Greenfoot:  No Answer 1, Weak 
1, Okay 11, Strong 3. Q: Describe your programming comfort level now: No Answer 1, Vague Idea 3, Reasonable 
Idea 7, Feel Confident 6. Q: Rate how your comfort level with technology changed: No Answer 1, Remained 
the Same 4, Improved 10, Jumped by Leaps and Bounds 2. Q: Rate your understanding of the Coordinate 
System:  No Answer 1, Shaky 1, Okay 10, Strong 5. Q: Rate your understanding of For Loops: No Answer 
1, Weak 4, Shaky 4, Okay 7, Strong 1. Q: Give an example of a for loop: No Answer 9, I don t know 2, 
two examples ( Waive your hand and say hi 8 times , doing something over ), three said something similar 
to for (i=0; i<20i) , one said Like having 4 different classes .  In every case the attitudes improved 
as we had hoped. Our main concern lies with whether the students understood basic programming concepts. 
Most of the students believed that they had a stronger understanding of classes, objects, and how to 
use Greenfoot. They also believed that they had a higher comfort level with programming in general and 
technology in general. Yet few of the students produced a correct if statement or for­loop on the post-surveys. 
Students correctly used these structures many times in their games. The post-survey was rushed due to 
a time limitation and we conjecture this was the cause for low quality answers on these two questions. 
From these survey results, and the enthusiasm and pride shown by both the young women and men when demonstrating 
their games at the final family celebration, we conclude that this method has been quite successful in 
teaching elementary programming concepts to novice programmers at a young age. Most important, students 
were more comfortable and interested in technology after the camp. 7. FUTURE WORK First, we plan to conduct 
deeper statistical survey of the students in future camps and in the high school programs. Second, we 
are building additional classes to add to the framework. One will provide the ability to create worlds 
which are larger than one screen and allow Actors to move seamlessly in this larger world (i.e. provide 
true scrolling or transition from one portion of the world to another). This new class will replace the 
Side Scrolling World class described earlier. We would also like to allow students to create worlds with 
non-square grids (hexagons and triangles) and general graph connectivity. We are also creating a talking 
bubble class which will allow narrative animations for Actors. Finally we are creating a simple network 
interface which would allow students to create multi-player games and simulations. 8. ACKNOWLEDGMENTS 
Our work is supported by National Science Foundation grant ESI-0624767. 9. REFERENCES [1] The Greenfoot 
Programming Environment, www.greenfoot.org [2] Bang, Molly, PICTURE THIS, How Pictures Work, SeaStar 
Books, 2000, ISBM 1-58717-030-2 [3] The BlueJ Programming Environment, www.bluej.org [4] Distasio, Joseph, 
Way, Thomas, P., Inclusive Computer Science Education Using a Ready-made Computer Game Framework, ITiCSE 
07, June 23-27, 2007, Dundee, Scotland, United Kingdom, ACM 2007. [5] Fajardo, R., Leutenegger, Scott 
T., Programming, Pixels and Play: A University Summer Game Camp To Attract Under-represented Populations 
to Game Development and Computer Science , Proc. of Future Play, 2006. [6] Henriksen, Poul, Kolling, 
Michael, greenfoot: Combining Object Visualisation with Interaction, OOPSLA 04, Oct 24­28, 2004, Vancouver, 
British Columbia, Canada, ACM. [7] The Inkscape drawing tool, www.Inkscape.org. [8] Pixels, Play, Programming, 
and Pedagogy, www.p4games.org [9] Salen, Katie, Zimmerman, Eric, Rules of Play, MIT Press, 2004, isbn 
0-262-24045-9 [10] Shaffer, David Williamson. How Computer Games Help Children Learn. Palgrave Macmillan. 
2006 [11] Wallace, Scott A., Nierman, Andrew, Addressing the Need for a Java Based Game Curriculum, Journal 
of Computing Sciences in Colleges, Volume 22, Issue 2 (December 2006), pp. 20-26.  
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
		<article_sponsors>
			<funding_agency>National Science Foundation</funding_agency>
			<grant_numbers>
				<grant_number>ESI-0624767</grant_number>
			</grant_numbers>
		</article_sponsors>
	</article_rec>
	<article_rec>
		<article_id>1401854</article_id>
		<sort_key>110</sort_key>
		<display_label>Pages</display_label>
		<pages>2</pages>
		<article_publication_date>08-09-2008</article_publication_date>
		<seq_no>5</seq_no>
		<title><![CDATA[Four views of procedural character animation for computer games]]></title>
		<page_from>61</page_from>
		<page_to>62</page_to>
		<doi_number>10.1145/1401843.1401854</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1401854</url>
		<abstract>
			<par><![CDATA[<p>This panel aims wide, showing four complementary aspects of procedural animation technology for computer games. Each panelist will briefly present core ideas of their respective technology, and then the discussion will center around how these complementary techniques can be used together. The panel will conclude with a discussion about opportunities for the future.</p>]]></par>
		</abstract>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1100717</person_id>
				<author_profile_id><![CDATA[81100250413]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Ken]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Perlin]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1100718</person_id>
				<author_profile_id><![CDATA[81335491736]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Chris]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Hecker]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1100719</person_id>
				<author_profile_id><![CDATA[81100469355]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Craig]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Reynolds]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1100720</person_id>
				<author_profile_id><![CDATA[81467653239]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Friedrich]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kirschner]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Four views of procedural character animation for computer games Ken Perlin, Chris Hecker, Craig Reynolds, 
Friedrich Kirschner This panel aims wide, showing four complementary aspectsof procedural animation technology 
for computer games.Each panelist will briefly present core ideas of their respective technology, and 
then the discussion will centeraround how these complementary techniques can be usedtogether. The panel 
will conclude with a discussion aboutopportunities for the future. The four procedural animation subtopics 
would be, in brief: Emotive Actors, Aliens, Crowds, and Puppetry, respectively, as follows: Ken Perlin 
(Emotive Actors) -Varying emotionalnuance in procedural actors We present an approach to creating and 
animating gamecharacters rather than being required to animate a character separately for each motion 
sequence, animatorsare able to interact with software authoring tools that letthem train an Autonomous 
Digital Actor (ADA) how to employ various styles of movement, body language, techniques for conveying 
specific emotions, best acting choices, and other general performance skills. Once properly trained, 
such a virtual actor is able to take directioninteractively from a non-animator, to function as a gamecharacter 
while effectively conveying changing nuances ofmood, personality and intention. Chris Hecker (Aliens) 
-Procedurally animatedcharacters with variable morphology: For the game SPORE we have been developing 
proceduralcharacter techniques in a way that continues to work acrosshighly variable actor morphologies, 
and that also allows incorporating the talents of keyframe animators in the creation of user modifiable 
procedural movement. Craig Reynolds (Crowds) -Procedurally generatedcrowd behavior: Early crowd models 
focused on group motion, they wereessentially "flat flocks". Crowds marched relentlessly toward their 
goal without motivation. Newer models address group behaviors beyond trudging. Applications ingames, 
movies, training and historical recreations requirelarge groups of people in social activities: populating 
acelebration, a shopping bazaar, or a battlefield. Controllers for such agents can be simple stochastic 
state machines.More interestingly are crowds that accomplish some globalgoal such as central-place foraging, 
group search or Copyright &#38;#169; 2008 by the Association for Computing Machinery, Inc. Permission 
to make digital or hard copies of part or all of this work for personal or classroom use is granted without 
fee provided that copies are not made or distributed for commercial advantage and that copies bear this 
notice and the full citation on the first page. Copyrights for components of this work owned by others 
than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, to republish, to post 
on servers, or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions 
from Permissions Dept, ACM Inc., fax +1 (212) 869-0481 or e-mail permissions@acm.org. Sandbox Symposium 
2008, Los Angeles, California, August 9 10, 2008. &#38;#169; 2008 ACM 978-1-60558-173-6/08/0008 $5.00 
collective construction. These latter behaviors types haveglobally observable results, and require more 
sophisticatedbehavioral controllers. Inspiration for constructing theseagents can be found in the organization 
of social insectsand other self-organizing natural systems. Friedrich Kirschner (Puppetry) -Driving proceduralactors 
through expressive puppetry: We discuss how to use low-cost input devices (and somefree software) for 
controlling character motion. We are currently developing a framework for simple 3D-real-timeanimation 
control with various common consumer interfaces, including webcams, Wii-motes and GameTrakcontrollers. 
 Bios: Ken Perlin is a professor in the Department of ComputerScience at New York University, He was 
founding director ofthe Media Research Laboratory and also directed the NYUCenter for Advanced Technology. 
His research interests include graphics, animation, user interfaces, science education and multimedia. 
He received an Academy Awardfor Technical Achievement from the Academy of Motion Picture Arts and Sciences 
for his noise and turbulence procedural texturing techniques, which are widely used infeature films and 
television, as well as the TrapCode awardfor achievement in computer graphics research, the NYCMayor's 
award for excellence in Science and Technologyand the Sokol award for outstanding Science faculty at 
NYU, and a Presidential Young Investigator Award from theNational Science Foundation. He has also been 
a featured artist at the Whitney Museum of American Art. Dr. Perlin received his Ph.D. in Computer Science 
from New York University, and a B.A. in theoretical mathematics from Harvard University. Before working 
at NYU he was Head ofSoftware Development at R/GREENBERG Associates in New York, NY. Prior to that he 
was the System Architect forcomputer generated animation at Mathematical ApplicationsGroup, Inc. He has 
served on the Board of Directors of theNew York chapter of ACM/SIGGRAPH, and currently serveson the Board 
of Directors of the New York Software IndustryAssociation. Chris Hecker focuses on solving hard problems 
found at theintersection of gameplay, aesthetics, and engineering. He isan outspoken advocate for pushing 
the current boundariesof design and interactivity, in the hope that games will achieve their full potential 
as an art and entertainment form.To this end he helps organize the yearly Indie Game Jamand the Experimental 
Gameplay Workshop, and his recentwork at Maxis has centered around using proceduralism toenhance player 
creativity and agency. Chris has been onthe advisory board for the Game Developers Conference formany 
years and is a regular speaker at the GDC, Siggraph,and other conferences. A frequent contributor to 
Game 61 Developer magazine, Chris was the technical columnist for the magazine for two years and the 
Editor-at-Large for three. Before joining Maxis he was an indie game developerfor 8 years with his company 
definition six, inc. He is also onthe editorial board of the computer graphics research publication, 
The Journal of Graphics Tools. Craig Reynolds researches technology for autonomous characters at Sony 
Computer Entertainment's US R&#38;D group in Foster City, California (www.research.scea.com). Recent 
projects include PSCrowd, a high performancecrowd simulator for PS3, and OpenSteer, an open sourcelibrary 
of steering behaviors. He has previously worked on animation and game production, plus developing tools 
forboth fields, at: DreamWorks, Silicon Studio, Electronic Arts, Symbolics and Information International 
Inc. He won a Scientific and Engineering Academy Award in 1998 for "pioneering contributions to the development 
of three dimensional computer animation for motion picture production." Friedrich Kirschner is a filmmaker, 
visual artist and software developer. He re-purposes computer games and realtime animation technology 
to create animated narratives and interactive performances. His work has been shown at various international 
animation festivals and exhibitions, including the Laboral Gameworld exhibit in Gijon, the American Museum 
of the Moving Image in New York, theOttawa international Animation festival and the Seoul Media Art Biennale. 
He is currently a production fellow withthe Eyebeam Center for Art and Technology in New York.  
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
	</article_rec>
	</section>
	<section>
		<section_id>1401855</section_id>
		<sort_key>120</sort_key>
		<section_seq_no>3</section_seq_no>
		<section_type>SESSION</section_type>
		<section_title><![CDATA[Game design]]></section_title>
		<section_page_from>63</section_page_from>
	<article_rec>
		<article_id>1401856</article_id>
		<sort_key>130</sort_key>
		<display_label>Pages</display_label>
		<pages>4</pages>
		<article_publication_date>08-09-2008</article_publication_date>
		<seq_no>1</seq_no>
		<title><![CDATA[Moving parts]]></title>
		<subtitle><![CDATA[the interdependence of game play and social dynamics in digital games]]></subtitle>
		<page_from>63</page_from>
		<page_to>66</page_to>
		<doi_number>10.1145/1401843.1401856</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1401856</url>
		<abstract>
			<par><![CDATA[<p><i>Moving Parts</i> is a hybrid physical/digital, two-player pinball game designed to elicit different social interactions between players. Using a mixture of consistent and variable rules, the game highlights interdependent and emergent relationships between game rules, social dynamics, and player experience, illustrating some possibilities for social malleability of digital games and presenting some specific pathways through which rules and social relationships affect each other. With the increasing prevalence of digital games that foreground social interaction, it is important to develop methods for understanding and designing such games to more deeply and meaningfully connect to players' social experiences.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[experimental game]]></kw>
			<kw><![CDATA[game rules]]></kw>
			<kw><![CDATA[iterative process]]></kw>
			<kw><![CDATA[situated play]]></kw>
			<kw><![CDATA[social games]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1100721</person_id>
				<author_profile_id><![CDATA[81365594363]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Daniel]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Soltis]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[New York University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Callois, R. 2001. <i>Man, Play, and Games.</i> Chaimpaign, IL: University of Illinois Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[deKort, Y. A. W., Ijsselsteijn, W. A., and Gajadhar, B. J. 2007. People, places, and play: A research framework for digital game experience in a socio-spatial context. In <i>Situated Play, Proceedings of the Digital Games Research Association (DiGRA) Conference.</i> University of Tokyo.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Hughes, L. 1999. Children's games and gaming. In <i>Children's Folklore</i>, Sutton-Smith, B., Mechling, J., Johnson, T. W., and McMahon, F. R., eds. Logan, Utah: Utah State University Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Jakobsson, M. 2007. Playing with the rules: social and cultural aspects of game rules in a console game club. In <i>Situated Play, Proceedings of the Digital Games Research Association (DiGRA) Conference.</i> University of Tokyo.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Juul, J. 2008. What makes casual games so appealing, so attractive: Looking for 'the casual' in casual video games. Lecture at Columbia University, New York.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1215723</ref_obj_id>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Salen, K. and Zimmerman, B. 2003. <i>Rules of Play:</i> Game Design Fundamentals. Cambridge, Mass: The MIT Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Moving Parts: the Interdependence of Game Play and Social Dynamics in Digital Games Daniel Soltis Interactive 
Telecommunications Program, Tisch School of the Arts, New York University Abstract Moving Parts is a 
hybrid physical/digital, two-player pinball game designed to elicit different social interactions between 
players. Using a mixture of consistent and variable rules, the game highlights interdependent and emergent 
relationships between game rules, social dynamics, and player experience, illustrating some possibilities 
for social malleability of digital games and presenting some specific pathways through which rules and 
social relationships affect each other. With the increasing prevalence of digital games that foreground 
social interaction, it is important to develop methods for understanding and designing such games to 
more deeply and meaningfully connect to players social experiences.  Keywords Social games, game rules, 
situated play, experimental game, iterative process 1 Introduction Games have historically been social 
activities. In Man, Play, and Games, Caillois argues that even when the player could play alone, games 
quickly become a pretext for a contest or an exhibition. [1] In contrast, many people tend to think of 
video games as primarily solitary. With the computer providing playing field, game tokens, rules, enforcement, 
and often narrative, extended solo play can be dynamic and engaging in a way that is rare in non-digital 
play. However, despite the viability of playing alone, digital games are frequently quite social.[2] 
From the earliest two-player digital games, such a Spacewar! and Tennis for Two; to public play in arcades 
in the 1980s; to current play with family and friends on home consoles, social interaction has been and 
remains a common and important aspect of digital game play. Social interaction in both non-digital and 
digital games is a powerful force for shaping player experience, and at times it can reshape the game 
itself. Conversely, game play in social contexts can reshape those contexts in ways not immediately apparent 
from the rules. For example, in Linda Hughes classic study of girls playing foursquare,[3] players developed 
a host of implicit and explicit rules that transformed an individually competitive game into one of unofficial 
teams based on friendship groups. The game in turn affected the player s external lives, such as when 
failure to meet in-game obligations disrupted out-of-game friendships. Copyright &#38;#169; 2008 by the 
Association for Computing Machinery, Inc. Permission to make digital or hard copies of part or all of 
this work for personal or classroom use is granted without fee provided that copies are not made or distributed 
for commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights 
for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. 
To copy otherwise, to republish, to post on servers, or to redistribute to lists, requires prior specific 
permission and/or a fee. Request permissions from Permissions Dept, ACM Inc., fax +1 (212) 869-0481 or 
e-mail permissions@acm.org. Sandbox Symposium 2008, Los Angeles, California, August 9 10, 2008. &#38;#169; 
2008 ACM 978-1-60558-173-6/08/0008 $5.00 Hughes distinguishes between game rules the mechanics and rule 
set of a game and gaming rules those rules, spoken and unspoken, about how the game is managed and how 
and if game rules are enforced. Salen and Zimmerman[6] propose a similar framework for understanding 
and analyzing game rules: operational rules, rules about the materials and actions for playing a given 
instantiation of a game; constituative rules, the abstract underlying system; and implicit rules, the 
often unspoken codes of game etiquette and proper behavior. Both sets of classifications highlight the 
fact that player experience is affected by more factors than codified rule sets, and that different players 
may play the same games in different ways. At first glance, digital games seem much less susceptible 
to such reshaping. How can implicit or gaming rules be applied when the rules and their enforcement are 
encoded into the game itself? In practice, many digital games are quite malleable. Players create different 
experiences from the same game by taking advantage of metagame factors that aren t encoded in the rules, 
in-game elements that allow for player choice, and emergent properties of the rules. Mikael Jakobsson[4] 
documents a console gaming club s tournament of Super Mario Smash Brothers in which organizers developed 
a system for randomly assigning players, choosing in-game characters, and eliminating losers. While the 
game itself is a one-on-one fighting game that rewards speed and skill, the tournament s structure deemphasized 
skill and increased spectacle, making the game more accessible to a wider range of club members. In describing 
the profound influence the tournament s metagame rules and the club s cultural dynamics had on player 
experience, Jakobsson concluded, the very nature of a game can change without changing the core rules 
Even at the most fundamental level, rules are influenced by, and affect, the social and cultural aspects 
of the gaming context. In the other direction, digital games often extend their influence beyond the 
screen. These influences are similar to those of non­digital games social interpretations of game actions, 
develop­ment of player culture, etc. In a recent talk at Columbia University,[5] Jesper Juul pointed 
out that a player often commits four hours to a single session of World of Warcraft not only out of individual 
desire but because to play for less time is to be a bad friend. The game s influence is not only on the 
time commit­ment, but on the social meaning driving that commitment which is nowhere encoded in the rules. 
While a wide variety of digital games may be transformed through creative implementation or reinterpretation 
of encoded rules, some emerging forms of digital games specifically foreground social dynamics and avenues 
for players to reshape the game. Massively multiplayer games (MMOs), games with performative physical 
interfaces, and transmedia/pervasive games emphasize social interactions as essential and potentially 
trans­formative aspects of game play. As these types of games become increasingly popular, it is increasingly 
relevant to evaluate how digital games and social interactions shape each other. 63  2 Game Description 
Moving Parts is a two-player, hybrid physical/video pinball game designed to elicit different social 
interactions between players. The game consists of a single core game played in four versions, each containing 
a small number of rule variations. Through playing different versions, players develop different relationships 
with each other and with the game. Part art game and part informal experiment, Moving Parts is intended 
to illuminate ways that game rules and social factors may interdependently shape player experience. 1 
Physical Design Moving Parts consists of a wooden table with a display projected onto the tabletop. Players 
face each other from opposite ends of the table and play simultaneously, manipulating physical buttons 
and plungers to control virtual flippers and plungers on the display. Each button is connected to a small 
spring pressing against a force sensing resistor (allowing analog input to control flipper position), 
and each plunger rests against a switch that is opened when the player pulls back the plunger. These 
inputs are sent via an Arduino microcontroller to the Java application that controls the virtual pinball 
game. 2 Consistent Game Rules The core game of Moving Parts is a simplified game of pinball. The physics 
conform closely to the physics of standard pinball, as do the basic game mechanics (players use buttons 
to control flippers that can propel the ball up the table and keep the ball in play). Screen elements 
consist of walls, bumpers and flippers; players score points by hitting bumpers with the ball(s); and 
(in most versions) when players hit all of the bumpers on the board at least once, that level is cleared 
and a new configuration of bumpers is initialized. 3 Variable Game Rules From this base game, different 
versions introduce variations to some aspects of game play, including who controls which flippers, how 
many balls are in play, bumper configuration, how the score is calculated, and win/lose conditions (see 
table). When the game was first implemented, each program ran for several days before a new version was 
introduced; a recent iteration allows players to choose which variation they want to play. 4 Social Environment 
The game ran for a month in a high-traffic hallway on the main floor of New York University s Interactive 
Telecommunications Playing Moving Parts Overhead view of projected display Program. The program contains 
approximately 200 interaction design students, and school culture emphasizes collaborative work. The 
lounge area contains game consoles and a foosball table, so students are accustomed to playing games 
on the floor. I gathered feedback from classmates and faculty by playing with them, informally asking 
about their experiences watching or play­ing with others, and collecting a small number of written surveys. 
 3 Design Intentions 1 Tension between Solitary and Social Play Different aspects of the physical interface 
and underlying pinball game conflictingly afford and inhibit social interaction and communication. For 
example, traditional pinball involves solo or turn-taking play, in tension with this version s simultaneous 
two­player play. The players face each other from a few feet away, which allows easy verbal communication 
and body language, but the digital display is projected onto the table between the players, so that they 
are drawn to look down rather than at each other. The game is non-verbal and non-narrative; game play 
is possible even if players do not talk to or even look at each other. However, even if players do not 
explicitly interact, they continually pass a ball back and forth, which functions as an implicit form 
of ongoing communication. It is through these tensions between solitary and social play that different 
rule sets can lead to different kinds of interactions. Emphasizing or deemphasizing specific elements 
of the game can tend to pull players together or push them apart. 2 A Note on Ball Exchange In some games, 
such as the foursquare described by Hughes,[3] passing a ball between players is rich with meaning to 
whom, exactly where, and how hard a player hits a ball can communicate anything from cooperative engagement 
to a desire not to play together at all, from friendship to indifference to dislike. In Moving Parts, 
players have few options for subtle ball control, but skilled players can send a limited number of implicit 
messages by sending the ball to different areas of the board. For example, in a cooperative version, 
a player may pass the ball to the other side of the board for shared strategic reasons or simply to let 
the other player have some active play time. In a competitive version, a player might keep the ball on 
his or her side of the table (communicating a self-directed desire to achieve a higher score) or might 
propel the ball down the center of the table to make the other player lose a life (communicating a desire 
for shared competitive play). For less skilled players, poor ball control limits clear communi­cation 
via game actions themselves. However, unintended ball movement often leads to more direct communication, 
as players speak to each other about the game apologizing for losing a life 64 or causing the other 
player to lose a life, describing an intention that didn t quite happen, etc. Thus, ball exchange can 
serve as a form of communication for players at any skill level.  4 How the Players Shaped the Game,How 
the Game Shaped the Players 1 Attention and Expectation The sensory experience of pinball greatly affects 
how players approach and understand the game. Because the ball can move quite quickly, nearly all players 
focus their attention in a very limited area immediately in front of their flippers. Thus, much of the 
board is fairly irrelevant to how players perceive and interpret the game; an event occurring toward 
the center or on the far side of the board is likely to remain unseen unless attention is very clearly 
and specifically called to it. Further, pinball has a history of being confusing and sensorially overwhelming. 
If a player sees an event but does not see its cause, he or she is unlikely to spend much time pondering 
exactly what happened. To a certain point, most players simply accept the unexpected. If too much cause 
and effect occurs outside of the players attention, the game becomes unintelligible. Overall, players 
tend to play pinball with a certain resiliency. If the game does not clearly indicate cause and effect 
and possi­bilities for meaningful shared play, they tend to default to a solo game of trying to keep 
the ball on the table as long as possible. 2 Responsive Game Design Because players perceptions and interpretations 
so strongly shape how they understand the game, it is important for the game design to take those factors 
into account. The game s earliest rule sets tended to be unintelligible. For meaningful in-game communi­cation 
(such as ball exchange) to occur, a player needs to notice a relevant event, understand where it came 
from and how it affects the game, and believe that his or her response will be seen and understood by 
the other player. It was only through watching people play, learning how they perceived and interpreted 
the game, and iterating rule variations, that I began to develop a sense of what game elements might 
afford different kinds of in-game communication between players. Through this process, players responses 
to the game affected game design which in turn affected player experiences. This design-mediated dialogue 
between players and game partially bridged one of the gaps between non-digital and digital games namely, 
that players are free to amend any rules of non­digital games, while the rules of digital games are set 
in code. It was, however, only a partial bridge because all changes were shaped by my own interpretations 
and decisions. Further, the process was idiosyncratic to this particularly experimental game. Because 
changing rules were part of the game itself, players and user testers were conflated. (A similar process 
does occur in alternate reality games, where designers may change digital game elements on the fly in 
response to players actions and speculations.) 3 In-Game Interaction and Conversation In some of the 
earliest versions, a virtual wall separated each side of the board from the other, and despite some underlying 
connections between the two sides of the board, the game effectively functioned as two independent games. 
The game only felt like shared play after the wall was removed, there were clear gaps between bumpers 
through which players could pass the ball to each other, and players were able to control flippers on 
both sides of the table. The meanings of in-game interactions (such as competitive versus cooperative) 
had less effect on player experience than the degree to which players felt that they were playing together. 
Players responded most positively when they had control over more of the board and the game had more 
avenues for the ball to move between them regardless of the consequences of ball exchange. They exhibited 
the most arousal, effort, and investment in outcome in the most meaningfully interconnected games. Rule 
Set Flippers Each player controls: Balls Bumpers and Score Win/Lose Conditions Collaborative 2 flippers 
on near side, 1 flipper on far side 1 ball on board at a time. Shared pool of five balls. Hitting a bumper 
scores points for both players (shared score). At higher levels, more points per bumper. Shared outcome. 
Win: Clear 4 levels. Lose: Lose all balls. Synchronized Half the motion range of all flippers 1 ball 
on board at a time. Shared pool of five balls. Hitting a bumper scores points for both players (shared 
score). At higher levels, more points per bumper. Shared outcome. Win: Clear 4 levels. Lose: Lose all 
balls. Competitive 2 flippers on near side, 1 flipper on far side 1 ball on board at a time. Each player 
has three balls. Hitting a bumper on the near side scores points for that player (separate scores). At 
higher levels, more points per bumper. Game ends when one player loses all balls. Survivor s score is 
doubled. Winner is the player with highest score. Multiball 2 flippers on near side Up to 5 balls on 
board at a time. Loss of a ball sends two balls to the other side of the table. Hitting a bumper on the 
near side scores points for that player (separate scores). Winner is first player to reach a set point 
total. Table: Some of the rule variations in Moving Parts. Changes in flipper control, ball movement, 
and bumper location tended to be the most visible, while scoring and win/lose conditions provided background 
structure to the games 65 The amount of conversation between players correlated with the amount of in-game 
interaction; players generally talked more when play was more shared. The content of the conversation, 
on the other hand, revealed differences between cooperative and competitive play. In cooperative variations, 
players tended to strategize, instruct, and apologize, while in competitive variations they tended to 
banter. 4 Game Culture Taken as a whole, the game shaped player s social interactions by creating a tiny 
piece of game culture. The game provided an additional outlet for stress relief at school and was most 
heavily used late at night. A large percentage of students were aware of the game, and over the weeks 
the idea of head-to-head two-player pinball became a norm. This was brought home to me one night when 
I was debugging the controls and a passing classmate said with shock (and some pity), You re playing 
alone? 5 Players, Environment, Existing Social Factors With a few exceptions, game play occurred at one 
location. Most players passed the game on their way to check out equipment for school projects, or they 
approached the game for a brief break from those projects. They played with classmates for five or ten 
minutes at a time and described the experience as fun, friendly and conversational. Although specific 
interactions did vary with different versions, these players approached all versions in a similarly light 
and conversational manner. Some players (mostly those interested in game design) played repeatedly, exploring 
the game as a system and taking more active advantage of different play possibilities in different versions. 
While the game did not include any explicit inter-variation learning curve, these players approaches 
created an implicit learning curve, with their interpretations of later versions shaped by their experiences 
from previous versions. Because the game s environment and pool of players was largely constant, specific 
effects of environment or pre-existing social relationships on game play are not clear. I did play with 
and observe a few players mostly friends from non-school contexts in living rooms, using a laptop to 
display the game and keys for inputs. While these players had similar cognitive experiences (tightly 
focused attention, a need for very clear avenues of communication) and were not specifically exploring 
the system, they tended to play for much longer periods of time at one sitting. This does not show much 
in and of itself but suggests that exploring changes in environment similarly to how this game explored 
changes in rules could be a valuable future approach.  5 Conclusions Despite limited avenues for in-game 
communication, simple rule variations generated a variety of social interactions between players. A number 
of factors proved particularly important for shaping players social experiences. These included what 
players saw and understood to be important and interpretable game events; how players used in-game and 
extra-game actions to communicate with each other; and the expectations and existing social relationships 
with which player approached the game. Although it is unclear which aspects of player experience were 
idiosyncratic to this particular game and which might illustrate more general principles, an open-ended 
iterative design process allowed game design issues and avenues for player interaction to reveal themselves. 
Using a similar approach with other games in other environments might be used to develop a more general 
framework for elucidating and understanding these connections. I initially began thinking about this 
project in response to playing performative console games and being surprised by the degree to which 
players could reshape their game experiences despite the context of encoded rules. These games along 
with MMOs, pervasive/ transmedia games, and other emerging forms of social digital and hybrid games introduce 
new possibilities for digital game play. They move games to new social and physical environments, allow 
a variety of avenues for verbal and non­verbal communication, and have unrealized possibilities for introducing 
new kinds of game mechanics. By considering social factors and game rules as interdependent parts of 
an emergent system and designing games that encourage and respond on a fundamental level to emergent 
game experiences, it may be possible to better understand social game forms and to develop deeper, more 
interesting, and more meaningfully connected player experiences.  References 1. CALLOIS, R. 2001. Man, 
Play, and Games. Chaimpaign, IL: University of Illinois Press. 2. DEKORT, Y.A.W., IJSSELSTEIJN, W.A., 
AND GAJADHAR, B.J. 2007. People, places, and play: A research framework for digital game experience in 
a socio-spatial context. In Situated Play, Proceedings of the Digital Games Research Association (DiGRA) 
Conference. University of Tokyo. 3. HUGHES, L. 1999. Children s games and gaming. In Children s Folklore, 
Sutton-Smith, B., Mechling, J., Johnson, T.W., and McMahon, F.R., eds. Logan, Utah: Utah State University 
Press. 4. JAKOBSSON, M. 2007. Playing with the rules: social and cultural aspects of game rules in a 
console game club. In Situated Play, Proceedings of the Digital Games Research Association (DiGRA) Conference. 
University of Tokyo. 5. JUUL, J. 2008. What makes casual games so appealing, so attractive: Looking 
for the casual in casual video games. Lecture at Columbia University, New York. 6. SALEN, K. AND ZIMMERMAN, 
B. 2003. Rules of Play: Game Design Fundamentals. Cambridge, Mass: The MIT Press.  66  
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
	</article_rec>
	<article_rec>
		<article_id>1401857</article_id>
		<sort_key>140</sort_key>
		<display_label>Pages</display_label>
		<pages>8</pages>
		<article_publication_date>08-09-2008</article_publication_date>
		<seq_no>2</seq_no>
		<title><![CDATA[Learning metaphor through mixed-reality game design and game play]]></title>
		<page_from>67</page_from>
		<page_to>74</page_to>
		<doi_number>10.1145/1401843.1401857</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1401857</url>
		<abstract>
			<par><![CDATA[<p>This paper describes a recent program for game-based learning within a mixed-reality environment, the Situated Multimedia Arts Learning Lab [<i>SMALLab</i>]. In the program, our research team collaborated with a 9<sup>th</sup> grade Language Arts teacher to design and deliver a new learning game and associated curriculum. Through the process of game-design and game-play, students advance their understanding of metaphor. We outline the theoretical basis upon which design decisions were made, and describe the rationale for choosing Language Arts as the subject area for this program.</p> <p>Three goals structure our research: (1) to advance students' understanding of literary devices with an emphasis on metaphor; (2) to engage otherwise under-performing students through game-based learning that is student-centered, collaborative, and based in reflective practice; and (3) to demonstrate effective game-based learning using a mixed-reality platform in a conventional classroom context. Twenty-four students attending a large suburban high school in the southwest United States participated in this learning experience once a week for seven weeks during the Fall of 2007. Our data indicates that these students attained a more globally coherent model of metaphor in the course of their participation, that they found both the game-design and the game-play process stimulating and rewarding, and that, given the necessary scaffolding, a mixed-reality learning environment can be effectively employed to teach standards-based curriculum in a conventional high school classroom.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[K-12]]></kw>
			<kw><![CDATA[digital games]]></kw>
			<kw><![CDATA[education]]></kw>
			<kw><![CDATA[game design]]></kw>
			<kw><![CDATA[game-based learning]]></kw>
			<kw><![CDATA[learning]]></kw>
			<kw><![CDATA[play]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>K.3.1</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010405.10010489</concept_id>
				<concept_desc>CCS->Applied computing->Education</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010489</concept_id>
				<concept_desc>CCS->Applied computing->Education</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Experimentation</gt>
			<gt>Human Factors</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P1100722</person_id>
				<author_profile_id><![CDATA[81338489053]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Sarah]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Hatton]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Arizona State University, Tempe, Arizona]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1100723</person_id>
				<author_profile_id><![CDATA[81100071531]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[David]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Birchfield]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Arizona State University, Tempe, Arizona]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1100724</person_id>
				<author_profile_id><![CDATA[81365597683]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[M.]]></first_name>
				<middle_name><![CDATA[Colleen]]></middle_name>
				<last_name><![CDATA[Megowan-Romanowicz]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Arizona State University, Tempe, Arizona]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Bransford, J. D., A. L. Brown, and R. R. Cocking, eds. <i>How People Learn: Brain, Mind, Experience, and School.</i> 2000, National Academy Press: Washington, DC.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Brown, A. and A. Palinscar, <i>Guided, Cooperative Learning and Individual Knowledge Acquisition</i>, in <i>Knowing, Learning, and Instruction: Essays in Honor of Robert Glaser</i>, L. Resnick, Editor. 1989, Lawrence Erlbaum Associates: Hillsdale, NJ. p. 393--452.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Megowan, M. C., <i>Framing Discourse for Optimal Learning in Science and Mathematics</i>, in <i>College of Education, Division of Curriculum and Instruction.</i> 2007, Arizona State University: Tempe, AZ.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Schon, D., <i>The Reflective Practitioner: How Professionals Think in Action.</i> 1983, New York: Basic Books.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Jenkins, H., et al., <i>Confronting the Challenges of Participatory Culture: Media Education for the 21st Century.</i> 2006, MacArthur Foundation.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Sutton-Smith, B., <i>The Ambiguity of Play.</i> 1997, Cambridge, MA: Harvard University Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Fauconnier, G. and M. Turner, <i>The Way We Think: Conceptual Blending and the Mind's Hidden Complexities.</i> 2002, New York, NY: Basic Books.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>983348</ref_obj_id>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Gee, J. P., <i>What Video Games Have to Teach Us About Learning and Literacy.</i> 2003, New York, NY: Palgrave Macmillan.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Middleton, J. and Z. Toluk, <i>First Steps in the Development of an Adaptive Theory of Motivation.</i> Educational Psychologist, 1999. &#60;b&#62;34&#60;/b&#62;(2): p. 99--112.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>802839</ref_obj_id>
				<ref_obj_pid>800088</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Malone, T. W., <i>What Makes Things Fun to Learn? A Study of Intrinsically Motivating Computer Games.</i> 1980, Xerox Research Center: Palo Alto, CA.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Adams, P., <i>Teaching and Learning with SimCity 2000.</i> Journal of Geography, 1998. &#60;b&#62;97&#60;/b&#62;(2).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Dede, C., Ketelhut, D. <i>Designing for motivation and usability in a museum-based multi-user virtual environment.</i> in <i>American Educational Research Association Conference.</i> 2003. Chicago, IL.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Kelleher, C., <i>Motivating Programming: Using Storytelling to Make Computer Programming Attractive to Middle School Girls</i>, in <i>Computer Science.</i> 2006, Carnegie Mellon University: Pittsburgh.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1340974</ref_obj_id>
				<ref_obj_pid>1340961</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Monroy-Hern&#225;ndez, A. and M. Resnick, <i>Empowering Kids to Create and Share Programmable Media.</i> Interactions, 2008. &#60;b&#62;15&#60;/b&#62;(2): p. 50--53.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Utterback, C., Achituv, R., <i>Text Rain.</i> 2006, Time Warner Center: New York, NY.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1179329</ref_obj_id>
				<ref_obj_pid>1179295</ref_obj_pid>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Birchfield, D., et al. <i>SMALLab: a Mediated Platform for Education.</i> in <i>ACM SIGGRAPH.</i> 2006. Boston, MA.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Anyon, J., <i>Social Class and the Hidden Curriculum of Work.</i> Journal of Education, 1980. &#60;b&#62;162&#60;/b&#62;(1): p. 67--92.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Arizona Department of Education, <i>Arizona Standards-Based Teaching and Learning: Writing Standard Articulated by Grade level.</i> 2007.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Arizona Department of Education, <i>School Effectiveness Division: K-12 Literacy.</i> 2007.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[National Council of Teachers of English, <i>Standards for the English Language Arts.</i> 1996, International Reading Association: USA.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Kress, G. and T. Van Leuwen, <i>Multimodal Discourse: the Modes and Media of Contemporary Communication.</i> 2001, London: Arnold.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Andrzejczak, N., G. Trainin, and M. Poldberg, <i>From Image to Text: Using Image in the Writing Process.</i> International Journal of Education and the Arts, 2005. &#60;b&#62;6&#60;/b&#62;(12).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[Lakoff, G., <i>Metaphors We Live By.</i> 1980, Chicago: University of Chicago Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[Birchfield, D., W. Savenye, and H. Thornburg. <i>AMEEd Edulink.</i> 2006 {cited; Available from: http://ame4.hc.asu.edu/edulink.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[Blasko, D. G. and C. M. Connine, <i>Effects of Familiarity and Aptness on Metaphor Processing.</i> Journal of Experimental Psychology: Learning, Memory, and Cognition, 1993. &#60;b&#62;19:&#60;/b&#62; p. 295--308.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[Landauer, T. K., P. W. Foltz, and D. Laham, <i>Introduction to Latent Semantic Analysis.</i> Discourse Processes, 1998. &#60;b&#62;25&#60;/b&#62;(259--284).]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Learning Metaphor through Mixed-Reality Game Designand Game Play Sarah Hatton David Birchfield M. Colleen 
Megowan-Arts, Media and EngineeringArts, Media and EngineeringRomanowicz Arizona State UniversityArizona 
State UniversityArts, Media and EngineeringTempe, ArizonaTempe, ArizonaArizona State University+1.480.965.3155 
+1.480.965.3155 Tempe, Arizona sarah.hatton@asu.edu dbirchfield@asu.edu +1.480.965.3155 megowan@asu.edu 
ABSTRACT This paper describes a recent program for game-based learning within a mixed-reality environment, 
the Situated Multimedia Arts Learning Lab [SMALLab]. In the program, our research team collaborated with 
a 9th grade Language Arts teacher to design and deliver a new learning game and associated curriculum. 
Through the process of game-design and game-play, students advance their understanding of metaphor. We 
outline the theoretical basis upon which design decisions were made, and describe the rationale for choosing 
Language Arts as the subject area for this program. Three goals structure our research: (1) to advance 
students understanding of literary devices with an emphasis on metaphor; (2) to engage otherwise under-performing 
students through game­based learning that is student-centered, collaborative, and based in reflective 
practice; and (3) to demonstrate effective game-based learning using a mixed-reality platform in a conventional 
classroom context. Twenty-four students attending a large suburban high school in the southwest United 
States participated in this learning experience once a week for seven weeks during the Fall of 2007. 
Our data indicates that these students attained a more globally coherent model of metaphor in the course 
of their participation, that they found both the game-design and the game­play process stimulating and 
rewarding, and that, given the necessary scaffolding, a mixed-reality learning environment can be effectively 
employed to teach standards-based curriculum in a conventional high school classroom.  Categories and 
Subject Descriptors K.3.1 [Computer Uses in Education]: Collaborative learning, Computer-assisted instruction 
 General Terms Design, Experimentation, Human Factors. Copyright &#38;#169; 2008 by the Association for 
Computing Machinery, Inc. Permission to make digital or hard copies of part or all of this work for personal 
or classroom use is granted without fee provided that copies are not made or distributed for commercial 
advantage and that copies bear this notice and the full citation on the first page. Copyrights for components 
of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy 
otherwise, to republish, to post on servers, or to redistribute to lists, requires prior specific permission 
and/or a fee. Request permissions from Permissions Dept, ACM Inc., fax +1 (212) 869-0481 or e-mail permissions@acm.org. 
Sandbox Symposium 2008, Los Angeles, California, August 9 10, 2008. &#38;#169; 2008 ACM 978-1-60558-173-6/08/0008 
$5.00  Keywords K-12, learning, digital games, game design, education, play, game-based learning. 1. 
INTRODUCTION In recent years, interactive media and digital games have been increasingly integrated into 
K-12 teaching and learning. Supporting this trend, there is a growing body of evidence that documents 
the exciting potential for well-designed game-based tools and curricula. When grounded in an appropriate 
theoretical foundation, game-based learning promises to have a transformative effect on the future of 
K-12 education. Specifically, game-based learning can be effectively structured by curricula that are 
student-centered, collaborative, and support reflective practice. In the continuing effort to improve 
student engagement in learning and move the teacher from his or her perch as sage on the stage to guide 
on the side , curriculum designers over the last 30 years have embraced student-centered activity as 
the gold standard for classroom participation frameworks [1]. Student­centered learning activities are 
designed to elicit students reasoning about the concepts under study and encourage explicit sense-making 
over rote memorization and regurgitation of facts. Since the digital age has placed facts at students 
fingertips, the structuring of information into coherent and useful conceptual models is where schooling 
must focus its energy. Student-centered learning by its very nature is collaborative as it relies on 
student-to-student discourse and joint activity to leverage the sense-making process. An extensive research 
base has demonstrated the efficacy of collaborative learning techniques [2]. Teachers manage this discourse, 
frame the target concepts and scaffold student thinking as needed, but students ideas and joint effort 
to make meaning ideally determines the direction of lessons. Such inquiry-based and model-based learning 
environments design in and depend upon reflective practice to advance students conceptual model building, 
model testing and model application skills [3]. This typically happens in small group work, subsequently 
shared with the whole class, aimed at articulating relationships between and among the fundamental elements 
of a concept and articulating the rules by which they interact. Donald Schon has proposed a more generalized 
theory of reflective practice [4] that can serve as model of student thinking in the context of game-based 
curricula. Schon defines two modes of reflection. First, reflection-in-action can be though of as thinking 
on one s feet while actively performing a task they are trying to gain expertise over. During reflection-in-action, 
students can take on the role of an informal coach and instruct their peers during the reflective learning 
process. Second, reflection-on-action occurs as students consider the processes and products of learning, 
often through group discourse. There is extensive research documenting the value of play in learning. 
Play can take many forms within different game spaces, but in the context of this study, we are informed 
by Jenkins definition of play as the capacity to experiment with one s surroundings as a form of problem 
solving and the assertion that play can increase students motivation for learning, keeping them engaged 
and encouraging them to take risks [5]. Sutton-Smith describes how play has lead to some of the greatest 
human achievements in subject areas including science and literature [6]. Sutton-Smith notes the extent 
to which, play, especially for children, is a means of true empowerment. Situating learning in a familiar 
context allows students to map new ideas onto existing conceptual models. These metaphorical mappings 
allow for inference about the relationships between unfamiliar ideas and help students build predictive 
models that are useful for solving problems [7, 8]. Games are an ideal platform for this type of learning, 
providing students with both arousal and control to motivate their engagement [9] with a fictitious world 
of which they are challenged to make sense. Moreover, there is growing evidence that games have the ability 
to hold the interest of a player for long periods of time, unlike traditional forms of media that are 
passive, because of the flow states that arise from engaging in an isolated, sensory activity [10]. A 
number of recent efforts have demonstrated the efficacy of game-based learning through game-play and 
game-design. For example, in SimCity2000, educators adopted a pre-existing commercial game platform, 
Sim City, for classroom use [11]. Students study urban geography concepts by iteratively designing virtual 
communities. During the process they assume the roles of urban planners, designers, and policy makers. 
In the River City project, educators and researchers created a massively-multiplayer game to address 
specific content learning goals through engaging game play [12]. The design of such a platform allowed 
educators to effectively design content into the experience rather than potentially work around the biases 
of an existing game. Game creation frameworks such as Scratch and Alice [13, 14] explicitly use the game-design 
process as a vehicle for learning. These platforms offer an exciting vision for the integration of game­design 
for learning, but thus far, much of the learning content resides in student understanding of the underlying 
procedural and technological elements that drive games. We have identified three trends that run through 
this prior work that suggest opportunities for continued research. First, many current game-based learning 
experiences rely on traditional desktop and console computing interfaces. While readily accessible, they 
can potentially limit the expressive and communicative capacities of students. However, recent research 
in mixed-reality offers the opportunity to engage students and teachers in new ways. Mixed-reality environments 
integrate the physical environment with digitally mediated components, often in an immersive framework 
where direct human-to-human interaction unfolds within a mediated space. Despite their exciting promise, 
mixed-reality systems can be large and costly, posing an additional set of financial and logistical obstacles 
for classroom based learning. Second, much of game-based learning has been most successful in the areas 
of science and technology to date. Nonetheless, language arts is fundamental to learning across all subject 
areas, and in addition to the pervasive use of games for language acquisition, there are many opportunities 
to engage core language arts content (e.g., metaphor, imagery, compositional structure) through game-based 
learning. Camille Utterbach s installation, Text Rain [15] offers a compelling vision of how mixed-reality 
can potentially be applied to language arts learning. With an open-ended and expressive interaction framework, 
it has engaged a diverse audience of learners in numerous museums. However, Text Rains s discovery learning 
structure does not address explicit content learning goals. Third, digital games remain on the periphery 
of most mainstream school learning at present, and it can be a difficult challenge to implement innovative 
game-based learning in conventional classroom settings. As a result, many such initiatives are deployed 
in museum and after school programs. Our research is informed by these three trends. We are pursuing 
a multi-faceted approach to the study of game-based learning. Specifically, we have developed a new mixed-reality 
learning environment. We are developing a replicable model for mixed­reality game-based learning in conventional 
classrooms. Finally, we are collaborating with language arts teachers and students to design, deploy 
and evaluate the efficacy of game-based learning. We present the context and results of a recent field 
test program for underserved 9th grade students in a regional urban high school.  2. RESEARCH CONTEXT 
Over the past three years, our research team has developed a new platform for learning, the Situated 
Multimedia Arts Learning Lab [SMALLab]. Figure 1. SMALLab mixed-reality learning environment SMALLab 
(Figure 1) is a mixed-reality learning environment that advances situated and embodied learning by allowing 
the body to function as an expressive interface [16]. Within SMALLab, students use a set of glowballs 
to interact in real time with each other and with dynamic visual, textual, physical and sonic media through 
full body 3D movements and gestures. As such, it establishes a porous relationship between a physical 
learning context and digitally mediated components. For example, within SMALLab students can interact 
in a productive and embodied way with virtual spring-mass systems and they can change symbolic representations 
(all laid onto real space) that exemplify and let learners produce the core dynamics of force and motion 
in physics. For example, working in the Spring Sling scenario, students are immersed in a complex physics 
simulation that involves multiple sensory inputs to engage student attention. They can hear the sound 
of a spring picking up speed, see projected bodies moving across the floor, feel a physical ball in their 
own hands and integrate how the projected ball moves in accordance with their own body movements to construct 
a robust conceptual model of the entire system. In the Layer Cake Builder game they work in collaborative 
teams to re-enact the interdependent geological processes that formed the surface of the Earth. Physically, 
SMALLab, is a 15 W x 15 W x 12 H freestanding, interactive space. A rectangular trussing structure frames 
its open architecture and supports the following sensing and feedback equipment: a six-element camera 
array for glowball tracking, a top-mounted video projector providing real time visual feedback, four 
audio speakers for surround sound feedback, and an array of tracked physical objects (glowballs). A networked 
computing cluster with custom software drives the interactive system. SMALLab also provides an embedded 
set of high level authoring tools that allow students and teachers to create and adapt interactive learning 
scenarios. This authoring environment, the SMALLab Core for Realizing Experiential Media [SCREM] and 
an extensible media database served as the game design platform for our study. SMALLab is designed to 
accommodate the real world financial and logistical constraints of today s classrooms and community centers 
while delivering emerging interactive technologies directly to communities where it is needed most. Over 
the past two years, our team has deployed SMALLab in a series of successful programs that have reached 
over 25,000 learners through regional school and museum programs. In Summer 2007 we began a long-term 
partnership with a large urban high school in the greater Phoenix, AZ metropolitan area. We have permanently 
installed SMALLab in a classroom and are working closely with teachers and students across the campus 
to design and deploy new learning scenarios. The student demographic is 50% white, 38% Hispanic, 6% Native 
American, 4% African American, 2% other. 50% of students are on free or reduced lunch programs, indicating 
that many students are of low socio-economic status. 11% are English language learners and 89% of these 
students speak Spanish at home. In this study, we are working with 9th grade students and teachers from 
the school s C.O.R.E. program for at-risk students. The C.O.R.E. program is a specialized school within 
a school with a dedicated faculty and administration. Students are identified for the program because 
they are reading at least two levels below their grade. After almost a year of classroom observation, 
it is clear that students are tracked into this type of program, not because they have low abilities, 
but because they are often underserved by traditional instructional approaches. Conventional classrooms 
for underperforming students are often highly structured environments that stress drill and skill learning 
activities [17]. As a consequence, teachers can come to have low expectations for students and student 
motivation is very low. Creativity, reflective practice, and complex problem solving are rarely emphasized. 
In Fall 2007, we initiated a pilot study of game-based learning for language arts in SMALLab. We collaborated 
with a first-year, 9th grade language arts teacher in the C.O.R.E. program to design and implement a 
new game-based learning scenario and 9-week curriculum. During the seven weeks, students worked once 
a week, for one fifty-minute class period in SMALLab. Our team provided technical support for the learning 
activities, but the teacher lead all sessions. During this process we also pursued professional development 
activities with the teacher, but discussion of that process is beyond the scope of this article. Given 
this context we established three goals for the study: Goal 1: Advance students understanding of literary 
devices with an emphasis metaphor. Goal 2: Engage otherwise under-performing students through game-based 
learning that is student-centered, collaborative, and based in reflective practice. Goal 3: Demonstrate 
effective game-based learning using a mixed-reality platform in a conventional classroom context.  3. 
THE METAPHOR GAME Through a series of initial planning sessions with the teacher, we identified metaphor 
as the content focus of the program for several reasons. First, from a pedagogical perspective, metaphor 
is a central component of the 9th grade curriculum. Our state s language arts standards for grade nine 
state that students should be able use figurative language (e.g., metaphor, simile, imagery) that is 
both expressive and responsive [18, 19]. Our partner teacher indicated that understanding and use of 
metaphor are difficult skills that students typically struggle to master. Traditional instructional methods 
address this topic through a variety of language base approaches, but it is rarely explored in a multimodal 
or experiential fashion in the classroom. SMALLab technology affords the opportunity to teach and learn 
metaphor in these new ways. Figure 2. Pairs of students cooperate to grab images and text in SMALLab 
Second, from a research perspective, we looked to the National Council of Teachers of English [20] which 
suggests students must have a working knowledge of language structures, such as metaphor, so that the 
texts they read and the texts they write are accessible. Metaphors are a key element of expressive writing 
and must be taught in ways that allow for deeper thinking. The NCTE supports curriculum that encourage 
the exploration of multimodal metaphors including visual and text elements. This allows students to visually 
represent textual elements in order to become more effective writers, and accords with students everyday 
experiences with text online and in print where text encompasses numerous modes [21]. Furthermore, recent 
research shows that just by adding a drawing element to the writing process, students can incorporate 
more metaphors into their poems and thus portray their ideas more expressively [22]. Lakoff s seminal 
research establishes the power of metaphorical thinking in structuring our daily communication and experience 
[23]. He shows that much of our language and action is grounded in metaphorical thought. As such, beyond 
mere reading comprehension and writing, it is clear that an understanding of metaphor will benefit students 
in terms of their ability to undertake problem solving tasks and structure their thinking in a variety 
of future learning contexts. Our team has created a new game for SMALLab, The Metaphor Game. It aids 
understanding of metaphor through student­centered, collaborative, and reflective learning. During the 
game­play process, students generate new metaphors by linking different media objects together. During 
game-design process, students author new game levels by configuring sets of interactive text and visual 
elements. 3.1 Game Scenario As pictured in Figure 2, pairs of students work cooperatively to play The 
Metaphor Game. Moving within interactive space, students see a set of media and text objects (Figure 
3) that are projected as floating across the floor. Students discuss the objects and negotiate potential 
metaphors that might motivate a pairing. Using the interactive glowballs, students move toward a target 
media object, grab it, and drop it into a metaphor bucket . Figure 3. Images and text from a student-designed 
game level After two media objects are dropped into the bucket, students can reflect on the pairing and 
work together, possibly coached by their teacher or peers, to generate a final metaphor and justification. 
For example, if the words lost child and an image of a boat are dropped into the bucket, players can 
explain, The boat is a lost child, searching for the harbor, its only mother. The metaphor is the boat 
is a lost child and its justification is understood to be that the boat, unable to find a harbor, is 
lost, just as a lost child would look for its mother. The metaphor and justification is entered into 
the SMALLab media database, serving as a semantic link between the two source media objects. The pairing 
and metaphor are immediately accessible to students and teachers via the SMALLab Link [24] online environment. 
This interaction is the template for the student-led game level design activities. During the game-design 
process, students collaborate in small teams of three or four. They use a combination of drawing tools 
(e.g., pen, paper, markers) and image software (e.g., Photoshop) to create new imagery. They specify 
game design details using a paper-based worksheet as shown in Figure 4. SMALLab provides a set of custom 
interaction authoring tools to upload images and text to the media database, annotate each object, and 
configure any combination of objects as a new game level. Due to time restrictions, our research team 
completed these basic configuration tasks outside of class time.  3.2 Game-based Curriculum Our Metaphor 
Game curriculum unfolded over a period of seven weeks where students met in SMALLab once each week during 
the school day for a fifty-minute period. There were three phrases of the curriculum, with each phase 
divided into two activities, the game-design process and the game-play process. During the game-design 
process, students or teachers author new game levels for The Metaphor Game. When complete, these new 
levels constitute the game played during the game-play process. The three curricular phases are teacher-led 
design, student-led design, and literature-based student-led design. The first phase spanned three sessions 
with the second and third phases lasting two sessions each. During the first phase, the full time was 
devoted to the game-play process since the game design occurred before the program began. During the 
second and third phases, one and a half sessions were allocated to game-design with the last half of 
one session allocated to game-play. During the teacher-led design phase, the teacher worked in collaboration 
with our design team to create four unique game levels. Each level was designed around a set of familiar 
word combinations and this phase functioned as an introductory experience. A practice mode of sorts, 
the students learned the game-play process and practiced metaphorical thinking. This play-testing phase 
prepared them to take the role of designer in subsequent phases. During this phase, the teacher designed 
forty­nine metaphors and students generated twenty-six metaphors through their play. Figure 4. Metaphor 
creation worksheet from game-design process During the student-led design phase, students first engaged 
in a game-design process, working in collaborative teams. Picking from a set of twenty-five images presented 
by the teacher, each team could selected four images. From that point, each team was tasked with devising 
a complementary set of four words to complete four designed metaphors and a justification statement, 
each relating to a theme of their choice. Once complete, these game levels were subsequently used by 
peer students. During this student-led design phase, the students designed seventeen metaphors during 
the game-design process and generated nine metaphors during the game-play process. The literature-based 
student-led design phase builds from the previous phrase, but now students author game levels using metaphors 
inspired by their reading of Shakespeare s Romeo and Juliet. Students were tasked to consider Shakespearian 
metaphor by mining the text of Romeo and Juliet. Working in teams, students identified a favorite scene 
and extracted four metaphors from the text. As illustrated in Figure 5, they were asked to create four 
images that visually express half of a metaphor with the other half completed by Shakespeare s text. 
During this final phase students created fourteen metaphors during the design process and created eight 
metaphors during the play process. Figure 5. Student created image to convey Shakespeare s text, Juliet 
is ripe for marriage  4. EVALUATION To evaluate the impact of this pilot program and the progress toward 
our three goals, we draw on a set of quantitative and qualitative data sources. These data include student 
outcomes, video footage of learning sessions, and pre-and post-treatment interviews with students. Goal 
1: Advance students understanding of literary devices with an emphasis metaphor To assess student performance 
during the program we examine quantitative data regarding the strengths of student-generated metaphors 
from each phase. From this data we can identify trends and draw conclusions. First, we rate metaphors 
along two independent dimensions: originality and aptness. Originality is a measure of how often a pair 
of terms appears together in everyday language and literary contexts. As defined by Blasko and Connine 
[25], aptness measures how well the metaphor expresses its specific nonliteral meaning." To measure the 
originality of paired terms in student metaphors, we use the Latent Semantic Analysis (LSA) pairwise 
comparison tool [26], we can rate each metaphor based on how semantically related the two elements of 
the metaphor are. LSA is a mathematical technique for extracting and representing the similarity of meaning 
of words or larger bodies of text. It constructs semantic spaces by measuring word co-occurrences in 
over 30,000 documents with over 90,000 different words for a total of 11 million words. If a particular 
pair of terms appears infrequently in the system s body of text, the pair will receive a low score, thus 
indicating high originality. Conversely, if the pair appears frequently, LSA will yield a high number. 
For example, during the early stages of the program, a team of students created the metaphor, waves are 
war. The LSA database returns a score of 0.01, revealing that this pairing of terms appears very infrequently. 
Thus, the metaphor ranks very highly along the originality dimension. By contrast, another student generated 
metaphor, fear is loneliness ranks low in originality with an LSA score of .47. For clarity, in Table 
1 we subtract the LSA pairwise ranking result from 1.0 to present average originality scores so that 
higher values indicate greater originality. During both the game-design and game-play phases, students 
were required to explicitly record a metaphorical justification for the pairing of each of their pairings. 
To measure the dimension of metaphorical aptness, eight experts from our research team rated each of 
these metaphorical justifications on a scale of 0 2. A rating of 0 indicates poor aptness, while a rating 
of 2 indicates high aptness. For example, a student generated metaphor, surgery is war because every 
move might be your last received a high average aptness score of 1.75. By contrast, the metaphor the 
flamingos are a class, because they learn from each other received a low score of 0.5. Table 1 summarizes 
the average scores for both originality and aptness during each phase of the curriculum. Aptness measures 
are not available for the teacher-led design phase because the teacher did not provide justifications. 
n indicates the number of metaphor pairings analyzed in each phase. Table 1. Summary analysis of student-generated 
metaphors Game Design Phase Game Play Phase Originality Aptness Originality Aptness Teacher­ 0.880 N/A 
0.893 1.254 led design (n = 49) (n = 26) Student-led 0.919 1.072 0.889 1.111 design (n = 17) (n = 9) 
Literature­ 0.921 1.321 0.864 1.000 based student (n = 14) (n = 8) lead design We see four meaningful 
trends in this data. (1) With each new phase of game design process, there is a progressive increase 
in metaphor originality and aptness. This increase is most pronounced in the transition from teacher-led 
design to student­led design. (2) There is a progressive decrease in originality and aptness with each 
phase of the game play process. (3) In the first two phases, students created stronger metaphors during 
the game­play process than during the game-design process. By the final phase, when students build from 
Shakespeare s Romeo and Juliet, students created stronger metaphors during the design process than in 
the play process. (4) Once the student-led game-design activity is introduced in the second phase, there 
is a dramatic decline in the number of metaphors created by students during the game-play process (i.e., 
n = 26, 9, 8 for phases 1, 2, and 3 respectively). Reflecting on these trends we draw three conclusions 
regarding the relationship between curriculum design and student performance. First, during the teacher-led 
design phase, students are able to create metaphors that exceed the originality scores of the designers. 
This phase of the curriculum was designed to introduce students to metaphor, where the teacher as game­designer 
is able to scaffold student learning. Here, as proposed by Gee [8], we see an example of good game design 
intersecting with curriculum design for the benefit of students. Second, during the student-led design 
process, there is a marked increase in both the originality and aptness scores. Metaphors created by 
students during the design process are stronger than those created by the teacher or during any of the 
game play processes. We posit that the during the design process, students challenge each other to build 
from scratch functional models of metaphor. During the game play process they are tasked to apply this 
model, a task which requires less effort. As a consequence, students are able to generate more powerful 
metaphors during design than play. From the perspective of Schon s theory of reflection, the play process 
is an example of learning via reflection-in-action while the design process is an example of learning 
via reflection-on-action. Our data suggests that while students achieved gains during the design process, 
in future work, our curriculum should build in more time for the play process. Building from this point, 
we draw a final conclusion. Simply put, during the second and third phases, game play was viewed by students 
and the teacher as an after thought to the game design process. Review of the learning session documentation, 
combined with the raw numbers of generated metaphors demonstrates a drastic reduction in time-on-task 
from the first phase, and a hurried approach to thinking and learning through play. We conclude that 
this fact is a second contributing factor to the decline in student performance during game play in spite 
of the increase during game design. Again, we conclude that in future iterations, play must be established 
as a valuable and necessary component of the learning process. Furthermore, the play process should be 
appropriately facilitated at every stage, offering substantial mentoring in early stages, and encouraging 
peer coaching as students advance. Goal 2: Engage otherwise under-performing students through game-based 
learning that is student-centered, collaborative, and based in reflective practice. At the beginning 
of this program our partner teacher noted that student motivation and engagement is probably the greatest 
obstacle for student learning in the C.O.R.E. program. The metaphor game and curriculum was designed 
to engage students in novel ways that are rooted in a foundation of proven learning theories. We now 
present a brief transcription of an early interaction between three students and the teacher during the 
first game-play process. Evan and Gina are working as a pair in the space. The teacher and another student 
coach the team. The group is reflecting on the pairing of an image of a long hallway and the word love 
that students initially paired during their interaction. They work through several ideas before arriving 
at a final construct. Note how students work together, with scaffolding instruction by their teacher, 
to craft a successful metaphor. As such, the game play process is framed as a cooperative endeavor where 
all participants reach shared success through their achievement. The resultant metaphor ( Love is a long 
hallway with many doors and many opportunities ) ranks highly with an originality score of 0.91 and an 
aptness of 1.625. Teacher: ok, so you have the hallway and love [looking at SMALLab] Chris (acting as 
a peer coach, from outside the environment): ooo hallway of looove Teacher: What is your sentence? Evan: 
Love is a long hallway Chris: WHY is it a long hallway? Evan: because Teacher: try not to say because 
. Love is a long hallway doing what? Chris: Love is never ending! [laughs] Evan: Because it is endless. 
Chris: There is always a door at the end of it. Have you thought of that? Teacher: OK, Chris came up 
with something different. Yeah maybe talk about the doors? Gina: Love has many doors. Teacher: So love 
is a hallway with Gina and Evan together: many doors!  Teacher: and Gina: many ways to I don t know 
? Chris: FIND LOVE! [student claps and snaps his fingers] Evan: many different opportunities OK, so love 
is a long hallway with many doors and many opportunities. In post-session interviews, students expressed 
high motivation for this type of game-based collaborative learning in SMALLab. For example, one student 
remarked, I think our school would have better scores on reading and writing and stuff because SMALLab 
brings fun, and then when you think of reading and stuff you think of SMALLab and you think of a way 
you could do it yourself at home except for without all the cool technology as you re reading out loud 
you could make your own sounds and your own extra little things Another student noted, I like the fact 
that we re in groups rather than by ourselves. Students also expressed a strong sense of ownership for 
their learning process and a desire to play a role in designing future SMALLab learning activities. One 
student expressed the desire to not only design student-centered learning activities, but to empower 
students to shape the curriculum for the benefit of their teachers: "The teachers will teach the students 
what to do first, and then the students should teach the teachers how to be fun with the program. So 
then the next step the teachers take--the next time they do it...they'll know what the students like 
for the next generation class." In the following transcription, two students express ideas for how to 
structure a game-based curriculum. They explore how their experience could be transferred to other content 
areas and describe the value of integrating game-play and game-design. Interviewer: Can you think of 
a way that SMALLab could be used in a math class? Chris: You can use it to like divide and stuff .the 
teacher could show like I think people would pay more attention .like honestly, I think people would 
pay more attention if they had more fun in their classes. If it was fun, people would pay attention. 
Cuz teachers are like you gotta do this and that and people don t understand. People say they don t understand 
the teachers way and they [teachers] want to help them but they can t find a way to help them. And actually 
students like listening to each other more than the teacher. Interviewer: Do you wish you guys were at 
the computer? I mean, do most people want to be on the floor, or would it be worthwhile to develop activities 
where students were actually at the computer? Joe: Yeah. Because when we were doing the metaphor exercise, 
when were behind there it was like a behind the scenes of it, you know? We saw what they did and when 
they finally picked a metaphor we would name it and just all the stuff that goes on on the computer that 
makes the SMALLab work it s pretty cool. Interviewer: So you feel like that s something that we should 
be making that learning experience on a broad scale basis? Or just for the people in the class that might 
be interested in that? Chris: Um broader scale. Interviewer: Broader scale? Let everybody have a turn 
at that? [speaking to student 2] Have you been behind the computer? Joe: No, but I think it should be 
like, pair up so that there s 3 to a team, and we have, like, everyone names their own team and we play. 
Like, an elimination game. One s at the computer and the other two are just thinking of metaphors they 
can still go to their other partner to figure something out and just like have fun with it. Later in 
the interview, the students discuss how SMALLab s architecture supports a shared experience of cooperative 
game­play in a large classroom of students: Interviewer: So do you think that even the people who weren 
t the players would be paying attention? Because one thing that I noticed standing by the side was that, 
certain activities, the people that were around the floor would tune out. Some things they were really 
tuned in to and the one thing that I noticed was, they were tuned into sounds [both students nod]. When 
the system makes sounds people pay attention. Joe: It s funny. Chris: Sometimes for me I like picking 
a person for anything, whether it be a sports team, a reality show anything that people are competing 
against, I ll pick someone, and that ll keep me watching the show because I want my pick to win. Interviewer: 
So even though you re watching outside the space you have somebody inside the space that you are rooting 
for  Chris: Yeah. Interviewer: Huh. What a good idea. I never thought about that. Joe: It s like you 
have your own cheer team. Chris: And that s what keeps me tuned in while other people are being tuned 
out. Interviewer: and you don t think that just that person s team is going to root for him? You think 
the whole class will root for him? Joe: I think everybody just wants to play like get into the game so 
that like it s like a football game people cheer for their side people cheer for their team they want 
to root for their team it s like, why would you want to cheer for the other team? But still it s your 
fiends you cheer for em. And people are just like we want to have fun. Goal 3: Demonstrate effective 
game-based learning using a mixed-reality platform in a conventional classroom context Through this pilot 
program our team has worked toward a replicable model for bringing innovative mixed-reality learning 
experiences into everyday K-12 classrooms. To do so effectively requires the design of learning activities 
that align with and enrich ongoing curricula. It requires professional development and support for participating 
teachers. Finally, it requires long term buy-in from all stakeholders including students, teachers, and 
administrators. Through quantitative and qualitative data presented above, we have documented several 
positive trends in student learning and evidence of their buy-in to the program. As a result of this 
study, a number of developments suggest that there is growing support and buy-in from the school. First, 
we have since engaged a number of additional teachers who are collaborating to develop game-based learning 
activities in SMALLab in content areas including Chemistry, Earth Science and Language Arts. Second, 
looking ahead to the next academic year we are working with the school administration to expand the program. 
Through this expansion we will partner to bring this model to the entire campus across all grade levels 
and subject areas, forging an onsite community of practice around game­based, mixed-reality learning. 
 5. CONCLUSIONS We have presented results pertaining to three primary goals: (1) Students have achieved 
measurable learning gains in the course of this nine weeks unit of instruction. More significantly, they 
volunteered substantive recommendations about future game design and testing. (2) As illustrated above, 
students expressed high interest in working in the SMALLab environment. (3) We have demonstrated that 
SMALLab is an effective learning tool in the traditional learning paradigm of K-12 schooling. SMALLab 
has been used for an entire year now in a conventional high school language arts classroom. Students 
look forward to their weekly work in SMALLab and offer suggestions on how SMALLab would be useful in 
their other classes. They even ask to play with SMALLab learning scenarios during their lunch hour. Teachers 
and administrators are pleased with this pilot study and are enthusiastic about extended access to this 
unique learning environment to other disciplines and student communities. We hope to extend the current 
game architecture to include 3d movements and gestures. Students can enact movements within the space 
that can be archived as 3d data. This data can animate their media within the space. Their media will 
become more sprite-like and thus add a kinesthetic element in the representation of metaphor. We will 
also explore the use of LSA as a scoring tool as students have expressed an interest in earning points 
and in having ways to compete with one another. If students know that they could achieve a high score 
by linking media together that are more original, they may challenge themselves to come up with metaphorical 
pairings that are more creative and more expressive. We will continue to look for ways to improve the 
curriculum to better address content learning goals and pedagogical approaches with particular attention 
to perfecting the participation framework to optimize whole group engagement. We will also look for ways 
to empower students to make substantive contributions in the design of learning scenarios. This study 
reveals that learning was best fostered through the study of existing literature and game­design. We 
hope to shift focus to this in the future.  6. ACKNOWLEDGEMENTS We extend our deepest gratitude to our 
partner students, teachers and staff for their enthusiasm and dedication to this program. Without their 
commitment, none of this work would be possible. We gratefully acknowledge generous support from the 
Kauffman Foundation for Entrepreneurship and the National Science Foundation CISE Infrastructure grant 
under Grant No. 0403428 that has partially funded this research. 7. ADDITIONAL AUTHORS Harper Piver, 
Department of Dance, Arizona State University, harper.piver@asu.edu; Ellen Campana, Arts, Media and Engineering/Department 
of Psychology, Arizona State University, ellen.campana@asu.edu.  8. REFERENCES 1. Bransford, J.D., A.L. 
Brown, and R.R. Cocking, eds. How People Learn: Brain, Mind, Experience, and School. 2000, National Academy 
Press: Washington, DC. 2. Brown, A. and A. Palinscar, Guided, Cooperative Learning and Individual Knowledge 
Acquisition, in Knowing, Learning, and Instruction: Essays in Honor of Robert Glaser, L. Resnick, Editor. 
1989, Lawrence Erlbaum Associates: Hillsdale, NJ. p. 393-452. 3. Megowan, M.C., Framing Discourse for 
Optimal Learning in Science and Mathematics, in College of Education, Division of Curriculum and Instruction. 
2007, Arizona State University: Tempe, AZ. 4. Schon, D., The Reflective Practitioner: How Professionals 
Think in Action. 1983, New York: Basic Books. 5. Jenkins, H., et al., Confronting the Challenges of 
Participatory Culture: Media Education for the 21st Century. 2006, MacArthur Foundation. 6. Sutton-Smith, 
B., The Ambiguity of Play. 1997, Cambridge, MA: Harvard University Press. 7. Fauconnier, G. and M. Turner, 
The Way We Think: Conceptual Blending and the Mind's Hidden Complexities. 2002, New York, NY: Basic Books. 
 8. Gee, J.P., What Video Games Have to Teach Us About Learning and Literacy. 2003, New York, NY: Palgrave 
Macmillan. 9. Middleton, J. and Z. Toluk, First Steps in the Development of an Adaptive Theory of Motivation. 
Educational Psychologist, 1999. 34(2): p. 99-112.  10. Malone, T.W., What Makes Things Fun to Learn? 
A Study of Intrinsically Motivating Computer Games. 1980, Xerox Research Center: Palo Alto, CA. 11. 
Adams, P., Teaching and Learning with SimCity 2000. Journal of Geography, 1998. 97(2). 12. Dede, C., 
Ketelhut, D. . Designing for motivation and usability in a museum-based multi-user virtual environment. 
in American Educational Research Association Conference. 2003. Chicago, IL. 13. Kelleher, C., Motivating 
Programming: Using Storytelling to Make Computer Programming Attractive to Middle School Girls, in Computer 
Science. 2006, Carnegie Mellon University: Pittsburgh. 14. Monroy-Hernández, A. and M. Resnick, Empowering 
Kids to Create and Share Programmable Media. Interactions, 2008. 15(2): p. 50-53. 15. Utterback, C., 
Achituv, R., Text Rain. 2006, Time Warner Center: New York, NY. 16. Birchfield, D., et al. SMALLab: 
a Mediated Platform for Education. in ACM SIGGRAPH. 2006. Boston, MA. 17. Anyon, J., Social Class and 
the Hidden Curriculum of Work. Journal of Education, 1980. 162(1): p. 67-92. 18. Arizona Department 
of Education, Arizona Standards-Based Teaching and Learning: Writing Standard Articulated by Grade level. 
2007. 19. Arizona Department of Education, School Effectiveness Division: K-12 Literacy. 2007. 20. 
National Council of Teachers of English, Standards for the English Language Arts. 1996, International 
Reading Association: USA. 21. Kress, G. and T. Van Leuwen, Multimodal Discourse: the Modes and Media 
of Contemporary Communication. 2001, London: Arnold. 22. Andrzejczak, N., G. Trainin, and M. Poldberg, 
From Image to Text: Using Image in the Writing Process. International Journal of Education and the Arts, 
2005. 6(12). 23. Lakoff, G., Metaphors We Live By. 1980, Chicago: University of Chicago Press. 24. 
Birchfield, D., W. Savenye, and H. Thornburg. AMEEd Edulink. 2006 [cited; Available from: http://ame4.hc.asu.edu/edulink. 
 25. Blasko, D.G. and C.M. Connine, Effects of Familiarity and Aptness on Metaphor Processing. Journal 
of Experimental Psychology: Learning, Memory, and Cognition, 1993. 19: p. 295-308. 26. Landauer, T.K., 
P.W. Foltz, and D. Laham, Introduction to Latent Semantic Analysis. Discourse Processes, 1998. 25(259-284). 
  
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
		<article_sponsors>
			<funding_agency>National Science Foundation</funding_agency>
			<grant_numbers>
				<grant_number>0403428</grant_number>
			</grant_numbers>
		</article_sponsors>
	</article_rec>
	<article_rec>
		<article_id>1401858</article_id>
		<sort_key>150</sort_key>
		<display_label>Pages</display_label>
		<pages>6</pages>
		<article_publication_date>08-09-2008</article_publication_date>
		<seq_no>3</seq_no>
		<title><![CDATA[A framework for analysis of 2D platformer levels]]></title>
		<page_from>75</page_from>
		<page_to>80</page_to>
		<doi_number>10.1145/1401843.1401858</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1401858</url>
		<abstract>
			<par><![CDATA[<p>Levels are the space where a player explores the rules and mechanics of a game; as such, good level design is critical to the game design process. While there are many broad design principles, level design is inherently genre-specific due to the wide variety of rules and types of challenge found between genres. Determining genre-specific design principles requires an in-depth analysis of games within the genre. We present such an analysis for the 2D platformer genre, examining level components and structure with a view to better understanding their level design. We then use this analysis to present a model for platformer levels, specifically focusing on areas of challenge. Our framework provides a common vocabulary for these items and provides level designers with a method for thinking about elements of platformers and how to compose them to create interesting and challenging levels.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[game analysis]]></kw>
			<kw><![CDATA[game design]]></kw>
			<kw><![CDATA[level design]]></kw>
			<kw><![CDATA[platform games]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>K.8.0</cat_node>
				<descriptor>Games</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>H.1.2</cat_node>
				<descriptor>Human information processing</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010178.10010216.10010217</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Philosophical/theoretical foundations of artificial intelligence->Cognitive science</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003121</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010476.10011187.10011190</concept_id>
				<concept_desc>CCS->Applied computing->Computers in other domains->Personal computers and PC applications->Computer games</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10011007.10010940.10010941.10010969.10010970</concept_id>
				<concept_desc>CCS->Software and its engineering->Software organization and properties->Contextual software domains->Virtual worlds software->Interactive games</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003251.10003258</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Multimedia information systems->Massively multiplayer online games</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<person_id>P1100725</person_id>
				<author_profile_id><![CDATA[81421599958]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Gillian]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Smith]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[UC Santa Cruz]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1100726</person_id>
				<author_profile_id><![CDATA[81546029656]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Mee]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Cha]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[UC Santa Cruz]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1100727</person_id>
				<author_profile_id><![CDATA[81100051605]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Jim]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Whitehead]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[UC Santa Cruz]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>1208533</ref_obj_id>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Adams, E., and Rollings, A. 2007. <i>Fundamentals of Game Design.</i> Pearson Prentice Hall, Upper Saddle River, New Jersey.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Bjork, S., and Holopainen, J. 2004. <i>Patterns in Game Design.</i> Charles River Media, ch. 2, 7--32.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Bleszinski, C. 2000. The Art and Science of Level Design. http://www.cliffyb.com/art-sci-ld.html.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Boutros, D. 2006. A Detailed Cross-Examination of Yesterday and Today's Best-Selling Platform Games. <i>Gamasutra</i> (August). http://www.gamasutra.com/features/20060804/boutros_01.shtml.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1076792</ref_obj_id>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Byrne, E. 2005. <i>Game Level Design.</i> Charles River Media. Co, P. 2006. <i>Level Design for Games: Creating Compelling Game Experiences.</i> New Riders.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Compton, K., and Mateas, M. 2006. Procedural Level Design for Platform Games. In <i>Proceedings of the 2nd Artificial Intelligence and Interactive Digital Entertainment Conference.</i>
]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>986102</ref_obj_id>
				<ref_obj_pid>985921</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Desurvire, H., Caplan, M., and Toth, J. 2004. Using Heuristics to Evaluate the Playability of Games. <i>CHI '04 Extended Abstracts on Human Factors in Computing Systems</i> (April).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Feil, J., and Scattergood, M. 2005. <i>Beginning Game Level Design.</i> Thompson Course Technology PTR.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Iyer, V., Bilmes, J., Write, M., and Wessel, D. 1997. A Novel Representation for Rhythmic Structure. In <i>Proceedings of the 23rd International Computer Music Conference</i>, 97--100.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Nelson, M. 2007. Breaking Down Breakout: System and Level Design for Breakout-style Games. <i>Gamasutra</i> (August). http://www.gamasutra.com/view/feature/1630/breaking_down_breakout_system_and_.php.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Nicollet, V. 2004. Difficulty in Dexterity-Based Platform Games. <i>GameDev.net</i> (March). http://www.gamedev.net/reference/articles/article2055.asp.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Rothstein, W. 1989. <i>Phrase Rhythm in Tonal Music.</i> Schirmer Books, New York, ch. 1, 3--15.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1215723</ref_obj_id>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Salen, K., and Zimmerman, E. 2004. <i>Rules of Play: Game Design Fundamentals.</i> MIT Press, Cambridge, Massachusetts, ch. 23, 313--327.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Zagal, J. P., Mateas, M., Fernandez-Vara, C., Hochhalter, B., and Lichti, N. 2005. Towards an Ontological Language for Game Analysis. In <i>Proceedings of the Digital Interactive Games Research Association Conferences (DiGRA 2005).</i>
]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 A Framework for Analysis of 2D Platformer Levels Gillian Smith Mee Cha Jim Whitehead gsmith@soe.ucsc.edu 
mc63874@ucsc.edu ejw@soe.ucsc.edu UC Santa Cruz UC Santa Cruz UC Santa Cruz Abstract Levels are the 
space where a player explores the rules and mechan­ics of a game; as such, good level design is critical 
to the game de­sign process. While there are many broad design principles, level design is inherently 
genre-speci.c due to the wide variety of rules and types of challenge found between genres. Determining 
genre­speci.c design principles requires an in-depth analysis of games within the genre. We present such 
an analysis for the 2D platformer genre, examining level components and structure with a view to better 
understanding their level design. We then use this analysis to present a model for platformer levels, 
speci.cally focusing on areas of challenge. Our framework provides a common vocabu­lary for these items 
and provides level designers with a method for thinking about elements of platformers and how to compose 
them to create interesting and challenging levels. CR Categories: K.8.0 [Personal Computing]: General 
Games; H.1.2 [Models and Principles]: User/Machine Systems Human information processing Keywords: level 
design, game design, game analysis, platform games 1 Introduction Good level design is vital for creating 
enjoyable games; as con­tainer[s] for gameplay [Byrne 2005], levels provide the player with an interactive 
space and the ability to explore within the context of the gameworld rules. As a result, level design 
is a complex task, requiring an understanding of all the components of the game and how to .t them together. 
Furthermore, the skills required differ by genre: a level for a 2D puzzle platformer has very different 
require­ments than a level for a role-playing game. Despite the different skillsets and the complexity 
of the task, few texts currently address issues in genre-speci.c level design. Those that do provide 
only a brief overview for each genre. We assert that principles underlying level design vary by genre, 
and a deep understanding of level design requires genre-speci.c analy­sis. For example, an FPS level 
designer must consider the player s need to take cover, regain health, and not get lost navigating an 
open world. Racing game levels tend not to have any of these require­ments, and are instead crafted to 
provide challenge to the player within the limits of the game s laws of physics. Moving beyond broad 
design principles requires an analysis of level design within each speci.c genre. Copyright &#38;#169; 
2008 by the Association for Computing Machinery, Inc. Permission to make digital or hard copies of part 
or all of this work for personal or classroom use is granted without fee provided that copies are not 
made or distributed for commercial advantage and that copies bear this notice and the full citation on 
the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting 
with credit is permitted. To copy otherwise, to republish, to post on servers, or to redistribute to 
lists, requires prior specific permission and/or a fee. Request permissions from Permissions Dept, ACM 
Inc., fax +1 (212) 869-0481 or e-mail permissions@acm.org. Sandbox Symposium 2008, Los Angeles, California, 
August 9 10, 2008. &#38;#169; 2008 ACM 978-1-60558-173-6/08/0008 $5.00 In this paper we explore level 
design for 2D platform games by breaking their levels down into their common components and studying 
how they .t together. We choose this genre because its rules are simple to understand, yet provide for 
substantial complex­ity. There are a number of different styles of platformer, which are exempli.ed by 
three popular games in the genre: Super Mario World, Sonic the Hedgehog, and Donkey Kong Country 2: Diddy 
s Kong Quest. Super Mario World is characterized by a reward structure closely tied to the probability 
of failure and a single path through the level with relatively few hidden areas accessible from vines 
or pipes. Players tend to play for the challenge of completing each level through mastery of its dexterity 
challenges. In contrast, Sonic the Hedgehog has rings liberally spread throughout the level. It is easy 
to gain rewards in this game; a skilled player will collect a large number of rings and extra lives to 
carry throughout the game. The primary challenge in this game comes from completing levels as quickly 
as possible. Sonic levels frequently have multiple paths to completion; often the player must choose 
the appropriate path to complete the level. Finally, Donkey Kong Country 2 is a game of exploration; 
playing the levels as they are initially presented is not the intended purpose. Instead, the player must 
.nd a number of hidden areas to collect rewards and secret coins. Despite the dif­ferences between these 
styles of platformer, there are a number of similarities in their component elements and how they .t 
together. The primary contribution of this paper is a common vocabulary for elements of platformer levels 
and a framework for modeling lev­els with them. This structural framework pays particular attention to 
rhythm and pacing, which prove important for providing chal­lenge to the player. Together they provide 
an improved theoretical understanding of level design for 2D platformers.  2 Related Work Books on game 
design typically do not directly address level de­sign. For example, Salen and Zimmerman s Rules of Play 
is primar­ily about game design, but does discuss important level design con­cepts such as repetition 
and interactivity when discussing crafting the play of experience [Salen and Zimmerman 2004]. Books that 
do address level design talk primarily about its general principles. Level Design for Games [Co 2006] 
discusses the importance of spa­tial layout and atmosphere. Fundamentals of Game Design [Adams and Rollings 
2007] and Beginning Game Level Design [Feil and Scattergood 2005] also largely focus on general issues, 
giving a couple of paragraphs on level design for speci.c genres. Short de­scriptions of genre-speci.c 
level design are not suf.cient to provide a detailed understanding of the structure and interrelationships 
of elements in a level. While there has not been a great deal of analysis for genre-speci.c level design, 
there are a few of notable exceptions. Nelson s article on level elements in Breakout is a good example 
of the kind of detail we need to provide for this level of understanding [Nelson 2007]. His article takes 
a reductionist view of level design for Breakout­style games, .rst decomposing levels into their genre-speci.c 
con­stituent components, and then giving rules for how to compose level elements into interesting designs. 
This approach of reducing lev­els to their base components and giving rules for their recomposi­tion 
is the essence of the modeling technique we use in this paper. Boutros writes about common design goals 
in best-selling platform games [Boutros 2006], focusing especially on visuals, controls, and structuring 
challenges. However, his focus is on helping game de­velopers understand what made these platform games 
so popular, whereas we wish to provide a common vocabulary and structure for levels to help students 
and developers discuss and analyze levels. There are a few other works that analyze games by dividing 
them into components based on their roll in the game. However, this work tends to be oriented towards 
game design rather than level de­sign. For example, Bjork and Holopainen discuss an activity-based framework 
for describing games [Bjork and Holopainen 2004]. Al­though the framework is intended for entire games 
rather than lev­els, their framework is similar to the process we use for determining level components 
and the ways they combine to form a level. They break down games into a series of patterns in much the 
same way that we break down levels into a series of patterns. We especially look at structural and temporal 
aspects of level design. Also, the Game Ontology Project [Zagal et al. 2005] analyzes a wide variety 
of games from a number of different genres in an ef­fort to discover similar components, challenges, 
and goals between games. The project splits games into segments called Levels , Waves , and Checkpoints 
, labeling levels speci.cally as a spa­tial segmentation, whereas Waves or Puzzles refer to challenge 
segmentation. In this paper we discuss levels as incorporating chal­lenge as well. The importance and 
structure of challenge is central to our model for how level components .t together, and especially in 
our notion of rhythm groups. In his book describing the role of a level de­signer, Byrne claims that 
challenge is the most important aspect of level design [Byrne 2005] because it is the key to the player 
en­joying the level. Nicollet also discusses the role of challenge in dexterity-based games [Nicollet 
2004]. He creates a series of rules for designing challenge, including the importance of rhythm, tim­ing, 
and handling failure. These rules have helped us understand how to segment levels into rhythm groups. 
 3 Model Overview Our model for platformer levels is in two parts: components, and a structural representation 
for how these components .t together. We focus primarily on the underlying structure of levels, rather 
than their visual representation. We categorize components by their pur­pose in the level; our .ve categories 
are platforms, obstacles, move­ment aids, collectible items, and triggers. Platforms are any object that 
the player runs or jumps across to traverse the level, such as .at surfaces, loops, or the tops of item 
boxes. Obstacles are any object that is capable of imparting damage to the avatar. Gaps between platforms 
are also considered obstacles, even though they are not explicitly objects in the level. Movement aids 
are any object that helps the player traverse the level, such as springs, moveable trampolines, or ropes. 
Collectible items are any object that provides a reward to the player; this could be a coin, power-up, 
or point reward. Triggers are any object in the level that somehow changes the state of the level. Examples 
of triggers include switches that turn blocks into coins, buttons that activate platforms for the player 
to rush across, or objects which change the avatar s behavior. We will discuss each of these components 
in more detail in section 4. Figure 1: Conceptual model of our level framework. Our structural representation 
is a hierarchy with the aforementioned components at the bottom and the entire level at the top. In creat­ing 
this representation we focus on dividing the level into areas of challenge: The highest subdivision 
of a level is called a cell, which is a section of linear gameplay. Cells are linked by portals.  In 
turn, cells are composed of rhythm groups, which are non-overlapping sets of the level components. These 
rhythm groups are often fairly small, encapsulating challenging sec­tions of gameplay. Breaks in rhythm 
groups are safe places for the player to rest before continuing the level.  Figure 1 shows the hierarchical 
nature of our model. Cells, portals, and rhythm groups will be explained more fully in section 5.  4 
Components of Platformer Levels We categorize components of platformer levels by their roles in the level. 
It is common for level components to be members of more than one category; for example, item boxes in 
Super Mario World are considered collectible items, but also as platforms because the avatar can walk 
along the top of them. Here we describe the dif­ferent types of components and their typical properties. 
We also discuss the player avatar as it relates to level design. 4.1 The Avatar The avatar refers to 
the character being controlled by the player. Although there are sometimes multiple playable characters, 
such as Diddy and Dixie Kong in Donkey Kong Country 2, the player can usually control only one character 
at any given time. Avatar choices are sometimes merely cosmetic, but there are often impor­tant differences 
in their behavior. Occasionally the avatar can be swapped at certain times during the level itself, for 
example at the stork stations in Yoshi s Island DS. The ability to change charac­ters mid-level introduces 
a puzzle aspect to the game; for example, Yoshi s Island DS has areas where the player must choose a 
partic­ular avatar to progress through the level. An avatar s speci.c movement ability varies according 
to the game, but all avatars have control over their horizontal motion and at least limited control over 
vertical motion, usually in the form of jumping or crouching. More advanced abilities include double 
jumping and wall jumps. Additionally, action platformers such as Mega Man are often provide the avatar 
with a set of weapons for destroying enemies.  4.2 Platforms 4.5 Collectible Items A platform is de.ned 
as any object that the avatar can walk or run across safely. Often objects that serve some other primary 
purpose, such as item boxes in Super Mario World, double as platforms. Plat­forms always have a coef.cient 
of friction, size, and slope. Friction and slope affect the avatar s movement across the surface. Plat­forms 
can be in constant or occasional motion, and often form paths planned by the designer. Finally, platforms 
may be temporary, either on a timer or allowing only a certain number of times the avatar may touch it 
before disap­pearing. Temporary platforms may also be deliberately destroyed by the player, such as by 
using Yoshi s ground pound attack. These platforms force the player to make a quick decision and can 
help create challenging situations. For example, Sonic the Hedge­hog has platforms are consumed by .re 
once Sonic has jumped on them. The player must quickly leave the platform before the .re catches up. 
There is astonishing variety in types of platforms. Many games have platforms that are .exible, bending 
or shifting under the weight of the avatar (Yoshi s Island). Some platforms are invis­ible; this is especially 
true of item boxes that double as platforms, where the player must hit the platform to make it appear 
visible (Super Mario World). There are also platforms that are slippery or sticky, forcing the player 
to react quickly to sudden changes in the avatar s movement.  4.3 Obstacles Obstacles are a major source 
of challenge in platform games. Ob­stacles are any object that is capable of causing damage to the avatar. 
These can be either scripted moving enemies such as Bullet Bills in Yoshi s Island DS, or static obstacles 
such as the spikes in Sonic the Hedgehog. Note that platforms that obstruct the player s movement are 
not obstacles unless they impart damage to the avatar. As with platforms, non-static obstacles have an 
equation modeling their motion. They also have a pattern for spawning; they can either spawn once, a 
.nite number of times, or in.nitely. The player must determine whether or not the obstacle can be killed. 
If it can be destroyed, the obstacle may leave behind a reward, which is some­times correlated to the 
dif.culty of killing it. 4.4 Movement Aids Movement aids objects that help the player through the level 
in a manner other than running or jumping. Examples of movement aids include ladders, ropes, springs, 
and moveable trampolines, al­though there can be dif.culty in the classi.cation of objects like springs, 
which might be either platforms or movement aids. We classify springs as movement aids because they are 
often placed on top of platforms rather than standing alone. Movement aids can often be manipulated by 
the player; for ex­ample, Super Mario World has trampolines that can be moved by Mario. Another example 
of a movement aid are the ladders that appear in Mega Man X2. Movement aids have an equation modeling 
their motion, but also allow the possibility for the player modifying that equation. For example, Yoshi 
s Island DS has swings that the player can interact with to be able to swing faster and higher. It is 
important to note that movement aids do not permanently modify the behavior of the avatar; they only 
act on the avatar for as long as it is interacting with the object. All platform games have a reward 
system, and almost always in the form of collectible items. Collectible items are any object in the level 
that provides a reward, such as coins, rings, power-ups, points, or weapons. They also include non-player 
characters (NPCs) that the avatar uses to move around the level, such as Yoshi in Super Mario World or 
the rhinoceros in Donkey Kong Country 2. These NPCs modify the avatar s behavior in much the same way 
as a .re .ower or feather powerup from Super Mario World. Collectible items often have a reward value 
associated with them, in the form of points assigned to the player. These points can be redeemed in a 
variety of ways depending on the rules of the game. Daniel Boutros gives a detailed account of reward 
systems and de­sign in a variety of platform games [Boutros 2006]. For example, in Super Mario World, 
the main way to collect points comes from collecting coins, which can then be redeemed for extra lives. 
Other rewards include power-ups for the avatar or an extra life. Collectible items have a great deal 
of impact on the player s satisfaction in playing the game; Desurvire et al. use the existence of power-ups 
and collectible items as a heuristic for evaluating the playability of a game [Desurvire et al. 2004]. 
Rewards are also important for other reasons, often serving as guides through the level (Donkey Kong 
Country 2). They also act as compensation for risk; for example, Super Mario World has many kinds of 
rewards, including large Yoshi coins. Yoshi coins have the largest potential reward and are frequently 
placed in areas of high risk, such as on top of a platform that can sink into the water. 4.6 Triggers 
Triggers are interactive objects that the avatar can use to alter the state of the level, or even game 
rules such as physics. Examples in­clude the triggers from Super Mario World, where Mario can jump on 
a blue P button to turn all the blocks into coins. Some triggers are also timed; for example, Yoshi s 
Island DS re­quires Yoshi to jump on a red button that turns red platforms active. Yoshi then has a short 
amount of time to run across the platforms and continue the level. Triggers can add an interesting puzzle 
element to a platform game. For example, N levels require the player to navigate their way to a series 
of triggers, with the eventual goal of hitting the trigger that opens the portal from that level to the 
next one. To enable triggers, each element of the game knows what it de­pends on and what depends on 
it. This introduces the possibility of activating a trigger and setting off a chain reaction.  5 Structural 
Representation for Levels Now that we have determined the prominent features of platform games, we can 
de.ne a structure for each level. This structure can help us analyze existing levels for repeated patterns, 
challenge, and potential paths through the level. Our framework is inspired by Compton and Mateas s work 
on procedural level generation for platform games [Compton and Mateas 2006], especially the impor­tance 
of rhythm and the hierarchical nature of the level representa­tion. 5.1 Rhythm Groups Rhythm and pacing 
are key to the player s enjoyment of the game [Bleszinski 2000; Compton and Mateas 2006] and also contribute 
signi.cantly towards the dif.culty of a platformer [Nicollet 2004]. We therefore set up rhythm groups, 
composed of the various components discussed earlier. Rhythm groups are short, non­overlapping sets of 
components that encapsulate an area of chal­lenge. These groups are inspired by a method for representing 
rhythmic structure in music [Iyer et al. 1997]. Rhythm groups help to identify challenging areas of a 
level and understand what makes them dif.cult. They also help us understand patterns and reuse in level 
design: rhythm groups are quite modular, and it is possible to reuse a rhythm group later in a level, 
or as a recurring theme in a set of levels, even if their graphical representation differs. Our rhythm 
groups are analogous to musical phrases. They have a distinct start, middle, and end, and culminate in 
a cadence [Roth­stein 1989]. This cadence is a place where the rhythm of the player s movement signi.cantly 
changes. It could also be an area where the player is safe to rest and pause before continuing a new 
challenging area. Such rest areas are especially important in dif­.cult levels, as long periods of action 
with little time to pause is more likely to result in player error [Nicollet 2004]. A transition between 
rhythm groups marks an area of rest, and could also be a place where there is a save point or reward 
for completing a chal­lenging section of the level. Rhythm can be found in platformers whenever the player 
performs actions such as jumping or shooting. These actions map directly to the controller, and the rhythm 
with which the player must hit the buttons on the controller is the rhythm we are de.ning. For exam­ple, 
a rhythm could be a series of three short hops, or alternating jumping back and forth up a series of 
platforms that form a ladder. An example of a rhythm group from Yoshi s Island is available on our website1. 
The player starts at the left of this rhythm group. They must then jump down onto the platform, gather 
coins and the .ower, then per­form a series of timed jumps on the rotating platforms back up to the top 
right. The rhythm group begins at the top left because it is an area where the rhythm has a pause; the 
player has just completed a similar jump to retrieve the two coins in the bottom left corner. It ends 
at the top right because the timed jumps around the rotating platforms have ended, and the player will 
now begin running down the hill towards the next challenge. Both the beginning and end of the rhythm 
group mark a change in the pace and rhythm of the player s actions. The rhythm group itself marks an 
area of chal­lenge; once the player has retrieved the red coins he must navigate his way back up to the 
top right platform without falling down. We can also examine two rhythm groups from Super Mario World1. 
At .rst glance it may appear as though the two groups shown should actually be a single group, since 
the platforms form a repeated pat­tern that the player must jump across. However, coin and enemy placement 
means that the components make up two separate rhythm groups. The key to this being two rhythm groups 
rather than a single group is the middle pair of coins in the .rst group, and their lack of a counterpart 
at the point where the two groups meet. In the .rst rhythm group, the player must perform a series of 
jumps with min­imal pauses to reach all the coins and kill the enemies. At the place where the groups 
meet, the player has an opportunity to pause, al­lowing him to correctly time his next jump to the Yoshi 
coin and the enemy. Even though this pause can be quite short, it still forms a break in the rhythm that 
would not be there if the player had coins to jump for on that second peak. 1Example screenshots for 
rhythm groups, cells and portals are available at http://www.cse.ucsc.edu/ gsmith/sandbox examples/. 
 5.2 Cells and Portals Cells and portals allow us to represent non-linearity in platformer levels. This 
non-linearity manifests itself in a variety of ways; for example, in Sonic the Hedgehog, there are usually 
multiple paths through a level. There are moments when the player can switch between these paths, and 
the player often attempts to .nd the path that allows him to complete the level in the shortest amount 
of time. In our structure for levels, each point where the paths meet is a portal. Cells de.ne regions 
of non-overlapping, linear gameplay connected by portals. Their boundaries are set by the placement of 
transitions into and out of the regions, such as a secondary entrance to a level, a transition between 
paths through a level, or a portal to a secret area in the game. We have two examples of cells and portals1: 
the .rst is a scene from Super Mario World divided into two cells and one portal. The second is a more 
complex example taken from Sonic the Hedgehog; the two platforms marked as portals move up and down and 
provide a transition to a different path through the game. Note that for the sake of clarity, the .gure 
does not have rhythm groups marked. In the Super Mario World example, the pipe in the top middle of the 
picture is the portal. The player can go into the pipe and enter a new area. The cells are split at that 
pipe because it is possible for the player to choose a different path at that point. The two platforms 
in the Sonic the Hedgehog example move up and down, allowing the player to choose between the top and 
bottom paths through the level. There are therefore four different cells, each representing a linear 
section of gameplay that ends where the player can choose a new path. Knowing where the cells and portals 
are in a level helps us analyze their structure and catalog the many paths through a level. These paths 
may be of different dif.culties, depending on the rhythm groups that make up the cells along the path. 
 6 Analysis of an Existing Level Having de.ned our model for platformer levels, we now apply it to a 
section of a level from an existing game. We have chosen to use an early section of Emerald Hill Zone, 
Act 1 from Sonic the Hedgehog 21. We have split this section into labeled rhythm groups and portals. 
Each group is also lightly shaded, indicating that it forms part of a cell. We will discuss what each 
of these rhythm groups is, and also how they form cells and portals. 1. This rhythm group has the player 
run uphill and hit a spring to be able to reach the rings and checkpoint in the top left corner. The 
grassy areas that the avatar runs across are platforms in this section, both in the top left corner and 
the bottom region. There are no obstacles in this rhythm group. The spring at the end of this rhythm 
group is a movement aid. The coins are collectible items, and there are no triggers. 2. Another rhythm 
group in the same cell, this time giving the player several options. The platform on the left moves up 
and down, allowing the player to jump up to the top of the loop and collect a power-up. The player can 
then jump back down and complete the loop, rolling down towards the twister. Rhythm groups 1 and 2 form 
a cell, since the player can move into a different cell if he doesn t have enough speed to complete the 
twister. 3. This lower rhythm group forms an entire cell on its own. The pace in this group is slow 
relative to the rest of the level; the player has some speed but must only make one or two  jumps to 
kill the enemies. The rhythm group ends for two reasons: .rstly, there is a cell boundary that forces 
the end of the rhythm group. However, even without that cell boundary it would still end here because 
the rhythm changes from being one that primarily has the player running to one that has the player jumping 
more often. 4. This rhythm group begins with a platform we call the twister . Even though it is possible 
to fall off the twister, no damage is done to the avatar. If the player has enough speed to complete 
the twister, he will also have enough to collect the lower set of coins. The group ends with the player 
collecting a box containing ten rings. 5. This space beneath the twister is a portal, where the player 
can transition from the upper left cell to either the upper right or lower right cell. This transition 
may be unintentional, as nav­igating the twister requires a great deal of speed to be built up already. 
Note that the portal is not a rhythm group, it is merely a region where it is possible to transition 
between cells. 6. A rhythm group characterized by timed jumps. The player must avoid the .sh that jump 
up towards him from under the bridge; correctly avoiding the .sh will reward the player with some rings. 
Failing to avoid the .sh will reduce the player s ring tally to zero, but the coins above the .sh serve 
as a guar­antee of retaining at least some rings as a shield for the rest of the level. Groups 6 and 
7 form a cell. 7. This last rhythm group consists of spikes that are easy to avoid as long as the player 
does not accidentally jump into them. It ends at a cell boundary.  Our analysis shows some interesting 
aspects of level design for Sonic the Hedgehog. The designers provide many choices for the player; these 
choices provide challenge since the main goal of the levels is to complete them quickly. The player must 
make the opti­mal choice to complete the level quickly. Rhythm group size and allocation re.ects the 
speed with which the player moves. Groups 3 and 4 are quite large, making up their own cells. The size 
of these groups is deceiving, though; the player is re­quired to jump no more than twice in each group 
to avoid obstacles, collect items, or destroy enemies. We also see that the designer provides a second 
chance to players who fail to pick up enough speed to complete the twister. Region 5 shows the portal 
that lets the player transition to the lower right cell. Staying on the top path may be preferable, since 
there are a number of coins available to collect at the end of the top right cell. However, failing to 
complete the twister still provides compensa­tion in the form of a temporary shield power-up. Indeed, 
the player may deliberately choose to fall through the twister and collect that power-up if he thinks 
it will help him later in the level.  7 Future Work and Conclusion With a formal de.nition of a platformer 
level, including a model for rhythm-based challenge, there are a number of different kinds of analysis 
we can perform. For example, it may be helpful to look at ways of classifying the dif.culty of a level 
based on the pace, length, and beat of a rhythm group. A short, arrhythmic section of the level may be 
dif.cult to master and therefore provide more dif.culty to the player. Similarly, an extremely long and 
rhythmic grouping may be easier at .rst but requires the player to concentrate longer, leading to more 
points of potential failure [Nicollet 2004]. We would also like to explore automated generation of levels 
based on our model for their structure. To effectively generate levels, a computer must understand two 
major ideas: .rstly, the components that make up the level, and secondly the way they .t together to 
cre­ate an entire level. It must also be able to reason about constraints on the model so it generates 
levels that are both playable and well balanced. These constraints are not yet known, and it would be 
interesting to explore a formal de.nition for what makes a level enjoyable. We have presented a framework 
for analysis of platformer compo­nents and level design. This framework can be especially helpful to 
educators who teach students how to design fun and challenging levels in games. It is our hope that this 
framework will also provide a common vocabulary for both game analysts and developers and open the .eld 
to similar frameworks for other genres.  References ADAMS, E., AND ROLLINGS, A. 2007. Fundamentals of 
Game Design. Pearson Prentice Hall, Upper Saddle River, New Jersey. BJORK, S., AND HOLOPAINEN, J. 2004. 
Patterns in Game Design. Charles River Media, ch. 2, 7 32. BLESZINSKI, C. 2000. The Art and Science of 
Level Design. http://www.cliffyb.com/art-sci-ld.html. BOUTROS, D. 2006. A Detailed Cross-Examination 
of Yes­terday and Today s Best-Selling Platform Games. Gamasutra (August). http://www.gamasutra.com/features/ 
20060804/boutros_01.shtml. BYRNE, E. 2005. Game Level Design. Charles River Media. CO, P. 2006. Level 
Design for Games: Creating Compelling Game Experiences. New Riders. COMPTON, K., AND MATEAS, M. 2006. 
Procedural Level De­sign for Platform Games. In Proceedings of the 2nd Arti.cial Intelligence and Interactive 
Digital Entertainment Conference. DESURVIRE, H., CAPLAN, M., AND TOTH, J. 2004. Us­ing Heuristics to 
Evaluate the Playability of Games. CHI 04 Extended Abstracts on Human Factors in Computing Systems (April). 
FEIL, J., AND SCATTERGOOD, M. 2005. Beginning Game Level Design. Thompson Course Technology PTR. IYER, 
V., BILMES, J., WRITE, M., AND WESSEL, D. 1997. A Novel Representation for Rhythmic Structure. In Proceedings 
of the 23rd International Computer Music Conference, 97 100. NELSON, M. 2007. Breaking Down Breakout: 
System and Level Design for Breakout-style Games. Gamasutra (August). http: //www.gamasutra.com/view/feature/1630/ 
breaking_down_breakout_system_and_.php. NICOLLET, V. 2004. Dif.culty in Dexterity-Based Platform Games. 
GameDev.net (March). http://www.gamedev. net/reference/articles/article2055.asp. ROTHSTEIN, W. 1989. 
Phrase Rhythm in Tonal Music. Schirmer Books, New York, ch. 1, 3 15. SALEN, K., AND ZIMMERMAN, E. 2004. 
Rules of Play: Game Design Fundamentals. MIT Press, Cambridge, Massachusetts, ch. 23, 313 327. ZAGAL, 
J. P., MATEAS, M., FERNANDEZ-VARA, C., HOCHHAL-TER, B., AND LICHTI, N. 2005. Towards an Ontological Lan­guage 
for Game Analysis. In Proceedings of the Digital Interac­tive Games Research Association Conferences 
(DiGRA 2005). Games Cited 1. Donkey Kong Country 2: Diddy s Kong Quest. Nintendo (SNES), 1995. 2. Mega 
Man. Capcom (NES), 1987. 3. Mega Man X2. Capcom (SNES), 1995. 4. N. Metanet Software (PC), 2005. 5. New 
Super Mario Bros.. Nintendo (DS), 2006. 6. Sonic the Hedgehog. SEGA (Genesis), 1991. 7. Sonic the Hedgehog 
2. SEGA (Genesis), 1992. 8. Super Mario World. Nintendo (SNES), 1991. 9. Super Mario World 2: Yoshi s 
Island. Nintendo (SNES), 1995. 10. Yoshi s Island DS. Nintendo (DS), 2006.  
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
	</article_rec>
	</section>
	<section>
		<section_id>1401859</section_id>
		<sort_key>160</sort_key>
		<section_seq_no>4</section_seq_no>
		<section_type>SESSION</section_type>
		<section_title><![CDATA[Learning through design]]></section_title>
		<section_page_from>81</section_page_from>
	<article_rec>
		<article_id>1401860</article_id>
		<sort_key>170</sort_key>
		<display_label>Pages</display_label>
		<pages>8</pages>
		<article_publication_date>08-09-2008</article_publication_date>
		<seq_no>1</seq_no>
		<title><![CDATA[Views from atop the fence]]></title>
		<subtitle><![CDATA[neutrality in games]]></subtitle>
		<page_from>81</page_from>
		<page_to>88</page_to>
		<doi_number>10.1145/1401843.1401860</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1401860</url>
		<abstract>
			<par><![CDATA[<p>Games are play with conflict. However, players rarely get the chance to explore gameplay besides open conflict. Neutrality in the real world allows actors to avoid conflict and is also used to describe how mediators should act when they negotiate a conflict resolution. Reviewing different definitions of what it means to be neutral this paper investigates how game mechanics that simulate neutrality act as neutral mediators between players. The neutrality of each of the seven game mechanics discussed is related to how impartial they act towards players. This paper concludes that current games have not explored all of the possible neutral mechanics and suggests ways for game developers to incorporate these missing mechanics into games.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[game mechanics]]></kw>
			<kw><![CDATA[games]]></kw>
			<kw><![CDATA[mediation]]></kw>
			<kw><![CDATA[neutrality]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>K.8.0</cat_node>
				<descriptor>Games</descriptor>
				<type>S</type>
			</primary_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010405.10010476.10011187.10011190</concept_id>
				<concept_desc>CCS->Applied computing->Computers in other domains->Personal computers and PC applications->Computer games</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10011007.10010940.10010941.10010969.10010970</concept_id>
				<concept_desc>CCS->Software and its engineering->Software organization and properties->Contextual software domains->Virtual worlds software->Interactive games</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003251.10003258</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Multimedia information systems->Massively multiplayer online games</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010476.10011187.10011190</concept_id>
				<concept_desc>CCS->Applied computing->Computers in other domains->Personal computers and PC applications->Computer games</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10011007.10010940.10010941.10010969.10010970</concept_id>
				<concept_desc>CCS->Software and its engineering->Software organization and properties->Contextual software domains->Virtual worlds software->Interactive games</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003251.10003258</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Multimedia information systems->Massively multiplayer online games</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<general_terms>
			<gt>Design</gt>
			<gt>Experimentation</gt>
		</general_terms>
		<authors>
			<au>
				<person_id>P1100728</person_id>
				<author_profile_id><![CDATA[81365598309]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Ben]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Medler]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Georgia Institute of Technology]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Andren, N. 1991. On the Meaning and Uses of Neutrality. <i>Cooperation and Conflict</i>, 26, 67--83.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Armed neutrality. 2007. In <i>Wikipedia, The Free Encyclopedia.</i> Retrieved 23:09, April 24, 2008, from http://en.wikipedia.org/w/index.php?title=Armed_neutrality&oldid=177198388]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Bartos, O., &amp; Wehr, P. 2002. <i>Using Conflict Theory.</i> Cambridge University Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Benjamin, R. 1998. <i>The Risks Of Neutrality - Reconsidering The Term And Concept</i> {Electronic Version}. Mediate.com. Retrieved February 21st, 2008 from http://www.mediate.com/pfriendly.cfm?id=424.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Big Blue Box. 2004. <i>Fable.</i> Microsoft Game Studios.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[BioWare. 2003. <i>Star Wars: Knights of the Old Republic.</i> Lucas Arts.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Blizzard Entertainment. 2002. <i>Warcraft 3.</i> Blizzard.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Blizzard Entertainment. 2004. <i>World of Warcraft</i> Blizzard.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2153677</ref_obj_id>
				<ref_obj_pid>2153634</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Burak, A., Keylor, E., &amp; Sweeney, T. 2005. PeaceMaker: A Video Game to Teach Peace. In <i>Intelligent Technologies for Interactive Entertainment</i>, 307--310.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[CCP. 2003. <i>EVE Online</i> Simon &amp; Schuster.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1202447</ref_obj_id>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Consalvo, M. 2007. <i>Cheating: Gaining Advantage in Videogames.</i> MIT Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[DeKoven, B. 2002. <i>New Games, still</i> {Electronic Version}. Deepfun.com. Retrieved February 26th, 2008.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1124834</ref_obj_id>
				<ref_obj_pid>1124772</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Ducheneaut, N., et. al. 2006. Alone Together? Exploring the Social Dynamics of Massively Multiplayer Games. In <i>Conference Proceedings on Human Factors in Computing Systems CHI 2006</i>, ACM Press, New York, NY. 407--416.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1240750</ref_obj_id>
				<ref_obj_pid>1240624</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Ducheneaut, N., et. al. 2007. The Life and Death of Online Gaming Communities: A Look at Guilds In World of Warcraft. In <i>Conference Proceedings on Human Factors in Computing Systems CHI 2007</i>, ACM Press, New York, NY. 839--848.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[EA Pacific. 2003. <i>Command &amp; Conquer: Generals.</i> EA Games.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Field, R. 2000. <i>Neutrality and Power: Myths and Reality</i> {Electronic Version}. Mediate.com. Retrieved February 20th, 2008 from http://www.mediate.com/pfriendly.cfm?id=1172.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Firaxis Games. 2005. <i>Civilization 4.</i> 2K Games.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Goetschel, L. 1999. Neutrality, a Really Dead Concept?. <i>Cooperation and Conflict</i>, 34, 115--139.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Griefer. 2008. In <i>Wikipedia, The Free Encyclopedia.</i> Retrieved 23:08, April 24, 2008, from http://en.wikipedia.org/w/index.php?title=Griefer&oldid=20 7939544]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Juul, J. 2007. A Certain Level of Abstraction. In <i>Situated Play: DiGRA 2007 Conference Proceedings</i>, Tokyo, Japan. A. Baba, Ed., 510--515.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Maiese, M. 2005. <i>Neutrality</i> {Electronic Version}. Beyond Intractability. Retrieved February 20th, 2008 from http://www.beyondintractability.org/essay/neutrality/.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Mayer, B. 2004. <i>Beyond Neutrality: Confronting the Crisis in Conflict Resolution.</i> Jossey-Bass Publishers.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[Medler, B. 2008. Using Conflict Theory to Model Complex Societal Interactions. {Under Review}.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[Microsoft Research. 2002. <i>TrueSkill</i>#8482; Retrieved January 15th, 2008, from http://research.microsoft.com/mlp/apg/trueskill.aspx]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[Mindscape. 1985. <i>Balance of Power.</i> Chris Crawford.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[NCsoft. 2007. <i>Tabula Rasa.</i> NCsoft.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[Nintendo. 1989. <i>Tetris.</i> Nintendo.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[Nintendo. 2005. <i>Mario Kart DS.</i> Nintendo.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[Origin Systems. 1997. <i>Ultima Online.</i> EA]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>30</ref_seq_no>
				<ref_text><![CDATA[Pandemic Studios. 2005. <i>Start Wars: Battlefront 2.</i> Lucas Arts.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>31</ref_seq_no>
				<ref_text><![CDATA[Petroglyph. 2006. <i>Star Wars: Empire at War.</i> Lucas Arts.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>32</ref_seq_no>
				<ref_text><![CDATA[Q Entertainment. 2005. <i>Meteos.</i> Nintendo.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>33</ref_seq_no>
				<ref_text><![CDATA[Relic. 2006. <i>Company of Heroes.</i> THQ.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>34</ref_seq_no>
				<ref_text><![CDATA[Rockstar North. 2005. <i>Grand Theft Auto: San Andreas.</i> Rockstar Games.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>35</ref_seq_no>
				<ref_text><![CDATA[Rubberband AI. 2008. In <i>Wikipedia, The Free Encyclopedia.</i> Retrieved 23:08, April 24, 2008, from http://en.wikipedia.org/w/index.php?title=Rubberband_AI&oldid=202822843]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1215723</ref_obj_id>
				<ref_seq_no>36</ref_seq_no>
				<ref_text><![CDATA[Salen, K., &amp; Zimmerman, E. 2003. <i>Rules of Play: Game Design Fundamentals.</i> MIT Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>37</ref_seq_no>
				<ref_text><![CDATA[Yee, N. 2008. Life as a Guild Leader. <i>The Daedalus Project.</i> Retrieved May 25, 2008, from http://www.nickyee.com/daedalus/archives/001516.php]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>38</ref_seq_no>
				<ref_text><![CDATA[Zap Dramatic. <i>The Mediator.</i> February 25th, 2008, from http://www.zapdramatic.com/dramas.htm]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Views from Atop the Fence: Neutrality in Games Ben Medler Adaptive Digital Media (ADAM) Lab Georgia 
Institute of Technology benmedler@gatech.edu Abstract Games are play with conflict. However, players 
rarely get the chance to explore gameplay besides open conflict. Neutrality in the real world allows 
actors to avoid conflict and is also used to describe how mediators should act when they negotiate a 
conflict resolution. Reviewing different definitions of what it means to be neutral this paper investigates 
how game mechanics that simulate neutrality act as neutral mediators between players. The neutrality 
of each of the seven game mechanics discussed is related to how impartial they act towards players. This 
paper concludes that current games have not explored all of the possible neutral mechanics and suggests 
ways for game developers to incorporate these missing mechanics into games. CCS: K.8.0 [Personal Computing]: 
General Games Keywords: neutrality, mediation, games, game mechanics 1. Introduction Many game researchers 
and industry professionals have defined games as play that involves conflict or competition, with a comprehensive 
look at these definitions in [Salen &#38; Zimmerman 2003]. These conflicts allow players to oppose one 
another or oppose an artificial system within a safe, abstracted environment [Juul 2007]. However, since 
games are abstracted conflicts they do not allow other options besides open opposition. In the real world 
one way to avoid open conflict would be to declare neutrality. A neutral party does not get involved 
or align themselves with either side of a conflict. This means neutrality can be used effectively for 
relation policies despite various negative viewpoints that neutral parties are untrustworthy or unsympathetic 
in the face of war or conflict injustices [Goetschel 1999]. These very notions of relationship building 
and negative stereotypes that surround neutrality, in respect to conflict, makes it an interesting concept 
to explore in games. This paper looks at how neutrality has been used within previous games, discusses 
what neutrality principles may be missing from current game mechanics, and presents future design ideas 
that can fill in these missing concepts of neutrality and, as later defined, mediation. To begin, a range 
of definitions for neutrality will be defined in order to understand what is expected of a neutral party. 
Next, a Copyright &#38;#169; 2008 by the Association for Computing Machinery, Inc. Permission to make 
digital or hard copies of part or all of this work for personal or classroom use is granted without fee 
provided that copies are not made or distributed for commercial advantage and that copies bear this notice 
and the full citation on the first page. Copyrights for components of this work owned by others than 
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, to republish, to post on 
servers, or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions 
from Permissions Dept, ACM Inc., fax +1 (212) 869-0481 or e-mail permissions@acm.org. Sandbox Symposium 
2008, Los Angeles, California, August 9 10, 2008. &#38;#169; 2008 ACM 978-1-60558-173-6/08/0008 $5.00 
model for evaluating neutrality within game mechanics will be used to assess past examples of games that 
use the concept. This section is broken up into common game mechanic themes which use neutrality for 
different purposes. Finally, new design ideas for filling in the gaps where games have neglected neutrality 
principles will be discussed along with the current and future work of the author that surrounds modeling 
conflict behavior.  2. Defining Neutrality Neutrality is often referred to within a context of a military 
or foreign policy example. A neutral country is one that does not take part militarily in foreign wars 
nor provides assistance to countries currently engaged in war [Goetschel 1999]. Switzerland has been 
a prime example of a neutral country since 1815 [Goetschel 1999]. Besides dealing with war-related issues 
neutrality is also a concept used when speaking about conflict resolution. Neutrality has a complex definition 
when used within this context, which is referred to as mediation, and will be the main focus of this 
paper. Mediation is defined as a dispute resolution practice that involves negotiating a conflict resolution 
between actors i.e. participants within a conflict [Maiese 2005]. . A neutral actor, one that is not 
directly involved in the conflict, acts as a negotiator or mediator between the conflict actors, who 
are in dispute. However neutrality in this circumstance is a convoluted term because, referring to the 
definition of neutrality previously stated, a neutral actor must not provide assistance to any conflicting 
actors (even refraining from conflict resolution itself). Instead alternate interpretations exist for 
how neutral mediators should act. First, neutrality in a negotiating situation is generally believed 
to mean that mediators should act indifferent, disinterested and unconcerned with the conflicting actors 
and the final outcome of the conflict [Benjamin 1998; Maiese 2005]. Additionally neutral mediators are 
trusted to have no outside relationship with any conflict actor [Benjamin 1998]. This includes, on the 
grounds of acting indifferent, that any negotiations that occur will not alter the relationships that 
currently stand between the conflict actors. This is a strict and conservative way of viewing neutrality, 
one that may be impossible to attain [Maiese 2005]. A second interpretation of mediator neutrality is 
that they should be impartial towards a conflict and attempt to give conflict actors as much equality 
as possible [Field 2000; Maiese 2005]. This allows mediators to become increasingly involved with the 
conflict actors in order to try and achieve a fair resolution, so long as mediator can stay impartial 
to either side of the conflict [Field 2000]. An increase in involvement is usually welcome by the conflict 
actors, hoping the mediator will provide advice about their current conflict situation [Benjamin 1998]. 
Active involvement is seen as being sympathetic towards the conflict, instead of having an indifferent 
view point which can be interpreted as being insensitive and uncaring [Benjamin 1998; Mayer 2004]. Allowing 
a mediator to become involved within a conflict is referred to as active neutrality [Andren 1991]. Taking 
the concepts of impartiality and active neutrality one step further, a third variation of mediator neutrality 
states that mediators should try to protect conflict actors by balancing the power relationships that 
exist between the actors [Benjamin 1998]. This means that the mediator actively manipulates the conflict 
by trying to help weaker conflict actors overcome any unequal power relationships they have with the 
other actors. Compared to the stricter definition of neutrality, as a practice of indifference, this 
balancing of power may be required in order to obtain a fair settlement between the conflict actors [Field 
2000; Maiese 2005]. These three definitions allow for a range of neutrality principles to exist, which 
may cause problems during the mediation process [Field 2000; Maiese 2005]. First, if conflict actors 
have one definition of neutrality, especially a stricter one, this can harm the trust and credibility 
the actors have for their mediator if the mediator s definition of neutrality is less conservative. This 
is especially true if a mediator begins to alter the power imbalances between the conflict actors, as 
this can be seen by stronger actors as proof of a biased opinion against them. Second, mediators taking 
a more active role in a conflict do in fact run the risk of becoming biased towards one actor s side. 
Third, mediators may not have access to all the information that is required to offer a fair outcome 
even if they become more active within the conflict. These three problems: trust, biases, and lack of 
information will be discussed in the next section along with how the different neutrality definitions 
relate to games.  2.1 An Impartiality Spectrum Summarizing the three definitions above a mediator can 
be seen as neutral when they are 1) indifferent towards a conflict 2) impartial to a conflict while striving 
for fairness between conflict actors or 3) protecting weaker conflict actors by balancing their power 
relationships with stronger actors involved in the conflict. Each definition has a level of impartiality 
which can be used to create a spectrum of impartiality. This spectrum is based on the level of how impartial 
a mediator behaves towards the conflict actors while negotiating a resolution. A mediator may have: high 
impartiality, meaning they are completely indifferent towards a conflict; medium impartiality, meaning 
they strive for equal and fair treatment of conflict actors; or low impartiality, meaning they actively 
seek to alter the power relationships between conflict actors thus almost crossing the line of becoming 
an active conflict actor themselves. Finally, the option for the mediator to have no impartiality does 
exist, though not shown, but the mediator would cease to be a neutral actor (thus this position will 
not be discussed). For this paper the author will be focusing on this impartiality spectrum where the 
mediator has at least some degree of impartiality. Using the impartiality spectrum this paper argues 
that game mechanics take on the role of neutral mediators between players. When exploring the levels 
of impartiality that exist in game mechanics, that simulate neutrality, interesting correlations between 
neutral mediators and these mechanics are found. The following section is broken up into separate game 
mechanic implementation where neutrality is used in some form. Each implementation will be discussed 
along the lines of the impartiality spectrum (Fig. 1) where each game mechanic will take the place of 
a mediator. Examples of each implementation will be presented based on their gameplay value, effects, 
and where they reside on the impartiality spectrum. These mediator mechanics are susceptible to the same 
problems as real world mediators and may not explore the entire impartiality spectrum, leaving open areas 
for new neutrality game mechanics to be created. Figure 1: A game s mechanics can be evaluated for how 
impartial they act towards players in comparison with how mediators act towards conflict actors. 3. 
How Neutrality is Used in Games 3.1 Neutrality is to be conquered Games regularly contain mechanics 
that force players into conflicts over resources [Salen &#38; Zimmerman 2003] which can be categories 
by representations of wealth, power and prestige [Bartos &#38; Wehr 2002]. Examples of these three areas 
include: money, a wealth resource; player domination over one another, a power resource; and notoriety 
within the game (e.g. owning rare items), a prestige resource. These resources are acquired by players 
as they progress through the game. For the sake of being fair each player begins with the same amount 
of resources. One way to provide a fair starting point for each player is by placing resources into a 
temporary neutral state. Resources stay in this neutral state until a player can liberate or laying claim 
to them. This is a common game mechanic used in real-time strategy (RTS) games, for example, where buildings 
must be captured in order to provide wealth related resources such as money or material goods [EA Pacific 
2003; Petroglyph 2006]. Territory control games are setup in a similar fashion; neutral land sections 
must be captured and held for a certain time period in order to win the game [Blizzard Entertainment 
2004; Pandemic Studios 2005; Relic 2006]. Players rush to take over sections of neutral territory, represented 
by nodes, while trying to keep their opponents from acquiring nodes. If an opponent does succeed in converting 
a node that was already owned by an opponent they must first convert the node back into a neutral state 
before taking over the node. This works so that it s harder to capture a node that is already owned by 
an opposing player. Furthermore, this means that territory can be converted back into a neutral state 
during the game (meaning the node is inactive and does not help any specific player) but will be seen 
as an easy target for capture by any player that happens by the node. This type of capture and control 
mechanic is very indifferent along the impartiality spectrum. A territory node, or another resource point, 
makes no distinction between the players. The mechanic does not try to balance the game, for instance 
it does not allow the player with the least amount of territory to capture territory nodes quicker. What 
actually occurs is the opposite effect, it takes longer to convert a conquered node, which makes it harder 
for the players with fewer resources or less territory to catch up. This mechanic has a bias towards 
the player that can convert resource points faster since they will have an easier time of controlling 
those points. In contrast to the bias towards stronger players, an upkeep tax is an example of a mechanic 
that keeps a player from obtaining too many resources (which will be discussed in the Neutrality is balancing 
the system section).  3.2 Neutrality is between good and evil The morality mechanic allows a game to 
play with the concept of good versus evil. In a morality game a player chooses between playing as a good 
and evil individual [Big Blue Box 2004; BioWare 2003]. This is done by monitoring the player s actions 
within the game and uses those actions to set the player s alignment along a linear morality scale. A 
games content and storyline are then shifted to reflect the choices a player makes towards one side or 
the other. When a player chooses to push towards one end of the morality spectrum they are rewarded with 
extra perks, for example in Knights of the Old Republic [BioWare 2003] players can access extra powers 
if they become extremely good or evil. Though receiving these extra perks means the player must give 
up the benefits they would have otherwise received if they moved towards the other end of the spectrum. 
However there is always a third option when deciding whether to be good or evil, and that is the player 
could be neither. A neutral player in these games will balance between being too good or too evil. This 
means that the player may help a non­player character (NPC) in one part of the game (a good action) but 
may rob another NPC later (an evil action). The benefit for staying neutral is that the player can access 
abilities or functions from both sides of the morality scale. Nevertheless a player that does not choose 
to align themselves with one side or the other will lose the chance to use the special alignment perks 
along with other experiencing specific alignment related game content. This morality mechanic is closer 
to the middle of the impartiality spectrum, though still indifferent. The mechanic is closer to the center 
of the spectrum because it does not care which alignment the player chooses and even offers a few benefits 
to players that choose no alignment at all (attempting to give equal treatment to all player types). 
Although the mechanic resides more towards the indifferent end of the spectrum, it is still biased towards 
alignment choosing players which receive stronger bonuses over neutral players. In this way the game 
offers the player a jack-of-all­trades option but does not promote it as the best option for players 
to choose.  3.3 Neutrality is balancing the system While balancing is at one end of the impartiality 
spectrum it is also a game mechanic. Balancing can both be seen as a way to keep opponents in a constant 
state of competition or as a goal for a player to achieve. In the former example balance can be found 
in games such as Tetris [Nintendo 1989] or Meteos [Q Entertainment 2005], puzzle games where the player 
must consistently work to clear the screen and maintain order as they are bombarded by game pieces. In 
a sense, players are trying to balance the system, keeping the pieces from overwhelming the game screen 
while trying to maximize their score. A player is mediating between how many pieces they can allow on 
the screen against how many they can take away. This type of balancing is valid but the latter example 
of balancing for competition reasons may prove more relevant to the practice of mediation. The competition 
related balancing that games perform is similar to the mediator practice of balancing power relationships. 
There are games that utilize competition enhancers which impose restrictions and enhancements upon players 
to keep each player around the same skill level. One example is an AI technique called Rubberbanding 
[Rubberband AI 2008]. This mechanic, which is predominant in the Mario Kart series [Nintendo 2005], will 
give bonuses or powerful items to players that are currently losing the game. For instance, in Mario 
Kart, if a player is falling behind in a race they will receive rarer and more powerful items that help 
them increase their position within the race. This means the mechanic is acting as a mediator attempting 
to balance the power relationships between the weaker players and the stronger players. Another method 
that can achieve the same competition effect is by placing restriction on a player s resources. Upkeep 
tax, as mentioned before, will penalize any player that amasses too many resources. For instance, in 
Warcraft 3[Blizzard Entertainment 2002], if a player s army population reaches a certain level the amount 
of money the player can collect will diminish as long as they keep that high population. This makes it 
harder for a player to continuously keep a large army because they will eventually run out of resources. 
In addition to taxing a player for their total amount of resources an upkeep mechanic may tax players 
on a smaller scale. One example is item damage, as a player uses an item within a game the item slowly 
loses durability and must be repaired. In some games after a number of repairs the item is lost [Origin 
Systems 1997] while in other games the repair tax is used as a time-related factor, if the player goes 
too long without getting the item repaired then they will lose the item [Blizzard Entertainment 2004]. 
 These competition enhancers have very low impartiality, they are meant to determine which players are 
weaker and balance them against the superior players. This tends to have two negative effects. First, 
these mechanics are biased towards weaker players and stronger players may view this bias with distrust 
and resentment. Second, players learn how to game or take advantage of these mechanics [Consalvo 2007]. 
Players will intentionally make themselves a weaker player, such as staying in second or third place 
in Mario Kart, in order to receive help from the game. This situation is an example of the mediator (i.e. 
the game mechanic) not having enough information in order to balance the conflict effectively. This problem 
may be overcome by allowing the game to analyze a player s skill level at a greater detail, such as recording 
skill level over long periods of time [Microsoft Research 2002], instead of just determining each player 
s current level of status.  3.4 Neutrality is safety Fairness is needed within games so that everyone 
has an equal chance of succeeding. However, when starting a new game players have not acquired the skills 
needed in order to function in the game world and may be taken advantage of by the system or other players 
[Griefer 2008]. A mechanic that helps new players get their feet wet is the concept of safe zones. New 
players are allowed into safe zones where they can be protected and usually taught how to function within 
the game. Ultima Online, for instance, had an entire island where only new players were allowed and where 
most of the basic game functions were readily available to them (new players were even given the option 
to teleport back to the island, no matter their location within the world). Other games may not have 
a physical space but a tutorial mode, or a time period, when a player s actions have fewer consequences. 
These achieve the same effect. Neutral locations may also exist in a game and provide refuge for any 
player that will follow the location s rules. World of Warcraft (WoW) has a number of neutral cities 
scattered across their game world where players from any conflicting alignment can enter [Blizzard Entertainment 
2004]. NPC guards within these cities act as a safety measure, attacking any player that becomes hostile 
towards another player. This allows game developers to create areas that all conflicting players can 
use forcing the players of opposite alignments to interact with one another.. The first type of safety 
mechanic, protecting new players, is another example of a low impartiality mechanic. On one hand newer 
players take presidents over older ones, i.e. the mechanic holds more bias towards newer players by allowing 
them to make more mistakes. Though at a certain point in the game these new players will cease to be 
new and will have to join the ranks of the older players. The second safety mechanic, the use of neutral 
locations, is very impartial. Using the example from WoW, the neutral cities are not biased towards any 
one alignment or how powerful a player is, so long as the player follows the city s rules. With safety 
mechanics the level of impartiality is determined by which player type a designer wishes to help over 
another or whether all player types receive the same treatment. 3.5 Neutrality is novelty Sometimes 
games use neutrality to add ambience to a game s environment. The Grand Theft Auto (GTA) [Rockstar North 
2005] series simulates city life by generating neutral city dwellers as the player travels through the 
game s cityscape. These NPCs will do nothing except walk around the city (perhaps interacting with one 
another), so long as the player does not interact with them. These NPCs are a novelty and generally have 
no major effect on the game itself except to provide an immediate experience. Other examples of novelty 
NPCs include small critters in games such as RTS or massively multiplayer online (MMOs) games. In Warcraft 
3 [Blizzard Entertainment 2002] a map may contain sheep critters that a player can blow up if they click 
on them one too many times. These sheep have no real strategic value to the game but provide a novelty 
for the players to experience. Novelty NPCs are seen as being part of the World player, a neutral agent 
run by the system that controls NPCs and other game environment aspects. In other cases when players 
do interact with one of these neutral NPCs the NPC may become active and/or resistant. Using GTA as an 
example, if a player attacks one of the game s neutral city dwellers they may begin to fight back. Other 
games use this concept [NCsoft 2007; Origin Systems 1997; Petroglyph 2006] which also works as a safety 
mechanic by allowing players to attack a neutral NPC first but does not allow the NPC to initiate an 
attack. Neutrality is thus given to certain NPCs in order to provide aesthetics within the game environment 
but the game will allow these NPCs to react believably if the player breaks that NPC s neutrality. This 
concept is referred to as armed neutrality within the context of foreign policy [Armed neutrality 2008]. 
This novelty NPC mechanic lies towards the higher offend of the impartiality spectrum. NPCs that are 
placed within a game to provide an immediate experience must be made neutral because they play no major 
role within the game s conflict. However this novelty can be removed if the player chooses to interact 
with those NPCs directly, taking away a NPC s neutrality as a result. When this occurs the bias of the 
mechanic is towards the player which has the upper hand when dealing with these novelty NPCs.  3.6 Neutrality 
is for smaller conflicts Most games do not allow a player to be neutral on a large scale but at a smaller 
scale there are plenty of examples. Smaller conflicts occur within large game worlds such as role playing 
games (RPGs) and MMOs [Blizzard Entertainment 2004; CCP 2003]. Players may choose whether to align themselves 
with one group over another as part of these micro-conflicts. Neutrality is also an option in these situations, 
either by the player not participating in the conflict or by actively stating they are taking a neutral 
stance. For a number of conflicts in games neutrality is used as a starting point for a player s alignment 
within these smaller conflicts. For instance, WoW has a reputation system where players can either help 
or harm a certain NPC group and affects their reputation with that group. When a player comes into contact 
with a new group their reputation value is set to neutral where neutrality is assumed to be the standard 
starting point for any relationship. This is very similar to the morality mechanic, stated above, since 
neutrality is also the starting point for that mechanic. However, since neutrality is seen as a starting 
point these smaller conflict alignments do not give bonuses to players for being neutral because any 
player can automatically achieve this neutral state. Neutrality is used in a very impartial way for 
these smaller conflict alignments. Unlike the morality mechanic neutrality is treated as a state of purgatory, 
one that any player can enter but gain nothing for staying neutral (another instance of bias towards 
the players that align themselves). Neutrality, in this sense, is just a starting point as a player begins 
to learn and experience the game s provided conflict mechanics.  3.7 Neutrality is the player s choice 
Mediation itself is a game mechanic that is employed in games where diplomacy is an option for players. 
Games like Civilization [Firaxis Games 2005], Peacemaker [Burak et al. 2005], and Balance of Power [Mindscape 
1985] allow a player to make the choice of how much mediation they wish to perform between themselves 
and other conflict actors. Nonetheless these types of games give players diplomatic options as a means 
of advancement within the game, which these options can thus be seen as not neutral. In Civilization 
players can act like a neutral civilization, via foreign policy standards, by choosing whether they enter 
into conflict with other civilizations. Players can act indifferent towards other civilizations by not 
interacting with them at all or players can create balancing agreements through helping weaker civilizations 
as a means to help themselves. The main goal in Civilization is to become the dominate civilization through: 
conquest, popular vote, or technological superiority, which forces a player to keep their own civilization 
s well being at the forefront of their mind. This means the player is rarely neutral because they are 
trying to subvert other civilizations, either by open opposition or mock neutrality, in order to win 
the game. Peacemaker is a game about the Jerusalem and Palestine conflict where the main focus is to 
achieve peace between these two groups. Similar to Civilization, players must align themselves with one 
side of the conflict over the other. Unlike Civilization however the winning condition for the game is 
that a peaceful resolution between the two sides be reached (a similar the game shares with Balance of 
Power). In this way neutrality is difficult to achieve because the player is both a conflict actor and 
is being prompted and forced towards mediating the conflict to achieve victory. A diplomacy mechanic 
should allow players to work along the entire impartiality spectrum. In the examples provided players 
can act with high impartiality if they decide to be indifferent towards other conflict actors in the 
game (Civilization) or low impartiality as they try to balance power relationship between themselves 
and other actors (Peacemaker and Balance of Power). But, this flexibility along the spectrum causes problems 
for players. First, these games position the player as a conflict actor, not a neutral mediator. The 
player wants to win the game and thus care about the outcome of the conflict, even if the outcome is 
to find a peaceful resolution. A mediator should not have any stock in the conflicts outcome, as a neutral 
mediator was defined, even if they choose to balance the power relationship between the conflict actors. 
Second, this spectrum flexibility also allows players to slip in and out of neutrality, which should 
destroy the trustworthiness of the player as a neutral actor. For instance when playing Civilization 
a player may sign a treaty with another civilization only to amass a gigantic force later and attack 
the same civilization. This is counter-acted in the game by recording how often a player breaks their 
neutrality or peace agreement with other civilizations. Representing how trustworthy a player has been 
in the current game s history affects whether other civilizations will trust the player in the future. 
These problems generally mean that players are forced to one side of the impartiality spectrum or the 
other. Since the player is a conflict actor trying to achieve victory and their trustworthiness is always 
in question, they can never give equality towards another actor, which resides in the middle of the spectrum. 
Players must act indifferent towards other actors (while trying to achieve a non­conflict related victory) 
or they must balance their power relationship in order to achieve victory (due to the games winning conditions 
or the player s weaker position). The middle of the impartiality spectrum requires all actors to be given 
equal treatment. Meaning, the only way that a player, who is also a conflict actor, can give this equality 
to another actor is to share a victory with them. Multiple player victory is not unheard of in cooperative 
style games [DeKoven 2002] but the example games presented so far see single player victory as that highest 
form of victory and force a player to act at the extremes of the impartiality spectrum.  4. Discussion 
of Game Neutrality Figure 2 illustrates the seven neutrality mechanics, presented in the last section, 
positioned on the impartiality spectrum (where the diplomatic and safety mechanics are split into two). 
All of the mechanics lean towards one side of the spectrum or the other, with the morality mechanic being 
the closest to the middle since neutral players are given some sense of equality. In essence, these mechanics 
can be combined into the categories of: Indifferent mechanics, where neutrality is seen as a starting 
point, normal state, and uninteresting; or Balanced mechanics, neutrality is for promoting competition 
by supporting weaker players. A gap arises is in the middle of the spectrum where the equality of all 
players is questioned. What type of neutrality related game mechanics can exist in this space along the 
spectrum? Cooperative play was mentioned in the previous section as allowing players to become more or 
less equal and can therefore achieve a combined victory. However, it can be argued that in these cases 
where players are working towards the common goal of victory they should be treated as a single conflict 
actor [Bartos &#38; Wehr 2002]. Defining these cooperative players as one conflict actor, combined with 
the fact that a game must have a conflict, the only other opponent available would have to be the game 
system itself. Given these facts, we find ourselves faced again with the argument that a conflict actor, 
who is trying to achieve victory in a neutral way, will be forced to one extreme side of the impartiality 
spectrum. Additionally, if one were to argue and/or give a game example where the game system is not 
an opponent (leaving the cooperative players with no opponent), then the impartiality spectrum is mute 
as it judges a mechanics neutrality where conflict is present. For these reasons, cooperative player 
games do not seem to fit within the middle of the impartiality spectrum.  Figure 2: The seven neutral 
related game mechanics form groups on the extreme ends of the impartiality spectrum leaving the middle 
unexplored. One thing that cooperative player games do achieve is they gather multiple players together 
and having them cooperate. Neutrality also needs multiple players (or actors) to work, some play the 
part of the conflicting actors while others choose to be neutral. However cooperation in these situations 
may focus on neutral actors mediating between the conflict actors instead of having every actor working 
towards a common goal. This may be where a portion of the missing equality mechanics from the spectrum 
lie, providing play-style mechanics that promote neutrality. What if neutral players were given their 
own class or a new mechanic gave players the ability to achieve some sense of active neutrality ? In 
this section the author will explore this question and provide a list of design recommendations for creating 
neutral and mediation oriented game mechanics. These recommendations will look at four levels of ideas 
that progressively increase in scope: altering an existing mechanic, adding a player class, creating 
a new set of player goals, and creating a large player­based organization. 4.1 Neutral alignment The 
morality mechanic gives players weak bonuses for staying neutral. Instead this mechanic should give them 
equal bonuses compared to the players that align themselves as either good or evil. This could be accomplished 
by allowing neutral players to receive special bonuses after staying neutral for a certain length of 
time and maintaining their neutrality in the future. Also, a player s ability to maintain neutrality 
could be seen as a representation of their trustworthiness which could affect other aspects of the game, 
such as using trustworthiness as an attribute within an RPG. These would elevate a neutral player to 
an equal level with the players that choose non-neutral alignments. 4.2 Mediator professions Beyond 
a player s alignment, a neutral profession could be available for players and allow them to participate 
in a game as a non-combative player. For instance, trading is a major factor in social games, which also 
means that it is a volatile mechanic between players where many disputes arise. A game could set up a 
trading system which allows neutral players to act as trading mediators (e.g. create contracts, transport 
resources, etc.). Acting as a mediator the neutral player would fulfill a new trading social role, one 
that is currently filled by one shot trades between players (who may never interact again) or a game 
controlled system like an auction. This social mediator role could be expanded into other areas such 
as guild mediator, where acting as a mediator has been found to be one role a guild leader must perform 
[Yee 2006]. 4.3 Neutral standards Players that choose a neutral role within a game could be given their 
own set of standards to follow and allow them to act along the entire impartiality spectrum. These players 
would be able to work towards their own goals or victory conditions alongside the game s conflict actors 
by successfully mediating situations or performing their own set of challenges within the game. For example, 
to promote trustworthy service an in-game reputation system would allow players to rank a mediators performance. 
Having a high reputation score is a sign of prestige and would be coveted by mediators in the game both 
from a popularity and a profitability standpoint. Adding these new mediator standards would alter games 
such as Peacemaker and Balance of Power because players could focus on performing a mediator role rather 
than being forced to choose a conflict actor and promoting their cause. Mediation games do exist [Zap 
Dramatic] and could be used as a starting point for adding their mechanics into other game genres.  
4.4 Disclosure and global organizations Currently, a larger MMO game s highest form of organization is 
a guild [Ducheneaut et. al. 2007]. While internal guild relations and external relations between rival 
guilds are areas that a mediator profession could fill, a higher level organization is another option. 
Civilization 4 has the ability for the United Nation, a multi­national organization that focuses on global 
corporation, to be created by a player which then allows every other player to participate in the organization. 
A similar situation could be set up in larger MMO games. Having a global , U.N. like, game organization 
could provide a game community with two features related to mediation: open conflict disclosure and a 
global player organization. MMOs provide players and guilds with multiple ways of communicating through 
text or voice, some of which are publicly accessible. In contrast, MMOs do not require guilds to announce 
to the collective game world when they perform actions such as declare war on another guild even though 
guilds may be required to formally announce a declaration of war to their opponent [CCP 2003]. With a 
U.N. type organization these declarations could be made public and monitored. Guilds would not necessarily 
have to seek approval from the U.N. to fight but making conflict information public would provide other 
players with valuable information about the dynamics of the game world. This would also provide players 
with a sort of news report that they could follow as an audience [Ducheneaut et. al. 2006], which may 
lead to other game dynamics such as player protests against certain conflicts. A U.N. organization could 
allow players to enforce or minimize undesired behavior or activity. Players within the game world could 
vote other players into the U.N. to monitor guild activities or game community managers could manage 
the organization. If guild conflict activities are known to the community then the U.N. could work as 
a central hub for mediation and peacekeeping activities. Mediators that work within the U.N. could be 
utilized by guilds for negotiation settlements and peacekeeping forces, whether made up of players or 
NPCs, could be used to provide assistance to weaker guilds or to enforce fair play practices. These four 
design recommendations focus on creating mechanics that support a neutral or mediator play style. Players 
who do not normally enjoy open conflict or combat oriented games may find a neutral style of gameplay 
enjoyable, where they do not have to make black and white decisions. Furthermore, adding mediation professions 
or organizations would allow players to take a more active role within a game s community and effectively 
allow them to provide equality among players. Future work must begin to implement these recommendations 
in order to discover if neutrality is a concept that can exist in games where conflict is so necessary 
for gameplay.  5. Future Work and Conclusion Current work by the author has already begun looking at 
modeling human societal conflict behavior for the purpose of creating AI agents that can imitate human 
conflicts [Medler 2008]. Part of this work includes understanding mediation and how it is used within 
real world conflicts as a resolution practice and to halt smaller conflicts from becoming open and violent. 
Neutrality is one area that must be understood in greater detail in order to begin to model mediation 
properly. It is the hope of the author to build AI NPCs for games that employ conflict behavior both 
from a conflict actor s and a mediator s point of view. Games that utilize these conflict models could 
provide a realistic conflict experience for entertainment games while also providing an avenue for the 
creation of serious games that can teach players about conflict and mediation. This paper has discussed 
how neutrality is defined in the context of mediators and how they resolve conflicts. Neutral mediators 
have a choice along a spectrum of impartiality based on the type of relationship they have towards the 
conflict actors they are negotiating between. Similarly, game mechanics can be judged on their impartiality 
towards players using this spectrum as well. The impartiality of a mechanic can range from being completely 
indifferent towards players to having a balanced effect where the mechanic attempts to create a more 
competitive atmosphere for the players. The author argues that two game mechanics are missing, or at 
least under-represented, on the spectrum. First, games do not allow equal consideration for neutral players, 
or an active neutrality mechanic. Conflict oriented players get bonuses for declaring their allegiances 
within a game s conflict. However, players that would choose to stay neutral do not receive any such 
bonuses. If games were to approach how neutral players are represented, for example giving these players 
separate social roles or victory conditions, games may allow for a new neutral player type to flourish. 
The second missing mechanic would allow neutral players to function more as a neutral mediator, flowing 
along the impartiality spectrum while staying neutral. This would require better mediation mechanics, 
models, and organization to be created for both player and NPC mediation abilities. While conflicts within 
games add to the enjoyment of playing them, neutrality is not used to its full potential. If games allowed 
players to become mediators and walk the line between in-game allegiances a new style of gameplay may 
be discovered. Determining how to effectively implement these neutral game mechanics whereby players 
are allowed to sit on the fence, so to speak, is the question that still needs to be answered.  REFERENCES 
Andren, N. 1991. On the Meaning and Uses of Neutrality. Cooperation and Conflict, 26, 67-83. Armed neutrality. 
2007. In Wikipedia, The Free Encyclopedia. Retrieved 23:09, April 24, 2008, from http://en.wikipedia.org/w/index.php?title=Armed_neutrality 
&#38;oldid=177198388 Bartos, O., &#38; Wehr, P. 2002. Using Conflict Theory. Cambridge University Press. 
Benjamin, R. 1998. The Risks Of Neutrality - Reconsidering The Term And Concept [Electronic Version]. 
Mediate.com. Retrieved February 21st, 2008 from http://www.mediate.com/pfriendly.cfm?id=424. Big Blue 
Box. 2004. Fable. Microsoft Game Studios. BioWare. 2003. Star Wars: Knights of the Old Republic. Lucas 
Arts. Blizzard Entertainment. 2002. Warcraft 3. Blizzard. Blizzard Entertainment. 2004. World of Warcraft 
Blizzard. Mayer, B. 2004. Beyond Neutrality: Confronting the Crisis in Burak, A., Keylor, E., &#38; Sweeney, 
T. 2005. PeaceMaker: A Video Game to Teach Peace. In Intelligent Technologies for Interactive Entertainment, 
307-310. CCP. 2003. EVE Online Simon &#38; Schuster. Consalvo, M. 2007. Cheating: Gaining Advantage in 
Videogames. MIT Press. DeKoven, B. 2002. New Games, still [Electronic Version]. Deepfun.com. Retrieved 
February 26th, 2008. Ducheneaut, N., et. al. 2006. Alone Together? Exploring the Social Dynamics of Massively 
Multiplayer Games. In Conference Proceedings on Human Factors in Computing Systems CHI 2006, ACM Press, 
New York, NY. 407-416. Ducheneaut, N., et. al. 2007. The Life and Death of Online Gaming Communities: 
A Look at Guilds In World of Warcraft. In Conference Proceedings on Human Factors in Computing Systems 
CHI 2007, ACM Press, New York, NY. 839-848. EA Pacific. 2003. Command &#38; Conquer: Generals. EA Games. 
Field, R. 2000. Neutrality and Power: Myths and Reality [Electronic Version]. Mediate.com. Retrieved 
February 20th, 2008 from http://www.mediate.com/pfriendly.cfm?id=1172. Firaxis Games. 2005. Civilization 
4. 2K Games. Goetschel, L. 1999. Neutrality, a Really Dead Concept?. Cooperation and Conflict, 34, 115-139. 
Griefer. 2008. In Wikipedia, The Free Encyclopedia. Retrieved 23:08, April 24, 2008, from http://en.wikipedia.org/w/index.php?title=Griefer&#38;oldid=20 
7939544 Juul, J. 2007. A Certain Level of Abstraction. In Situated Play: DiGRA 2007 Conference Proceedings, 
Tokyo, Japan. A. Baba, Ed., 510-515. Maiese, M. 2005. Neutrality [Electronic Version]. Beyond Intractability. 
Retrieved February 20th, 2008 from http://www.beyondintractability.org/essay/neutrality/. Conflict Resolution. 
Jossey-Bass Publishers. Medler, B. 2008. Using Conflict Theory to Model Complex Societal Interactions. 
[Under Review]. Microsoft Research. 2002. TrueSkill . Retrieved January 15th, 2008, from http://research.microsoft.com/mlp/apg/trueskill.aspx 
Mindscape. 1985. Balance of Power. Chris Crawford. NCsoft. 2007. Tabula Rasa. NCsoft. Nintendo. 1989. 
Tetris. Nintendo. Nintendo. 2005. Mario Kart DS. Nintendo. Origin Systems. 1997. Ultima Online. EA Pandemic 
Studios. 2005. Start Wars: Battlefront 2. Lucas Arts. Petroglyph. 2006. Star Wars: Empire at War. Lucas 
Arts. Q Entertainment. 2005. Meteos. Nintendo. Relic. 2006. Company of Heroes. THQ. Rockstar North. 2005. 
Grand Theft Auto: San Andreas. Rockstar Games. Rubberband AI. 2008. In Wikipedia, The Free Encyclopedia. 
Retrieved 23:08, April 24, 2008, from http://en.wikipedia.org/w/index.php?title=Rubberband_AI&#38; oldid=202822843 
Salen, K., &#38; Zimmerman, E. 2003. Rules of Play: Game Design Fundamentals. MIT Press. Yee, N. 2008. 
Life as a Guild Leader. The Daedalus Project. Retrieved May 25, 2008, from http://www.nickyee.com/daedalus/archives/001516.php 
Zap Dramatic. The Mediator. February 25th, 2008, from http://www.zapdramatic.com/dramas.htm  
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
	</article_rec>
	<article_rec>
		<article_id>1401861</article_id>
		<sort_key>180</sort_key>
		<display_label>Pages</display_label>
		<pages>10</pages>
		<article_publication_date>08-09-2008</article_publication_date>
		<seq_no>2</seq_no>
		<title><![CDATA[Games about LOVE and TRUST?]]></title>
		<subtitle><![CDATA[harnessing the power of metaphors for experience design]]></subtitle>
		<page_from>89</page_from>
		<page_to>97</page_to>
		<doi_number>10.1145/1401843.1401861</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1401861</url>
		<abstract>
			<par><![CDATA[<p>In this paper we will tackle the question of how thinking about game design as metaphorical process can help game designers to systematically expand the experiential scope of videogames. Sharing Eric Zimmerman's and Katie Salen's frustration with the reality of the game store, the "endless racks of adolescent power fantasies, witless cartoon characters, and literal minded sports simulations." [2004], we set out to explore the potential for future development of games that are <i>about</i> something, that tackle complex concepts and ideas in a medium-specific manner and thus provide players with thought-provoking, and insightful experiences.</p> <p>Central to our investigations is digital games' natural affinity to metaphors. Metaphors can enter games in a variety of ways. In the following we are going to focus on two of them: interface metaphors that provide the very foundation for the communication between game and player, and games that are based as a whole on metaphorically-structured abstract concepts such as LOVE or TRUST. Applying Lakoff's and Johnson's research on "metaphors we live by" [1980] to game studies, we will identify potential for future development and give suggestions of how it can be tapped. Qualitative analyses of existing game examples will round up our explorations of how harnessing the power of metaphors in game design can create rich and insightful game-play experiences.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[abstract concepts]]></kw>
			<kw><![CDATA[abstraction]]></kw>
			<kw><![CDATA[game design]]></kw>
			<kw><![CDATA[meaning generation]]></kw>
			<kw><![CDATA[mediacy]]></kw>
			<kw><![CDATA[metaphors]]></kw>
			<kw><![CDATA[multidimensional gestalts]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1100729</person_id>
				<author_profile_id><![CDATA[81365597489]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Doris]]></first_name>
				<middle_name><![CDATA[C.]]></middle_name>
				<last_name><![CDATA[Rusch]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Singapore-MIT GAMBIT Game Lab, Cambridge, MA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1100730</person_id>
				<author_profile_id><![CDATA[81485641571]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Matthew]]></first_name>
				<middle_name><![CDATA[J.]]></middle_name>
				<last_name><![CDATA[Weise]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Singapore-MIT GAMBIT Game Lab, Cambridge, MA]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Bogost, I. 2006. Persuasive Games: Wii's Revolution is in the Past. In: <i>Serious Games Source.</i> URL (consulted Jan. 2007) http://seriousgamessource.com/features/feature_112806_wii_2.php]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Griffin, S. 2005. Push. Play: An Examination of the Gameplay Button. Paper presented at the <i>Digital Games Research Association (DiGRA) Conference</i>, Vancouver BC, 2005. http://ir.lib.sfu.ca/handle/1892/1626 (URL consulted April 8th 2008).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Grodal, T. 2000. Video Games and the Pleasures of Control. In: Zillmann, D. and Vorderer, P. (Eds.): <i>Media Entertainment. The Psychology of its Appeal.</i> Mahwah NJ: Lawrence Erlbaum Associates. 197--215.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Hocking, C. 2008a. Game Designer's Rant. Presented at <i>Game Developers Conference</i>, San Francisco, 2008. http://clicknothing.typepad.com/click_nothing/2008/02/gdc-2008---part.html (URL consulted on April 8&#60;sup&#62;th&#60;/sup&#62; 2008).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Hocking, C. 2008b: I-fi: Immersive Fidelity in Game Design. <i>Game Developers Conference</i>, San Francisco, 2008. http://clicknothing.typepad.com/click_nothing/2008/02/gdc-2008---part.html (URL consulted on April 8&#60;sup&#62;th&#60;/sup&#62; 2008)]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Jenkins, H. 2004. Game Design as Narrative Architecture. In: Wardrip-Fruin, N. and Harrigan, P. (Eds.) <i>First Person: New Media as Story, Performance, and Game.</i> Cambridge, MIT Press. 118--130.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Juul, J. 2007. A Certain Level of Abstraction. In: <i>Situated Play: DiGRA 2007 Conference Proceedings</i>, edited by Akira Baba, Tokyo: DiGRA Japan, 2007. http://www.jesperjuul.net/text/acertainlevel/ (URL consulted April 8th 2008). 510--515.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1214937</ref_obj_id>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[King, G. and Krzywinska, T. 2006. <i>TombRaiders. Space Invaders. Videogames Forms &amp; Contexts.</i> London, UK: I.B.Tauris.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1207478</ref_obj_id>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Koster, R. 2005. <i>A Theory of Fun for Game Design</i>. Scottsdale, Arizona: Paraglyph Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Lakoff, G. and Johnson, M. 1980. <i>Metaphors We Live By.</i> Chicago and London: University of Chicago Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Mateas, M. and Stern, A. 2003. Fa&#231;ade: An Experiment in Building a Fully-Realized Interactive Drama. In <i>Game Developer's Conference: Game Design Track</i>, San Jose, California, March 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Rusch, D. C. 2008. Emotional Design of Computer Games and Fiction Films. In: Jahn-Sudmann, A. and Stockmann, R. (Eds.): <i>Games Without Frontiers - War Without Tears. Computer Games as a Sociocultural Phenomenon.</i> New York: Palgrave.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Rusch, D. C. and K&#246;nig, N. 2007. Barthes Revisited: Perspectives on Emotion Strategies in Computer Games. In: <i>Computerphilology Yearbook</i>, TU Darmstadt. http://computerphilologie.tu-darmstadt.de/jg07/koenigrusch.html (URL consulted on April 8&#60;sup&#62;th&#60;/sup&#62; 2008).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1215723</ref_obj_id>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Salen, K. and Zimmerman, E. 2004. <i>Rules of Play: Game Design Fundamentals.</i> Cambridge MA, The MIT Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Games about LOVE and TRUST? Harnessing the Power of Metaphors for Experience Design Doris C. Rusch Post 
Doctoral Researcher dcrusch@mit.edu Matthew J. Weise Lead Game Designer sajon@mit.edu Singapore-MIT GAMBIT 
Game Lab 77 Massachusetts Ave Bldng NE25-383 Cambridge, MA 02139 Abstract In this paper we will tackle 
the question of how thinking about game design as metaphorical process can help game designers to systematically 
expand the experiential scope of videogames. Sharing Eric Zimmerman s and Katie Salen s frustration with 
the reality of the game store, the endless racks of adolescent power fantasies, witless cartoon characters, 
and literal minded sports simulations. [2004], we set out to explore the potential for future development 
of games that are about something, that tackle complex concepts and ideas in a medium-specific manner 
and thus provide players with thought-provoking, and insightful experiences. Central to our investigations 
is digital games natural affinity to metaphors. Metaphors can enter games in a variety of ways. In the 
following we are going to focus on two of them: interface metaphors that provide the very foundation 
for the communication between game and player, and games that are based as a whole on metaphorically-structured 
abstract concepts such as LOVE or TRUST. Applying Lakoff s and Johnson s research on metaphors we live 
by [1980] to game studies, we will identify potential for future development and give suggestions of 
how it can be tapped. Qualitative analyses of existing game examples will round up our explorations of 
how harnessing the power of metaphors in game design can create rich and insightful game-play experiences. 
 Keywords Game design, mediacy, abstraction, metaphors, meaning generation, abstract concepts, multidimensional 
gestalts 1. Introduction There are a growing number of game designers, as well as players, who want 
games to be about something games that Copyright &#38;#169; 2008 by the Association for Computing Machinery, 
Inc. Permission to make digital or hard copies of part or all of this work for personal or classroom 
use is granted without fee provided that copies are not made or distributed for commercial advantage 
and that copies bear this notice and the full citation on the first page. Copyrights for components of 
this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, 
to republish, to post on servers, or to redistribute to lists, requires prior specific permission and/or 
a fee. Request permissions from Permissions Dept, ACM Inc., fax +1 (212) 869-0481 or e-mail permissions@acm.org. 
Sandbox Symposium 2008, Los Angeles, California, August 9 10, 2008. &#38;#169; 2008 ACM 978-1-60558-173-6/08/0008 
$5.00 matter and make us see the world from a different perspective.1 Mary Flanagan s work on Values 
at Play deserves a special mentioning here.2 Clint Hocking and Raph Koster claim that games can have 
the potential to move us profoundly and provide deep insights into the human condition [Hocking 2008a; 
Koster 2005]. It all depends on what experiences you set out to design and how you design them. The cut-scenes 
may claim that a game is really about a deep and complicated relationship between the heroine and her 
significant other while the actual game-play is all about running, hiding, ducking, aiming, pulling the 
trigger and reloading; the cut-scenes might be about unconditional love but the player does not get to 
experience this concept through the game-play.3 For a game to successfully convey its message it needs 
to be implemented within the rule system. It has to become tangible to the player in the moment­to-moment 
game-play. It must make use of the medium-specific possibilities to get the experience across, and strategies 
that worked well in traditional media may not work the same way in games.4 As Henry Jenkins has noted 
in regard to their narrative potential: we must ( ) be attentive to the particularity of games as a medium, 
specifically what distinguishes them from other narrative traditions. [2004]. In 2007, we played and 
analyzed a range of single-player digital representational games games that represent any kind of real 
1http://www.manifestogames.com, http://www.igf.com/, http://www.smartlab.uk.com/, http://www.tiltfactor.org/, 
http://www.seriousgames.org/index2.html, http://www.gameresearch.nl/ 2 see the Values @ Play website 
for more information about Mary Flanagan s research projects on designing social values in computer games: 
http://valuesatplay.org/?page_id=2 3 Please note that we are not claiming that it is impossible to make 
a game about LOVE in which shooting is a crucial game­play mechanic. It all depends on how shooting is 
employed in the game to support the experience of LOVE.4 An illuminating article in this regard is Grodal, 
Torben (2000): Video Games and the Pleasures of Control. In: Zillmann, Dolf and Vorderer, Peter (Eds.): 
Media Entertainment. The Psychology of its Appeal. (pp. 197-215). Mahwah NJ: Lawrence Erlbaum Associates. 
See also: Rusch, Doris C. (2008): Emotional Design of Computer Games and Fiction Films. In: Jahn-Sudmann, 
Andreas/Stockmann, Ralf (eds.): Games Without Frontiers -War Without Tears. Computer Games as a Sociocultural 
Phenomenon. New York: Palgrave. or imagined world and that are played on some kind of computer, in contrast 
to highly abstract, non-narrative games that seemed somehow unusual, thought-provoking and interesting 
to us in regard to their topic (what?) or the way they made use of the medium-specific possibilities 
of digital games, especially the process of mediation and abstraction, to convey it (how?). We selected 
a subset of games to examine by drawing on recommendations from friends and colleagues and our own extensive 
experience as active players. Our study is qualitative and we do not claim our findings to be quantitatively 
representative. We started by naïvely asking what kinds of experiences were offered most by current games 
and tried to identify blank spots that had potential for future development. Heavily inspired by Lakoff 
s and Johnson s seminal book Metaphors We Live By [1980], which provided us with an enormously useful 
framework to systematize our explorations, we found that game-play experiences are rarely based on abstract 
concepts and ideas (e.g. HOPE, LOVE, SACRIFICE, TRUST, JUSTICE5 etc.) but tended to emphasize a limited 
number of straightforward physical concepts that afforded an apparent immediacy of interaction with the 
game-world (e.g. running, grabbing, fighting). This suggested two paths for future development: 1. Exploring 
abstract concepts as the basis for game ideas and 2. Opening up the range of physical concepts employed 
in games by downplaying the primacy of apparent immediacy of interaction with the game-world.  Each 
of these paths requires us to think of game design as metaphorical process. Firstly, abstract concepts 
are often understood in terms of metaphors [Lakoff and Johnson, p.85]. Secondly, due to the mediated 
nature of digital games, communication between game and player relies heavily on interface metaphors. 
We will elaborate on this special relationship between digital games and metaphors and provide concrete 
game examples to illustrate how it can be harnessed to systematically expand the experiential scope of 
this still­evolving, but powerful, expressive form.  2. Metaphors are Everywhere People are often under 
the misconception that metaphors are something fancy, that they belong exclusively to the realm of art 
and literature. This is not true. Metaphors are everywhere. They structure our everyday experiences and 
build the foundation for our understanding of the world. According to Lakoff and Johnson, the essence 
of metaphor is understanding and experiencing one kind of thing in terms of another. [1980, p.5]. When 
we make sense of our experiences we constantly understand one kind of thing in terms of another kind 
of thing. Particularly abstract concepts or ideas are understood metaphorically, i.e. in terms of something 
immediately graspable, something that is directly delineated from our physical being in the world as 
humans. This happens mostly unconsciously. We do not question why we think of ideas as objects when we 
say we have dropped them. It does not seem noteworthy to us anymore that we understand our emotional 
5 Lakoff and Johnson refer to concepts and multidimensional gestalts by writing them in captial letters. 
In this paper we will do the same whenever we refer to an experience as concept. states in terms of 
physical orientation in space, such as feeling high or low. We rarely stop and think who is going to 
find the nerves someone has lost; if we should throw a life vest to someone who is drowning in work; 
or if there is enough space on the floor to stomp on a person s feelings. These sub­conscious sense-making 
processes also apply to more complex concepts such as experiencing argument as war, or love as a journey. 
 3. About the Special Connection Between Games and Metaphors We argue that digital representational games 
have a natural affinity to metaphors because they need to deal with mediacy and because the abstraction 
process necessary in game design is a precondition for metaphor creation. What do we mean by that? 3.1. 
Mediacy While in real life we draw on metaphors mainly to make sense of abstract concepts and ideas (e.g. 
understanding ideas as objects or argument as war) metaphors in digital games come into play on a much 
more basic level: they build the very foundation for the player s interaction with the game-world and 
thus their function is not only to make the abstract intelligible, but to make the physical graspable, 
too. The way and extent to which the gameworld and its various objects and characters, including the 
player s avatar, become tangible to the player depend to a large degree on metaphors. This is due to 
the fact that digital games are mediated experiences. Because of technical limitations that make mediation 
necessary, there is always a gap between the player, his avatar and the game world [Hocking 2008b] The 
player is physically positioned outside the gameworld which means she is not able to reach into the screen 
to manipulate it directly; she has only a limited or indirect sensory perception of what is going on 
inside the virtual environment; if playing some sort of distinct character, she never becomes that characters. 
At times, players might experience a strong sense of being invested in, bound to or in synch with the 
character, but they never step fully into the character s shoes, entirely present in the gamescape. [King 
and Krzywinska 2006, p.100] To bridge the gap, translation processes are called for: one thing has to 
be understood in terms of another thing, e.g. health loss is understood in terms of a shrinking health 
bar, running is understood in terms of moving the controller s analog stick forward, etc. We will in 
the following refer to these kinds of metaphors as interface metaphors. 3.2. Abstraction Before designers 
can decide how to make an experience tangible to the player, they need to decide what shall be conveyed 
in the first place. The abstraction process thus is a precondition for interface metaphor design. It 
further requires a way of systematically analysing and identifying the essential elements of experiences 
that cannot only be applied to physical concepts but also to abstract concepts. We believe that being 
able to approach the abstraction process consciously and systematically will facilitate metaphorical 
game design. According to Jesper Juul, videogames always have a certain level of abstraction [Juul 2007]. 
For one, the designer always has to decide which aspects of the gameworld shall be represented on screen, 
and further, which aspects of the world shall be implemented into the rule system. Juul: If we assume 
the perspective that games have two complementary elements of rules and fiction all content in the game 
can either be purely fictional and not implemented in the rules system (such as in the case of a game 
s back story), purely rules and unexplained by the fiction (such as the multiple lives of a player), 
or in the zone in between where the rules of the game are motivated by the game s fiction (cars that 
can drive, birds that can fly, etc.) [ ] The combination of rules and fiction is sometimes described 
as virtual or simulation. The level of abstraction concerns the border between the content that is purely 
fictional and the content that is presented in the fiction as well as implemented in the rules of a game 
[2007]. The process of abstraction includes highlighting certain aspects of an experience and hiding 
others. The designer makes a deliberate decision about which elements of the imagined world shall be 
implemented into the rule-system and which shall remain purely fictional. She also determines the degree 
of detail to which actions are available to the player. When abstracting, game designers adopt a certain 
perspective towards an experience and shape the virtual part of the gameworld (i.e. the part that is 
implemented into the rule system) according to what they define as crucial to the experience they want 
to convey and what is neglectable (conscious muscle movement might not be essential to the experience 
of cooking; adding the right ingredients, stirring and regulating the heat at the right time is. However, 
if the game should convey the experience of cooking from the perspective of an Alzheimer s patient, then 
maybe conscious control of body parts becomes an essential element). Thus, abstraction is a precondition 
for the design of interface metaphors. The transition between identifying the crucial elements of an 
experience and translating them into interface metaphors is fluid. The abstraction process is not just 
an integral part of game design. It is also fundamental to the way we understand and structure our experiences 
in real life. According to Lakoff and Johnson, we classify our experiences in terms of complex concepts, 
so called multidimensional gestalts (also referred to as experiential gestalts or multidimensionally 
structured wholes). A multidimensional gestalt consists of a variety of structural elements (dimensions) 
that have a fairly obvious experiential basis. The most basic natural dimensions of experiential gestalts 
are Participants: This dimension arises out of the concept of the SELF as actor distinguishable from 
the actions he performs. We also distinguish kinds of participants (e.g. people, animals, objects). Parts: 
we experience ourselves as having parts (arms, legs, etc.) that we can control independently. Likewise, 
we experience physical objects either in terms of parts that they naturally have or parts that we impose 
upon them, either by virtue of our perceptions, our interactions with them, or our uses for them. Similarly 
we impose a part­whole structure on events and activities. And, as in the case of participants, we distinguish 
kinds of parts (e.g., kinds of objects, kinds of activities, etc.) Stages: Our simplest motor functions 
involve knowing where we are and what position we are in (initial conditions), starting to move (beginning), 
carrying out the motor function (middle) and stopping (end), which leaves us in a final state. Linear 
Sequence: Again, the control of our simplest motor functions requires us to put them in right linear 
sequence. Purpose: From birth (and even before), we have needs and desires, and we realize very early 
that we can perform certain actions (crying, moving, manipulating objects) to satisfy them. [Lakoff and 
Johnson 1980, p.82] When we are flirting with someone we automatically and unconsciously classify this 
experience in terms of the natural dimensions of the FLIRT gestalt: who is participating (me and the 
cute guy); what is the purpose (boost self-esteem, get a date); whose turn it is (mine again? oh no!); 
what stage we are at (OK, we gathered the basic information about each other. Isn t it about time he 
asked me for my phone number?) etc. If the actual experience matches the FLIRT gestalt dimension for 
dimension, we know that there is flirting going on. Of course, an inappropriate remark or some unpleasant 
piece of information can make one of the participants lose interest and he/she stops flirting. This will 
change the experience of the situation. It will not be classified as flirting anymore, because the FLIRT 
gestalt ceases to fit when there is a mismatch between aspects of the actual activity (formerly trying 
to impress, now trying to get away) and the dimensions of the FLIRT gestalt. It is by means of conceptualizing 
our experiences in this manner that we pick out the important aspects of an experience. And by picking 
out what is important in the experience, we can categorize the experience, understand it, and remember 
it. [Lakoff and Johnson, p.83] In the abstraction process, game designers pre-filter information and 
action possibilities for players. From all the imaginable things they could put into the game, they settle 
on those that they have identified as the important aspects of an experience and formulate corresponding 
rules to express their take on the experience. This is also a crucial factor in making the game­world 
tangible to the player, because it means that the essential aspects of the world and its characters (including 
the player s avatar) are directly conveyed via the rule-system and cannot possibly be ignored by the 
player [see Juul 2007; Rusch and König 2007]. It is a medium-specific way of experience design. So far, 
digital representational games mainly feature abstractions of gestalts whose dimensions can be directly 
delineated from experience, e.g. COOKING, WAITRESSING, HUNTING, FIGHTING. We agree that games based on 
physical concepts can be great fun. They can also make us think differently (or more consciously) about 
physical processes and activities, thus providing a pleasurable meeting of minds with the designers who 
identified the essential elements of these processes and activites. However, for games to mature as media, 
they must not be afraid of abstracting abstract concepts, too. These concepts are structured mainly in 
terms of metaphors. Certain concepts are structured almost entirely metaphorically. The concept LOVE, 
for example, is structured mostly in metaphorical terms: LOVE IS A JOURNEY, LOVE IS A PATIENT, LOVE IS 
A PHYSICAL FORCE, LOVE IS MADNESS, LOVE IS WAR, etc. The concept of LOVE has a core that is minimally 
structured by the subcategorization LOVE IS AN EMOTION and by links to other emotions, e.g., liking. 
 This is typical of emotional concepts, which are not clearly delineated in our experience in any direct 
fashion and therefore must be comprehended primarily indirectly, via metaphor. [Lakoff and Johnson, p.85]. 
Designing games that successfully tackle abstract concepts has a great potential of making us see the 
world with different eyes. Clint Hocking points out that the mechanics of trust are not more difficult 
to model than the mechanics of rope. [2008a]. We share Hocking s belief in the meaning potential of games 
and we agree that the mechanics of TRUST or other complex abstract concepts might not be more diffcult 
to model then the mechanics of anything physically graspable. However, we acknowledge the challenge of 
identifying these mechanics in the first place. While it is relatively easy to abstract from something 
concrete, because its essential dimensions can be directly observed, it can be quite tricky to abstract 
from something abstract. Before this can be done, the abstract has to be made concrete. A metaphor must 
be found. Complex abstract concepts are multidimensional gestalts, too, only that their dimensions cannot 
be directly delineated from experience. A metaphor is an experiential multidimensional gestalt that matches 
the experience of the abstract concept dimension for dimension. Understanding LOVE as a JOURNEY provides 
the designer with parts, stages, purposes and a sequential structure that can be more easily abstracted 
and consequently translated into a gameworld with concrete goals and obstacles etc. Thus, being aware 
of these dimensions or elements helps one to approach the abstraction process in a systematic manner, 
both in regard to physical but especially in regard to complex abstract concepts.  4. Identifying the 
Blind Spots Before we go on to suggest two approaches to how the experiential scope of digital representational 
games could be expanded by drawing on the metaphorical potential intrinsic to the mediation and abstraction 
process, we would like to present our interpretation of what we observed in our explorative qualitative 
game analyses in 2007. 1. Digital representational games mostly focus on tackling physical rather than 
abstract concepts. 2. Games can tackle physical concepts on two different scales: a) the concept provides 
the basis for the whole game e.g. a game about WAITRESSING b) the concept provides the basis for a single 
incident in the moment-to-moment gameplay. Put differently: it is the basis for an interface metaphor. 
 3. When the concept provides the basis for the whole game, its inherent meaning potential the insights 
it can provide into the concept, how it works or what it feels like tends to survive the abstraction 
process. To sustain a whole game, designers make use of a range of the concept s dimensions to create 
game-play opportunities. Carrying out the various actions afforded by the physical concept is a precondition 
(but not a guarantee) for the multi-dimensional experiential gestalt to become tangible to the player. 
Only when a complex concept becomes tangible in its multi­dimensionality can it unfurl its meaning potential 
and provide this meeting of minds that caused our dear colleague Clara Fernández-Vara to exclaim over 
Diner  Dash, this is exactly how waitressing feels like. They really got it right! 4. The interface 
metaphors that are used to convey physical concepts often have an almost literal core. They emphasize 
physical mapping of player input and on-screen action. It seems like game designers are reluctant to 
draw on physical concepts that require more elaborate translation processes (and thus more visible interface 
metaphors) to become tangible to players. 5. The apparent primacy of unobtrusive interface metaphors 
reduces the use of physical concepts on the singular incident level. On the one hand, there seems to 
be a focus on essentially physical concepts not only can their dimensions be directly delineated from 
experience, but the physical aspects of the dimensions are in the foreground. Consequently, concepts 
that can be directly experienced, but whose main characteristic is not their physicality, tend to be 
ignored. For example, the CONVERSATION gestalt is physical since its dimensions can be directly experienced, 
but the essential activities involved, the talking and listening, are not primarily physical actions 
but mental processes. Since this is hard to convey in a seemingly immediate manner, few games even try. 
On the other hand, even in the physical concepts that are primarily physical, there is a limitation. 
To avoid breaking the immersive spell with interface metaphors that draw attention to themselves, the 
physical concepts employed tend to be either very simple to begin with or, if they are theoretically 
complex, they are often so abstracted that they can be conveyed in a simple manner. This strategy might 
foster immersion, but the drawback is that a lot of meaning potential is lost. If the player can cook 
a whole meal with the push of a single button, she will not gain much insight into the cooking experience. 
  Through these observations, we realized that current digital representational games did not make full 
use of the metaphorical potential inherent in the mediacy as well as the abstraction process. We identified 
two main areas that are underexplored in the design of digital representational, which shall be discussed 
in the following. 5. Harnessing the Power of Metaphors 5.1. Basing Games on Abstract Concepts We believe 
that basing games on complex abstract concepts could indeed provide deep insights into life and the human 
condition and produce lasting, deeply moving, and profoundly thought-provoking experiences. When the 
experience of waitressing gained from a game can create so much pleasure because of its resonance with 
the real thing imagine playing a game that manages to convey the mechanisms of LOVE, JUSTICE, EMANCIPATION 
or SELF-SABOTAGE in a way that resonates with the player. These abstract gestalts are powerful and pervasive 
in our lives but hard to grasp. When a gifted filmmaker, author or game designer manages to do that for 
us, it has the potential to change our lives because something suddenly falls into place, makes sense 
and we learn something about ourselves. Here are two game examples that achieve this effect. 5.1.1. Passage 
Passage is a very simple game that tackles the complex (mostly) abstract concept LIFE. The metaphor used 
in this game to concretize the concept, to make it graspable and emotionally intelligible to the player, 
is the JOURNEY. For the JOURNEY to work as a metaphor for LIFE, there must be a match in dimensions between 
these two gestalts. One of LIFE s most obvious dimensions is temporality. Temporality is commonly represented 
by some sort of spatial metaphor (e.g. the timeline ). Now, having the player simply move from A to B, 
from birth to death, would not have told us much about life at all. LIFE is a rich multi-dimensional 
gestalt. It has many elements that can be highlighted depending on one s perspective on the concept. 
Passage focuses on the following, creating an individual, deliberate statement about LIFE: Participants: 
you either go through life alone or with a significant other. Parts: the main part of life is, as trivial 
as it sounds, living it. This is broken down into overcoming obstacles, enduring setbacks, making achievments 
and encountering surprises. When you play the game in the company of your significant other, sacrifice 
becomes another essential element of LIFE. Stages: there is youth, old age and eventually death. Life 
progresses in a linear sequence towards death. There is no way to turn back time or skip part of the 
way. But there is memory on the one hand and a foggy idea of what the future might hold on the other 
hand. Purpose: The game does not provide an answer to the philosophical question of what the purpose 
of life is. Instead, it allows you to formulate your own goals and act accordingly. This game makes only 
one explicit claim about life, namely that death is inevitable. So, how are LIFE s dimensions matched 
by the dimensions of the JOURNEY gestalt, both visually and in terms of game-play? Most obviously, living 
is translated into screen navigation. You control a single character represented in simple, blocky 2D 
graphics. At all times you can only perceive a very limited section of the gameworld. Moving left and 
right, up and down allows you to explore it, but your perspective stays restricted. The effect is quite 
profound: you realize that you will never know what you are missing unless you go and find out. Once 
you start exploring life, you become aware of how much else there must be that you will never get to 
experience. However, you can also choose to stay put and wait for death. The game makes it quite clear 
that what you get out of life is really up to you. At the beginning of the Passage, you might encounter 
a female character. A big read heart will appear, symbolizing love, and she will start following you 
around. There is also the possibility that you never meet her. True love is an option, not something 
that is guaranteed. Should you choose to explore life with your companion the alternative would again 
be to just wait on the spot until your time is up and you both die you will discover that a relationship 
requires sacrifice. Passage through life is not without obstacles represented by walls as obstacles 
in space and sometimes navigating around an obstacle is rewarded by an experience represented by boxes 
that boost your experience (?) meter on the top right corner of the screen. The passage à deux makes 
navigating around these obstacles more complicated and you have to spend time to find another route that 
is broad enough for both of you. It also means that you cannot collect all the boxes, implying that some 
adventures or experiences are out of reach when you are in a relationship and need to take somebody else 
into account. In Passage, LIFE is represented by a spatial metaphor. This space is visually restricted 
by blurry edges i.e. the pixels at the left and right edge of the screen appear to be scrambled. As you 
move, all the landscapes, obstacles, and objects you encounter seem to unscramble out of the blur in 
front of you and scramble again into the blur behind you. One reading that suggests itself: the scrambled 
left and right edges of the screen are a visual metaphor for the human cognitive experience of life, 
one in which a hazy future and a hazy past are expressed in scrambled pixels. So not only is LIFE a JOURNEY, 
it is a journey in which only the immediate present can be clearly comprehended. As you near the end 
of your virtual life in Passage, you have the experience of looking back at the scrambled pixels that 
represent your past and attempting to make them out, an abstract representation of the loss of memory 
in old age. Also, as time but not necessarily your exploration of the gamespace progresses you get 
automatically pushed towards the right side of the screen. The blurry edge on the right side that has 
once held the promise of new adventures slowly turns into a grey haze. Your future is used up and so 
is your time on earth. Even if you have not made good use of it, it is now too late. Passage is a simple 
game but the five minutes of playing time might bring up some difficult questions about how you choose 
to live your life. Memento mori. 5.1.2. Ico Ico is a game that has been widely recognized in the videogame 
community for its exploration of the multidimensional gestalt COMPANIONSHIP. The core metaphor by which 
COMPANIONSHIP is concretized in the game is again a sort of JOURNEY, probably best described as a dangerous 
OBSTACLE COURSE. COMPANIONSHIP includes at least two participants and one essential part of the experience 
consists of being physically together over a certain amount of time. In the case of Ico these participants 
are a young boy with horns who has been sent away by his village to be imprisoned in a huge castle, and 
the fragile and ghost-like princess Yorda, who is also held prisoner there by her mother, a wicked sorceress. 
Physically being together over a certain amount of time manifests itself in Ico s and Yorda s mutual 
traversal through the castle. The stages of COMPANIONSHIP match the stages of Ico s and Yorda s common 
journey. It all begins with their first aquaintance, when Ico frees Yorda from a huge birdcage where 
she is imprisoned. From that moment on, they try to escape from the castle together. A new stage begins 
now that consists of getting to know each other s strengths and weaknesses and bonding. This sets the 
scene for the rest of the game, the longest stage of the companionship between Ico and Yorda, where you 
(i.e. the player) already know that Yorda does not only look fragile, but actually is physically weaker 
than you are and quite absent-minded. You are aware that she needs your help to overcome the many obstacles 
on the path to freedom and your protection from the shadow demons that appear unexpectedly, trying to 
abduct her into smoke portals. Towards the end of the journey the companionship between Ico and Yorda 
enters a seemingly final stage when the two get separated and it appears Ico has lost his companion. 
The purpose of COMPANIONSHIP is normally an end in itself companionship for companionship s sake. However, 
the circumstances under which Ico and Yorda meet and their complementary abilities add another dramatic 
element to their relationship: they depend on each other to escape. Not only does Yorda need Ico s help 
and protection, Ico also needs Yorda s supernatural powers to open the magic doors that regularly block 
their path. She further makes him stronger in combat and helpfully points out possible next steps when 
Ico seems to be stuck. Many elements constitute the emotional experience of Ico. The fantastic graphics, 
the music, and of course the extremely powerful game-play mechanic of holding Yorda s hand by pressing 
the R1 button on the Playstation controller that serves multiple relationship building purposes: e.g. 
holding her hand allows you to keep her close in case shadow demons attack; you hold her hand when helping 
her over a particularly difficult chasm and you grab her hand when pulling her out of smoke portals. 
But what is most interesting for our purposes is to investigate how the designers managed to make two 
specific parts of the COMPANIONSHIP experience tangible to the player, namely the feeling of caring and 
responsibility for Yorda. Caring for somebody can be understood as being concerned about the other person 
s well-being. Feeling responsible for somebody implies some sort of hierarchical difference in abilities 
between the person who feels responsible and the recipient of this feeling. The JOURNEY metaphor offers 
many opportunities to construct concrete situations where due to the imbalance in abilities between Ico 
and Yorda, caring and feeling responsible comes naturally. Due to Yorda s lesser physical abilities, 
you frequently have to create a safe passage for her. This forces you to leave her behind while destroying 
blockages or letting down draw-bridges. Unfortunately, this means you are not there when shadow demons 
attack, which can happen at any time. Being aware of this makes it impossible to just focus on the task 
at hand when away from Yorda. You are constantly concerned about her well-being and hurry back to her 
so you will be there when she needs you. Ico presents one of many possible interpretations of the concept 
COMPANIONSHIP by identifying the following elements as essential to the experience: being there for your 
companion, protecting him / her, lending a helping hand and paving the road for him / her. The player 
enacts all these elements of COMPANIONSHIP over and over again in the course of the common JOURNEY through 
the castle, exploring the concept and consequently understanding it emotionally. 5.2. Visible Interface 
Metaphors: Using the Potential of Complex Physical Concepts More visible, multi-modal interface metaphors 
would open games up to a wider range of experiences, enabling designers to tackle experiences that cannot 
be conveyed to the player directly either because of the gap between gameworld and player or because 
of the gap between player and avatar. Interface metaphors that are not simply based on physical analogies 
between real-world input and on-screen action but draw on more complex translation processses can help 
to at least approximate or fake these experiences. On the one hand, this allows game designers to take 
on complex physical concepts that are not primarily physical (such as the CONVERSATION gestalt), which 
provides a great inspiration source for new game-play ideas. At the same time it creates pleasurable 
insights into these gestalts. How this can be achieved will be illustrated by an analysis of the parley 
mini-game featured in the MMORPG Vanguard. On the other hand, dealing with the gap creatively enables 
experiences players could never have in real life, not just because of possible dangers but because they 
stay always themselves. How interface metaphors can not only simulate stepping into the shoes of the 
heroe but into the body of a completely different species will be illustrated by a close reading of Mr. 
Mosquito. This example will also show to what large extent game design choices depend on the designers 
subjective interpretation of an experience and how much ideological potential interface metaphors thus 
possess. 5.2.1 Vanguard: PARLEY Convincing communication with NPCs is still quite an AI challenge and 
so far it is impossible to convey this experience to the player in an apparently immediate manner. Michael 
Mateas and Andrew Stern made promising attempts at solving that problem in their Façade project [2003], 
but it also showed that the technology is not quite there yet and playing the game evokes some strange 
effects when the NPCs suddenly become psychotically unresponsive. In current digital representational 
games, dialogues are usually chopped into prescripted pieces and the player can choose an answer or question 
from some sort of menu in the course of the conversation. The experience is reduced to the dimensions 
of listening (or reading), understanding and waiting your turn to reply or ask the next question. Often, 
there is not even much choice involved in picking an answer / question since the player has to go through 
all the options before the game continues, so the important strategic element inherent in real-life conversation 
is reduced to a minimum. Dialogues in current digital representational games thus serve the communicative 
function of information transfer (often they are skipped by the player altogether, because the information 
can be obtained in other ways, too) but they have only a peripheral resemblance to the actual experience 
of talking to another human because only a fraction of the gestalt s essential dimensions is integrated 
into the game. This is a pity since the various forms of CONVERSATION provide a rich source for insightful 
and rewarding experiences. A game that dares to tackle an interesting variant of conversation is the 
MMORPG Vanguard. Vanguard features a mini-game called parley that aims to make the experience of diplomatic 
negotiation tangible to the player. Since apparent immediacy is not an option to convey this experience, 
the designers tried to make it enactable via metaphor: they translated the experiential gestalt of PARLEY 
into a strategy card game, whose rules match those elements of PARLEY the designers have identified as 
essential to the original experience. PARLEY is a physical concept. In real life, metaphorical understanding 
of the concept would not be necessary, since its dimensions can be directly delineated from experience. 
But to make it tangible in the context of a game, where interaction must be mediated, the metaphorical 
understanding serves as precondition for the design of a working interface metaphor. The parley game 
is rather complex, and we will not explain it here in detail, but point out only some of the dimensions 
the designers have identified as essential to the original experience and therefore implemented into 
the game s rule system. -The purpose of the game is to convince your opponent (an NPC) to do something 
he / she is not willing to do from the start (e.g. trust you, give you information etc.) -Both participants 
have a variety of conversation cards (=parts) which represent different statements. The player gets to 
choose his deck of five cards in the beginning of the mini-game. Playing of cards is turn based. Each 
card has a specific point value. By playing the right card, you make your point and the conversation 
slider moves towards your NPC or back to the player s side when she is losing ground in the course of 
the conversation. -Card value depends on character class. This implies that certain personality types 
have particular persuasive strengths and weaknesses. Not everybody is a born flatterer. If flattery works 
depends on the flatterer. Also, not everybody has a talent to demand. -By exercising parley, one gets 
better at it, in the sense that the quality of the actual conversation statements improves (e.g. the 
awkward flattery from the beginning becomes sophisticated, unresistable complementing). This is analogous 
to improvement of vocabulary and expressive finesse in real life. -Another similarity to real life negotiation 
is that the player has to vary her strategy. If she continuously boasts or flatters, she will lose all 
credibility. Thus, a particular statement card is tapped for a while after it has been played out. (This 
is comparable to recast timers in physical combat.) -To win the game, the player has to get rid of all 
her conversation points before her opponent does, meaning she has to make her point before the other 
party has a chance to do so. That the initial card set is limited can be interpreted as analogous to 
the limited patience of real life conversation partners. You know in advance that this exchange cannot 
go on forever and you have to be clever, forward looking, strategic and efficient if you want to succeed. 
Only with time does the richness of the metaphor become clear to the player and how well it matches the 
experiential gestalt it is imposed on, dimension by dimension. If the player wants to play the game well, 
she needs to understand and interpret its rules. Doing so creates insight into the mechanics of diplomatic 
negotiation, providing cognitive pleasure upon the realization of what the rules mean in regard to the 
experiential concept they model. Further, by enacting PARLEY in this manner, the emotional experience 
of negotiation is approximated, giving the player an opportunity to feel skillful, even if the skills 
used are mathematical rather than verbal. It is a metaphor, after all. 5.2.2. Mr. Mosquito Mr. Mosquito 
is a game that claims to create the day-to-day experience of being a mosquito in a Japanese home during 
hot summer. The game is built on the physical concept of MOSQUITOHOOD as seen from the perspective of 
humans. From the human perspective being a mosquito seems to be all about preying upon the victim, finding 
the right spot to land and sucking her blood. Thus, these are the central game-play elements of the game. 
In sum, these activities supposedly allow the player to experience the thrills of being a mosquito, which, 
apart from skillful navigation, also consist of the pleasures of voyeurism. While the spying and flying 
and landing are not so different from other games featuring anything airborne or stealthy, the blood 
sucking is. Herein lies the mosquitoness , and Mr. Mosquito goes to great lengths to make sucking a challenging 
experience. Once the player guides her avatar, a cute and somewhat abstract-looking mosquito, to her 
target, the naked flesh of an unsuspecting family member, the suckery can begin. How does one translate 
the experience of not only sucking blood, but sucking blood like a mosquito, when the only delivery device 
is a Playstation 2 controller? A serious multi­modal interface metaphor is called for. Before sucking 
the player must penetrate the victim. Mr. Mosquito prompts the player to press the R3 button, which is 
accomplished by depressing the analog stick itself. The player pushes the stick down, into the controller, 
and the mosquito on­screen pushes its proboscis down into the human s skin. This is accompanied by a 
squeak of pleasure. Now the player is prompted to rotate the analog stick clockwise in order to suck 
blood. A vertical meter appears on the screen with a fluctuating blue haze in the middle. There is also 
a white circle in the meter, which quickly begins to fall towards the bottom. The faster the player rotates 
the analog stick the faster they suck, which causes the white circle to move up the meter. The player 
tries to keep the white circle in the middle of the blue haze without letting it touch either the top 
or bottom of the meter. If she fails, the victim suddenly feels the bite and swats the mosquito into 
oblivion. The goal is to keep the victim from feeling the bite while collecting a certain amount of blood 
needed to accomplish the level goal. Mr. Mosquito makes sucking an action with a certain amount of tension 
and nuance. It is also physically exhausting, since the player must perform a repetitive muscle action 
(rotating the analog stick quickly) in order to suck. The player must try hard to suck, similar to how 
they might have to exert themselves when sucking in real life. When sucking in real life e.g. when sucking 
liquid through a straw you must exert the muscles in your face to create a vacuum. Mr. Mosquito defines 
the essentials of sucking as physical exertion and timing, qualities that humans associate with sucking. 
Interestingly, this is at odds with how mosquitos actually suck blood. Real mosquitos do not suck. They 
inject their victims with their saliva, which acts as an anti-coagulant. This prevents the blood from 
clotting, allowing it to flow into the mosquito based on the human s own blood pressure. Mr. Mosquito 
does not actually model the mosquito experience at all. More accurately, it models the human assumption 
of what the mosquito experience is like, and what pleasures it could provide, should the insect possess 
a (particular) human mind. Given that the target group for the game is humanoid rather than insectoid, 
this approach makes sense. Consequently, the game provides a metaphorical model that enables players 
to sneak up on people, penetrate them, and steal their fluids through repetitious physical exertion. 
In this way, Mr. Mosquito models the voyeuristic and sexually predatory instincts of human beings. Mr. 
Mosquito seems quite aware of this and reinforces it in every aspect, first and foremost by the fact 
that the mosquito is impossibly male (only female mosquitos suck blood). The first challenge in the game 
involves sucking the blood of the family s 14-year old daughter, whose body has to be identified for 
suckable points. Add to this the orgasmic squeak the (male) mosquito makes when penetrating his prey 
as well as the vaguely erotic moaning the girl makes when she is being sucked, and it seems quite obvious 
that the gestalt Mr. Mosquito is indulging in has very little to do with insect biology and everything 
to do with human biology. It uses the concept of MOSQUITOHOOD to loosely arrive at an interface metaphor 
that is modeled primarily on human sexual concepts. In this lies its appeal and, depending on your perception, 
its charm. The makers of Mr. Mosquito clearly understand the metaphorical affordances of videogames. 
They ve constructed a game in which insectoid haematophagy is not only made palatable in terms of a controller 
interface, it adds an additional metaphorical layer of human meaning to this behavior. Mr. Mosquito is 
a game in which being a mosquito can be understood as a metaphor for being a sexual pervert.  6. Conclusion 
In this paper, we explored the special relationship between digital representational games and metaphors. 
We asked how it could be harnessed to produce emotionally rich, insightful and thought-provoking experiences. 
Based on our preliminary qualitative game analyses that helped us identify potential for future development 
of games, we suggested two distinct approaches: a) basing games on abstract concepts and b) using the 
power of multi-modal interface metaphors to tap the experience potential inherent in complex physical 
concepts. In regard to approach, a) we explained that the process of abstraction intrinsic to game design 
is also fundamental to the way we make sense of our everyday life. We understand and structure our experiences 
by way of identifying their essential elements, by highlighting what is important to an experience and 
by ignoring what is not. We do so in regard to straightforward physical concepts, but also in regard 
to complex abstract concepts, only that to understand abstract concepts we additionally draw on metaphors. 
The problem is that these sense-making processes are largely unconscious. To make games that successfully 
tackle abstract ideas, it is crucial to make these sense-making processes conscious again, to abstract 
from the abstract and to make it concrete by finding suitable metaphors that can be enacted by the player. 
We illustrated this approach with close readings of the games Passage and Ico, hoping to provide a more 
systematic understanding of how abstract concepts can be made tangible, first for designers, then for 
players. Also, in regard to approach b) we showed how dealing creatively with the gap between game / 
avatar and player can also dramatically expand the experiential scope of digital representational games 
by way of multi-modal interface metaphors. Having to identify metaphors for everyday experiences to bridge 
this gap can make the player see the usual from an unusual perspective, as shown with the parley example 
from the MMORPG Vanguard. Further, if every complex interaction with the gameworld requires complicated 
interface metaphors anyway, you might as well attempt to translate unusual experiences such as being 
a mosquito. The restrictions of the medium, the impossibility of direct manipulation, could be seen as 
an invitation for experimentation. Nothing will be truly immediate anyway, so why not tackle the extraordinary? 
Whatever experience designers choose to make tangible, it will always start with their personal interpretation 
of this experience. Be it in regard to abstract or physical concepts, coming up with suitable metaphors 
is key. Metaphors are never neutral. They are not totally idiosyncratic either, but shaped by socio-cultural 
factors. They provide a perspective about how things are and feel like, and thus contain strong ideological 
potential. Being conscious about this potential and using it will foster games that are about something. 
 References BOGOST, I. 2006. Persuasive Games: Wii s Revolution is in the Past. In: Serious Games Source. 
URL (consulted Jan. 2007) http://seriousgamessource.com/features/feature_112806_wi i_2.php GRIFFIN, S. 
2005. Push. Play: An Examination of the Gameplay Button. Paper presented at the Digital Games Research 
Association (DiGRA) Conference, Vancouver BC, 2005. http://ir.lib.sfu.ca/handle/1892/1626 (URL consulted 
April 8th 2008). GRODAL, T. 2000. Video Games and the Pleasures of Control. In: Zillmann, D. and Vorderer, 
P. (Eds.): Media Entertainment. The Psychology of its Appeal. Mahwah NJ: Lawrence Erlbaum Associates. 
197-215. HOCKING, C. 2008a. Game Designer s Rant. Presented at Game Developers Conference, San Francisco, 
2008. http://clicknothing.typepad.com/click_nothing/2008/02/gdc­2008---part.html (URL consulted on April 
8th 2008). HOCKING, C. 2008b: I-fi: Immersive Fidelity in Game Design. Game Developers Conference, San 
Francisco, 2008. http://clicknothing.typepad.com/click_nothing/2008/02/gdc­2008---part.html (URL consulted 
on April 8th 2008) JENKINS, H. 2004. Game Design as Narrative Architecture. In:Wardrip-Fruin, N. and 
Harrigan, P. (Eds.) First Person: New Media as Story, Performance, and Game. Cambridge, MIT Press. 118-130. 
JUUL, J. 2007. A Certain Level of Abstraction. In: Situated Play: DiGRA 2007 Conference Proceedings, 
edited by Akira Baba, Tokyo: DiGRA Japan, 2007.http://www.jesperjuul.net/text/acertainlevel/ (URL consulted 
April 8th 2008). 510-515. KING, G. and KRZYWINSKA, T. 2006. TombRaiders. SpaceInvaders. Videogames Forms 
&#38; Contexts. London, UK: I.B.Tauris. KOSTER, R. 2005. A Theory of Fun for Game Design. Scottsdale, 
Arizona: Paraglyph Press. LAKOFF, G. and JOHNSON, M. 1980. Metaphors We Live By.Chicago and London: University 
of Chicago Press. MATEAS, M. and STERN, A. 2003. Façade: An Experiment in Building a Fully-Realized Interactive 
Drama. In Game Developer's Conference: Game Design Track, San Jose, California, March 2003. RUSCH, D.C. 
2008. Emotional Design of Computer Games and Fiction Films. In: JAHN-SUDMANN, A. and STOCKMANN, R. (Eds.): 
Games Without Frontiers -War Without Tears. Computer Games as a Sociocultural Phenomenon. New York: Palgrave. 
RUSCH, D.C. and KÖNIG, N. 2007. Barthes Revisited: Perspectives on Emotion Strategies in Computer Games. 
In: Computerphilology Yearbook, TU Darmstadt. http://computerphilologie.tu­darmstadt.de/jg07/koenigrusch.html 
(URL consulted on April 8th 2008). SALEN, K. and ZIMMERMAN, E. 2004. Rules of Play: Game Design Fundamentals. 
Cambridge MA, The MIT Press. Game References DINER DASH. 2004. Gamelab. ICO. 2001: Sony Mr. MOSQUITO. 
2002. Eidos Interactive. PASSAGE. 2007: Jason Rohrer. (URL consulted April 13th 2008) http://hcsoftware.sourceforge.net/passage/ 
VANGUARD. 2006. SOE.   
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
	</article_rec>
	<article_rec>
		<article_id>1401862</article_id>
		<sort_key>190</sort_key>
		<display_label>Pages</display_label>
		<pages>8</pages>
		<article_publication_date>08-09-2008</article_publication_date>
		<seq_no>3</seq_no>
		<title><![CDATA[Film informing design for contemplative gameplay]]></title>
		<page_from>99</page_from>
		<page_to>106</page_to>
		<doi_number>10.1145/1401843.1401862</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1401862</url>
		<abstract>
			<par><![CDATA[<p>Borrowing from film and filmmaking styles, techniques and devices that manipulate spectators' attention and experience, this paper proposes an approach to inform design of games and gameplay to manipulate player's focus of attention and encourage contemplation -- in design features, characters, story elements, etc. or even break the player's engaged attention in the game/virtual world altogether -- to provide meaning, experience and opportunities for learning. Focusing on film styles alternative to the continuity style of Hollywood filmmaking, we discuss examples of design for contemplative gameplay in game-based learning environments/serious games, machinima and augmented and mixed reality games in previous, current and future projects. We propose that one goal of game design is to establish a rhythm between contemplation and engagement, and the appropriate rhythm is determined largely by a game's genre, platform and/or narrative.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[Asian film]]></kw>
			<kw><![CDATA[French New Wave]]></kw>
			<kw><![CDATA[continuity style]]></kw>
			<kw><![CDATA[engagement]]></kw>
			<kw><![CDATA[experience]]></kw>
			<kw><![CDATA[film theory]]></kw>
			<kw><![CDATA[filmmaking]]></kw>
			<kw><![CDATA[game design]]></kw>
			<kw><![CDATA[interruption]]></kw>
			<kw><![CDATA[machinima]]></kw>
			<kw><![CDATA[mixed reality]]></kw>
			<kw><![CDATA[reflection]]></kw>
			<kw><![CDATA[serious games]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>K.8.0</cat_node>
				<descriptor>Games</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>H.5.1</cat_node>
				<descriptor>Artificial, augmented, and virtual realities</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010387.10010866</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces->Virtual reality</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003121.10003124.10010392</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)->Interaction paradigms->Mixed / augmented reality</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003121.10003124.10010866</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)->Interaction paradigms->Virtual reality</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010476.10011187.10011190</concept_id>
				<concept_desc>CCS->Applied computing->Computers in other domains->Personal computers and PC applications->Computer games</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10011007.10010940.10010941.10010969.10010970</concept_id>
				<concept_desc>CCS->Software and its engineering->Software organization and properties->Contextual software domains->Virtual worlds software->Interactive games</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003251.10003258</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Multimedia information systems->Massively multiplayer online games</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<person_id>P1100731</person_id>
				<author_profile_id><![CDATA[81320492462]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Tim]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Marsh]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[National University of Singapore]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1100732</person_id>
				<author_profile_id><![CDATA[81318491041]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Michael]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Nitsche]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Georgia Institute of Technology]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1100733</person_id>
				<author_profile_id><![CDATA[81325489384]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Wei]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Liu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[National University of Singapore]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1100734</person_id>
				<author_profile_id><![CDATA[81365594990]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Peichi]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Chung]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[National University of Singapore]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1100735</person_id>
				<author_profile_id><![CDATA[81332490551]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Jay]]></first_name>
				<middle_name><![CDATA[D.]]></middle_name>
				<last_name><![CDATA[Bolter]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Georgia Institute of Technology]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1100736</person_id>
				<author_profile_id><![CDATA[81100418633]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>6</seq_no>
				<first_name><![CDATA[Adrian]]></first_name>
				<middle_name><![CDATA[D.]]></middle_name>
				<last_name><![CDATA[Cheok]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[National University of Singapore]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Arnheim, R. 1957. <i>Film as Art.</i> Berkley. Los Angeles: University of California Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Bal, M. <i>Narratology.</i> 1997. Toronto; Buffalo; London: University of Toronto Press Inc.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Berge J. 1999. Dream Machines New Media as New Intoxicants. In: <i>Stimuli: Too much noise. Too much movement</i>, published following the exhibition "Stimuli" at Witte de With, centre for contemporary art, Rotterdam. Printed by: Belgium, Ghent: Snoeck-Ducaju &amp; Zoom, pp. 15--28.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>940274</ref_obj_id>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Bolter, J. D. and Gromala, D. 2003. <i>Windows and Mirrors: Interaction Design, Digital Art, And The Myth of Transparency.</i> Cambridge, MA: MIT Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Bordwell, D., Staiger, J. and Thompson, K. 1988. <i>The Classical Hollywood Cinema -- Styles &amp; Mode of Production to 1960.</i> London: Routledge.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>992041</ref_obj_id>
				<ref_obj_pid>992039</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Cheok, A. D., Goh, K. H., Liu, W., Farbiz, F., Fong, S. W., Teo, S. L., Li, Y., and Yang, X. 2004. Human Pacman: a mobile, wide-area entertainment system based on physical, social, and ubiquitous computing. <i>Personal and Ubiquitous Computing</i>, Volume 8, Issue 2, May, pp. 71--81.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Duhamel, G. 1930. Interm&#232;de cin&#233;matographique ou le divertissement du libre citoyen, In: <i>Sc&#232;nes de la vie future.</i> Paris: Passim.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>713632</ref_obj_id>
				<ref_obj_pid>646956</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Fencott, C. 2001. Virtual Storytelling as Narrative Potential: Towards an Ecology of Narrative. <i>Virtual Storytelling: Using Virtual Reality Technologies for Storytelling ICVS '01.</i> Edited by Olivier Balet, Gerard Subsol and Patrice Torguet. Vol. 2197. Berlin, Heidelberg: Springer-Verlag, pp. 90--100]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Genette, G. 1980. <i>Narrative Discourse: An Essay in Method.</i> Ithaca, NY: Cornell University Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Gibson, J. 1986. <i>The Ecological Approach to Visual Perception.</i> Hillsdale, NJ; London: Erlbaum.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Hendriksen, T. D. 2006. Educational role-play: moving beyond entertainment. Seeking to please or aiming for the stars. <i>Conference paper presented at: "On Playing Roles" Seminar</i>, Tampere, FI.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>54402</ref_obj_id>
				<ref_obj_pid>54386</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Holtzblatt, K. A., Jones, S. and Good, M. 1988. Articulating the Experience of Transparency: An Example of Field Research Techniques, <i>SIGCHI Bulletin</i>, 20 (2), October, pp 46--48.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>237159</ref_obj_id>
				<ref_obj_pid>237121</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Hubbold, R., Murta, A., West, A. and Howard, T. 1995. Design Issues for Virtual Reality Systems. In: M. Gobel. (ed.), <i>Virtual Environments' 95</i>, Springer-Verlag, 224--236.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>557439</ref_obj_id>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Krug, S. and Black, R. 2000. <i>Don't Make Me Think: A Common Sense Approach to Web Usability.</i> New Riders Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Laurel, B. 1986. Interfaces As Mimesis, in Norman, D. A. and Draper, S. W. (Eds.) in <i>User Centered System Design: New Perspectives on Human-Computer Interaction.</i> Hillsdale, NJ: Lawrence Erlbaum Associates.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>529145</ref_obj_id>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Laurel, B. 1993. <i>Computers as Theatre.</i> Reading, MA: Addison-Wesley.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>178967</ref_obj_id>
				<ref_obj_pid>178951</ref_obj_pid>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Laurel, B., Strickland, R. and Tow, R. 1994. Placeholder: Landscape and Narrative in Virtual Environments, <i>Computer Graphics</i>, 28, 2, ACM SIGGRAPH, pp. 118--126.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Lombard, M. and Ditton, T. 1997. "At the Heart of It All: The Concept of Presence." <i>Electronic Journal of Computer-Mediated Communication</i> 3, 2. Accessed 04/04/08: http://jcmc.indiana.edu/vol3/issue2/lombard.html]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Marino, P. 2004. <i>3D Game-Based Filmmaking: The Art of Machinima.</i> Scottsdale, AZ: Paraglyph Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Marsh, T. 2002. <i>Towards Invisible Style of Computer-Mediated Activity: Transparency and Continuity.</i> Unpublished Ph.D Thesis, Human-Computer Interaction (HCI) Group, University of York, UK.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>976091</ref_obj_id>
				<ref_obj_pid>976083</ref_obj_pid>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Marsh, T. 2003a. Presence as Experience: film informing ways of staying there. <i>Presence: Teleoperators and Virtual Environments</i> 12, 5:538--549.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Marsh, T. 2003b. Staying there: an activity-based approach to narrative design and evaluation as an antidote to virtual corpsing, In: <i>Being There: Concepts, Effects and Measurements of User Presence in Synthetic Environments.</i> Amsterdam, The Netherlands: IOS Press, Chapter 5, 85--96.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[Marsh, T., Wong, W. L., Carriazo, E., Nocera, L., Yang, K., Varma, A., Yoon, H., Huang, Y-L, Kyriakakis, C, and Shahabi, C. 2005. User Experiences and Lessons Learned from Developing and Implementing an Immersive Game for the Science Classroom. In: <i>Proceedings of HCI International 2005</i>, Las Vegas, Nevada, USA.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[May, J., and Barnard, P. 1995. Cinematography and interface design, <i>Human-Computer Interaction: Interact '95.</i> London: Chapman and Hall, 26--31.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>196545</ref_obj_id>
				<ref_obj_pid>195966</ref_obj_pid>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[McGreevy, M. W. 1992. The Presence of Field Geologists in Mars-Like Terrain, <i>Presence: Teleoperators and Virtual Environments</i>, MIT Press, 1, 4, 375--403.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[Messaris, P. 1994. <i>Visual "Literacy": Image, Mind and Reality.</i> San Francisco: Westview Press,.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>223827</ref_obj_id>
				<ref_obj_pid>223826</ref_obj_pid>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[Nardi, B. 1996. <i>Context and Consciousness: Activity Theory and Human-Computer Interaction.</i> Nardi B, ed. Cambridge, Massachusetts: MIT Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[Nitsche, M. 2007. Claiming Its Space: Machinima <i>Dichtung Digital: New Perspectives on Digital Literature: Criticism and Analysis</i> ed. by Astrid Ensslin and Alice Bell, Vol 37.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[Nitsche, M. 2005. "Focalization in 3d Video Games." <i>FuturePlay</i>, (digital proceedings). Lansing, MI.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>288759</ref_obj_id>
				<ref_seq_no>30</ref_seq_no>
				<ref_text><![CDATA[Norman, D. 1998. <i>The Invisible Computer.</i> Cambridge, Massachusetts: MIT Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>274477</ref_obj_id>
				<ref_obj_pid>274450</ref_obj_pid>
				<ref_seq_no>31</ref_seq_no>
				<ref_text><![CDATA[Pausch, R., Snoddy, J., Taylor, R., Watson S. and Haseltine, E. 1996. "Disney's Aladdin: First Steps Toward Storytelling in Virtual Reality." pp. 357--372 in <i>Digital Illusion: Entertaining the Future with High Technology</i>, edited by C. Dodsworth Jr. London, UK: Addison-Wesley.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1215723</ref_obj_id>
				<ref_seq_no>32</ref_seq_no>
				<ref_text><![CDATA[Salen, K., and Zimmerman, E. 2003. <i>Rules of Play: Game Design Fundamentals.</i> Cambridge, Mass.: MIT Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>523237</ref_obj_id>
				<ref_seq_no>33</ref_seq_no>
				<ref_text><![CDATA[Schneiderman, B. 1987. <i>Designing the User Interface: Strategies for Effective Human-Computer Interaction.</i> Addison-Wesley Publishing Company: Reading, MA.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1246900</ref_obj_id>
				<ref_obj_pid>1246899</ref_obj_pid>
				<ref_seq_no>34</ref_seq_no>
				<ref_text><![CDATA[Slater M and Steed A. 2000. A Virtual Presence Counter, <i>Presence: Teleoperators and Virtual Environments</i>, vol. 9 Issue 5, MIT Press, 413--434.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>35</ref_seq_no>
				<ref_text><![CDATA[Weiser, M. 1991. The Computer for the Twenty-First Century. <i>Scientific American.</i> September.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>576359</ref_obj_id>
				<ref_seq_no>36</ref_seq_no>
				<ref_text><![CDATA[Winograd, T. and Flores F. 1986. <i>Understanding Computers and Cognition: A New Foundation for Design.</i> Norwood, NJ: Ablex Publishing Corporation.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Film Informing Design for Contemplative Gameplay Tim Marsh, Michael Nitsche, Wei Liu, Peichi Chung, 
Jay D. Bolter, Adrian D. Cheok National University of Singapore Georgia Institute of Technology Abstract 
Borrowing from film and filmmaking styles, techniques and devices that manipulate spectators attention 
and experience, this paper proposes an approach to inform design of games and gameplay to manipulate 
player s focus of attention and encourage contemplation in design features, characters, story elements, 
etc. or even break the player s engaged attention in the game/virtual world altogether to provide meaning, 
experience and opportunities for learning. Focusing on film styles alternative to the continuity style 
of Hollywood filmmaking, we discuss examples of design for contemplative gameplay in game­based learning 
environments/serious games, machinima and augmented and mixed reality games in previous, current and 
future projects. We propose that one goal of game design is to establish a rhythm between contemplation 
and engagement, and the appropriate rhythm is determined largely by a game s genre, platform and/or narrative. 
CR Categories: K.8.0 [Personal Computing]: General Games; H.5.1 [Information Interfaces and Presentation]: 
Multimedia Information Systems Artificial, augmented, and virtual realities Keywords: game design, film 
theory, filmmaking, French New Wave, Asian film, continuity style, engagement, interruption, reflection, 
experience, serious games, mixed reality, machinima 1 Introduction While there s on­going criticism outlining 
the differences between film and video games, game design continues to successfully draw upon cinematic 
techniques for creative inspiration and to enhance player engagement and experience. Engagement is commonly 
used to describe a positive characteristic of virtual and game environment and other interactive digital 
media design and is commonly associated with terms like agency, immersion, presence and flow. Implied 
in these terms is that users focus of attention is directed towards pursuing objectives (e.g. to play, 
learn, or be entertained, etc.). Engagement provides opportunities for user/player experience and it 
has been commonly argued that conversely, disruptions may interrupt user/player attention and consequently 
disrupt their experience. email: {tmarsh, idmliuw, cnmcp, adriancheok} @nus.edu.sg email: {michael.nitsche, 
jay.bolter} @lcc.gatech.edu Copyright &#38;#169; 2008 by the Association for Computing Machinery, Inc. 
Permission to make digital or hard copies of part or all of this work for personal or classroom use is 
granted without fee provided that copies are not made or distributed for commercial advantage and that 
copies bear this notice and the full citation on the first page. Copyrights for components of this work 
owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, to 
republish, to post on servers, or to redistribute to lists, requires prior specific permission and/or 
a fee. Request permissions from Permissions Dept, ACM Inc., fax +1 (212) 869-0481 or e-mail permissions@acm.org. 
Sandbox Symposium 2008, Los Angeles, California, August 9 10, 2008. &#38;#169; 2008 ACM 978-1-60558-173-6/08/0008 
$5.00 One early approach that aims to be antidote to disruptive interaction and so can inform design 
for engagement is the concept of transparency. Transparency has long been central to informing design 
of computer­based applications to help maintain users /players focus of attention in pursuing objectives, 
for instance in the design discipline of human­computer interaction (HCI). Much attention has been focused 
on transparency and similar concepts informing interface design [e.g. Holzblatt et al. 1988; Laurel 1986, 
1993; Nardi 1996; Norman 1998; Schneiderman 1987; Weiser 1991; Winograd and Flores 1986] and in virtual 
environments [e.g. Lombard and Ditton 1997; Slater and Steed 2000]. Transparency has been described in 
many ways and is captured well in the words of Nardi [1996 p. 11] to describe a good user interface [and 
following mastery] one that is supportive and unobtrusive, but which the user need pay little, if any, 
attention to . So having reached a level of competence or mastery in operation, interaction is performed 
with minimal conscious thought or effort and so disappears from the main focus of our attention. However, 
as Bolter and Gromola [2003] pointed out, with new and emerging media, transparency is only half the 
story because designers often want users/players to reflect on a visible interface for the experience 
it provides them. To address this limitation, they use the metaphors "window" and "mirror" for the digital 
media user interface and the corresponding attributes "transparent" (disappearing, invisible) made possible 
by mastery of techniques as opposed to "reflective" (not disappearing, visible) that helps us understand 
our experience of it . They propose that the goal of digital design is to establish a rhythm between 
a transparent window that gets out of the users way (Structuralists focus) and reflection on the interface's 
mirror that reflects the user and their contexts (Designers focus). Other work has looked to film, where 
spectator engagement is central, to address the limitations of using transparency alone to inform new 
and emerging media design. For example, Marsh [2002; 2003a] borrowed ideas from the continuity style 
of the Hollywood filmmaking process [e.g. Bordwell et al. 1988; Messaris 1994] to inform media content 
design and analysis (e.g. virtual and game environments). Continuity is to maintain a continuous, coherent 
flow of content or narrative. Bordwell et al. [1988] argue that continuity stood for smoothly flowing 
narrative and suggest that increasingly the conception of quality in films came to be bound up with the 
term continuity . Later, it came to specifically refer to a set of guidelines for cutting shots/scenes 
together. The present use of the term means both quality and a set of goals and principles or conventions 
(e.g. 180° rule, establishing shot, flashbacks, close­ups, transitions, etc.) that underlie the entire 
film s visual storytelling process. When a Hollywood film exhibits continuity, the filmic devices or 
conventions are less apparent, and become transparent or invisible to the spectator. Hence, the Hollywood 
or continuity style of filmmaking is also referred to as invisible style . Conversely, awareness of filmic 
devices or the Hollywood filmmaking process may disrupt spectators engaged experience and can be regarded 
 as discontinuity and referred to as continuity errors . These are 2 Film informing manipulation of player 
problematic/noticeable transitions, mismatches in on­screen objects and props, or narrative errors. For 
example, jump cuts in which objects appear to move or jump in position, time changes on background clocks, 
clothes are rearranged/removed from one shot to the next, firing of ten bullets from a six­shooter revolver 
or flaws in the storyline, etc. In addition to these continuity errors and largely with reference to 
early Hollywood filmmaking, Burch [1986 pp. 486­488] coined the term non­closure to refer to the reliance 
on extra information in film to supplement weak narrative and/or filmmaking process. For example, the 
hands of a clock spinning round, pages torn from a calendar, text/inter­titles between scenes or voiceovers 
(narration or commentary) to suggest spatial and temporal transitions (i.e. shifts in places/locations 
or the passing of time). Turning our attention to virtual and game environments, Marsh [2002; 2003a] 
used continuity to refer to the continuous and coherence of, and constraints imposed by, content that 
includes the imagery and audio that shape the social and cultural structure, and the unfolding narrative/story 
in which users/players interact or play. Similarly, other work has looked to the continuity style to 
inform interface design by preserving thematic continuity [May and Barnard 1995], and in the design of 
smooth animation to maintain an illusion of a perceptually consistent [virtual] world to provide continuity 
of experience [Hubbold et al. 1995] and similarly continuity of presence [McGreevy 1992]. So, in contrast 
to transparency that following mastery becomes invisible , continuity provides ways to inform and reason 
about the design of, and our experience with, virtual, game or media content that is noticeable, in­focus 
or visible to the user/player [Marsh 2002; 2003a]. While continuity addresses limitations of transparency 
and provides a way to inform design and analysis to maintain user/player engagement in visible social 
and cultural structures of virtual and gaming environments, our primary interest in this paper is in 
shifting user s/player s focus of attention between and towards design features, characters and story 
elements, or even break the player s engaged attention in the virtual/gaming world altogether to provide 
meaning, experience and opportunities for learning. In this paper we present ideas informed from film 
styles other than the Hollywood filmmaking process to inform game design towards this goal of design 
for contemplation. We propose that one goal of game design is to establish a rhythm between contemplation 
and engagement, and the appropriate rhythm is determined largely by a game s genre, platform and/or narrative. 
The next section starts by identifying criticisms leveled against the continuity style of Hollywood filmmaking 
and the corresponding goal of spectator engagement. This is followed by discussions on other filmmaking 
styles that are alternative to and in some respects intentionally subvert the Hollywood style to shift 
the spectator from the engaged to a more contemplative role. We then continue discussion on related ideas 
of focalization or point­of­view. Next we argue for incorporating similar devices discussed herein to 
inform design of interactive digital media. Focusing on digital games, we provide examples of how current 
and future moves are taking place to inform game design and gameplay for contemplation. attention / contemplation 
Film and the effect it has on an audience isn t without criticism. In his essay, Dream Machines: New 
Media as Intoxicants , Jos ten Berge [1999] presents arguments that compare the experience of film and 
new media with that obtained from Art. In particular, he refers to the frequently cited work of the French 
writer Georges Duhamel [1930] who disparagingly described film as a pastime for helots who seek solace 
in a type of entertainment requiring absolutely no effort . His remarks derive from the dynamics of moving 
images that he described as: Too much noise. Too much movement! requiring film spectators little chance 
for contemplation beyond the experience that is predetermined . Consequently, he described the mental 
state of the spectator as anaesthetised, gorged, paralysed, and hypnotic . In contrast true Art for 
Duhamel [1930] was something conquered by the mind with an effort causing what Berge [1999] describes 
as a superior and active intellectual contemplation . However, it can be argued that Duhamel s [1930] 
criticisms are not necessarily extensible to all filmmaking styles and are perhaps most applicable to 
the dominant mainstream filmmaking style of the day, that is, the invisible style or continuity style 
of Hollywood. For example, Duhamel s [1930] arguments sharply contrast with early Russian filmmakers 
(e.g. Sergei Eisenstein) who would fiercely defend their films as Art brought about by the use of editing 
techniques to form a montage of visual imagery [Arnheim 1957] whereby juxtaposed shots evoke emotion, 
experience and/or provide meaning. In addition, though more in­line with, and perhaps developing from 
Duhamel s [1930] arguments, are the development of later filmmaking styles such as, avant­garde and experimental. 
Filmmaking styles like these and others such as Asian and French New Wave, as discussed below, provide 
an alternative to, and in some respects are intentionally subverting the invisible style [Messaris 1994] 
by shifting the spectator from the entranced to a more active and contemplative role. In Japanese films 
for example, an alternative style exists whereby filmmakers use still shots and low camera angles to 
tell stories. One of the most obvious examples of this is demonstrated in the classic movies of Yasujiro 
Ozu. This low camera angle technique is most commonly used during character conflicts, with the spectator 
in the third person perspective. For example, when the characters sit on tatami mats for a Japanese tea 
ceremony, the spectator is placed in a sitting position from afar, so allowing them to engage in the 
unfolding conflict. Alternative styles are also shown when the director uses long shots or takes without 
continuity editing to build up narrative breathing space. With the camera fixed in one position, the 
spectator can then concentrate on the atmosphere built up through background music and the action playing 
out in the scene (e.g. Tokyo Story 1953; Ohayo Good Morning 1959). Another filmmaking style that provides 
an alternative to Hollywood filmmaking can be seen in the changing concept of space and speed in presenting 
character movement in Chinese cinema. Chinese kung fu cinema enhances spectator s viewing experience 
by allowing them to see the potential of the human body to engage in all kinds of actions (e.g. free 
fall, roof top flying and fast speed fist combat, etc.). Filmmakers such as Ang Lee and Zhang Yimou do 
not simply rely on editing or camera movement to engage in storytelling, rather, Chinese cinema (e.g. 
 Crouching Tiger Hidden Dragon, 2000; Hero 2002) draws the spectators attention by moving characters 
through the air using wires. This concept of unrestricted free human body movement demonstrates an alternative 
version to that of action in the traditional Hollywood cinema. While Western spectators have recently 
become familiar with these techniques, their original screenings in Western cinema in early 2000 s and 
subsequent copycatting in Hollywood films was enough to surprise and awake audiences from a hypnotic 
engaged state to a more contemplative role so adding to the excitement and experience of the film. Similar 
techniques have already been used to inform action in video games. For example, fight sequences in Heavenly 
Sword (Sony PS3) resemble both Chinese film kung fu fight sequences and, in some respects, Japanese warrior 
games. Finally, let us consider French New Wave cinema, another successful style of filmmaking in contrast 
to the Hollywood continuity style. French New Wave film encourages spectators not only to reflect or 
contemplate about what they are watching per se, but also consider the filmmaking process and devices 
used to make the film. For example, characteristics of this style of filmmaking that aim to achieve this 
are long tracking shots and fluid camera movements made possible by lightweight hand­held cameras, noticeable 
jump cuts, and corpsing (i.e. falling out of character by forgetting lines or laughing; Marsh 2003b) 
or breaking the fourth wall (i.e. deliberately stepping out of character roles in order to directly address 
the audience). These are all devices that constantly remind the audience that what they are watching 
is simply a film composed of a sequence of moving images. Pioneers of this movement (e.g. Jean­Luc Godard, 
François Truffaut) intentionally surprise, shock, startle, and interrupt spectators from an engaged state 
and draw attention to their films through these devices and others such as voiceovers (e.g. Band a Part 
, Godard, 1964) and repeated (i.e. shown more than once) and reverse (i.e. backwards) action (e.g. A 
Bout de Souffle , Godard 1959), making spectators muse or question the filmmakers intentions, the significance 
of the editing devices and commentary and their relation to the film s meaning. This is by no means an 
exhaustive discussion of the techniques, devices and filmmaking styles that encourage spectator contemplation 
and are alternative to the continuity style of Hollywood. Similar techniques and devices have also been 
used in the theater to interrupt audiences and encourage contemplation. Probably some of the most well 
known of these techniques comes from the work of the playwright Bertolt Brecht who used devices such 
as unnatural and excessive stage lighting, characters addressing the audience directly, interrupted lines, 
songs and gestures, and display boards with descriptive or explanatory text, signs or drawings. Clearly, 
all of these are similar to alternative film styles and indeed Brecht is acknowledged to have played 
an important role in influencing French New Wave filmmaking. A contributing discussion is the principle 
of focalization or point of view, which provides another narrative tradition that can be applied by game 
design and technology to support a certain direction for the user/player. Focalization originally emerged 
from a distinction between the doing and the telling about action [Genette 1980]. Based on this distinction, 
Bal defines focalization as the relationship between the vision the agent that sees, and that which is 
seen [Bal 1997 p. 146]. During any gaming situation the player is situated in­between these poles. Players 
are looking at the virtual world displayed on their screens but they also engage with them as performers 
involved in the interaction with the ongoing events. Thanks to this dual engagement, the relationship 
between the interaction and its presentation can be used to shift the focus of the player. Means of focalization 
in games [Nitsche 2005] can affect the player, for example through directed camera behavior, lights, 
or sounds. Through these adjustments games can direct players without interrupting the interactive access 
as they do not directly restrict the interaction layer but only the presentations layer of these interactive 
events. Focalization, thereby, provides a consistent way to suggest to the player without enforcing single 
solutions. A focalizing camera can invite/draw attention to a certain detail in the game world and evoke 
certain expectations of Gibson s affordances in the player [Gibson 1986]. This goes parallel to Fencott 
s principle of perceptual opportunities [Fencott 2001] but it puts a stronger emphasis on the visualization 
as a structural and affective mechanism. Relating these discussions to the work of this article, an important 
question is: how much should users be made to think or contemplate? At one extreme, advocating ideas 
of transparency from HCI (i.e. not referring to games), Krug and Black [2000] argue that users should 
not be made to think, or to think needlessly about how to operate an interface so as not to impede the 
flow of interaction. On the other hand, if interaction involves an element of reflection or contemplation 
brought about through interruption, surprise, or rousing the user/player, then designers have the potential 
to actively engage the user/player in, for example, domain knowledge and information, and/or the unfolding 
narrative/story, to provide meaning, experience and opportunities for learning. So like film, the manipulation 
of design and design features to provide shifts in focus of attention and contemplation for the user/player 
can be considered as new kinds of idioms (e.g. phrase, vernacular, language or dialect) constructed with 
a lexicon (e.g. vocabulary, glossary) just like the lexicon of film (e.g close­ups, cross cuts, flashbacks, 
etc.) between directors and spectators [Pausch et al. 1998]. Thus, in the words of Laurel et al. [1994] 
provide the potential to design virtual and game environments and interactive digital media of increasing 
complexity and power . Continuing discussions on film from above, it will also provide the potential 
to design virtual and game environments and digital media that are more contemplative and in turn, satisfying 
and fulfilling beyond the experience that is predetermined . In the next section we present examples 
of ideas informed from film styles other than the Hollywood filmmaking process to inform game design 
for contemplation. In order to assist the reader, table 1 brings together some of the examples outlined 
in discussions above on techniques and devices largely associated with non­continuity filmmaking styles 
to surprise, interrupt, rouse, and provide emphasis, humor, experience and meaning to inform game design 
for contemplation. Technique / Device Description &#38; Effect / Affect Transitions and edits technique 
by which shots, scenes or animations are juxtaposed, usually influenced by narrative, to suggest spatial 
and temporal change (shift in places/locations or the passing of time) or convey mood and meaning: jump 
cut edit in which a section of a continuous shot or animation is removed and discarded so that objects 
and characters, etc. appear to jump to a new position, to interrupt and surprise montage juxtaposed 
shots or images to surprise, shock, evoke emotion, experience and/or provide meaning fades screen/display 
turns black, white or blank, etc. to momentarily interrupt or pull the spectator/player out of an engaged 
state Voiceovers narration or commentary on events, action or story, or to provide extra information, 
to interrupt, surprise, etc. Breaking the fourth wall character deliberately stepping out of their role 
in order to address an audience/player directly, to interrupt and startle Corpsing falling out of character, 
usually through forgetting lines or by laughing, startling and injecting a sense of humor Focalization 
invite, interrupt or direct attention to emphasize certain objects or details in the film/game world 
through directed camera behavior, lights, or sounds Non­closure devices provide emphasis or extra information 
to supplement narrative such as, inter­titles between shots, the hands of a clock spinning round or pages 
torn from a calendar, to suggest shifts in places/locations/spaces or the passing of time Repeat action 
replaying of action, event, music, dialogue or sound to interrupt, surprise and emphasize Reverse action 
backwards or reverse showing of action, event or sound to interrupt, startle and add humor Display board 
static or dynamic notice/poster/window with text, sign or drawing to emphasize, describe, illustrate, 
interrupt, add humor, etc. Table 1: Some examples of techniques/devices largely associated with filmmaking 
styles alternative to the Hollywood continuity style to surprise, interrupt, rouse, and provide emphasis, 
humor, experience and meaning to inform game design for contemplation 3 Between Engagement &#38; Contemplation 
This section presents design ideas and concepts informed from film styles other than the Hollywood filmmaking 
process to inform game design towards a goal of design for contemplation. But what will these devices 
look like in digital games? We discuss examples of design in game­based learning environments/serious 
games, machinima and augmented and mixed reality games in past, current and future projects. 3.1 Educational 
Serious Games Initial research was carried out in order to investigate the proposed ideas of manipulating 
user focus of attention by revisiting the development of an educational learning environment or serious 
game. Hendriksen [2005] talks about a similar goal for design of game­based learning but focuses on the 
concept of flow. We utilize, in particular, the ideas from film and filmmaking styles that have been 
argued herein, some of which are outlined in table 1, to help in our analysis, interpretation and reasoning 
of why design solutions were successful. In addition, recommendations to address design and learning 
problems captured in studies are provided. A serious game has been developed in the Integrated Media 
Systems Center (IMSC) at the University of Southern California (USC) [Marsh et al. 2005]. The games objective 
is to help students learn the physiology and biological processes of human organs. It consists of two 
learning activities or missions: Nature Pumps mission helps students learn the processes of digestion 
and absorption of nutrients, and the Control Systems mission teaches students the roles of glucagon and 
insulin in maintaining blood glucose levels. Throughout the development cycle, many analytic and empirical 
studies were carried out to make improvements in development. This earlier work focused on the concept 
of transparency and breakdown in transparency to detect problems mainly associated with usability, but 
also some aspects related to user experience In one study session, an expert games player completed the 
game missions more efficiently and faster than any of the other players but scored lower in a post­study 
learning questionnaire than in the pre­study baseline questionnaire, suggesting that he learnt very little 
from playing the educational game. This indicates problematic design whereby the user was allowed to 
proceed through the game and complete it without having to think about the content of the game. In the 
development of the game, one aim was to include many game­like design features or devices so the game 
would be more appealing, exciting and motivating for users, in an attempt to reach a balance between 
fun and education. For our example game player, it can be reasoned that these design features were very 
familiar, requiring little conscious attention in interaction in their operation; that is, they can be 
considered to be transparent to the player. While he self­reported in a debriefing session that he had 
enjoyed playing the game, the questionnaire results suggest that he had learnt very little and indeed 
in one mission he learnt nothing.  Figure 1: Left­hand side is an earlier version of the educational 
serious game environment with design problems and on the right­hand side a later version with the design 
problems resolved. This shows many examples of using design features to manipulate user focus of attention 
and encourage contemplation. For example: ­animated design features represent abstractions of chemical 
and biological processes. The more intuitive the design the more transparent and less players have to 
contemplate about their meaning. ­sliding instruction box appears at the bottom right­hand side of the 
screen for a short duration as a reminder to subjects of their tasks/goals. This shifts player s attention 
to consider their past and planned actions. ­revolving green cylinder with black arrows in the membrane 
wall helps players understand that they may pass through it. The green cylinder is a device to manipulate 
player s attention, encourage contemplation and provide meaning which in this case means there is a 
space to explore beyond this membrane wall. Using the ideas proposed in this paper, some of which are 
outlined in table 1, we can identify that the challenge for design to overcome this problem is to ensure 
that design aspects or features introduced are not too familiar so as to be transparent, requiring little 
conscious thought, but instead encourage the player to contemplate the subject matter and in turn learn. 
For example, the simplest solution would be to make players pause to answer a question correctly about 
the subject matter before being able to proceed further within the game. A more elegant solution is to 
incorporate this into a device, feature or plot/narrative design that is not too familiar to players 
so as not to be transparent in operation but requires a level of contemplation to reflect on the subject 
matter and hence, to encourage the player to learn as well as play. Utilizing the techniques or devices 
shown in table 1 provides a way to achieve this and design gameplay for contemplation, which in turn 
can help players to learn. In reference to Figure 1, the left­hand side shows an earlier version of the 
educational serious game environment with design problems captured in empirical studies and on the right 
hand side a later version is shown with the design problems resolved. This shows many examples of using 
design features to manipulate users /players focus of attention and encourage contemplation. For example, 
the simple animated design features (e.g. arrows and spheres) represent abstractions of chemical and 
biological processes taking place inside the human body. Using the ideas proposed herein we can reason 
that the more intuitive the design the more transparent and so players have to think less to understand 
the meaning. In the example, one can intuitively understand from the animation, the direction of flow 
and see any corresponding effects that are directly or indirectly caused. If a deeper understanding of 
the chemical and biological processes is required then alternative design features and/or different animation 
is required (e.g. voiceover or display boards) to encourage contemplation and provide meaning. Another 
example illustrated in Figure 1, is the sliding instruction or task box which is a good example of a 
display board as described in table 1. It was found in a study sessions that tasks were not explicitly 
explained, and in some case players forgot current tasks and/or tended to be unaware of the next task 
in order to complete the mission. A sliding instruction box appearing at the bottom right­hand side of 
the screen for a short duration as a reminder of their goals was found to resolve this problem. From 
studies we know that the sliding box broke or shifted players attention, and so using the ideas from 
film proposed herein, we can reason that user s then considered the intended task and contemplated their 
actions (past and planned) in order to achieve the task. Finally, it was found in empirical studies that 
players had no idea that they pass through an opaque membrane wall. The introduction of a revolving green 
cylinder with black arrows, as shown in Figure 1, was an attempt to indicate to users that they could 
walk through the membrane and explore the space beyond it. Perhaps this is not the most elegant of solutions, 
but in follow­up empirical studies it was found that all users correctly established that they could 
pass though the membrane. In debriefing sessions, many users confirmed that the design feature made them 
question why it was there and following a short period of contemplation, utilize it accordingly. This 
corresponds to, and its effect can be described well by, the design techniques/devices of focalization 
(i.e. directing/interrupting attention) and non­closure (i.e. providing supplementary information). Finally, 
looking at the broader picture, while an important challenge has been to design games to engage students 
exclusively in gaming activities to learn, less focus appears to be on the design of games to allow students 
to learn through game play combined with collaboration with other students in the classroom in the real 
world. Techniques or devices introduced herein to deliberately interrupt or break attention in engaged 
game play at appropriate times to promote contemplation and/or discussion may help with this collaborative 
learning approach. For example, at a predefined point in gameplay, characters break the fourth wall (see 
table 1) by turning to players and addressing them directly by asking questions and/or inviting them 
to discuss with other students any issues or concerns that arose out of gameplay. Similar effects can 
also be achieved through the use of devices such as, fades, displays boards and voiceovers whereby follow­on 
exercise instructions are described or narrated to players/students to interrupt or pull them from an 
engaged state.  3.2 Mixed Reality Games: Human Pacman Based on the popular arcade Pacman game using 
ubiquitous computing and mixed/augmented reality (AR) technologies, Human Pacman is a role­playing computer 
game that blends the natural physical world seamlessly with a fantasy virtual playground. It was developed 
in the Mixed Reality Labs at the National University of Singapore [Cheok et al. 2004]. It combines real 
human­social and mobile­gaming, providing collaboration and competition between players in both the wide 
outdoor physical areas and the computer game world. With Human Pacman, Pacmen and Ghosts are real human 
players who can move around in the wide outdoor game area and perform tasks to reach their goals and 
experience mixed computer graphics fantasy­reality provided by using wearable computers (Figure 2). Following 
the 2D arcade Pacman game rules, Virtual cookies are incorporated into the game for the Pacman player 
to collect by physically walking through them and tangible physical objects are used as super cookies 
for the Pacman player to physically collect to obtain ghost­devouring power for a predetermined time. 
In order to increase players experience and motivate them to keep playing, we are in the process of adding 
new design features to manipulate players focus of attention. The design features aim to introduce a 
degree of contemplation in the game for the players. This will be achieved by players being able to send 
information, codes and other agreed conventions to other players in order for them to be able to construct 
meaning and increase the complexity and experience in the game. For example, as illustrated in Figure 
3, text messages indicating that an enemy is close by and virtual design features such as arrows (e.g. 
non­closure and focalization) that appear superimposed with the real world through the player s AR goggles, 
interrupt as well as guide them where to go to escape from the enemy are sent one from one team member 
to another. Other windows (e.g. display boards) shown here are presented to players intermittently to 
interrupt, emphasize, alarm, illustrate, etc. These devices indicate the position of other team members, 
provide a bird s eye view location map of the player and others in the immediate vicinity and details 
of weaponry, if any. We are also investigating the use of other devices illustrated in table 1, such 
as, voiceovers to narrate or provide commentary on events and action, to interrupt, surprise, shock or 
even amuse. Figure 2: Human pacman players with AR goggles and hand­held controls in the real­world 
playground Figure 3: Player s point­of­view of real world playground seen through AR goggles showing 
superimposed codes information and conventions  3.3 Machinima and Mixed Media Another example where 
the potential of these techniques and devices can be applied is machinima. Machinima is defined as filmmaking 
with a real­time virtual 3D environment [Marino 2004]. The term machinima originated from the combination 
of machine and cinema and the format has thrived as a hybrid for more than a decade. In the creation 
of a machinima production, players become producers, directors, camera operators and performers to stage 
and present an event in a game space. These productions are forms of emergent play [Salen and Zimmerman 
2003] that utilize the predetermined settings of the game but strive toward the cinematic and apply mainly 
the tools of film language. Through this process machinima productions become an expression based on 
play where cinematic traditions and game play interactions converge. The results are inherently intertextual 
employing established visual as well as narrative traditions on the one side and game settings and operations 
on the other [Nitsche 2007]. As machinima is essentially a linear presentation of gameplay, that includes 
events, lights, camera angles, etc. in a gaming environment, many of the techniques from alternative 
styles of film other than the continuity style of Hollywood and focalization discussed earlier and outlined 
in table 1, can be applied and incorporated to provide a level of contemplation for the user/player. 
For example, devices such as transitions (fades, montage, jump cuts) and repeat and reverse action to 
surprise, startle, interrupt and provide meaning. The Second Life Augmented Reality project conducted 
by MacIntyre, Bolter, Nitsche, and Farley at Georgia Tech originated as such a machinima production environment 
in which the client of the massively multiplayer online world of LindenLab s Second Life was connected 
to an Augmented Reality interface. This combination resulted in a mixed media set up where real performers 
can see themselves in virtual worlds or can project virtual avatars into the image of the real world. 
 Figure 4: Museum of the Mind machinima (Vandagriff 2008) avatar projected into the real world Figure 
5: Live mixed media performance between real improvisation actors and virtual character The static­camera 
set up as seen in Figure 4 and Figure 5 creates a shared stage as it combines the images of physical 
and virtual world live on a single screen creating a form of mixed media proscenium. Limiting as this 
visual frame might be, it provides a space in which narrative/action can be played out. In addition, 
the same interface can be operated using a head­mounted display that allows complete freedom of view 
as it incorporates a first­person point of view based on the physical situation of the user. As we move 
into a new era of ubiquitous, mobile, mixed and augmented reality games, opportunities are opening to 
design novel ways to manipulate users /players focus of attention to shift between engagement and contemplation. 
We anticipate that as we search for new ways to inform design of new and emerging gameplay, increased 
focus will be placed upon techniques, such as those in table 1, to inform design to invite contemplation 
 whether that is to stir, shock, anger, amuse and/or arouse. 4 Discussion The main purpose of this paper 
has been to inform analysis and design of techniques and devices to manipulate user/player s focus of 
attention in digital games. To do this, we have borrowed techniques largely from filmmaking as a means 
to encourage the player to consider or contemplate the virtual or gaming environment, so providing meaning, 
experience and opportunities for learning. We focused on film styles alternative to the continuity style 
of Hollywood filmmaking and then discussed examples of design for contemplative gameplay in game­based 
learning environments/serious games, machinima and augmented and mixed reality games in previous, current 
and future projects. It is acknowledged that some of the techniques outlined in this paper may already 
be in use in games in one form or another however the work herein provides concepts, arguments and a 
language to categorize a range of techniques and devices for the design of contemplative gameplay. The 
proposed ideas to inform design to manipulate player focus of attention represents an example to develop 
idioms or conventions for virtual, mixed and game environments, and so provide the potential for designs 
of increasing complexity and power . One goal of future work is to investigate how games technology, 
genre and narrative determine the appropriate rhythm between contemplative and engaging gameplay. Finally, 
in on­going work we are using the same approach to that described herein to reason about the manipulation 
of users experience with new and emerging interactive and digital media. Acknowledgements Thanks to members 
of the 2020Classroom project IMSC, USC. References ARNHEIM, R. 1957. Film as Art. Berkley. Los Angeles: 
University of California Press. BAL, M. Narratology. 1997. Toronto; Buffalo; London: University of Toronto 
Press Inc. BERGE J. 1999. Dream Machines New Media as New Intoxicants. In: Stimuli: Too much noise. Too 
much movement, published following the exhibition Stimuli at Witte de With, centre for contemporary art, 
Rotterdam. Printed by: Belgium, Ghent: Snoeck­Ducaju &#38; Zoom, pp. 15­28. BOLTER, J.D. AND GROMALA, 
D. 2003. Windows and Mirrors: Interaction Design, Digital Art, And The Myth of Transparency. Cambridge, 
MA: MIT Press. BORDWELL, D., STAIGER, J. AND THOMPSON, K. 1988. The Classical Hollywood Cinema Styles 
&#38; Mode of Production to 1960. London: Routledge. CHEOK, A. D., GOH, K.H., LIU, W., FARBIZ, F., FONG, 
S.W., TEO, S.L., LI, Y., AND YANG, X. 2004. Human Pacman: a mobile, wide­area entertainment system based 
on physical, social, and ubiquitous computing. Personal and Ubiquitous Computing, Volume 8, Issue 2, 
May, pp. 71 81. DUHAMEL, G. 1930. Intermède cinématographique ou le divertissement du libre citoyen, 
In: Scènes de la vie future. Paris: Passim. FENCOTT, C. 2001. Virtual Storytelling as Narrative Potential: 
Towards an Ecology of Narrative. Virtual Storytelling: Using Virtual Reality Technologies for Storytelling 
ICVS 01. Edited by Olivier Balet, Gerard Subsol and Patrice Torguet. Vol. 2197. Berlin, Heidelberg: Springer­Verlag, 
pp. 90­100 GENETTE, G. 1980. Narrative Discourse: An Essay in Method. Ithaca, NY: Cornell University 
Press. GIBSON, J. 1986. The Ecological Approach to Visual Perception. Hillsdale, NJ; London: Erlbaum. 
HENDRIKSEN, T.D. 2006. Educational role­play: moving beyond entertainment. Seeking to please or aiming 
for the stars. Conference paper presented at: On Playing Roles Seminar, Tampere, FI. HOLTZBLATT, K.A., 
JONES, S. AND GOOD, M. 1988. Articulating the Experience of Transparency: An Example of Field Research 
Techniques, SIGCHI Bulletin, 20 (2), October, pp 46­48. HUBBOLD, R., MURTA, A., WEST, A. AND HOWARD, 
T. 1995. Design Issues for Virtual Reality Systems. In: M. Gobel. (ed.), Virtual Environments' 95, Springer­Verlag, 
224­236. KRUG, S. AND BLACK, R. 2000. Don't Make Me Think: A Common Sense Approach to Web Usability. 
New Riders Press. LAUREL, B. 1986. Interfaces As Mimesis, in Norman, D.A. and Draper, S.W. (Eds.) in 
User Centered System Design: New Perspectives on Human­Computer Interaction. Hillsdale, NJ: Lawrence 
Erlbaum Associates. LAUREL, B. 1993. Computers as Theatre. Reading, MA: Addison­Wesley. LAUREL, B., STRICKLAND, 
R. AND TOW, R. 1994. Placeholder: Landscape and Narrative in Virtual Environments, Computer Graphics, 
28, 2, ACM SIGGRAPH, pp. 118­126. LOMBARD, M. AND DITTON, T. 1997. At the Heart of It All: The Concept 
of Presence. Electronic Journal of Computer­Mediated Communication 3, 2. Accessed 04/04/08: http://jcmc.indiana.edu/vol3/issue2/lombard.html 
MARINO, P. 2004. 3D Game­Based Filmmaking: The Art of Machinima. Scottsdale, AZ: Paraglyph Press. MARSH, 
T. 2002. Towards Invisible Style of Computer­Mediated Activity: Transparency and Continuity. Unpublished 
Ph.D Thesis, Human­Computer Interaction (HCI) Group, University of York, UK. MARSH, T. 2003a. Presence 
as Experience: film informing ways of staying there. Presence: Teleoperators and Virtual Environments 
12,5:538­549. MARSH, T. 2003b. Staying there: an activity­based approach to narrative design and evaluation 
as an antidote to virtual corpsing, In: Being There: Concepts, Effects and Measurements of User Presence 
in Synthetic Environments. Amsterdam, The Netherlands: IOS Press, Chapter 5, 85­96. MARSH, T., WONG, 
W.L., CARRIAZO, E., NOCERA, L., YANG, K.,VARMA, A., YOON, H., HUANG, Y­L, KYRIAKAKIS, C, AND SHAHABI, 
C. 2005. User Experiences and Lessons Learned from Developing and Implementing an Immersive Game for 
the Science Classroom. In: Proceedings of HCI International 2005, Las Vegas, Nevada, USA. MAY, J., AND 
BARNARD, P. 1995. Cinematography and interface design, Human­Computer Interaction: Interact 95. London: 
Chapman and Hall, 26­31. MCGREEVY, M. W. 1992. The Presence of Field Geologists in Mars­Like Terrain, 
Presence: Teleoperators and Virtual Environments, MIT Press, 1, 4, 375­403. MESSARIS, P. 1994. Visual 
Literacy : Image, Mind and Reality. San Francisco: Westview Press,. NARDI, B. 1996. Context and Consciousness: 
Activity Theory and Human­Computer Interaction. Nardi B, ed. Cambridge, Massachusetts: MIT Press. NITSCHE, 
M. 2007. Claiming Its Space: Machinima Dichtung Digital: New Perspectives on Digital Literature: Criticism 
and Analysis ed. by Astrid Ensslin and Alice Bell, Vol 37. NITSCHE, M. 2005. "Focalization in 3d Video 
Games." FuturePlay, (digital proceedings). Lansing, MI. NORMAN, D. 1998. The Invisible Computer. Cambridge, 
Massachusetts: MIT Press. PAUSCH, R., SNODDY, J., TAYLOR, R., WATSON S. AND HASELTINE, E. 1996. Disney 
s Aladdin: First Steps Toward Storytelling in Virtual Reality. pp. 357­372 in Digital Illusion: Entertaining 
the Future with High Technology, edited by C. Dodsworth Jr. London, UK: Addison­Wesley. SALEN, K., AND 
ZIMMERMAN, E. 2003. Rules of Play: Game Design Fundamentals. Cambridge, Mass.: MIT Press. SCHNEIDERMAN, 
B. 1987. Designing the User Interface: Strategies for Effective Human­Computer Interaction. Addison­Wesley 
Publishing Company: Reading, MA. SLATER M AND STEED A. 2000. A Virtual Presence Counter, Presence: Teleoperators 
and Virtual Environments, vol. 9 Issue 5, MIT Press, 413­434. WEISER, M. 1991. The Computer for the Twenty­First 
Century. Scientific American. September. WINOGRAD, T. AND FLORES F. 1986. Understanding Computers and 
Cognition: A New Foundation for Design. Norwood, NJ: Ablex Publishing Corporation.  
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
	</article_rec>
	</section>
	<section>
		<section_id>1401863</section_id>
		<sort_key>200</sort_key>
		<section_seq_no>5</section_seq_no>
		<section_type>SESSION</section_type>
		<section_title><![CDATA[Navigation, physical and spatial]]></section_title>
		<section_page_from>107</section_page_from>
	<article_rec>
		<article_id>1401864</article_id>
		<sort_key>210</sort_key>
		<display_label>Pages</display_label>
		<pages>8</pages>
		<article_publication_date>08-09-2008</article_publication_date>
		<seq_no>1</seq_no>
		<title><![CDATA[Integrating video games and robotic play in physical environments]]></title>
		<page_from>107</page_from>
		<page_to>114</page_to>
		<doi_number>10.1145/1401843.1401864</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1401864</url>
		<abstract>
			<par><![CDATA[<p>Active Learning Environments with Robotic Tangibles (ALERT) are mixed reality video gaming systems that use sensors, vision systems, and robots to provide an engaging experience that may motivate hitherto underrepresented kinds of learners to become interested in game design, programming, and careers in science, technology, engineering, and mathematics. Through the use of fiducials (i.e., meaningful markers) recognized by robots through computer vision as just-in-time instructions, users engage in spatially-based programming without the encumbrances of traditional procedural programs? syntax and structure. Since humans, robots, and video environments share many inherently spatial qualities, this natural style of physical programming is particularly well suited to fostering playful interactions with mobile robots in dynamic video environments. As these systems broaden the capabilities of video game technology and human-robot interaction (HRI) they are lowering many existing barriers to integrated video-robot game development and programming. Diverse ALERT video game scenarios and applications are enabling a broad range of gamers, learners, and developers to generate and engage in their own physically interactive games.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[embodied learning]]></kw>
			<kw><![CDATA[mobile robots]]></kw>
			<kw><![CDATA[participatory design]]></kw>
			<kw><![CDATA[tangible media]]></kw>
			<kw><![CDATA[video games]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1100737</person_id>
				<author_profile_id><![CDATA[81435602025]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Byron]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Lahey]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Arizona State University, Tempe, AZ]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1100738</person_id>
				<author_profile_id><![CDATA[81366590839]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Winslow]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Burleson]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Arizona State University, Tempe, AZ]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1100739</person_id>
				<author_profile_id><![CDATA[81338488882]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Camilla]]></first_name>
				<middle_name><![CDATA[N&#248;rgaard]]></middle_name>
				<last_name><![CDATA[Jensen]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Arizona State University, Tempe, AZ]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1100740</person_id>
				<author_profile_id><![CDATA[81392595602]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Natalie]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Freed]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Arizona State University, Tempe, AZ]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1100741</person_id>
				<author_profile_id><![CDATA[81365596318]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Patrick]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Lu]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Arizona State University, Tempe, AZ]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[BattleBots. Accessed 28 May 2008. http:\www.battelebots.com/]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>986097</ref_obj_id>
				<ref_obj_pid>985921</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Bickmore, T. W., and Picard, R. W. 2004. Towards caring machines. In CHI '04 Extended Abstracts on Human Factors in Computing Systems (Vienna, Austria, April 24 - 29, 2004). CHI '04. ACM, New York, 1489--1492.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1179329</ref_obj_id>
				<ref_obj_pid>1179295</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Birchfield, D., Ciufo, T., and Minyard, G. 2006. SMALLab: a mediated platform for education. In ACM SIGGRAPH 2006 Educators Program. SIGGRAPH '06. ACM, New York, 33.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>330541</ref_obj_id>
				<ref_obj_pid>330534</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Bobick, A., Intille, S., Davis, J., Baird, F., Pinhanez, C., Campbell, L., Ivanov, Y., Sch&#252;tte, A., Wilson, A., 2000. The KidsRoom. <i>Communications of the ACM</i>, Vol. 43, No. 3, 60--61.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1357123</ref_obj_id>
				<ref_obj_pid>1357054</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Buechley, L., Eisenberg, M., Catchen, J., and Crockett, A. 2008. The LilyPad Arduino: Using Computational Textiles to Investigate Engagement, Aesthetics, and Diversity in Computer Science Education, CHI 2008 Proceedings, Florence, Italy.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1304506</ref_obj_id>
				<ref_obj_pid>1304059</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Burleson, W., Picard, R. W. "Evidence for Gender Specific Approaches to the Development of Emotionally Intelligent Learning Companions," IEEE Intelligent Systems, Special issue on Intelligent Educational Systems, Vol 22, No 4, July 2007, pp. 62--69.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1149137</ref_obj_id>
				<ref_obj_pid>1149126</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Cavallo, D., Sipitakiat, A., Basu, A., Bryant, S., Welti-Santos, L., Maloney, J., Chen, S., Asmussen, E., Solomon, C., Ackermann, E. 2004. RoBallet: Exploring Learning through Expression in the Arts through Constructing in a Technologically Immersive Environment. Accessed 28 May 2008 from www.media.mit.edu/~edith/publications/collective %20papers/RoBallet%20icls2004-cavallo-1.pdf]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Center for LifeLong Learning and Design. Accessed 28 May 2008 at http://13d.cs.colorado.edu/]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Center for Youth and Communities, Brandeis University, 2005. FIRST Robotics Competition Evaluation: Executive Summary, Accessed 28 May 2008 at www.usfirst.org/uploadedFiles/Who/Impact/Brandeis_Studies/05FLL_Underserved_Summary.pdf]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Clarke, A. C. 1984. <i>Profiles of the future: An inquiry into the limits of the possible.</i> New York: Holt, Rinehart &amp; Winston.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Gardner, H. 1983. <i>Frames of mind: The theory of multiple intelligences.</i> New York: Basic Books.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Hayes, B., 2007. GameStar Mechanic Monday: Betty Hayes on the academic goals of GameStar Mechanic. Accessed 28 May 2008 at http://www.gamelab.com/reports/2007-oct-gamestar _mondays_5]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Intel Corporation. Intel&#174; Play#8482; Me2Cam* Computer Video Camera. Accessed 28 May 2008 at http://www.intel.com/support/intelplay/me2cam/]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[iRobot Corp. iRobot&#174; Roomba&#174; Vacuum Cleaning Robots. Accessed 28 May 2008 at www.irobot.com/sp.cfm?pageid=122]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[LEGO Group. Accessed 28 May 2008 at http://www.lego.com]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Lifelong Kindergarten. Projects. Accessed 28 May 2008 at http://llk.media.mit.edu/projects.php]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Logo Foundation. Accessed 28 May 2008 at http://el.media.mit.edu/logo-foundation/]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Microsoft Corp. 1997. Microsoft ActiMates Interactive Barney to Interact With "Barney &amp; Friends" on PBS. Accessed 28 May 2008 at http://www.microsoft.com/presspass/press/1997/sept97/mspbspr.mspx]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1095592</ref_obj_id>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Papert, S. 1980. <i>Mindstorms: Children, computers, and powerful ideas.</i> New York: Basic Books.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>265013</ref_obj_id>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Picard, R. W. 1997. <i>Affective computing.</i> MIT Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[reacTIVision 1.3. Accessed 2 June 2008 at http://reactable.iua.upf.edu/?software]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Resnick, M. 1991. MultiLogo: A Study of Children and Concurrent Programming. <i>Interactive Learning Environments</i>, vol. 1, no. 3, pp. 153--170.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[Robocup. Accessed 28 May 2008 at http://www.robocup.org/]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[Robotics Institute at Carnegie Mellon University. 2004. The Personal Exploration Rover. Accessed 28 May 2008 at http://www.cs.cmu.edu/~myrover/PER/]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[RoombaComm. Accessed 2 June 2008 at http://hackingroomba.com/code/roombacomm/]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Integrating Video Games and Robotic Play in Physical Environments Byron Lahey,1 Winslow Burleson,1, 
2 Camilla Nørgaard Jensen,1 Natalie Freed,2 Patrick Lu2 Arts Media and Engineering1 / School of Computer 
Science and Informatics2 Arizona State University, Tempe, AZ 85281 Abstract Active Learning Environments 
with Robotic Tangibles(ALERT) are mixed reality video gaming systems that usesensors, vision systems, 
and robots to provide an engagingexperience that may motivate hitherto underrepresented kinds oflearners 
to become interested in game design, programming, andcareers in science, technology, engineering, and 
mathematics.Through the use of fiducials (i.e., meaningful markers)recognized by robots through computer 
vision as just-in-timeinstructions, users engage in spatially-based programmingwithout the encumbrances 
of traditional procedural programs syntax and structure. Since humans, robots, and video environments 
share many inherently spatial qualities, thisnatural style of physical programming is particularly well 
suitedto fostering playful interactions with mobile robots in dynamicvideo environments. As these systems 
broaden the capabilitiesof video game technology and human-robot interaction (HRI)they are lowering many 
existing barriers to integrated video­robot game development and programming. Diverse ALERTvideo game 
scenarios and applications are enabling a broadrange of gamers, learners, and developers to generate 
andengage in their own physically interactive games. CR Categories: Games. Video. Robotics. Collaborative 
and Informal Learning. Collaborative Computing. User Centered Design. Prototyping. Interactive Environments. 
Artificial, Augmented and Virtual Realities. Keywords: Mobile Robots, Tangible Media, Video Games, Embodied 
Learning, Participatory Design. 1 Introduction: Robots and Video Games This paper presents a new interaction 
and developmentparadigm for video-robot game development and play. Videogames are becoming more and more 
physically interactivethrough the use of low-cost sensors (e.g., accelerometers) andcomputer vision systems. 
Robots, which have always beenphysical, are becoming affordable and ubiquitous. Likewise,robots are incorporating 
a greater variety of sensors and advanced computer vision systems. Most importantly, robotsand mixed 
reality robot systems are becoming more playful!These concurrent advances are creating new synergies 
for theadvancement of video games and novel human-robot interactions (HRI) through play and learning 
experiences. Advances in the technological medium of video games have recently included the deployment 
of physical activity-based controller technologies, such as the Wii, and vision-based controller systems, 
such as Intel s Me2Cam [Intel Corporation]. Copyright &#38;#169; 2008 by the Association for Computing 
Machinery, Inc. Permission to make digital or hard copies of part or all of this work for personal or 
classroom use is granted without fee provided that copies are not made or distributed for commercial 
advantage and that copies bear this notice and the full citation on the first page. Copyrights for components 
of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy 
otherwise, to republish, to post on servers, or to redistribute to lists, requires prior specific permission 
and/or a fee. Request permissions from Permissions Dept, ACM Inc., fax +1 (212) 869-0481 or e-mail permissions@acm.org. 
Sandbox Symposium 2008, Los Angeles, California, August 9 10, 2008. &#38;#169; 2008 ACM 978-1-60558-173-6/08/0008 
$5.00 The rapid deployment of millions of iRobot Roomba home robots [iRobot Corp.] and the great popularity 
of robotic play systems, such as LEGO Mindstorms and NXT [LEGO Group] now presents an opportunity to 
extend the realm of video game advances even further, into physical environments, through the direct 
integration of human-robot interaction techniques and architectures with video game experiences. Over 
the past thirty to forty years, a synergistic evolution ofrobotic and video game-like programming environments, 
suchas Turtle Logo [Papert 1980], has occurred. At the MIT MediaLab, these platforms have been advanced 
through the constructionist pedagogies, research, and collaborations ofSeymour Papert, Marvin Minsky, 
Mitch Resnick, and theircolleagues, leading to Logo [Logo Foundation], Star Logo[Resnick 1991], programmable 
Crickets and Scratch [LifelongKindergarten] and Lego MindStorms [Resnick 1991]. In 2000,Kids Room [Bobick 
et al. 2000] demonstrated that an immersiveeducational gaming environment with projected objects andcharacters 
in physical spaces (e.g., on the floor or walls), couldinvolve children in highly interactive games, 
such as hide-and­seek. In 2004, RoBallet [Cavallo et al. 2004] advanced theseconstructionist activities 
further, blending elements of projectedvirtual environments with sensor systems that reacted to childrendancing 
in a mediated physical environment. The realm of toysand robotic pets has also seen the development of 
a wide arrayof interactive technologies (e.g., Furby, Aibo, Tamagotchi) and more recently Microsoft s 
Barney [Microsoft Corporation1997], which has been integrated with TV-based video content.Interactive 
robotic environments for education are now beingextended to on-line environments, such as CMU s educationalMars 
rover [The Robotics Institute at CMU], and becomingpopular through robotics challenges such as FIRST 
RoboticsCompetition [Center for Youth and Communities, BrandeisUniversity, 2005], BattleBots [BattleBots], 
and Robot WorldCup soccer tournaments [Robocup]. Figure 1: iRobot Create, laptop, and servo-mounted 
camera, observing a fiducial marker with human-legible whirlpool icons. Video game technologies are also 
extending their range of impact in education through game development environments, such as Game Star 
Mechanics [Hayes 2007], and SMALLab [Birchfield et al. 2006] (discussed further below), in which children 
get to create their own games. In the LifeLong Learning and Design research group at the University of 
Colorado at Boulder [The Center for LifeLong Learning and Design], the constructionist activities have 
integrated technology with traditional crafts such as sewing and weaving. An exciting quality of these 
new gaming and programming environments, which engage users in self-motivated and collaborative gaming 
activities, is that girls and underserved minorities are readily adopting them [Buechley et al. 2008]. 
This paper presents research and development work that demonstrates a wide range of possibilities for 
video-robot games with a particular focus on players physical interactions with robots and immersive 
video game environments. ALERT systems are supporting play, learning, programming, and end­user game 
design, and have been applied by users to the development of advanced video game scenarios and applications 
as diverse as terrain-mapping, pet-building, and Astronaut Robot Mission Simulators. These examples show 
that ALERT systems are suitable for a wide range of ages and skill levels, for girls and underserved 
minorities who have tended not to pursue Science, Technology, Engineering, and Math (STEM) topics, and 
for people of varied economic levels (since the systems are accessible via the Internet). Participatory 
design and evaluation is showing that ALERT systems can engage a new generation of gamers, learners, 
and developers with video games and robotics in ways that nurture intrinsic motivations.  2 System Architectures 
2.1 Robotics Architecture The core architecture of all of the scenarios and applications (see section 
3 for scenarios and applications) is the robotics system architecture. The Create (produced by iRobot, 
which makes the popular Room ba autonomous vacuuming robot) is the foundation of that architecture. It 
is designed to be a relatively low-cost, user-friendly platform, programmable and physically expandable 
by users who are interested in robotics but may not have the time, tools, or expertise to build their 
own mechanical robotics foundation. Using the Create lets our research focus on programming and interactions, 
while also making our results highly accessible to schools, museums, and individuals who can thus apply 
the same technologies in their own environments. We have equipped the iRobot Creates with cameras that 
enable them to see the physical environment. In the physical environment we use fiducials [Fig. 1] or 
meaningful markers to provide just-in-time instructions to the robots. The fiducials can be placed physically 
or projected onto the floor or attached to the robots [Fig. 5]. (We have also, at times, presented fiducials 
on PDA s, mobile phone screens, and other mobile devices that are easily carried by people and robots.) 
The instructions associated with each fiducial allow the Create to respond, in real time, to its dynamic 
environment. In developing this system architecture we first used a MacBooklaptop computer placed on 
the Create and used the MacBook sCamera to acquire images of the environment and fiducials.Later, desiring 
a more stable camera and a lighter-weight robot,we used a wireless camera to transmit the robot s view 
of the world to a remote MacBook or MacBook Pro. The computers,running OSX, use reacTIVision computer 
vision software[reacTIVision 1.3] to recognize the fiducials and their angle andposition in the robot 
s field of view. Java software written in theEclipse IDE then translates instructions associated with 
thefiducials into RoombaCom library commands [RoombaComm],which are wirelessly transmitted via Bluetooth 
to the Creates Bluetooth Adapter Module (BAM). 2.2 SMALLab Architecture The Situated Multimodal Arts 
Learning Lab (SMALLab; seeFig. 2) [Ref. SMALLab] is a mixed reality environment thatconsists of an overhead-mounted 
video projector, quadspatialized sound system, camera-based motion tracking engine,smart objects, and 
supporting software tools. The software tools support a gesture recognition engine, a system server to 
managemultiple simultaneous data streams, and audio and visual renderengines [Birchfield et al. 2006]. 
Physical objects (e.g., sGlowBalls) and robots, their sensor systems, and theirresponsive behaviors are 
integrated into this system through thecamera-based motion-tracking engine and through wirelesscommunication. 
The SMALLab is used in conjunction with therobotics architecture (see section 2.1) to create an immersivevideo 
game environment (projected video, sound, and gamingscenarios) that incorporates users embodied interactions 
withrobots. Figure 2: Robots and humans explore SMALLab s projected Mars terrain; sGlowBalls control 
interfaces are tracked in 3D. 2.3 Distributed Architecture The distributed architecture for controlling 
on-line roboticgaming environments consists of the robotics architecture (seesection 2.1) and the SMALLab 
architecture (see section 2.2)coupled with a server and downloadable Java applications thatallow users 
to interact with remote physical and virtual robots,characters, and users in the SMALLab and virtual 
environments.The downloadable software allows users to run reacTIVision on their own machines and transmit 
their interactions, via TCP andUDP sockets, to control remote and/or co-located robots andvideo gaming 
elements. The simplest application that uses thisarchitecture enables users to print fiducials to control 
remoterobots via their own web cams.  2.4 ARMS Architecture The Astronaut Robot Mission Simulator (ARMS) 
architectureleverages the robotics, SMALLab, and distributed architectures(see sections 2.1, 2.2, 2.3) 
and couples these with an advancedimmersive planetary exploration mission environment that hasbeen created 
for the study of various mission contingencies. A particular focus of these contingencies (e.g., loss 
of communication or power, injury, solar flare) is their impact onthe optimal return of scientific data 
with respect to the resourcesexpended. An Open-Scene-Graph (OSG) environment managesthe immersive planetary 
environments and presents them to bothco-located and distributed participants. The OSG environment supports 
multiple representations of astronauts, rovers, andambient data within high-fidelity planetary environments. 
The environments that have been incorporated to date include thedigital elevation model (DEM) of the 
Apollo 15 lunar landingsite, the Jet Propulsion Laboratory s Mars Yard [Ref.], andMount Everest. The 
ambient data within these environments has included the status of the astronauts and rovers, navigationaltrails 
and waypoints (including the presentation of virtual fiducials and virtual robots), projected scientific 
data, andvarious filters that enable augmented reality like visualizationsof planetary environments and 
their features (as they relate toscientific value, safety hazards, parameters of human-robotcollaboration, 
etc.). An OSG environment rendered withinASU s Decision Theater, a 270-degree rear-projectedenvironment 
(similar to a CAVE), supports, at any given time,25-30 co-located participants and many more distributed 
participants. The OSG environment has been linked, throughhigh-resolution global positioning systems 
(GPS) and radar­reflection positioning systems and physiological data (e.g., heartrate and respiration), 
to remote participants (robots and astronauts ) at the Jet Propulsion Laboratory (JPL) and atMIT s Field 
and Space Robotics Lab and MIT s MannedVehicle Lab. The ARMS architecture has also been linked to JPL 
s robot and planetary simulation software ROAMS andSimScape and their real-time physics and soil-dynamicsmodeling 
engines. Bi-directional communication between all participants has been realized via UDP, TCP, Skype, 
andPolycom video conferencing.  Figure 3: Remote participants OSG view of Astronaut Robot Mission Simulator 
(ARMS) with navigational waypoints.  Figure 4: Co-located participants in ASU s Decision Theater interacting 
with ARMS s virtual Apollo 15 lunar landing site.  3 Scenarios and Applications Through the iterative 
design and development and user testing of the ALERT architectures hardware and software elements, many 
structured interaction scenarios and applications have been realized. Collectively, they establish a 
broad context of playful learning activities and meaningful human-robot interactions. These scenarios 
and applications make use of a wide variety of video game elements --for example, visual elements and 
constructs (such as maps, multiple camera angles, or zooming) and audio elements that provide feedback 
for particular events or take the form of background stories and ambient sounds. These elements frequently 
represent a set of rules --the game or interaction models or engagement paradigms that define the activities. 
ALERT scenarios and applications range from highly structured interactions with specific goals to open-ended 
learning experiences with multiple intrinsically motivated goals. ALERT experiences frequently involve 
learners in activities in which they are not only playing a game but are inventing the game, and sharing 
it with others as well! 3.1 Learning to Be a Robot On the one hand, robotic systems can be highly engaging; 
on theother, they can be extremely frustrating. In order to introduceparticipants to some of the realities 
-- the great potential and thesignificant limitations --of robotics, several preliminaryactivities have 
been developed. These help participants learn todeal with encumbrances e.g., time delays in a (simulated) 
realsetting and introduce understandings of autonomy, avoidanceof obstacles, and shared control between 
human and roboticinputs. Sometimes humans can override robots actions; othertimes they cannot. One popular 
activity does not even use anytechnology as it engages participants in a simulated experience.A volunteer 
is blindfolded and the group attempts to instructthem, as if they were a remote robot, to follow a maze 
or simply,find a chair or corner. The participants are thereby introduced tofundamental complexities 
of robot control and navigation(autonomy vs. direct control, ambiguity, shared world view).Another way 
of getting an understanding of the robot withoutthe effort of programming is to use the Remote Control 
(orsimple tele-operation) to gain experience in direct manipulationand navigation. In this scenario the 
robot has no autonomy (orvery little: iRobot Creates have cliff sensors in their wheelswhich are still 
active during remote control). 3.2 Fiducials: Meaningful Markers The ALERT robotics architecture enables 
the use of fiducials for direct control. The simplest way to use the fiducials is as just-in­time instructions 
to the robot: users show the robot the desired fiducial precisely when they want the robot to execute 
theassociated command. A slightly more sophisticated way of using fiducials is to place one or more in 
the physicalenvironment in a location that the user anticipates the robot willtraverse. Another version 
of this scenario is to place a series offiducials in a sequence that instructs the robot to move from 
onefiducial to the next (e.g., go forward, turn right, go forward, turnleft, go forward, you ve encountered 
a whirlpool so spin andmake sounds, you see a danger zone so do a u-turn, etc.). If the user wants the 
robot to have more autonomous behavior,fiducials may be placed in a less sequential manner. One of the 
most basic versions of this scenario would be to place a largering of fiducials around a space, in effect 
creating a boundary,border, or fence that would bounce the robot around withinthe space. An extension 
of this approach could be used tocreate a labyrinth. A more open-ended variant would be to placefiducials 
in the physical environment more sparsely. When encountered, the fiducials might instruct the robot to 
veer awayfrom one fiducial or set of fiducials (obstacles) and towardothers, or they might elicit a behavior 
such as a dance or songfrom the robot. The placement of ambient fiducials raises theissue of perspective: 
a robot orientation, in which a right-turnfiducial instructs the robot to turn 90 degrees to the right, 
vs. aworld orientation, in which a fiducial might instruct the robot togo north. Within a tracking environment, 
such as SMALLab orthe ARMS tracking systems, the robots can readily take oneither a robot orientation 
or a world orientation. Since fiducials simply serve as instructions they can be extremely flexible: 
their use and meaning is ultimately boundedonly by the creativity of the user/programmer (see section 
4).Fiducials can be variously employed -- as targets for robots tofollow and keep within their field 
of view, as sensor events, asx-interrupts, as new individual commands, or as sequences ofprocedural commands. 
They can be variables or variable flags (you have a key and can now unlock the treasure chest); theycan 
elicit randomized events (go left, right, straight, or beep) oraugment existing sets of procedural commands. 
They could evensay, When you are done with your existing commands, then celebrate, or Go find another 
robot and ignore all otherfiducials. 3.3 Mixed Reality The ALERT architectures create a mixed reality 
environment that integrates robotics play with many standard elements of video gaming experiences. The 
use of projected video in SMALLab [see Figure 2] and ARMS environments enables many of the standard environmental 
and navigational features of video games (game levels, worlds, time travel, etc.). Likewise, the audio 
features can be spatial, ambient, and/or synthesized by the robots. Within these rich video game environments 
and augmented physical spaces, virtual fiducials can be placed. This permits dynamic fiducials that can 
change in meaning and/or be repositioned either in terms of physical location or orientation. The real-time 
tracking systems present in the SMALLab and ARMS environments allow for multiple methods of collision 
detection or obstacle avoidance. One way would be to use virtual fiducials as a barrier (mentioned above); 
another would be to have the system keep track of the location of boundaries and objects and have it 
transmit this information to the robots at the appropriate time or location. In addition to the cameras 
on the robots, the SMALLab and ARMS environments can use their own cameras to recognize the position, 
location, and meaning of fiducials. These could be used not only to program the robots but to program 
and interact with the SMALLab and ARMS environments as well. Once the environment knows about the fiducial, 
it can use color-coding (e.g., green for food resources, yellow for navigational elements, red for danger 
or barriers) or other projected annotation to help users understand the meanings of the fiducials and 
environmental features. The mixed reality environment blends the virtual and physical elements (robots, 
humans, physical fiducials, and other physical objects). The nature of fiducials allows for low-cost 
replication of the icons through standard printing. 3.4 Navigation and Terrain Mapping As discussed 
above, the ALERT fiducials can be used to control the ways robots navigate the space. Just as in a labyrinth 
scenario (discussed above), users might employ the fiducials to guide their robots through a projected 
or physical maze. This activity might extend to guiding robots through a domestic environment or an adventure 
game s virtual environments, or to exploring a Martian crater or a lunar or planetary surface. As terrains 
are explored, the robots can build up an understanding of their environment and increase their navigational 
skill and autonomy. 3.5 Pet Building One of the most compelling scenarios thus far, for the diverse 
users of the ALERT systems, has been robotic pet-building. This scenario adds a direct creative social 
component that makes the integration of video games and robots more engaging to those who may not otherwise 
be attracted to the stereotypical aesthetic of these technologies (e.g., DOS prompts and weapons). Figure 
5: ALERT robotic pets, a frog and bird, with projected virtual fiducials; fiducials on the robot also 
facilitate interaction. Figure 6: Close-up view of a frog-themed iRobot Create with a camouflaged wireless 
camera above the frog's eyes. Through the combination of varied elements of the 3.1-3.4scenarios, robots 
short- and long-term behaviors can be developed. Just as users have become engaged in theappearance of 
their game characters and avatars, ALERT usershave become engaged in physically and virtually augmenting 
the cuteness of the robots with wiggle eyes, colorful clay,wagging tails, and projected elements in order 
to create pets(e.g., birds and frogs). This is also a scenario that allows for further exploration of 
balancing levels of autonomy pets donot require constant direct interaction, and, likewise, they do 
notalways pay attention to their owners. Pets can recognize theirowners through sequences of interactions 
with their sensors,cameras, and/or through fiducials used as IDs. The tracked objects can be used as 
virtual leashes to walk or guide roboticpets through a virtual or physical environment and train the 
petsto do tricks and accept and react to fiducials as virtual rewards.Interactions in this realm can 
lead to the development of uniquebehavioral characteristics in the robotic pets and to elements of social 
bonding between the humans and their robotic pets[Picard 1997; Bickmore and Picard 2004]. In the near 
future wewill be incorporating face recognition and wearable physiological sensors into the pet-building 
scenarios. 3.6 Multi-Robot Scenarios ALERT s integrated video-robot environment permits numerous multi-robot 
scenarios. Just as pets can be led on a virtual leash by their humans, similar leashes can enable one 
robot to guide another. Through the distributed architectures, multiple humans and robots can engage 
in physical and virtual environments. One scenario we have implemented in this domain is a robot car 
race in which a remote user can use a fiducial and its orientation as a steering wheel and interact with 
their robot via a web cam. In this scenario there is an opportunity to augment the physical race with 
virtual elements such as smoke screens. A second scenario we have implemented involves pets and humans 
in a virtual ecology: a frog robot and stork robot engage in a frogger -like game. Just as video games 
have different characters, different robots can have different programs and can respond to the gaming 
environment in different ways, with their own personalities. For example, a parent robot might protect 
a child robot from cliffs and be more generous with its food. An obvious long-term goal of a multi-robot 
video game is swarm behaviors with multiple physical and virtual robots. 3.7 Hybrid Teams and Human-Robot 
Games The ARMS architecture has been used to realize a virtual Apollo 15 lunar landing site in ASU s 
Decision Theater. Within this environment, virtual fiducials act as breadcrumbs representing the human 
and robot paths. This type of distributed physical/virtual gaming scenario can be used to explore the 
relative benefits of using humans and robots in planetary exploration. Similar challenges exist in the 
FIRST Robot Competitions, in which human-robot systems compete with one another; in human-computer chess 
championships; and in the Robo-World Cup in which the goal for 2050 is to have a robotic soccer team 
that is capable of beating a human team. In the interim it is likely that a hybrid human-robot team (and 
possibly even an official Hybrid Human-Robot Robo-World Cup category) will be necessary to explore the 
relative merits of the human and robot players. The ARMS architecture is an initial example of a system 
that is geared toward elucidating the respective contributions of humans and robots in hybrid systems. 
Another feature of the distributed systems is the ability to deploy massively multi-player games. In 
spring 2008, Arizona State University hosted 20 youth from the Chinese Youth Space Academy and engaged 
them in ALERT space exploration scenarios. These 20 students were selected from over 12,000 applicants. 
The sheer magnitude of the interest in space exploration and technology shows the immediate need for 
greater access to educational experiences through on-line and distributed interfaces. LEGO Group and 
NASA are both interested in the potential of on-line distributed learning environments, and we are involving 
each of them in ALERT space exploration scenarios. ALERT systems are also being prepared for deployment 
in interactive exhibits at the Exploratorium in San Francisco.  4 Iterative Participatory Design This 
research pursued an iterative user-centered participatory design methodology to advance and evaluate 
the ALERT scenarios and applications. This process advanced understanding of the opportunities for seamless 
integration of video games with novel HRI techniques. The ALERT system architectures and the scenarios 
and applications have been developed and tested in the following settings: ASU s Sally Ride Festival, 
geared to promote women in science; two user studies within ASU s Active Learning in Mediated Environments 
course; with two sisters ages 9 and 11 in two separate 2-hour sessions; at ASU s Science &#38; Technology 
Fair; and at the Phoenix Do It Yourself hackers forum, affiliated with Make Magazine; and participants 
in the ARMS events. Sally Ride Festival: The Sally Ride Festival, an event for middle-school students 
and their younger siblings, with the goal of inspiring girls to pursue education and careers in science 
and technology, gave us an opportunity to share our system with a large and enthusiastic audience. The 
participants were curious and very comfortable interacting with the technology. To provide an engaging 
terrain mapping theme, we used a large plastic poster (provided by ASU s Mars Education Program) with 
a section of the surface of Mars printed onto it as the terrain for the robots to navigate. This poster 
served well to confine our exhibition area, but drew little attention from the children. They were much 
more interested in exploring the instantaneous responses provided by the real-time programming and control 
of the robot through the fiducials. An important finding from this event was that the system appealed 
to both boys and girls and to children and adults. An interesting (and at times amusing) observation 
was that the technology seemed more puzzling to some of the parents than to their children. The children 
we asked were able to make the connection that the camera on the robot saw the fiducial markers and could 
interpret the fiducials as commands or pieces of information, much like barcodes in a supermarket. In 
contrast, one of the parents was suspicious of the system and did not believe that the robot was able 
to retrieve information from the icons, but rather felt that the whole interaction was staged -- that 
the presenters were remote-controlling the behaviors of the robot in response to the fiducials and children. 
To the parent, being able to communicate with a robot in this informal manner, by simply showing it a 
sheet of paper with a cookie-like print on it, just seemed too good to be true; as Arthur C. Clarke s 
3rd law says, any sufficiently advanced technology is indistinguishable from magic. [Clarke 1984] That 
the fiducial interactions did not faze the children might indicate that they are ready to accept the 
magic of this sufficiently advanced technology . Consistent with Alan Kay s famous dictum that technology 
is everything that was invented after you were born, the children see the magic of video pattern recognition 
and robotics and their integration as a natural part of their everyday play patterns. Two sisters: The 
Sally Ride Festival led to additional user­testing opportunities. We met two sisters, a pair of middle­school 
girls ages 9 and 11 (and their mom), who volunteered for two subsequent 2-hour play sessions. The sisters 
participated in ASU s Active Learning in Mediated Environments class presentation. This session focused 
mainly on terrain mapping and navigation, getting the robot from point A to B within the SMALLab environment 
(see above). The girls exhibited intuitive understanding of the system as long as they were allowed to 
engage in just-in-time programming. They found pre­planning the robot s path, by placing fiducials throughout 
a projected maze environment, to be somewhat less intuitive but nonetheless a highly engaging challenge. 
Through this user session we also began to identify which of the fiducials human­legible icons [Figure 
1.] (e.g., whirlpools, u-turn, left turn, right turn, key, lock) were intuitive and which needed to be 
improved. A second session with these sisters explored pet-building scenarios and aspects of human-robot 
relationships in this context. To enhance the plot of the projected video game scenario, the research 
team had, prior to the second session, equipped the robots with physical costumes, which depicted them 
as a frog and a bird. The girls greeted this change with great enthusiasm; they were eager to start playing 
with the animals right away. One sister said, I thought it was just a robot with a laptop on it but 
it s not! Throughout this session, the robots were no longer referred to as robots, but as Froggy and 
Birdy. They had become integral physical characters in the hybrid video-robot game. Science &#38; Technology 
Fair: A second user-testing opportunitythat emerged from the Sally Ride Festival was an invitation topresent 
at ASU s Science &#38; Technology Fair. Users did the placement of fiducials and operated a co-located 
steering wheel application. The interaction of some robots that only respondedto fiducials and others 
that had combined steering wheel /fiducial control demonstrated that game scenarios can incorporate varying 
levels of autonomy and human control.During this session one participant suggested we add facialrecognition 
software to the system. We are actively engaged inintegrating not only facial expression software but 
wearable skinconductance sensors to enable the ALERT system to recognizeand respond to elements of users 
emotional states [Burlesonand Picard 2007]. Active Learning in Mediated Environments: Most of the ALERT 
scenarios and applications were tested within ASU s Active Learning in Mediated Environments course, 
a project-based design course within which much of the ALERT system was developed. Eight to ten students 
and teachers ranging in age from 19 to ~50 used the system during these sessions. They were initially 
a little more hesitant than the children in our user studies to interact with the system. However, after 
the first few tries they became very enthusiastic and engaged fully in all of the diverse scenarios and 
applications that the system affords. In one interaction, robotic sounds were added to the scenario: 
the robot was babbling to itself as it moved through the maze. This experience led to some thrilled interpretations 
like, Oh, it s talking! Phoenix DIY: Throughout the user testing we found thatinnovation frequently involved 
combining existing technologiesin novel ways. The hacker world, exemplified by Make magazine, illustrates 
that this form of technology developmentcan be very accessible to a broad audience of non-traditionalengineers. 
As part of our testing and development process, wedemonstrated our system to ~20 members of the Phoenix 
Do ItYourself (DIY) group, an organization initially spawned fromthe Make and Craft magazine blogs. Within 
this forum,participatory design activities led to the implementation of awide range of ALERT ideas, scenarios, 
and applications. At this three-hour session, some small groups undertook a programmingexercise to realize 
a PONG-like game that resulted in theexploration of playful angle of incidence/refraction behaviors,demonstrating 
not only the traditional reciprocal angles, butmischievous abnormal angles as well, such as negative 
angles ofincidence/refraction. Others engaged in diverse pet-building andsocial (robot-to-robot) scenarios, 
including prototyping bee-likedancing behaviors to communicate a robot s prior navigationalhistory or 
intended future path. They even speculated on theability of a robot to lie to another robot about its 
intentions.Another exciting development was the demonstration of the useof multiple co-planar fiducials 
(i.e., printed on the same piece ofpaper) within the camera s field of view to determine a distancemap 
of the fiducials from the robot. Among many other uses,this ability could be used by the steering wheel 
applications as athrottle adjustment, making the robot go faster when the wheelwas closer to the camera 
and slower when it was moved away. Astronaut Robot Mission Simulator: Many components of theARMS architecture 
were developed and are continuing to berefined as part of a JPL-ASU-MIT Strategic University ResearchPartnership 
grant which fostered a collaboration between twoundergraduate courses at ASU: Engineering Systems andExperimental 
Design, offered by the School of Earth and SpaceExploration, and Computer Science and Engineering s SeniorCapstone 
Project course. As noted in sections 2.4 and 3.7, these scenarios involve co-located and distributed 
participants atJPL, ASU, and MIT. We have had over 30 participantsdistributed across these locations, 
controlling robots, monitoringastronaut physiology, conducting scientific analysis, etc.Through ongoing 
simulations and development cycles, the useof the Decision Theater as an immersive environment, coupledwith 
information from remote participants in simulatedplanetary environments, is creating a next-generation 
gamingexperience that is blending real-world and virtual spaces andapplying them to learning, team work, 
and real-world scientificplanetary exploration.  5 ALERT Discussions The implications and future applications 
of systems thatcombine video gaming technology with human-robot interactions, such as the ones we have 
described, are extensive.This section presents an overview of the experiential andeducational qualities 
of these systems. In particular, it focuses on the potentials of the ALERT systems scenarios and applications 
and iterative participatory design process, as theyrelate to educational objectives of research on video-robotgaming 
synergies. 5.1 Mixed Reality Gaming The integration of robotic elements and video gameenvironments produces 
a mixed reality system (as detailed insection 2). This synthesis of physical and virtual environmentscreates 
opportunities unavailable in either environment by itself.For example, objects in the physical world 
cannot simply appearor disappear with no physical cause, but a virtual object can bearbitrarily generated 
and destroyed. If a physical object, such asa robot with a camera and computer vision system, can detectsuch 
a virtual object, then a dynamic virtual environment canaffect the physical behavior of the robot. Physical 
objects, suchas a robot, can do things that a virtual object cannot directly do,such as push other physical 
objects around. Combining theseideas, one might have a virtual object stimulating a robot tomove another 
physical object, which might in turn have someeffect on the virtual components of this environment. The 
ability to bounce back and forth between the physical and thevirtual, providing links between the two 
and enjoying theadvantages of both, establishes an engaging space with richcreative possibilities. An 
important feature of the ALERTsystem is the ease with which environments can be created andaltered by 
the users. Fiducial markers can be boundaries,dangers, prizes, tools, or other such interactive elements.Changing 
the arrangement of any of these fiducials can alter the game. Walls can be built up and torn down; robots 
can be set topatrol circuits. The scenarios we have described are stories and background concepts suggesting 
the interactions that can takeplace. Users can take charge of these scenarios and switchseamlessly back 
and forth between the roles of game players andgame creators. Storytelling and character development 
is another importantfunction that the ALERT system aids. The system enablesmultiple methods (discussed 
in section 4) for development ofcharacters by 1) customizing the physical appearance of therobots, 2) 
attaching fiducial markers to them that will affect thebehavior of other robots, and 3) by directly changing 
theprogramming of the robot. We are actively engaged inexpanding the range of available forms of interactions 
by exploiting additional sensing capabilities of the robot, includingbump sensors, cliff sensors, wheel 
drop sensors, and IR remotesensing, and by expanding the architectures discussed in section 2.2 (e.g., 
with facial recognition and physiological sensors). 5.2 Mixed Reality Gaming for Education The applicability 
of these technologies to educational environments is a primary motivation for our development ofthese 
systems. The interactive experience of dynamicallyprogramming robots and game environments by physicallyconfiguring 
environments with meaningful symbols is one that engages students who might not otherwise be drawn to 
traditional programming or logic problems. Our system canchange the way students perceive engineering 
tasks, revealingengineering as the creative endeavor that it is. Our vision is to have students engaged 
in problem solving, logical thinking,testing, and other engineering activities as a form of play beforethe 
labels of math, science, or engineering are applied. There are important reasons to promote the development 
offuture scientists and engineers and general technologicalliteracy. Our knowledge-based economy is driven 
bytechnology innovation; many societal problems requiretechnological solutions, and people require at 
least a basicfluency with technology to thrive in the world as it continues toevolve. STEM (Science, 
Technology, Engineering andMathematics) learning is vital for all students, not just those whoare naturally 
attracted to these topics in the ways they arefrequently presented in schools today. We are particularly 
excited by the potential to positively impact girls andunderserved minorities by providing a low-skill 
entrance leveland initial success experiences in an environment that allowsthem to develop their STEM 
skills via multi-sensory learning. Despite the importance of engineering and related fields to theeconomic 
growth of the United States, there is evidence ofdeclining interest and abilities in these fields. For 
example,enrollment in engineering programs has been steadily decliningin recent years. Attempts have 
been made to counteract thistrend by implementing standardized testing in schools, loweringenrollment 
standards in engineering colleges, and eliminatingarts programs in favor of more math and science classes; 
yet thenegative trend continues. Recently, programs such as FIRST(For Inspiration and Recognition of 
Science and Technology),whose mission includes the goals To create a world wherescience and technology 
are celebrated and where young peopledream of becoming science and technology heroes [Kamen],have been 
very successful in energizing kids to see engineeringas a competitive, collaborative sports activity. 
The success of this approach is documented in a study of FIRST Robotics Competition participants [Center 
for Youth and Communities, Brandeis University]. 5.3 Active, Engaged, and Alert Learners Engaging subject 
matter promotes learning. Gaining andholding the attention of students in today s classrooms can bedifficult. 
For students lacking experience with, or doubting theircapacity in, a given subject, this problem is 
amplified. One wayto make a subject inviting for these students is to provide a lowfloor (a point of 
entry that is simple and intuitive) [Resnick1991]. Our system provides this low floor through the naturaljust-in-time 
programming enabled by the fiducials (as described in sections 2.1 and 3.1-3.7). The storylines and themes 
established by the participants and appealing scenarios andapplications serve to maintain interest in 
the learningexperiences offered by the ALERT system. The multimodal interactions and feedback provided 
by this system create adynamic user experience with multiple channels for informationtransmission, serving 
diverse thinking and learning styles[Gardner 1983]. These channels include audio and videofeedback, kinesthetic 
experiences through the use of tangibleinterfaces, and verbal communications between users. Our system 
is intended to engage students on multiple levels. At its basic level (the low floor ), it provides problem 
solving andcompetitive games that require logical thinking and spatialreasoning skills. At a medium level, 
it offers the opportunity forstudents to create their own games and challenges, using thesystem as it 
already exists. This requires more creative thinkingand a deeper understanding of the tools we ve created. 
At a still higher level, revealing the high ceiling of the project, studentscan delve into the design 
and programming of the individualtechnology components that make up the system, altering andexpanding 
on what we ve provided. Students enter the systemenjoying the seemingly magical control over the robots 
actionsthrough communicating commands by showing the robotsprinted images (the fiducial markers), but 
eventually want tounderstand how to perform the magic trick how to do the programming that makes the 
system work. Just as games can start off being easy (so as not to immediatelyfrustrate players) but gradually 
become more challenging (so asto remain engaging as the players skills improve), a learningsystem should 
be dynamic and adaptable in order to maintain itseffectiveness as a teaching tool. One of the strengths 
of oursystem is its flexibility. It functions as an open-ended learningenvironment in which students 
can freely play, explore, invent,and evolve understandings of space, timing, logic, interrelations,and 
dependencies. In certain scenarios ALERT systems can alsoaid learning of specific directed lessons, such 
as a geometryproblem illustrating the Pythagorean theorem. Students show an enthusiastic willingness 
to combine multiple scenarios andapproaches when working with and designing robots and robot­robot or 
video-robot interactions. We ve observed these self­motivated and largely self-directed creative activities 
to be apromising way to generate a wide diversity of hybrid video­robotic games. Throughout this participatory 
design and development process, emergent behaviors frequently occur in the system, suggesting new games 
and learning activities, including puzzles, hide-and­seek (and other robotic implementations of traditional 
children s games), and artistic applications (such as dancing). To date we are capturing these ideas 
and using them to develop and refine additional scenarios and applications.  6 Conclusions The ALERT 
system and the iterative participatory design,development, and evaluation described in this paper representthe 
evolution of, and contributions to, a new spatial paradigm foradvancing video game technologies, human-robot 
interactions,and embodied educational experiences, in physicalenvironments. The diverse systems, scenarios, 
and applicationspresented here show the significant potential afforded byintegrating robots and video 
games through the use of tangible fiducial interactions. Within the ALERT system, human-robotinteractions 
and programming experiences can be made accessible to users with no traditional programming experienceby 
simply leveraging their preexisting logical thinking abilitiesand experience with everyday programming 
examples such asstreet signs (stop, go, speed limit, right turn). Since humans,robots, and video environments 
share many inherently spatialqualities, this natural style of physical programming isparticularly well 
suited to fostering playful interactions withmobile robots in dynamic video environments. The low floor 
ofthis system makes experiences with technology easy andexciting and opens up STEM learning experiences 
to thoseindividuals who are typically not drawn to these subjects. TheALERT scenarios and applications 
are enabling a very broadrange of gamers, learners, and developers to generate andengage in their own 
physically interactive games. The attractive qualities of video games, including interesting characters,storylines, 
and multi-sensory feedback mechanisms, combinedwith the physically active involvement promoted by roboticelements 
and tangible fiducials, are resulting in systems thatbroaden the capabilities of video game technology 
and human­robot interaction.  Acknowledgments For their support and contributions, we thank WilhelminaSavenye, 
Kip Hodges, Dava Newman, Chris Assad, UdayKumar, Assegid Kidane, Brian Grigsby, Sheri Klug, ASU sSchool 
of Computer Science and Informatics Capstone Team,members of ASU s Active Learning in Mediated Environmentscourse, 
iRobot Corporation, LEGO Group, the Jet PropulsionLaboratory, and ASU s Arts Media and Engineering (AME)SMALLab 
researchers. References BattleBots. Accessed 28 May 2008. http://www.battlebots.com/ Bickmore, T. W., 
and Picard, R. W. 2004. Towards caringmachines. In CHI '04 Extended Abstracts on Human Factors in Computing 
Systems (Vienna, Austria, April 24 - 29, 2004). CHI'04. ACM, New York, 1489-1492. Birchfield, D., Ciufo, 
T., and Minyard, G. 2006. SMALLab: amediated platform for education. In ACM SIGGRAPH 2006Educators Program. 
SIGGRAPH '06. ACM, New York, 33. Bobick, A., Intille, S., Davis, J., Baird, F., Pinhanez, C.,Campbell, 
L., Ivanov, Y., Schütte, A., Wilson, A., 2000. TheKidsRoom. Communications of the ACM, Vol. 43, No. 3, 
60-61. Buechley, L., Eisenberg, M., Catchen, J., and Crockett, A. 2008.The LilyPad Arduino: Using Computational 
Textiles toInvestigate Engagement, Aesthetics, and Diversity in ComputerScience Education, CHI 2008 Proceedings, 
Florence, Italy. Burleson, W., Picard, R.W. "Evidence for Gender SpecificApproaches to the Development 
of Emotionally IntelligentLearning Companions," IEEE Intelligent Systems, Special issueon Intelligent 
Educational Systems, Vol 22, No 4, July 2007, pp.62-69. Cavallo, D., Sipitakiat, A., Basu, A., Bryant, 
S., Welti-Santos,L., Maloney, J., Chen, S., Asmussen, E., Solomon, C.,Ackermann, E. 2004. RoBallet: Exploring 
Learning through Expression in the Arts through Constructing in aTechnologically Immersive Environment. 
Accessed 28 May2008 from www.media.mit.edu/~edith/publications/collective%20papers/RoBallet%20icls2004-cavallo-1.pdf 
Center for LifeLong Learning and Design. Accessed 28 May2008 at http://l3d.cs.colorado.edu/ Center for 
Youth and Communities, Brandeis University, 2005.FIRST Robotics Competition Evaluation: Executive Summary,Accessed 
28 May 2008 at www.usfirst.org/uploadedFiles/Who/Impact/Brandeis_Studies/05FLL_Underserved_Summary.pdf 
Clarke, A. C. 1984. Profiles of the future: An inquiry into thelimits of the possible. New York: Holt, 
Rinehart &#38; Winston. Gardner, H. 1983. Frames of mind: The theory of multipleintelligences. New York: 
Basic Books. Hayes, B., 2007. GameStar Mechanic Monday: Betty Hayes onthe academic goals of GameStar 
Mechanic. Accessed 28 May2008 at http://www.gamelab.com/reports/2007-oct-gamestar_mondays_5 Intel Corporation. 
Intel® Play Me2Cam* Computer VideoCamera. Accessed 28 May 2008 athttp://www.intel.com/support/intelplay/me2cam/ 
iRobot Corp. iRobot® Roomba® Vacuum Cleaning Robots.Accessed 28 May 2008 at www.irobot.com/sp.cfm?pageid=122 
LEGO Group. Accessed 28 May 2008 at http://www.lego.com Lifelong Kindergarten. Projects. Accessed 28 
May 2008 athttp://llk.media.mit.edu/projects.php Logo Foundation. Accessed 28 May 2008 athttp://el.media.mit.edu/logo-foundation/ 
Microsoft Corp. 1997. Microsoft ActiMates Interactive Barneyto Interact With "Barney &#38; Friends" on 
PBS. Accessed 28 May2008 at http://www.microsoft.com/presspass/press/1997/sept97/mspbspr.mspx Papert, 
S. 1980. Mindstorms: Children, computers, and powerfulideas. New York: Basic Books. Picard, R. W. 1997. 
Affective computing. MIT Press. reacTIVision 1.3. Accessed 2 June 2008 at http://reactable.iua.upf.edu/?software 
Resnick, M. 1991. MultiLogo: A Study of Children andConcurrent Programming. Interactive Learning Environments,vol. 
1, no. 3, pp. 153-170. Robocup. Accessed 28 May 2008 at http://www.robocup.org/ Robotics Institute at 
Carnegie Mellon University. 2004. ThePersonal Exploration Rover. Accessed 28 May 2008 athttp://www.cs.cmu.edu/~myrover/PER/ 
RoombaComm. Accessed 2 June 2008 at http://hackingroomba.com/code/roombacomm/  
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
	</article_rec>
	<article_rec>
		<article_id>1401865</article_id>
		<sort_key>220</sort_key>
		<display_label>Pages</display_label>
		<pages>8</pages>
		<article_publication_date>08-09-2008</article_publication_date>
		<seq_no>2</seq_no>
		<title><![CDATA[A combined tactical and strategic hierarchical learning framework in multi-agent games]]></title>
		<page_from>115</page_from>
		<page_to>122</page_to>
		<doi_number>10.1145/1401843.1401865</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1401865</url>
		<abstract>
			<par><![CDATA[<p>This paper presents a novel approach to modeling a generic cognitive framework in game agents to provide tactical behavior generation as well as strategic decision making in modern multi-agent computer games. The core of our framework consists of two characterization concepts we term as the tactical and strategic personalities, embedded in each game agent. Tactical actions and strategic plans are generated according to the weights defined in their respective personalities. The personalities are constantly improved as the game proceeds by a learning process based on reinforcement learning. Also, the strategies selected at each level of the agents' command hierarchy affect the personalities and hence the decisions of other agents. The learning system improves performance of the game agents in combat and is decoupled from the action selection mechanism to ensure speed. The variability in tactical behavior and decentralized strategic decision making improves realism and increases entertainment value. Our framework is implemented in a real game scenario as an experiment and shown to outperform various scripted opponent team tactics and strategies, as well as one with a randomly varying strategy.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[game agent architecture]]></kw>
			<kw><![CDATA[game artificial intelligence]]></kw>
			<kw><![CDATA[learning]]></kw>
			<kw><![CDATA[multi-agent cooperation]]></kw>
			<kw><![CDATA[strategic planning]]></kw>
			<kw><![CDATA[tactical behavior]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.2.1</cat_node>
				<descriptor>Games</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.2.11</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010178.10010219</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Distributed artificial intelligence</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010476.10011187.10011190</concept_id>
				<concept_desc>CCS->Applied computing->Computers in other domains->Personal computers and PC applications->Computer games</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003752.10010070.10010099</concept_id>
				<concept_desc>CCS->Theory of computation->Theory and algorithms for application domains->Algorithmic game theory and mechanism design</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10011007.10010940.10010941.10010969.10010970</concept_id>
				<concept_desc>CCS->Software and its engineering->Software organization and properties->Contextual software domains->Virtual worlds software->Interactive games</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002951.10003227.10003251.10003258</concept_id>
				<concept_desc>CCS->Information systems->Information systems applications->Multimedia information systems->Massively multiplayer online games</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<person_id>P1100742</person_id>
				<author_profile_id><![CDATA[81365592562]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Chek]]></first_name>
				<middle_name><![CDATA[Tien]]></middle_name>
				<last_name><![CDATA[Tan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[National University of Singapore]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1100743</person_id>
				<author_profile_id><![CDATA[81100098498]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Ho-lun]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Cheng]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[National University of Singapore]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>1082648</ref_obj_id>
				<ref_obj_pid>1082473</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Andrade, G., Ramalho, G., Santana, H., and Corruble, V. 2005. Automatic computer game balancing: A reinforcement learning approach. <i>In Proceedings of the Autonomous Agents And Multi Agent Systems Conference</i> (July), 1111, 1112.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Blizzard Entertainment, 2006. Warcraft III. Accessed April 12, 2006. Available via http://www.blizzard.com/war3/.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Blizzard, 2006. Diablo ii. Accessed April 12, 2006. Available via http://www.blizzard.com/diablo2/.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Blizzard, 2006. World of warcraft. Accessed April 12, 2006. Available via http://www.worldofwarcraft.com/.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Buro, M., 2007. ORTS - A Free Software RTS Game Engine. Accessed March 20, 2007. Available via http://www.cs.ualberta.ca/mburo/orts/index.html.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Charles, D., Kerr, A., McNeill, M., McAlister, M., Black, M., Kcklich, J., Moore, A., and Stringer, K. 2005. Player-centred game design: Player modeling and adaptive digital games. <i>In Proceedings of the Digital Games Research Conference</i>, 285,298.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Christian J. Darken, G. H. P. 2006. <i>Findin Cover in Dynamic Environments</i>, first ed. Charles River Media, Hingham, Massachusetts.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Co-op, S., 2006. Sven co-op. Accessed September 15, 2006. Available via http://www.svencoop.com/.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Electronic Arts, 2006. Battlefield 2142. Accessed December 20, 2006. Available via http://battlefield.ea.com/battlefield/bf2142/.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Exluna, Inc. 2002. <i>Entropy 3.1 Technical Reference</i>, January.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>383260</ref_obj_id>
				<ref_obj_pid>383259</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Fedkiw, R., Stam, J., and Jensen, H. W. 2001. Visual simulation of smoke. In <i>Proceedings of SIGGRAPH 2001</i>, ACM Press / ACM SIGGRAPH, E. Fiume, Ed., Computer Graphics Proceedings, Annual Conference Series, ACM, 15--22.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1248295</ref_obj_id>
				<ref_obj_pid>1247761</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Foka, A., and Trahanias, P. 2007. Real-time hierarchical POMDPs for autonomous robot navigation. In <i>Proceedings of Robotics and Autonomous Systems</i>, 561,571.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Geramifard, A., Chubak, P., and Bulitko, V. 2006. Biased cost pathfinding. <i>In Proceedings of the Artificial Intelligence and Interactive Digital Entertainment conference</i>, 112,114.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Horswill, I., and Zubek, R. 1999. Robot architectures for believable game agents. <i>In Proceedings of the 1999 AAAI Spring Symposium on Artificial Intelligence and Computer Games, AAAI Technical Report SS-99-02.</i>
]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1178573</ref_obj_id>
				<ref_obj_pid>1178477</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Hunicke, R., and Chapman, V. 2004. AI for Dynamic Difficult Adjustment in Games. <i>In Proceedings of the Challenges in Game AI Workshop, Nineteenth National Conference on Artificial Intelligence.</i>
]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Hussain, T. S., and Vidaver, G. 2006. Flexible and purposeful npc behaviors using real-time genetic control. <i>In Proceedings of The IEEE Congress on Evolutionary Computation</i> (July), 785,792.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Jobson, D. J., Rahman, Z., and Woodell, G. A. 1995. Retinex image processing: Improved fidelity to direct visual observation. In <i>Proceedings of the IS&T Fourth Color Imaging Conference: Color Science, Systems, and Applications</i>, vol. 4, 124--125.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>931254</ref_obj_id>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Kartch, D. 2000. <i>Efficient Rendering and Compression for Full-Parallax Computer-Generated Holographic Stereograms.</i> PhD thesis, Cornell University.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Khoo, A., and Dunham, G. 2002. Efficient, realistic npc control systems using behavior-based techniques. <i>In AAAI Technical Report</i>, 02--01.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Landis, H., 2002. Global illumination in production. ACM SIGGRAPH 2002 Course #16 Notes, July.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>344849</ref_obj_id>
				<ref_obj_pid>344779</ref_obj_pid>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Levoy, M., Pulli, K., Curless, B., Rusinkiewicz, S., Koller, D., Pereira, L., Ginzton, M., Anderson, S., Davis, J., Ginsberg, J., Shade, J., and Fulk, D. 2000. The digital michelangelo project. In <i>Proceedings of SIGGRAPH 2000</i>, ACM Press / ACM SIGGRAPH, New York, K. Akeley, Ed., Computer Graphics Proceedings, Annual Conference Series, ACM, 131--144.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[McDonald, D., Leung, A., Ferguson, W., and Hussain, T. 2006. An abstraction framework for cooperation among agents and people in a virtual world. <i>In Proceedings of the Second Conference on Artificial Intelligence and Interactive Digital Entertainment</i> (June).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[Michael E. Tipping, C. M. B. 1999. Probabilistic principal component analysis. <i>Technical Report NCRG/97/010, Neural Computing Research Grou</i> (September).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[NCsoft, 2006. Guild wars. Accessed April 12, 2006. Available via http://www.guildwars.com/.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[Oliehoek, F. 2005. Game Theory and AI: A unified Approach to Poker Games. <i>Masters Thesis</i>, 561,571.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[Orkin, J. 2004. <i>Applying Goal-Oriented Action Planning to Games</i>, first ed. Charles River Media, Hingham, Massachusetts.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[Orkin, J. 2004. <i>Finite State Machines</i>, first ed. Charles River Media, Hingham, Massachusetts.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[Orr, G., Schraudolph, N., and Cummins, F., 1999. Cs-449: Neural networks lecture notes. Accessed December 20, 2005. Available via http://www.willamette.edu/gorr/classes/cs449/intro.html.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1110756</ref_obj_id>
				<ref_obj_pid>1110642</ref_obj_pid>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[Park, S. W., Linsen, L., Kreylos, O., Owens, J. D., and Hamann, B. 2006. Discrete sibson interpolation. <i>IEEE Transactions on Visualization and Computer Graphics 12</i>, 2 (Mar./Apr.), 243--253.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>249651</ref_obj_id>
				<ref_seq_no>30</ref_seq_no>
				<ref_text><![CDATA[Parke, F. I., and Waters, K. 1996. <i>Computer Facial Animation.</i> A. K. Peters.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1073214</ref_obj_id>
				<ref_obj_pid>1073204</ref_obj_pid>
				<ref_seq_no>31</ref_seq_no>
				<ref_text><![CDATA[Pellacini, F., Vidim&#269;e, K., Lefohn, A., Mohr, A., Leone, M., and Warren, J. 2005. Lpics: a hybrid hardware-accelerated relighting engine for computer cinematography. <i>ACM Transactions on Graphics 24</i>, 3 (Aug.), 464--470.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>32</ref_seq_no>
				<ref_text><![CDATA[Remco Straatman, A. B., and van der Sterren, W. 2006. <i>Dynamic Tactical Postion Evaluation</i>, first ed. Charles River Media, Hingham, Massachusetts.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>33</ref_seq_no>
				<ref_text><![CDATA[Sailera, F., Buro, M., and Lanctot, M. 2007. Adversarial planning through strategy simulation. <i>In Proceedings of the IEEE Symposium on Computational Intelligence and Games</i> (April).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>34</ref_seq_no>
				<ref_text><![CDATA[Sako, Y., and Fujimura, K. 2000. Shape similarity by homotropic deformation. <i>The Visual Computer 16</i>, 1, 47--61.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>35</ref_seq_no>
				<ref_text><![CDATA[Sierra, 2006. No one lives forever 2. Accessed April 12, 2006. Available via http://nolf.sierra.com/.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>36</ref_seq_no>
				<ref_text><![CDATA[Sierra, 2007. First encounter assault recon. Accessed December 23, 2007. Available via http://www.whatisfear.com/fear.html.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>37</ref_seq_no>
				<ref_text><![CDATA[Silver, D. 2005. Cooperative pathfinding. <i>In Proceedings of the First Artificial Intelligence and Interactive Digital Entertainment conference</i>, 117,122.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>38</ref_seq_no>
				<ref_text><![CDATA[Spronck, P., Sprinkhuizen-Kuyper, I., and Postma, E. 2004. Difficulty Scaling of Game AI. <i>In Proceedings of GAMEON 2004: 5th International Conference on Intelligent Games and Simulation</i>, 33,37.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>39</ref_seq_no>
				<ref_text><![CDATA[Spronck, P., Ponsen, M., Sprinkhuizen-Kuyper, I., and Postma, E. 2006. <i>Adaptive Game AI with Dynamic Scripting.</i> Springer Netherlands, Netherlands.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>40</ref_seq_no>
				<ref_text><![CDATA[Spronck, P. 2005. A model for reliable adaptive game intelligence. <i>In IJCAI-05 Workshop on Reasoning, Representation, and Learning in Computer Games</i>, 95,100.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>551283</ref_obj_id>
				<ref_seq_no>41</ref_seq_no>
				<ref_text><![CDATA[Sutton, R. S., and Barto, A. G. 1998. <i>Reinforcement Learning: An Introduction.</i> The MIT Press, Cambridge, Massachusetts.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>42</ref_seq_no>
				<ref_text><![CDATA[Sweetser, P. 2005. An emergent approach to game design. <i>Ph.D Thesis.</i> Available via http://www.itee.uq.edu.au/penny/publications.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>43</ref_seq_no>
				<ref_text><![CDATA[Tan, C. T., and Cheng, H. 2007. Personality-based Adaptation for Teamwork in Game Agents. <i>In Proceedings of the Third Conference on Artificial Intelligence and Interactive Digital Entertainment</i>, 37.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>44</ref_seq_no>
				<ref_text><![CDATA[Thue, D., and Bulitko, V. 2006. Modeling goal-directed players in digital games. <i>In Proceedings of the Artificial Intelligence and Interactive Digital Entertainment conference</i>, 285,298.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>45</ref_seq_no>
				<ref_text><![CDATA[Wallace, N. 2004. <i>Hierarchical Planning in Dynamic Worlds</i>, first ed. Charles River Media, Hingham, Massachusetts.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>46</ref_seq_no>
				<ref_text><![CDATA[White, C., and Brogan, D. 2006. The self organization of context for multi agent games. <i>In Proceedings of 2nd Annual Conference on Artificial Intelligence in Interactive Digital Entertainment</i> (June).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>47</ref_seq_no>
				<ref_text><![CDATA[Wikipedia, 2006. Game balance. Accessed December 20, 2006. Available via http://en.wikipedia.org/wiki/Gamebalance.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2136757</ref_obj_id>
				<ref_obj_pid>2136743</ref_obj_pid>
				<ref_seq_no>48</ref_seq_no>
				<ref_text><![CDATA[Yannakakis, G. N., and Maragoudakis, M. 2005. Player modeling impact on players entertainment in computer games. <i>In Springer-Verlag: Lecture Notes in Computer Science</i>, 3538:74.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>49</ref_seq_no>
				<ref_text><![CDATA[Yee, Y. L. H. 2000. <i>Spatiotemporal sensistivity and visual attention for efficient rendering of dynamic environments.</i> Master's thesis, Cornell University.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 A Combined Tactical and Strategic Hierarchical Learning Framework in Multi-agent Games Chek Tien Tan* 
Ho-lun Cheng National University of Singapore Abstract This paper presents a novel approach to modeling 
a generic cog­nitive framework in game agents to provide tactical behavior gen­eration as well as strategic 
decision making in modern multi-agent computer games. The core of our framework consists of two char­acterization 
concepts we term as the tactical and strategic personal­ities, embedded in each game agent. Tactical 
actions and strategic plans are generated according to the weights de.ned in their re­spective personalities. 
The personalities are constantly improved as the game proceeds by a learning process based on reinforcement 
learning. Also, the strategies selected at each level of the agents command hierarchy affect the personalities 
and hence the decisions of other agents. The learning system improves performance of the game agents 
in combat and is decoupled from the action selection mechanism to ensure speed. The variability in tactical 
behavior and decentralized strategic decision making improves realism and in­creases entertainment value. 
Our framework is implemented in a real game scenario as an experiment and shown to outperform var­ious 
scripted opponent team tactics and strategies, as well as one with a randomly varying strategy. CR Categories: 
I.2.1 [Arti.cial Intelligence]: Applications and Expert Systems Games I.2.11 [Arti.cial Intelligence]: 
Dis­tributed Arti.cial Intelligence [Intelligent agents, Multiagent sys­tems] Keywords: game arti.cial 
intelligence, game agent architec­ture, multi-agent cooperation, tactical behavior, strategic planning, 
learning 1 Introduction In the domain of modern game Arti.cial Intelligence (AI), recent years have 
seen much work being performed in the area of synthe­sizing intelligent behaviors in game agents [Hussain 
and Vidaver 2006; Horswill and Zubek 1999; Geramifard et al. 2006; Khoo and Dunham 2002; McDonald et 
al. 2006; Spronck et al. 2006; Sweetser 2005; Tan and Cheng 2007; White and Brogan 2006]. Role Playing 
Games (RPG), Real Time Strategy (RTS) games, First Person Shooters (FPS) and Sports games make up the 
major com­ponents of modern games and game agents constitute the core of the game worlds. A game agent 
is de.ned as a .ctional character in the game world, either a player controlled character (PC) or a non­player 
character (NPC). Agent behavioral planning can be classi.ed *e-mail: tanchekt@comp.nus.edu.sg hcheng@comp.nus.edu.sg 
Copyright &#38;#169; 2008 by the Association for Computing Machinery, Inc. Permission to make digital 
or hard copies of part or all of this work for personal or classroom use is granted without fee provided 
that copies are not made or distributed for commercial advantage and that copies bear this notice and 
the full citation on the first page. Copyrights for components of this work owned by others than ACM 
must be honored. Abstracting with credit is permitted. To copy otherwise, to republish, to post on servers, 
or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from 
Permissions Dept, ACM Inc., fax +1 (212) 869-0481 or e-mail permissions@acm.org. Sandbox Symposium 2008, 
Los Angeles, California, August 9 10, 2008. &#38;#169; 2008 ACM 978-1-60558-173-6/08/0008 $5.00 as either 
tactical or strategic. Tactical refers to low level plan­ning of primitive actions like shoot , attack 
and heal by each agent. Strategic encompasses high level planning like deciding on whether to execute 
a .anking attack or a mass frontal attack as a team. In short, tactical decisions are short-term and 
individually­based whereas strategic decisions are long-term and team-based. This paper describes our 
efforts at modeling a generic cognitive framework in game agents that enables planning in both tactical 
and strategic aspects. We .nd a combined planning approach lacking in current work, especially in complex 
modern game environments. It builds upon an earlier work in tactical behavior generation [Tan and Cheng 
2007] to include strategic planning and the integrated frame­work has been implemented with positive 
results. Our framework is applicable for the different modern game genres as described above. 1.1 Motivation 
Although there are large amounts of research being done in the area of agent planning, current work are 
more suited for chess-like board games than for modern games. Most work are based on classical theories 
that focus on the intelligent agent problem in a generic sense. In doing so, they are often too complicated 
and impractical for use in commercial games, and are focused on theory rather than gameplay. In board 
games, algorithms like alpha-beta game-tree search can exhaustively enumerate future states to evaluate 
action outcomes because of the tactical nature and the branching factor is relatively small. Modern game 
developers are also reluctant to use state of the art intelligent agent algorithms due to the fear of 
game agents learning to produce strange or even erratic behavior that is totally unexpected. Modern game 
developers require sim­plicity whilst achieving speed and effectiveness, hence simple and comprehendible 
AI like scripting and .nite state machines (FSMs) [Orkin 2004b] are still dominant in today s game AI. 
Whilst we acknowledge that generic and theoretical advancements are of ut­most importance in the general 
AI community as a whole, we also recognize that there is a concurrent need for studies that are imple­mentable 
in (or can be combined with) the AI of modern commer­cial games. Automatically devising a good playing 
strategy is much more com­plex in modern games than in classical board games for a variety of reasons. 
Modern games include a variety of agents, each possess­ing a vast number of diverse actions, whereas 
board game pieces are mainly de.ned by only the type of movement they can make. Addi­tionally, all agents 
in modern games are able to act simultaneously in real time, in contrast with turn-based board games. 
Considering the world space, modern game worlds are enormous and continu­ous compared to the 64 discrete 
positions of chess or even the 361 positions in Go. These factors make the search space exceptionally 
larger and it is impossible to exhaust all searches within a reason­able time interval for game playing 
to be smooth. Take for example if we were to model an RPG in a classical Partially Observable Markov 
Decision Process (POMDP) [Foka and Trahanias 2007], it would be almost impossible to obtain a working 
policy without tremendous amounts of heuristics and abstractions, due to the enor­mous number of belief 
states. Current successful algorithms solve to the complexity level of simple poker games [Oliehoek 2005], 
which is a far fetch from the complexity we get in modern com­mercial games [Sailera et al. 2007]. In 
addition to the performance aspect, modern game AI also needs to take into account the enter­tainment 
value for human players. As such, research in this area is promising, challenging and interesting. Given 
that modern games involve teams of multiple agents work­ing together with a common goal, there is a need 
for team-based cooperative planning. In FPS games like Battle.eld 2142 [Elec­tronic Arts 2006], a player 
can form teams with non-player char­acters(NPCs) to play against computer controlled opponent teams in 
military-style combat. This is often the case in RPGs like Guild Wars [NCsoft 2006] when a player teams 
up with NPCs for mis­sions, and opponents are mostly organized in large packs. Simi­larly in RTS games 
like Warcraft 3 [Blizzard Entertainment 2006], the computer opponent manages a whole team of units and 
re­sources. The AI in these teams is largely scripted and often per­forms predictably, making the games 
un-challenging and dull when the player .gures out the patterns. Other than multi-agent path.nd­ing, 
research in multi-agent coordination is minimal in modern games. Current work mainly focuses on tactical 
behaviors and not enough attention has been given to strategic decision making. More details are given 
in the section on Related Work.  1.2 Aim The goal of this paper is to model an integrated framework 
to en­able both tactical and strategic planning capabilities for agents in a team-based environment. 
To reinforce the cooperative capabili­ties, we establish a communication and command-passing system amongst 
the agents. In general, our framework serves as a generic representation of the cognitive ability of 
an agent in the game. We also consider the factors of performance, speed and entertainment value, three 
of the most important requirements for game AI to be useful practically [Spronck et al. 2006]. Besides 
synthesizing im­mediate behaviors in normal agents, our work provides strategic capabilities to agents 
with leadership abilities. In the simplest case, each team has a single commander. In more sophisticated 
games, there may be a hierarchy of commander agents and our framework can be used to serve the different 
management requirements at each hierarchy of the opposing teams. For example, each team of units the 
player or computer agent groups up can be incorporated with our framework and automatically function 
on its own after being given a high level task. This eases the micro-management imposed on the player 
in RTS games to allow for more strategic gameplay. The framework is also generic enough to be applied 
other game genres like RPG, FPS and sports games. 1.3 Our Approach First, each team is organized into 
a hierarchical tree structure where each agent is a node in the tree and each parent node is able to 
pass a command to its children. A tree-structured team is better than a graph-like one in terms of performance 
because the acyclic manner of command-passing facilitates convergence in the learning process. Allowing 
the team to form a cyclic structure may result in in.nite loops as agents affect each other in a back 
and forth manner. Moreover, a tree structure better re.ects real-life combat establish­ments like in 
the military. Each agent in the hierarchy possesses a tactical personality drawn from [Tan and Cheng 
2007] and a strategic personality. Tactical and strategic planning is based on the weights de.ned in 
the person­alities and updated based on reinforcement learning concepts [Sut­ton and Barto 1998] as the 
game proceeds. In addition, we improve multi-agent coordination by introducing a hierarchical command­passing 
mechanism into the framework. With these methods we aim to: enable tactical and strategic adaptivity 
to the game environ­ment,  conceive effective and interesting character behaviors, and  enable a hierarchical 
command-passing system between agents.  Adaptive learning improves agent performance as the game pro­ceeds 
whilst behavioral variability makes agents more interesting hence improving the entertainment value. 
Moreover, since our tactical and strategic selection processes only depend on numeric weights for decision 
making, the process is very quick in-game. Hence our framework satis.es the three requirements in our 
goal­speed, performance and entertainment value. In the remaining sections of this paper, we .rst review 
literature related to our work. Then we describe the system architecture in detail. Thereafter, we show 
our experimental results as empirical proof of our concept, along with an analysis of the results. Lastly, 
we conclude the paper together with our plans for future work.   2 Related Work Synthesizing intelligent 
game agents has been one of the core ar­eas in game AI research [Horswill and Zubek 1999; Hussain and 
Vidaver 2006; Geramifard et al. 2006; Khoo and Dunham 2002; McDonald et al. 2006; Sweetser 2005; White 
and Brogan 2006], but most studies ignore the strategic aspect. [Khoo and Dunham 2002] devised a stateless 
FSM system for game agents to ef.ciently react to environmental changes. [Sweetser 2005] combines in.u­ence 
maps with cellula automata techniques for game agent deci­sion making. Others [Horswill and Zubek 1999; 
Hussain and Vi­daver 2006] made use of work in robotics and applied them to game agents. In view of various 
agent controllers, [McDonald et al. 2006] devised a .ve-level architecture as an abstracted framework 
to en­able inter-operability amongst them. [White and Brogan 2006] pre­sented a method that employs a 
self-organizing Kohonen map cou­pled with reinforcement learning to produce effective gameplay in multiple 
agents in RoboCup simulated soccer. These work mainly targeted at devising tactical behavior architectures. 
Additionally, these studies make use of decision making systems that need to per­form heavy computations 
before each action taken by the agents, with frequent updates to the knowledge in the system which would 
likely cause disruptions to the actual gameplay. In [Tan and Cheng 2007], they have devised a natural 
and convenient way to represent actions in a weighted set, in which they call a personality model. They 
have also alleviated the problem by decoupling the learning system from the action selection mechanism. 
The intensive learn­ing process only takes place at convenient intervals in the game (like scenario or 
map transitions in the game) whereas a fast and simple action selection can take place as often as needed. 
However, their work only plan for primitive action sequences. The work in this paper largely makes use 
of their personality representation to cater for a combined tactical and strategic planning architecture. 
A number of studies also focused on speci.c areas of planning like path.nding [Geramifard et al. 2006; 
Silver 2005] and tactical po­sitioning [Remco Straatman and van der Sterren 2006; Christian J. Darken 
2006]. Recent path.nding work [Geramifard et al. 2006; Silver 2005] concentrated on cooperative, multi-agent 
path.nding primarily in RTS games. [Remco Straatman and van der Sterren 2006] provides a simple map representation 
to aid the game agent in evaluating tactical positions, whilst [Christian J. Darken 2006] combines level 
annotation with sensor grid algorithm to allow the agent to dynamically .nd cover. These studies aim 
atissues of lo­cation and do not consider the actual actions that need to be done after the agents arrive 
at the location. A prominent advancement in adaptive agent behavior was the in­troduction of dynamic 
scripting [Spronck et al. 2006] where adap­tive behavior was de.ned by choosing from a set of scripted 
ac­tions. They have shown that dynamic scripting using a learn­ing system that is adapted from reinforcement 
learning performs very well against computer opponents. Moreover, they balanced the practicality of scripting 
with the learning capability of rein­forcement learning. In this paper we adopt a similar approach for 
the learning system. However, while their work focuses on de.ning adaptive tactical behavior in individual 
agents, our frame­work includes strategic decision making as well as a hierarchical command-passing mechanism 
for multiple agents. Also, our plan­ning system reaches into the level of individual actions, whilst 
theirs are based on scripts. This adds .exibility in the framework. In terms of strategic AI in moderngames, 
[Sailera et al. 2007] de­vised a method that searches through all scenarios to conclude a winning strategy 
for an RTS game environment. They simulate strategy pairs in a fast-forwarded simulation to determine 
which strategy would give the best winning chance. Though the simula­tion is supposedlyfast-forwarded 
according to their algorithm, the obvious setback is still that it is a tedious search method that re­quires 
simulating each scenario all the way to the end to arrive at a conclusion. In contrast, the strategy 
selection mechanism in this pa­peris basedona machine learning approach whichis muchfaster, albeit at 
the expense of having a learning period. In summary, currentworkin moderngames focuseson tacticalAI or 
strategic AI in isolation. In moderngames where large agent teams exist, an AI that encompasses both 
aspects would prove very useful. 3 Agent Cognitive Framework Every agent in the game possesses the cognitive 
framework as shownin Figure1. First,astrategy, si,is passeddown fromaparent agent in the previous hierarchical 
level. Based on this strategy and taking certain environmentvariables into consideration, the tactical 
cognition and the strategic cognition de.ne the tactical personality, Ptactical, and strategic personality, 
Pstrategy, respectively.Via the tactical personality, the behavior generator outputs a sequence of actions, 
Bi, for the agent s current tactical behavior. Similarly, the strategy generator makes use of the strategic 
personality to produce a strategy, si+1, for use by the next agent(s). Note that our de.­nition of strategy 
is synonymous with that of a command decision being passed down from a commander to a subordinate. 3.1 
Agent Personality The concept of agent personality was .rst introduced in [Tan and Cheng 2007] and an 
illustration can be seen in the top diagram in Figure 2. In their work, when an action selection mechanism 
is applied, the weight determines the chance of choosing an an ac­tion in view of other simultaneous 
adaptable actions. To reiter­ate the de.nition using a similar terminology, if P . is the tactical set 
of all tactical personalities, the tactical personality of an agent, . P . , is a function that assigns 
a weight to each adaptable action. Ptactical : A . W, (1) Ptactical tactical where W . [Wmin,Wmax] is 
the set of all weights with Wmin and Wmax being the bounds for the weight values, and A is the set of 
all adaptable actions. Figure 1: Agent CognitiveFramework: The tactical behavior and its strategy for 
the agents in the current hierarchical level is gov­ernedbythestrategybeinggeneratedfromthe commanderagents 
in the previous hierarchical level. Central to the framework are the adaptive tactical and strategic 
personalities which control the selection process for the behaviors and strategies for eachagent. In 
our new strategic personality (the bottom diagram in Figure 2), the primitive actions in the tactical 
personality are replaced with high level strategies. The commander has several strategies in mind, each 
of which is assigned a weight before the start of the decision making process. Similarly, if P . is the 
set strategic of all strategic personalities, the strategic personality of an agent, strategic, is a 
function that assigns a weight to each strategy which is determined by the learning framework as elabo­rated 
on in later sub-sections. Pstrategic . P . Pstrategic : S . W, (2) where S is the set of all strategies. 
 3.2 Behavior and Strategy Selection Common to anyonline learning framework, we need to address the 
problem of exploration versus exploitation, namely, at each loop, thebehaviorand strategy generators 
either choosetoexploitthecur­rently learnt knowledge and choose an optimal item, or to choose a suboptimal 
item to create new learning instances and improve that item s assigned weight. For the behavior generator, 
as described in [Tan and Cheng 2007], we adopt the standard .-greedy algorithm [Sutton and Barto 1998]. 
This basically means that the generator chooses a random tactical behavior sequence with probability 
., and exploits the knowledge to generate the best behavior (actions with the highest weight) oth­erwise. 
For the strategy generator, the selection process follows a softmax kindof rule [Suttonand Barto 1998] 
whereahigher wi value means a higher chance of being selected, where wi . W is the weight assigned to 
strategy si . S. The probability, Pr, of selecting a  Figure 2: An example tactical personality (top) 
and strategic personality (bottom): For the tactical personality, each action is tagged witharelative 
weight that canbeevaluated intoaprobabil­ity of choosing it. The shaded ones are the adaptable actions 
whilst the unshaded ones are non-adaptable. The strategic personality is similarly de.ned. strategy, 
si, at time t is wi/t e Pr(st = si)= , (3) .nk=1 ewk /t where n is the total number of strategies and 
t is a temperature variable to control the greediness of the approach [Sutton and Barto 1998]. These 
straightforward selection methods ensure that behavior gen­eration and strategy selection can be done 
very quickly without in­terruptingoroverlapping with actualgameplay. Also,a changein the weights directly 
leads to a different tactical and strategic char­acteristic for an agent, hence enabling a platform for 
variability of gameplay which improves entertainment value. Note that strategy generation uses a softmax 
rule as opposed to the .-greedy method used in tactical behavior generation. This is because strategically 
we prefer a more constant performance over variability whereas tactically, variability is as important 
as constant performance (for the purpose of entertainment value as mentioned). Asoftmax rule ensures 
that higher weights would always result in a higher chance of being selected whereas the .-greedy method 
chooses randomly when exploring. After the strategies are passed down the hierarchyand each agent has 
determined its behavioral action, thegameisexecuted until the next reevaluation time, T . This reevaluation 
time is basically the time step that is set for the agents to reevaluate the strategies and hence their 
behaviors. It canbea periodic timeingame or mile­stones (for example map transitions in an RPG or respawn 
times in an FPS). After each execution, a reward value, rT , is generated via an error function .. rT 
= . .k|HT (ok)|- . .k|HT (ok)|, (4) ok.Oo. .O. k for the particular strategy, i, is used before this 
reevaluation time, where O is the set of all objects of the player team (agents,build­ings, turrets, 
or other objects useful in determining the winning chance) and O. is the set of all objects of the computer 
controlled team. Ht(x) de.nes a function that returns the hit-points or health of a game object x at 
time t. .k and .k . are coef.cients to bal­ance the weightage of each type of unit, where .allk .k =1 
and .allk .k . =1. This value, rT , represents the environmentfac­tor as shown in Figure2 which is passed 
on to the reinforcement process in the tactical and strategy cognitions.  3.3 Reinforcement and Command 
Injection The tactical and strategic cognitions each perform a two stage pro­cess to determine the personalities 
to be used in behavior and strat­egy selection, namely reinforcement and command injection. In the reinforcement 
stage, only the behavior and strategy in use (before the current reevaluation time step) is affected. 
For each adaptable action,j,inthebehavior sequenceinuse,theupdate functionforits weight, wj , is wj = 
wj + a(rT - rT ), (5) where a isa positive step-size parameterto controlthe magnitude of change. rT is 
a reference point to determine whether the current reward is large or small [Sutton and Barto 1998], 
and it can either be a heuristic value or simply the average rewards over all the pre­vious reevaluation 
time steps until the current time step. Similarly, if strategy i is the current strategy in use, then 
the update function for the strategy weight, wi, is wi = wi + ß(rT - rT ). (6) After the tactical and 
strategic personalities are updatedbythe rein­forcement process, the strategy received from the previous 
hierar­chyis used to temporarily affect the weight values before the selec­tion processes are performed. 
This is the command injection stage. If si-1 is the strategy passed down from the agent from the previous 
hierarchy, we can de.ne . P = Ctactical(Ptactical,si-1) and (7) tactical . Pstrategic = Cstrategic(Pstrategic,si-1), 
(8) where P . and P . strategic are the new personalities respec­tively. The functions Ctactical and 
Cstrategic can be rule-bases that de.ne the effect of each individual strategy on the current weights 
or a machine learning system trained to assign changes to each of the weights according to the strategy 
being received. In this pa­per, the experimental setup follows a rule-base system because the nature 
of ourgame requires domain knowledge for each strategy received. Having the functions as rule-bases provides 
an avenue for the inclusion of domain knowledge (speci.c to differentgame genres) in our framework. tactical 
 4 Empirical Evaluation and Discussion In ordertoevaluate our frameworkinarealgameenvironment,we implementatypical 
actiongame scenariobuilt on theTruevision3D 6.5game engine(a screenshotof the environmentis as shownin 
Figure 3). While this scenario is close to that of an FPS, the frame­work canbe appliedto othergamesofdifferent 
genres. 4.1 Game Mechanics Our test environment consists of two opposing teams with symmet­rical initial 
geometric positions and identical team structures. Each team consists of agents having one base to defend. 
The team struc­tureofourmainexperimentisshownin Figure4withatoplevel commander directing multiple sub-teams, 
each with a team leader agentandanumberof subordinate agents. Neither teamwouldhave anytactical or strategic 
advantage at the start. The experiments are performed in iterations that end when either team wins or 
a draw occurs. A team wins only when the opposing team s base is de­stroyed. A draw happens when both 
teams have no more agents alivebut both bases are not destroyed. Figure 3: ScreenshotofTestEnvironment: 
TeamAconsistsofthe lighter colored characters (mainly on the bottom side of the .gure) whilstTeamBconsistsof 
the darker coloredcharacters. The constituents that make up the tactical and strategic personal­ities 
are also shown in Figure 4. Tactically, each agent is able to either melee (close range attack with larger 
damage), shoot (long range attack with lesser damage) or heal an ally agent. The base acts as a turret 
that has a longer range than agents and can attack a single enemy at a time. Strategically, the strategies 
available to the commander agents of each team are 1. Hunting attack. All ally agents would move towards 
and at­tack enemy agents .rst, destroying all opponent agents before moving on to destroythe enemy base. 
 2. Critical attack. All ally agents would move towards the en­emy base and try to bring it down. Theykeep 
attacking until either the enemy base is destroyed or the whole team is anni­hilated. 3. Flanking attack. 
Some ally agents would move towards and attack enemy agents whilst the rest of the ally agents move towards 
one side of the enemy base and attack it from there. 4. All defense. All ally agents would stay near 
the ally base and attack any enemy agents that come within range. When all enemy agents are destroyed, 
theywill move to and attack the enemy base. 5. Attack &#38; Defend. Some ally agents would stay near 
the ally base whilstthe restwouldmovetowardsand attackthe enemy agents or enemy base.  For the team 
incorporated with our framework (Team A), the be­havior and strategies are selected and adapted according 
to the tech­niques depictedinthispaper.Forthe opposingteam(TeamB),the Figure 4: Experimental Setup of 
Units Hierarchy: Each team in the experiment consists of one commander, two sub-team leaders and 6 units. 
All agents have the same type of tactical personal­ity (with different weights), but the strategic personalities 
at each hierarchical level are made up of different items. tactical behavior is randomly selected between 
the3types shown. For eachexperimental setup, oneof the5strategiesis chosen and .xed forTeamB. HenceTeamB 
portraysa team scripted witha proper strategy and at the same time having some variance in their tactical 
behavior. At the start of each experimental setup, Team Ahas their tactical and strategic personalities 
randomly initialized. We also include anexperimental setup wherebyTeamBchoosesa random strategy at each 
iteration. To evaluate the scalability of our framework, we have also ran the experiments with an increasingly 
large number of agents. The total time needed for all the agents to complete decision making at each 
reevaluation stepis recorded andaveragedover 500 runs for each experiment set.  4.2 Results and Discussion 
The main results are shown in Figure 5 on the last page of this paper. The graphs show the reward value 
plotted against the num­ber of iterations. We chose to include all the agents hit-points as well as the 
bases hit-points for the calculation of the reward as de­pictedin Equation4.Apositivereward meansTeamAhaswonthe 
game, and the larger it is, the larger the margin of success (higher performance), and vice versa. As 
can be seen, all the experiments eventually convergetoastable state whereTeamAconstantly wins. In cases 
whereTeamArandomly starts witha poormixof tactics and strategies (Sets1,2and4),it loses .rst and tries 
out eachof the other approaches and eventually .nds a winning strategy which is reinforced and constantly 
applied. In other cases,TeamAstarts with a relatively good strategy (Sets 3 and 5) which is also rein­forcedand 
constantly utilizedtowinthegame.ForexperimentSet 2 we can see that the opponent s strategy (all Team 
B agents at­tacking the base at once) is a harder one to beat and the positive rewards are smallinvalue.NeverthelessTeamAstill 
.ndsthebest approachin the end. Inexperiment Set6,TeamA also manages to .nda winning strategyeven thoughTeamBrandomly 
chooses a strategy at every round. At around 400 iterations there is a spike down probably due to the 
randomness,butTeamAstill manages to recover after another 50 iterations. In general, we can observe that 
our adaptive framework enables the agent to constantly per­form better than teams with .xed approaches. 
In Figure 6, the graph shows the decision making times needed for experimental runs involving different 
number of agents. Although the time requiredisincreasingina roughly linearfashion,it still only takes 
slightly more than one millisecond for 100 agents, which is ratherfast. This shows that the framework 
can be implemented evenfor massive moderngames withalarge numberof intelligent  Figure 6: ScalabilityTest 
Results: The average timerequired for decision making is plotted against the number of agents. The deci­sion 
time increases roughly linear with the number of agents. agents.  5 Conclusion and Future Work We have 
presented a generic cognitive multi-agent framework for both tactical and strategic planning which is 
shown to exhibit bet­ter performance against various scripted opponent team tactics and strategies, as 
well as one with a randomly varying strategy. Ad­vancing from thework doneby[Tan and Cheng 2007], wehave 
in­troduced a new strategic personality concept as well as established a command-passing mechanism for 
team hierarchy. The combined personalities provide a means for adaptation both towards the feed­back 
from the environment as well as the strategy command passed down from the previous hierarchical level. 
Our method also de­couples action and strategy selection from the resource intensive learning process, 
hence reducing disruptions to actual gameplay. Moreover, the tactical .exibility in behavioral selection 
and decen­tralized strategic planning process introduce interesting and vari­able character behaviors, 
increasing the entertainment value for the player. As a next step, we hope to investigate a generic system 
to represent the tactical and strategic cognitions. The system should ideally be able to automatically 
provide the weight differences to the person­alities, given a new strategy. To do so, we need to formally 
de.ne the strategy space. Also, as we did not evaluate the improvements we achievedin termsof entertainmentvalue,wehopetodosointhe 
future,usinga user surveymethodto recordthegamingexperience of players for our analysis.  References 
ANDRADE, G., RAMALHO, G., SANTANA, H., AND CORRUBLE, V. 2005. Automatic computergame balancing:Areinforcement 
learning approach. In Proceedings of the Autonomous Agents And Multi Agent Systems Conference (July), 
1111,1112. BLIZZARD ENTERTAINMENT, 2006. Warcraft III. Accessed April 12, 2006.Available via http://www.blizzard.com/war3/. 
BLIZZARD, 2006. Diablo ii. Accessed April 12, 2006.Available via http://www.blizzard.com/diablo2/. BLIZZARD, 
2006. World of warcraft. Accessed April 12, 2006. Available via http://www.worldofwarcraft.com/. BURO, 
M., 2007. ORTS -A Free Software RTS Game Engine. Accessed March 20, 2007. Available via http://www.cs.ualberta.ca/ 
mburo/orts/index.html. CHARLES, D., KERR, A., MCNEILL, M., MCALISTER, M., BLACK, M., KCKLICH, J., MOORE, 
A., AND STRINGER, K. 2005. Player-centredgame design: Player modeling and adap­tivedigitalgames. In Proceedings 
of the Digital Games Research Conference, 285,298. CHRISTIAN J. DARKEN, G. H. P. 2006. Findin Cover in 
Dy­namic Environments, .rst ed. Charles River Media, Hingham, Massachusetts. CO-OP, S., 2006. Sven co-op. 
Accessed September 15, 2006. Available via http://www.svencoop.com/. ELECTRONIC ARTS, 2006. Battle.eld 
2142. Accessed December 20, 2006. Available via http://battle.eld.ea.com/battle.eld/bf2142/. EXLUNA, 
INC. 2002. Entropy 3.1Technical Reference, January. FEDKIW, R., STAM, J., AND JENSEN, H. W. 2001. Visual 
sim­ulation of smoke. In Proceedings of SIGGRAPH 2001, ACM Press/ACM SIGGRAPH, E. Fiume, Ed., Computer 
Graphics Proceedings, Annual Conference Series,ACM, 15 22. FOKA, A., AND TRAHANIAS, P. 2007. Real-time 
hierarchical POMDPs for autonomous robot navigation. In Proceedings of Robotics andAutonomous Systems, 
561,571. GERAMIFARD,A.,CHUBAK,P., AND BULITKO,V. 2006. Biased cost path.nding. In Proceedings of the 
Arti.cial Intelligence and Interactive Digital Entertainment conference, 112,114. HORSWILL,I., AND ZUBEK,R. 
1999. Robot architectures for be­lievablegame agents. In Proceedings of the 1999 AAAI Spring Symposium 
on Arti.cial Intelligence and Computer Games, AAAITechnical Report SS-99-02. HUNICKE, R., AND CHAPMAN, 
V. 2004. AI for Dynamic Dif.­cult Adjustment in Games. In Proceedings of the Challenges in Game AIWorkshop, 
Nineteenth National Conference on Arti.­cial Intelligence. HUSSAIN,T.S., AND VIDAVER,G. 2006. Flexible 
and purpose­ful npc behaviors using real-time genetic control. In Proceed­ings of The IEEE Congress on 
Evolutionary Computation (July), 785,792. JOBSON, D. J., RAHMAN, Z., AND WOODELL, G. A. 1995. Retinex 
image processing: Improved .delity to direct visual ob­servation. In Proceedings of the IS&#38;T Fourth 
Color Imaging Conference: Color Science, Systems, and Applications, vol. 4, 124 125. KARTCH,D. 2000. 
Ef.cient Rendering and Compression for Full-Parallax Computer-Generated Holographic Stereograms. PhD 
thesis, Cornell University. KHOO,A., AND DUNHAM,G. 2002. Ef.cient, realistic npc con­trol systems using 
behavior-based techniques. In AAAITechnical Report, 02 01. LANDIS,H., 2002. Global illuminationin production.ACM 
SIG-GRAPH 2002 Course #16 Notes, July. LEVOY, M., PULLI, K., CURLESS, B., RUSINKIEWICZ, S., KOLLER, D., 
PEREIRA, L., GINZTON, M., ANDERSON, S., DAVIS, J., GINSBERG, J., SHADE, J., AND FULK, D. 2000. The digital 
michelangelo project. In Proceedings of SIGGRAPH 2000,ACM Press/ACM SIGGRAPH,NewYork,K.Akeley, Ed., Computer 
Graphics Proceedings, Annual Conference Se­ries,ACM, 131 144. MCDONALD, D., LEUNG, A., FERGUSON, W., 
AND HUSSAIN, T. 2006. An abstraction framework for cooperation among agents and people in a virtual world. 
In Proceedings of the Sec­ond Conference on Arti.cial Intelligence and Interactive Digital Entertainment 
(June). MICHAEL E. TIPPING, C. M. B. 1999. Probabilistic principal component analysis. Technical Report 
NCRG/97/010, Neural Computing Research Grou (September). NCSOFT, 2006. Guild wars. Accessed April 12, 
2006. Available via http://www.guildwars.com/. OLIEHOEK, F. 2005. Game Theory and AI: A uni.ed Approach 
to Poker Games. Masters Thesis, 561,571. ORKIN, J. 2004. Applying Goal-Oriented Action Planning to Games, 
.rst ed. Charles River Media, Hingham, Massachusetts. ORKIN, J. 2004. Finite State Machines, .rst ed. 
Charles River Media, Hingham, Massachusetts. ORR, G., SCHRAUDOLPH, N., AND CUMMINS, F., 1999. Cs-449: 
Neural networks lecture notes. Accessed December 20, 2005. Available via http://www.willamette.edu/ gorr/classes/cs449/intro.html. 
PARK, S. W., LINSEN, L., KREYLOS, O., OWENS, J. D., AND HAMANN, B. 2006. Discrete sibson interpolation. 
IEEE Trans­actions on Visualization and Computer Graphics 12, 2 (Mar./ Apr.), 243 253. PARKE, F. I., 
AND WATERS, K. 1996. Computer Facial Anima­tion. A. K. Peters. PELLACINI, F., VIDIM .CE, K., LEFOHN, 
A., MOHR, A., LEONE, M., AND WARREN, J. 2005. Lpics: a hybrid hardware­accelerated relighting engine 
for computer cinematography. ACM Transactions on Graphics 24, 3 (Aug.), 464 470. REMCO STRAATMAN, A. 
B., AND VAN DER STERREN, W. 2006. Dynamic Tactical Postion Evaluation, .rst ed. Charles River Media, 
Hingham, Massachusetts. SAILERA, F., BURO, M., AND LANCTOT, M. 2007. Adver­sarial planning through strategy 
simulation. In Proceedings of the IEEE Symposium on Computational Intelligence and Games (April). SAKO, 
Y., AND FUJIMURA, K. 2000. Shape similarity by ho­motropic deformation. The Visual Computer 16, 1, 47 
61. SIERRA, 2006. No one lives forever 2. Accessed April 12, 2006. Available via http://nolf.sierra.com/. 
SIERRA, 2007. First encounter assault recon. Accessed December 23, 2007. Available via http://www.whatisfear.com/fear.html. 
SILVER, D. 2005. Cooperative path.nding. In Proceedings of the First Arti.cial Intelligence and Interactive 
Digital Entertain­ment conference, 117,122. SPRONCK, P., SPRINKHUIZEN-KUYPER, I., AND POSTMA, E. 2004. 
Dif.culty Scaling of Game AI. In Proceedings of GAME-ON 2004: 5th International Conference on Intelligent 
Games and Simulation, 33,37. SPRONCK, P., PONSEN, M., SPRINKHUIZEN-KUYPER, I., AND POSTMA, E. 2006. Adaptive 
Game AI with Dynamic Scripting. Springer Netherlands, Netherlands. SPRONCK, P. 2005. A model for reliable 
adaptive game intel­ligence. In IJCAI-05 Workshop on Reasoning, Representation, and Learning in Computer 
Games, 95,100. SUTTON, R. S., AND BARTO, A. G. 1998. Reinforcement Learning: An Introduction. The MIT 
Press, Cambridge, Mas­sachusetts. SWEETSER, P. 2005. An emergent approach to game design. Ph.D Thesis. 
Available via http://www.itee.uq.edu.au/ penny/publications. TAN, C. T., AND CHENG, H. 2007. Personality-based 
Adapta­tion for Teamwork in Game Agents. In Proceedings of the Third Conference on Arti.cial Intelligence 
and Interactive Digital En­tertainment, 37. THUE, D., AND BULITKO, V. 2006. Modeling goal-directed play­ers 
in digital games. In Proceedings of the Arti.cial Intelligence and Interactive Digital Entertainment 
conference, 285,298. WALLACE, N. 2004. Hierarchical Planning in Dynamic Worlds, .rst ed. Charles River 
Media, Hingham, Massachusetts. WHITE, C., AND BROGAN, D. 2006. The self organization of context for multi 
agent games. In Proceedings of 2nd Annual Conference on Arti.cial Intelligence in Interactive Digital 
En­tertainment (June). WIKIPEDIA, 2006. Game balance. Accessed December 20, 2006. Available via http://en.wikipedia.org/wiki/Gamebalance. 
YANNAKAKIS, G. N., AND MARAGOUDAKIS, M. 2005. Player modeling impact on players entertainment in computer 
games. In Springer-Verlag: Lecture Notes in Computer Science, 3538:74. YEE, Y. L. H. 2000. Spatiotemporal 
sensistivity and visual atten­tion for ef.cient rendering of dynamic environments. Master s thesis, Cornell 
University.  Figure 5: Experimental Results:Eachexperimentsethastherewardvalueplottedagainstthenumberofiterations.IngeneralTeamA(with 
our AI) is always able to converge to a set of good tactics and strategies for a winning approach.  
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
	</article_rec>
	<article_rec>
		<article_id>1401866</article_id>
		<sort_key>230</sort_key>
		<display_label>Pages</display_label>
		<pages>6</pages>
		<article_publication_date>08-09-2008</article_publication_date>
		<seq_no>3</seq_no>
		<title><![CDATA[Supporting wayfinding through patterns within procedurally generated virtual environments]]></title>
		<page_from>123</page_from>
		<page_to>128</page_to>
		<doi_number>10.1145/1401843.1401866</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1401866</url>
		<abstract>
			<par><![CDATA[<p>Procedurally generated 3D worlds pose their own problems in terms of user's navigation. The rules for supporting wayfinding through specific world generation have to be categorized and implemented in the generative algorithms. Our answer to this problem is based on a combination of the architectural theories by Lynch and Alexander. We adjusted a procedural world generator to include selected patterns as suggested by these theorists. Unlike other research, we put our main focus not on an arrangement of obvious landmarks but instead on the organization of objects that form patterns of much smaller scale in their spatial combination to trace how players structure and comprehend these environmental patterns. Our hypothesis was that these smallscale patterns would assist player navigation in procedural worlds. We tested our model in the procedural world generator <i>Charbitat.</i> Statistical analyses showed no significant effect of environmental patterns on player navigation. However, post-experiment questionnaires indicated that users were aware of the patterns and had used them for orientation. This suggests that while patterns were sought after, they alone apparently were not sufficient to improve user navigation in the 3D world.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[gaming]]></kw>
			<kw><![CDATA[navigation]]></kw>
			<kw><![CDATA[procedural]]></kw>
			<kw><![CDATA[virtual space]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1100744</person_id>
				<author_profile_id><![CDATA[81421601765]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Michael]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Biggs]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Georgia Institute of Technology]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1100745</person_id>
				<author_profile_id><![CDATA[81365593753]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Ute]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Fischer]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Georgia Institute of Technology]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1100746</person_id>
				<author_profile_id><![CDATA[81318491041]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Michael]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Nitsche]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Georgia Institute of Technology]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Alexander, C. <i>The Timeless Way of Building.</i> New York: Oxford University Press, 1979.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Alexander, C., Ishikawa, S., and Silverstein, M. <i>A Pattern Language.</i> New York: Oxford University Press, 1977.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Biederman, I. 'Recognition by components: A theory of human image understanding.' <i>Psych. Rev.</i> 94, 1987, 115--147.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Darken, R. P., Bernatovich, D., Lawson, J. P., and Peterson, B. 'Quantitative Measures of Presence in Virtual Environments: The Roles of Attention and Spatial Comprehension.' <i>Cyberpsychology and Behavior</i>, 2(4) 1999, 337--347.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Lynch, K. <i>The Image of the City.</i> Cambridge, MA: MIT Press, 1960.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Lawton, C. and Kallai, J. 'Gender Differences in Wayfinding Strategies and Anxiety About Wayfinding: A Cross-Cultural Comparison.' <i>Sex Roles</i>, 47(9--10), 2002, 389--401.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Ljungstr&#246;m, M. 'The use of architectural patterns in MMORPGs.' Presented at <i>Aesthetics of Play</i>, Bergen, Norway (14--15 Oct) 2005 http://www.aestheticsofplay.org/ljunstrom.php.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Nitsche, M., Ashmore, C., Hankinson, W., Fitzpatrick, R., Kelly, J. and Margenau, K., 'Designing Procedural Game Spaces: A Case Study' in: <i>Proceedings of FuturePlay</i> 2006 London, Ontario (October 10--12), 2006, (digital proceedings)]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>383292</ref_obj_id>
				<ref_obj_pid>383259</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Parish, Y. I. H. and Muller, P. 'Procedural modeling of cities', <i>Proceedings of the 28th Annual Conference on Computer Graphics and Interactive Techniques</i>, Los Angeles, CA, 2001, 301--308.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Strohecker, C., Barros, B., and Slaughter, A. 'Mapping Psychological and Virtual Spaces' MERL TR 98--12 (Sept) Cambridge, MA, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>303062</ref_obj_id>
				<ref_obj_pid>302979</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Vinson, N. G. 'Design guidelines for landmarks to support navigation in virtual environments.' <i>Proceedings of the SIGCHI conference on Human Factors in Computing Systems: The CHI is the Limit</i>, May 15--20, Pittsburgh, PA, 1999, 278--285.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Supporting Wayfinding through Patterns within Procedurally Generated Virtual Environments Michael 
Biggs * Ute Fischer Michael Nitsche LCC LCC LCC Georgia Institute of Technology Georgia Institute 
of Technology Georgia Institute of Technology Terrain is created during runtime and objects in the landscape 
are ABSTRACT positioned and selected based on generative algorithms. This 3DProcedurally generated 3D 
worlds pose their own problems in world is implemented in a case study designing procedural game terms 
of user s navigation. The rules for supporting wayfinding spaces. The algorithms used to manipulate the 
terrain and to through specific world generation have to be categorized and position objects accept parameters 
that can be affected by the implemented in the generative algorithms. Our answer to this user s actions. 
Actions that the user performs change these problem is based on a combination of the architectural theories 
by underlying seed values and cause the environment to be generated Lynch and Alexander. We adjusted 
a procedural world generator differently. The result is a user-driven 3D space that combines to to include 
selected patterns as suggested by these theorists. an infinite game world that grows larger as the player 
continues to Unlike other research, we put our main focus not on an play in it [Nitsche et al. 2006]. 
Like any other 3D virtual world, arrangement of obvious landmarks but instead on the organization this 
environment has to support a number of functions to remain of objects that form patterns of much smaller 
scale in their spatial accessible and comprehensible; one of them is to support acombination to trace 
how players structure and comprehend these player s navigation of the world. environmental patterns. 
Our hypothesis was that these small­scale patterns would assist player navigation in procedural worlds. 
We tested our model in the procedural world generator Charbitat. Statistical analyses showed no significant 
effect of environmental patterns on player navigation. However, post-experiment questionnaires indicated 
that users were aware of the patterns and had used them for orientation. This suggests that while patterns 
were sought after, they alone apparently were not sufficient to improve user navigation in the 3D world. 
 Keywords Gaming, navigation, procedural, virtual space 1. INTRODUCTION Figure 1 Screenshot of the 
original version of Charbitat Procedural world generation is emerging as a new way of content generation 
in video games. On the one hand, it supports In order to facilitate user navigation within Charbitat, 
we traditional game features such as automated level generators. On experimented with the generative 
algorithms to take guidelines the other hand, it provides high level detail environments for next for 
supporting wayfinding into account. The aim was to generation game engines with relative ease and allows 
for new implement and test a procedural method for structuring 3D game concepts that explore the feature 
of content generation at spaces. This paper will discuss how users wayfinding ability their very core. 
During our own work with procedurally within Charbitat changed in relation to specific spatial generated 
3D worlds in the Charbitat project we noticed that the configurations placed in the environment. The 
data gathered may generation of the world itself although challenging was not the be used to find new 
techniques of object placement and main and certainly not the final problem in this area. Instead, the 
orientation within a procedurally generated environment and question how to use, read, and comprehend 
these worlds became inform future 3D world design. central the moment players started to actually interact 
with them. It is largely accepted that players navigate virtual worlds by Charbitat is an experimental 
game project that investigates making sense of the space in a manner very closely related to the procedurally 
generated, navigable, 3D virtual environments. way they read physical real space. Consequently, spatial 
design patterns for real and virtual environments are often connected. For example, Parish and Müller 
generate cityscapes procedurally * email: mbiggs3@gatech.edu from road layout to building assemblies 
and facades [Parish/ email: ute.fischer@gatech.edu Muller 2001]. Norman Vinson suggests higher level 
frameworks email: michael.nitsche@lcc.gatech.edu for designing virtual environments based on studies 
of human navigation within real environments [Vinson 1999]. Darken has tested multiple facets of navigation 
in virtual work, and found that Copyright &#38;#169; 2008 by the Association for Computing Machinery, 
Inc. users recognize a landmark in relation to their presence within the Permission to make digital or 
hard copies of part or all of this work for personal or virtual environment which, in turn, impacts their 
orientation skills for commercial advantage and that copies bear this notice and the full citation on 
the [Darken et al. 1999]. However, most of these studies of first page. Copyrights for components of 
this work owned by others than ACM must be wayfinding within virtual environments focus on static spaces. 
honored. Abstracting with credit is permitted. To copy otherwise, to republish, to post on They were 
not designed, implemented, or tested in procedural servers, or to redistribute to lists, requires prior 
specific permission and/or a fee. Request permissions from Permissions Dept, ACM Inc., fax +1 (212) 869-0481 
or e-mail worlds. Environments that algorithmically create spatial elements permissions@acm.org. Sandbox 
Symposium 2008, Los Angeles, California, August 9 10, 2008. &#38;#169; 2008 ACM 978-1-60558-173-6/08/0008 
$5.00 lack the conscious (or sub-conscious) arrangement of terrain and objects by a level designer. 
Instead, they are the result of a given rule system that operates precisely, can be replicated, and adjusted 
to new conditions. This paper reports on the findings regarding our implementation of rules we adopted 
from Alexander s pattern language and Lynch s model for cognitive mapping in this world generation. 
  2. PROCEDURAL OBJECT PLACEMENT 2.1 Alexander s Patterns In "A Pattern Language" [Alexander/ Ishikawa/ 
Silverstein 1977], Christopher Alexander, Sara Ishikawa, and Murray Silverstein describe 253 architectural 
patterns they derived from existing real world structures. The patterns comprise an archetypical language 
for what Alexander has termed the one timeless way of building [Alexander 1979] which emphasizes the 
liveliness of architectural structures. Liveliness relates to the degree in which these patterns reflect 
and support the human use of architectural structures. Based on existing arrangements, these patterns 
present a valuable bridge into the real world architecture when applied to virtual environments. The 
patterns vary in scale and context and range from the materials that should be used when developing a 
building to the differences between tree arrangements. For instance Pattern 1 Independent Regions describes 
regional arrangements in large urban areas while Pattern 253 Things from Your Life suggests wall hangings 
for individual rooms. While the majority of Alexander s patterns are germane to the architecture of urban 
environments, some can be applied to game worlds to create designs familiar to users. Alexander s patterns 
can be used when procedurally generating individual cities or a series of towns. Out of the 253 patterns 
listed within Alexander s work, the first 94 patterns deal with the way whole towns and communities can 
be organized. The parameters listed in the pattern Distribution of Towns (2) describe how far apart towns 
of certain sizes are from one another. They can be used within an algorithm determining the layout of 
a series of towns. If one was to procedurally generate the roads within a city by a body of water, the 
pattern Access to Water (25) would provide useful advice stating that roads are typically orientated 
in right angles of the water. Patterns that describe room lay-outs within different types of buildings 
can be used to provide variety when procedurally generating buildings within a city. The Holy Ground 
(66) pattern describes buildings that are used for religious purposes. They are typically made up of 
a number of nested precincts that gradually get smaller, ending in a room that can be referred to as 
the innermost sanctum. This room can only be reached by passing through each gateway of the outer precincts. 
In the Intimacy Gradient (127) pattern, Alexander describes how all buildings should have rooms that 
are more public near their entrances. These public areas should lead to slightly more private areas which 
lead to the most private rooms in the building. Pattern 120 Paths and Goals specifies that landmarks 
have to be sufficiently separated from one other to facilitate walking between them, but they have to 
be within line of sight so that the player can know how to get to the next landmark. Ljungström provides 
examples of this pattern in World of Warcraft [Ljungström 2005]. High Places (62): There should be occasional 
high places within a city. Increased elevation in a procedurally generated world would allow a player 
to survey the area that he or she has covered. Tree Places (171), Alexander lists three main types of 
tree arrangements that have different meanings to a person in the space. An umbrella arrangement serves 
as a place for someone to sit or rest. A pair of trees serves as a gateway. A grove is a circle of trees 
with space in the center that separates the inner space from the outside. An avenue is a double row of 
trees that serves a path to another location. For this study, we concentrated on the patterns that were 
listed in the Tree Places section as it related most directly to the world generations in Charbitat that 
generate mainly virtual outdoor scenarios. Alexander believes that trees have a very deep and crucial 
meaning to human beings. [Alexander/ Ishikawa/ Silverstein 1977] He goes on to state that there is an 
indication that trees, along with houses and other people, constitute one of the three most basic parts 
of the human environment. [ibid.] We attempt to utilize this fundamental aspect of an environment by 
populating the test world with basic objects and textures that map to tree structures. We modified the 
world generator to spawn objects in Alexander-like patterns. The first question was, whether players 
would recognize these patterns during play testing. A single pattern provides for orientation only in 
its immediate vicinity, not covering the necessary breadth needed for a navigation exercise. Thus, we 
spawned these patterns all over the 3D world in the hope that players would start to assemble them into 
more complex cognitive patterns as suggested by Kevin Lynch.  2.2 Lynch s Elements In Image of the City 
, Kevin Lynch describes five types of elements that people use to form cognitive maps of urban environments 
[Lynch 1960]. These five elements are: Landmarks: that often have some unique feature that lets them 
stand out as singularities in the environment  Paths: that indicate a direction and might be channels 
that an observer travels  Edges: that provide a form of (not necessarily impenetrable) border  Nodes: 
that can include junction points or a strategic point for decision  Districts: that often use homogeneous 
elements in, for example, façade, material, or skyline which distinguish them from other zones  His 
model has been applied to virtual environments in numerous projects as analytical tool (as seen in Darken) 
and as design guideline. For an early example, see Strohecker, Barros, and Slaughter s Placeholder project 
[Strohecker/ Barros/ Slaughter 1998]. Its value for the design and comprehension of virtual spaces is 
widely discussed and generally accepted. Charbitat features multiple structural characteristics that 
Lynch describes in his work as supportive of a player s ability to form cognitive maps. Most of the projects 
dealing with Lynch s model operate on the level of landmarks and large-scale orientation and navigation 
helpers. In addition to these (often obvious) arrangements, we wanted to examine how the less obvious 
pattern structures suggested by Alexander can serve as navigational helpers and support the generation 
of a cognitive map of the virtual world as proposed by Lynch. Thus, our approach differs in two significant 
ways from past research: 1) rather than concentrating on navigation along clearly marked unique and 
singular landmarks, we investigate small-scale patterns; 2) instead of fixed virtual environments that 
often include conscious or sub-conscious design patterns, we present and test a system in a procedural 
setting. Two questions motivated our research: First, we wanted to determine whether the patterns are 
indeed recognized by players. An affirmative answer would prove the functionality of our procedural generation 
and the value of patterns as such. Second, we wanted to find out whether players can use these patterns 
alone to effectively navigate the 3D world. Our hypothesis was that a procedural implementation of a 
selection of Alexander s patterns will assist players navigation of a virtual world as players will recognize 
these patterns and use them for spatial reasoning in the way suggested by Lynch even in the absence of 
other markers.  3. STUDY OF PLAYER NAVIGATION 3.1 Approach In previous Charbitat installments a number 
of Lynch-like structures were actively supported. Procedurally generated rivers and sea shores referred 
to possible edges, roads to paths, extremely rare 3D objects or especially high ones could be seen as 
unique landmarks. Numerous clearly distinguishable objects of varying size, color, and texture were positioned 
in the generated game world (see fig. 1). A random noise function was used as the main factor in positioning 
the environmental objects and algorithms controlled consistency of larger scale objects (e.g. a river 
would run continuously through multiple sections of the environment). Instead of random placement, the 
pattern-infused version applied certain patterns established by Alexander to the arrangement and spatial 
relationship between the visible objects in the 3D world. The selected patterns were: Figure 2 Picture 
from A Pattern Language showing three tree patterns The project deliberately concentrated on the recognition 
of these patterns as opposed to singular objects and elements. That meant that individual objects forming 
these patterns could not have any unique traits. To avoid possible unintended recognition of individual 
objects as landmarks in the testing environment, we replaced the descriptive geometry of the original 
Charbitat environment with abstract shapes called geons. Geons are basic geometric shapes that have been 
proposed, within the recognition-by-component theory [Biederman 1987], as a way people segment their 
viewing of complex objects. Figure 3. A subset of geons from Biederman s Recognition by Component Theory 
The theory proposes that people map basic shapes such as rectangular blocks or curved cylinders onto 
certain portions of the object they are viewing depending on how close the components of the viewed object 
match the basic shapes. Although geons are abstract, they remain recognizable and distinct. That means 
that while the individual geon does not appear as a single unique landmark object, it is sufficiently 
distinct to help the user distinguish between each type of environmental object. The user's avatar will 
be unable to move or see through these environmental objects. They act as obstacles as well as visual 
cues for the user. We used four different types of geons to construct the objects within the 3D environment: 
the rectangle, cylinder, rectangular pyramid and the cylindrical pyramid. Figure 4. Example of a geon 
next to the avatar in the 3D environment At the same time, the detailed texturing at work in the original 
Charbitat project was reduced to minimal differences in the texturing of the geons. This additional graphical 
limitation was applied to prevent that individual outstanding objects could be defined by their material 
and used for orientation. Ultimately, geons provided the necessary variety of objects but care was taken 
to avoid the generation of obvious singular landmark objects. This design feature of the Charbitat world 
was intended to make recognition of individual objects more difficult, and instead to direct a user s 
attention to the spatial relationships between them. Alexander s patterns were included into the world 
generating algorithms of Charbitat and realized as spatial patterns formed by geon objects in the 3D 
world. Our hypothesis was that this kind of micro-structured landscape will facilitate players navigation 
through the 3D world.  3.2 Design of Experiment To test this hypothesis, players were assigned to one 
of two groups: One group navigated through a procedurally generated environment with geon objects placed 
according to Alexander s patterns; the control group navigated through a procedurally generated environment 
with randomly placed geon objects. The study involved three different phases. In the first phase, floating 
key objects surrounded a player s avatar (see fig. 5). The keys were placed in the world slightly above 
the avatar, so a player-avatar had to jump to make contact with a key. Once the player had made contact 
with a key, it disappeared permanently from the world. Players were asked to have their avatar touch 
all 5 keys in order to familiarize them with the controls of the system. All necessary control options 
had to be performed by a player to succeed in this phase: movement of the avatar, jumping, and camera 
control. Data collected from this portion of the study were not included in assessing players navigation 
performance. The second phase started with a navigation task that required players to explore the world. 
Players were informed that there was another key (just like the ones used in the first stage) hidden 
in the game world and that they had to find it. Data collected from this portion of the study were used 
to examine whether experimental and control groups exhibited different movement patterns while searching 
the 3D environment. We hypothesized that environmental patterns will help players to better structure 
their search. The third stage was initiated once players found the last key. At that point, players were 
asked to find their way back to the place where they had started their search. Data collected from their 
return trip was used to determine whether players had created a cognitive map during the search phase 
that aided them to find their way back. Upon completion of the game, players received a questionnaire. 
Two demographic questions concerned players gender as research has shown that male and females use different 
strategies to navigate within an environment [Lawton/ Kallai 2002] and familiarity with virtual 3D environments 
(rated as either very familiar, familiar, less familiar , or entirely unfamiliar ). Three questions 
probed players game experience. Players were asked to indicate how difficult it had been to find the 
way back to the origin. Answers for that question range from Very Easy to Normal to Very Hard. An open-ended 
question probed players to describe any strategy they had used to navigate back to the starting point. 
Lastly, players were asked to provide an adjective that described the game world and whether they would 
have navigated through the world longer if given the opportunity.  3.3 Setup and Configuration The Charbitat 
modification used for this test runs on consumer level PCs using keyboard and mouse as input devices. 
It is based on a modification of the Unreal Tournament 2004 game engine. The world generation is computed 
in an independent Java program, which also tracked the user behavior in-world. At the beginning of each 
game players were presented with their avatar inside the Charbitat world. The avatar s control scheme 
followed established conventions of 3D games and virtual worlds. Players could move their avatars forwards, 
backwards, and strife left and right by using the 'w', 's', 'a' and 'd' keys respectively (or the up, 
down, left and right arrow keys). The camera was consistent with game conventions: it was a following 
camera positioned behind and above the main avatar. The mouse controlled the orientation of the camera 
which in turn re-oriented the avatar in the world. As players navigated through the game world (the pattern-infused, 
or the randomly arranged environment), our system automatically traced the position of their avatars 
and stored this information to a file along with a time-stamp (see Figure 6). This allowed us to re­trace 
and interpret the movements of a player in the game world. Figure 5. The starting location of a user 
within the patterned 3D environment Finally, we had users fill out the aforementioned questionnaire to 
provide additional feedback on their overall experience. In-game data and questionnaires were stored 
along with random ID numbers to allow for correct cross-referencing of player responses while assuring 
participants anonymity. 3.5 Participants 50 individuals, mostly students, took part in the study. Participants 
were randomly assigned to the experimental or control condition. Eighteen males and seven females were 
in the control group. The experimental group consisted of fifteen male and ten female players.  4. 
RESULTS AND DISCUSSION 4.1 Measurement of Player Movement Data collection started with the second phase, 
i.e., the search for the final missing key. An alpha level of .05 was used for all statistical tests. 
Significance testing involved Analysis of Variance with game condition (control versus experimental) 
as independent variable, or when the assumption of normality was violated, the two-sample Kolmogorov-Smirnov 
(K-S) Test, or where appropriate the Spearman rank correlation (rS).  Figure 6 Visualization of one 
player s path through the 3D world (experimental group) Players in both groups found the final key and 
were able to return to the game s starting point. To examine players navigation and search behavior, 
we divided the game world into a 16x16 grid of zones and recorded each time a player passed through a 
zone in the grid, thus tracing his or her path, its length and shape. The same measures were taken during 
the return phase of the game, in addition to the amount of time players took to get back to the origin. 
Contrary to expectations, no significant differences between the control (random) group and the experimental 
(patterned) group were observed concerning the length of the return trip (K-S Z(50) Experimental Control 
Figure 9. Average number of grids passed by players in = .707, p = .699), nor time needed to navigate 
back to the starting point (K-S Z(50) = -.029, p = .98). Figure 7. Average length of the path players 
in experimental and control groups traveled to return to the origin from the location of the key experimental 
and control groups while searching for the key However, when we examined the paths players took during 
their search and return trip we noted that the navigation by participants in the experimental (patterned) 
group tended to have a structure while control subjects showed more random movements. This difference 
may suggest that subjects in the experimental group who moved through a patterned environment proceeded 
in a more goal-oriented fashion than the subjects in control group who faced a randomly generated world. 
 Two different navigation behavior characteristic of experimental and control subjects are depicted 
in Figures 6 and 10, respectively. As can be seen the path taken by experimental subjects appears compact 
and neat; in contrast the path observed for control subjects seems round-about, with many detours. This 
difference suggests that the patterned environment influenced how experimental subjects navigated the 
game world; however, the impact of the patterns apparently was not sufficiently strong to build an accurate 
cognitive map of the game space as experimental subjects were not more effective or faster to return 
to the point of origin than control subjects. Factors that may have moderated the effect of environmental 
patterns, will be addressed in the next section.   4.2 Player Variables and Perceptions Control and 
experimental subjects differed in terms of their experience with 3D games (X2(N=50; df=2) = 9.441, p 
= .009). Experimental and control groups also did not differ significantly in terms of the size of the 
area (= number of grids) they covered Specifically, as can be seen in Figure 11, control subjects indicated 
higher familiarity with 3D virtual environments than while searching for the final key (F(1,48) = .155, 
p = .70). experimental subjects. Moreover, participants familiarity with 3D games was negatively correlated 
with their judgments of how difficult it was to navigate back to the game s starting point (rS(50) = 
-.51, p = .000). That is, participants who thought the return trip was very easy or easy were predominantly 
(88.9%) those reporting high familiarity with 3D games. This finding suggests that players game literacy 
may have influenced their navigation behavior and may have moderated the effect of the visual appearance 
(patterned or random) of the game world. Players' Familiarity with 3D Games 100 80 60 40 20 0 Less Familiar 
Very Familiar Familiar Figure 11. Levels of game familiarity reported by players in experimental and 
control groups Participants descriptions of the game world revealed that we had succeeded in generating 
a world devoid of singular landmarks. Participants in both groups perceived the game world as nondescript 
(22% of respondents), maze-like (16%), barren (14%), intimidating (6%), or cluttered (6%). Despite the 
plain appearance of the game environment, players tried to find visual cues that could guide them on 
their way back to the game s starting point. While experimental and control subjects mentioned strategies 
in the post-experiment questionnaire, they did so with different frequencies (X2(N=50; df=3) = 19.84, 
p = .000) and, more importantly, referred to different cues. Most (60%) experimental subjects stated 
they had identified certain patterns in the environment and had looked for them during their return trip. 
The remaining experimental subjects indicated that they had focused on some significant landmark (12%), 
or had relied on the outer edges of the 3D space as reference (4%). This latter strategy was the dominant 
strategy reported by control subjects (32%); others mentioned landmarks (16%), or some pattern (4%). 
This finding suggests that a majority of players in both groups attempted to construct a cognitive map 
of their game environment utilizing whatever visual clues the game world afforded them. Control subjects 
navigating a randomly generated world used the edges of their world as their only available marker. While 
this behavior is consistent with Lynch s typology of cognitive map elements, the edges in our game world 
were too uninformative as to facilitate spatial orientation. For participants in the experimental group, 
in contrast, outer edges were apparently less salient than the patterns of objects present in their virtual 
environment. Consistent with our hypothesis, experimental subjects were sensitive to the Alexander patterns; 
yet their pattern recognition did not improve their spatial understanding. One possible explanation is 
that experimental subjects failed to appreciate the spatial relationships between patterns. Thus, the 
3D world remained a puzzle to them. While individual chunks Percentage of Players Experimental Control 
  were discerned, they could not be integrated into a coherent overall picture.   5. FURTHER RESEARCH 
Local patterning seems to be a useful design feature of procedural worlds because players are able to 
recognize even highly abstracted implementations of these spatial structures. However, our research suggests 
that players may not be able to construct an accurate cognitive map of a game world on the basis of these 
patterns alone. One possibility is that players may also need a certain amount of more unique landmarks 
to support cognitive maps, either in the form of special texturing or in the form of dominant patterns, 
such as Alexanders high places.  6. REFERENCES ALEXANDER, C. The Timeless Way of Building. New York: 
Oxford University Press, 1979. ALEXANDER, C., ISHIKAWA, S.,AND SILVERSTEIN, M. A Pattern Language. New 
York: Oxford University Press, 1977. BIEDERMAN, I. Recognition by components: A theory of human image 
understanding. Psych. Rev. 94, 1987, 115--147. DARKEN, R. P., BERNATOVICH, D., LAWSON, J. P., AND PETERSON, 
B. Quantitative Measures of Presence in Virtual Environments: The Roles of Attention and Spatial Comprehension. 
Cyberpsychology and Behavior, 2(4) 1999, 337-347. LYNCH, K. The Image of the City. Cambridge, MA: MIT 
Press, 1960. LAWTON, C. AND KALLAI, J. Gender Differences in Wayfinding Strategies and Anxiety About 
Wayfinding: A Cross-Cultural Comparison. Sex Roles, 47(9-10), 2002, 389 401. LJUNGSTRÖM, M. The use of 
architectural patterns in MMORPGs. Presented at Aesthetics of Play, Bergen, Norway (14-15 Oct) 2005 http://www.aestheticsofplay.org/ljunstrom.php. 
NITSCHE, M., ASHMORE, C., HANKINSON, W., FITZPATRICK, R., KELLY, J. AND MARGENAU, K., 'Designing Procedural 
Game Spaces: A Case Study' in: Proceedings of FuturePlay 2006 London, Ontario (October 10-12), 2006, 
(digital proceedings) PARISH, Y. I. H. AND MULLER, P. 'Procedural modeling of cities', Proceedings of 
the 28th Annual Conference on Computer Graphics and Interactive Techniques, Los Angeles, CA, 2001, 301 
308. STROHECKER, C., BARROS, B., AND SLAUGHTER, A. Mapping Psychological and Virtual Spaces MERL TR 98-12 
(Sept) Cambridge,MA, 1998. VINSON, N. G. Design guidelines for landmarks to support navigation in virtual 
environments. Proceedings of the SIGCHI conference on Human Factors in Computing Systems: The CHI is 
the Limit, , May 15-20, Pittsburgh, PA, 1999, 278-285.  
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
	</article_rec>
	</section>
	<section>
		<section_id>1401867</section_id>
		<sort_key>240</sort_key>
		<section_seq_no>6</section_seq_no>
		<section_type>SESSION</section_type>
		<section_title><![CDATA[New technologies, tools, and techniques]]></section_title>
		<section_page_from>129</section_page_from>
	<article_rec>
		<article_id>1401868</article_id>
		<sort_key>250</sort_key>
		<display_label>Pages</display_label>
		<pages>6</pages>
		<article_publication_date>08-09-2008</article_publication_date>
		<seq_no>1</seq_no>
		<title><![CDATA[A novel network architecture for crowded online environments]]></title>
		<page_from>129</page_from>
		<page_to>134</page_to>
		<doi_number>10.1145/1401843.1401868</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1401868</url>
		<abstract>
			<par><![CDATA[<p>A scheme for autonomous player avatar behaviour is suggested, in which player patterns are identified and then used to navigate through subdued parts of a first person multi-player game. Thus, instead of sending a complex sequence of key presses, a single packet would be transmitted giving start and end coordinates, and the avatar would be controlled by an AI system in between. We present and evaluate a novel architecture for crowded online virtual environments that employs a multi-layered state description to maintain relaxed state synchronization among clients. The proposed technique significantly reduces total bandwidth costs and is suitable for especially crowded virtual environments.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[latency]]></kw>
			<kw><![CDATA[multiplayer games]]></kw>
			<kw><![CDATA[networked games]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>D.1</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>C.2.5</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10003033.10003083.10003084.10003086</concept_id>
				<concept_desc>CCS->Networks->Network properties->Network range->Local area networks</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003033.10003083.10003084.10003088</concept_id>
				<concept_desc>CCS->Networks->Network properties->Network range->Wide area networks</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10011007.10011074.10011092</concept_id>
				<concept_desc>CCS->Software and its engineering->Software creation and management->Software development techniques</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<person_id>P1100747</person_id>
				<author_profile_id><![CDATA[81321496403]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[J.]]></first_name>
				<middle_name><![CDATA[R.]]></middle_name>
				<last_name><![CDATA[Parker]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Digital Media Laboratory]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1100748</person_id>
				<author_profile_id><![CDATA[81436594864]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Nathan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Sorenson]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Digital Media Laboratory]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>856578</ref_obj_id>
				<ref_obj_pid>851038</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Bangun, R. A. and Dutkiewicz, E. 2000. Modelling multi-player games traffic. In <i>Proceedings of the International Conference on Information Technology: Coding and Computing</i>, Las Vegas, NV, March, 228--233.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>618391</ref_obj_id>
				<ref_obj_pid>616043</ref_obj_pid>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Barrus, J. W., Waters, R. C., &amp; Anderson, D. B. 1996. Locales: Supporting Large Multi-User Virtual Environments. <i>IEEE Computer Graphics and Applications</i>, 16(6), 50--57.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>258588</ref_obj_id>
				<ref_obj_pid>258549</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Benford, S., Greenhalgh, C., and Lloyd, D. 1997. Crowded collaborative virtual environments. In <i>Proceedings of the SIG-CHI Conference on Human Factors in Computing Systems</i> (Atlanta, Georgia, United States, March 22--27, 1997). S. Pemberton, Ed. CHI '97. ACM, New York, NY, 59--66.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Bernier, Y. W. 2001. Latency compensating methods in client/server in-game protocol design and optimization. In <i>Proceedings of the 15th Games Developers Conference</i>, San Jose, CA, March 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Blizzard Entertainment Inc. 2008. World of Warcraft. http://www.worldofwarcraft.com (February 20, 2008.)]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>218405</ref_obj_id>
				<ref_obj_pid>218380</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Blumberg, B. M. and Galyean, T. A. 1995. Multi-level direction of autonomous creatures for real-time virtual environments. In <i>Proceedings of the 22nd Annual Conference on Computer Graphics and interactive Techniques</i> S. G. Mair and R. Cook, Eds. SIGGRAPH '95. ACM, New York, NY, 47--54.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1167860</ref_obj_id>
				<ref_obj_pid>1167838</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Claypool, M., Claypool, K. 2006. Latency and Player Actions in Online Games. <i>Communications of the ACM</i>, &#60;b&#62;49&#60;/b&#62;(11), 40--45]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Cronin, E., Filstrup, B. and Jamin, S. 2003. Cheat-Proofing Dead Reckoned Multiplayer Games. In <i>Proceedings ADCOG</i> 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1103624</ref_obj_id>
				<ref_obj_pid>1103599</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Dick, M., Wellnitz, O., Wolf, L. 2005. Analysis of factors affecting players' performance and perception in multiplayer games. In <i>Proceedings of the 4th ACM Network and System Support for Games (NetGames)</i>, Hawthorne, NY, USA.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Fr&#233;con, E., and Stenius, M. 1998. DIVE: A Scalable Network Architecture for Distributed Virtual Environments. <i>Distributed Systems Engineering Journal</i>, 5(3), 91--100.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>199418</ref_obj_id>
				<ref_obj_pid>199404</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Funkhouser, T. A. 1995. RING: a client-server system for multi-user virtual environments. In <i>Proceedings of the 1995 Symposium on interactive 3D Graphics</i> (Monterey, California, United States, April 09--12, 1995). SI3D '95. ACM, New York, N Y, 85-ff.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Garage Games. 2008. Game Development Tools and Software. http://www.garagegames.com/ (February 20, 2008.)]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Gautier, L., Diot, C. and Kurose, J. 1999. End-to-end transmission control mechanisms for multiparty interactive applications in the internet. In <i>IEEE INFOCOM'99</i>, New York, NY, March]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Hughes, R. L. 2002. A continuum theory for the flow of pedestrians. <i>Transportation Research Part B 36</i>, 6 (July), 507535.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>987236</ref_obj_id>
				<ref_obj_pid>987232</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[L&#233;ty, E., Turletti, T., and Baccelli, F. 2004. SCORE: a scalable communication protocol for large-scale virtual environments. <i>IEEE/ACM Trans. 1etw.</i> 12, 2 (Apr. 2004), 247--260.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Linden Research Inc. 2008. Second Life: Economic Statistics. http://secondlife.com/whatis economy_stats.php (February 20, 2008.)]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Macedonia, M., Zyda, M., Pratt, D., Barham, P., &amp; Zeswitz, S. 1994. NPSNET: A Network Software Architecture for Large Scale Virtual Environments. <i>Presence</i>, 3(4), 265--287.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Mauve, M. 2000. How to keep a dead man from shooting. In <i>7th International Workshop on Interactive Distributed Multimedia Systems and Telecommunication Services</i> (IDMS), pages 199--204.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2219590</ref_obj_id>
				<ref_obj_pid>2219091</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Palazzi, C. E. Ferretti, S. Cacciaguerra, S. Roccetti, M. 2006. Interactivity-loss avoidance in event delivery synchronization for mirrored game architectures, <i>IEEE Transactions on Multimedia</i>, Volume: 8, Issue: 4, August, page(s): 874--879.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>507674</ref_obj_id>
				<ref_obj_pid>507670</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Pantel, L., Wolf, L. C. 2002. On the impact of delay on real-time multiplayer games. In: <i>Proceedings of the Workshop on Network and Operating Systems Support for Digital Audio and Video</i> (NOSSDAV), Miami, FL, USA.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>237258</ref_obj_id>
				<ref_obj_pid>237170</ref_obj_pid>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Perlin, K. and Goldberg, A. 1996. Improv: a system for scripting interactive actors in virtual worlds. In <i>Proceedings of the 23rd Annual Conference on Computer Graphics and interactive Techniques SIGGRAPH '96.</i> ACM, New York, NY, 205--216.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>323695</ref_obj_id>
				<ref_obj_pid>323663</ref_obj_pid>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Pettifer, S. and West, A. 1999. Subjectivity and the relaxing of synchronization in networked virtual environments. In <i>Proceedings of the ACM Symposium on Virtual Reality Software and Technology</i> (London, United Kingdom, December 20--22, 1999). VRST '99. ACM, New York, NY, 170--171.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>37406</ref_obj_id>
				<ref_obj_pid>37401</ref_obj_pid>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[Reynolds, C. W. 1987. Flocks, herds and schools: A distributed behavioral model. In <i>Proceedings of the 14th Annual Conference on Computer Graphics and interactive Techniques</i> M. C. Stone, Ed. SIGGRAPH '87. ACM, New York, NY, 25--34.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[Singhal, S. K. and Cheriton, D. R. 1995. Exploiting Position History for Efficient Remote Rendering in Networked Virtual Reality, <i>Presence: Teleoperators and Virtual Environments</i>, vol. 4, no. 2, pp. 169--193, 1995.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1079826</ref_obj_id>
				<ref_obj_pid>1078037</ref_obj_pid>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[Steed, A. and Angus, C. 2005. Supporting Scalable Peer to Peer Virtual Environments Using Frontier Sets. In <i>Proceedings of the 2005 IEEE Conference 2005 on Virtual Reality</i> (March 12--16, 2005). VR. IEEE Computer Society, Washington, DC, 27--34.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1142008</ref_obj_id>
				<ref_obj_pid>1141911</ref_obj_pid>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[Treuille, A., Cooper, S., and Popovi&#230;, Z. 2006. Continuum crowds. <i>ACM Transactions on Graphics</i>, 25, 3, 1160--1168.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>507673</ref_obj_id>
				<ref_obj_pid>507670</ref_obj_pid>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[Widmer, J., Mauve, M. and Damm, J. P. 2002. Probabilistic congestion control for non-adaptable flows. In <i>NOSSDAV</i>, Miami, FL, May.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Abstract - A scheme for autonomous player avatar behav­iour is suggested, in which player patterns are 
identified and then used to navigate through subdued parts of a first person multi­player game. Thus, 
instead of sending a complex sequence of key presses, a single packet would be transmitted giving start 
and end coordinates, and the avatar would be controlled by an AI system in between. We present and evaluate 
a novel architecture for crowded online virtual environments that employs a multi-layered state description 
to maintain relaxed state synchronization among cli­ents. The proposed technique significantly reduces 
total bandwidth costs and is suitable for especially crowded virtual environments. Keywords: multiplayer 
games, networked games, latency.Subject Descriptors: D.1 PROGRAMMING TECHNIQUES; C.2.5 Local and Wide-Area 
Networks 1. IntroductionOnline games and virtual environments allow hundreds of individuals to collaborate 
in an interactive setting, facilitating activities such as commerce, entertainment, and social networking. 
These systems use network bandwidth to send and receive the positions of the players and objects in a 
game. For example, Sec­ond Life, a popular online world, boasts over ten million registered users [Linden 
Research 2008]. This popularity, while evidence of the usefulness of online virtual worlds, is also the 
source of consid­erable network congestion, which impairs the usability of the envi­ronment by introducing 
latency. The basic algorithm used by a typical multiplayer online game uses a client-server communication 
scheme where the server(s) know the true positions, orientations, velocities, and all other attributes 
of all objects, players, lights, and sound sources within the game. This architecture is designed to 
ensure that a sin­gle, synchronized state is accurately reflected on all the networked machines. This 
is a difficult task since the complexity of this state grows as the number of interacting users increases, 
and the band­width required to transmit this state to every client machine becomes prohibitive [Funkhouser 
1995]. A key aspect of this para­digm is that every motion of the player s avatar is instigated by the 
player, and corresponds to a key press, mouse motion, or controller button push. Latency in such a game 
can be described as the time delay between a key press (action request) and the time when that action 
is embodied on the player s screen. It is caused by computational delays in servers and client machines, 
bandwidth limitations on the Internet, and natural light speed transmission delays and bounces from one 
intermediate network machine to another - it is rare for a player to link directly to a game server. 
Instead, there will be a set of computers that read the player s data packet and send it on to the next 
computer on the route to the server. Each such stopover cre­ates a slight delay, and these sum to a significant 
figure. The delay affects the way that players interact with the game and how enjoy­able the experience 
is [Claypool and Claypool 2006; Dick et al. 2005; Pantel and Wolf 2002]. Some online games (and games 
in general) recognize the con­cept of a macro, and allow the player to collect a sequence of but­ton 
or key presses into a single key. Players of fighting games especially find this useful; the macro corresponds 
to a sequence of moves, or a combination in fighting parlance, and good players have a number of these 
that can be deadly against beginning play­ers. This can be useful in reducing latency if fewer commands 
are sent to the server as a result. Because of latency considerations, online virtual environ­ments, 
as they are currently designed, must impose a limit on the number of users that can interact with each 
other at any given moment. The M-COVE architecture overcomes this limitation by abandoning the requirement 
that a single, synchronized state be duplicated perfectly on every client machine. It does not focus 
on eliminating the inconsistencies introduced among clients but rather capitalizes on this lack of synchronicity 
to realize significant band­width savings; once the need to keep states strictly synchronized is abandoned, 
state descriptions can employ far less precision and therefore consume much less bandwidth. M-COVE achieves 
this by regarding all objects on a client not as direct embodiments of other users, but rather as autonomous 
agents equipped with behav­iour models that aim to realistically mimic user behaviour. As well, server 
state is expressed both in terms of individual object behav­iour, where necessary, and in terms of large-scale 
crowd dynamics, which ultimately requires less bandwidth. This multi-layered approach results in a novel 
virtual environment architecture that incorporates both loose synchronicity and crowd animation tech­niques 
in order to facilitate highly populated virtual environments. 2. Latency AmeliorationMany systems have 
been designed to alleviate network con­gestion in crowded online environments. Early efforts to limit 
latency looked at end-to-end patterns [Gautier et al. 1999] and algorithms inspired by operating systems 
[Palazzi et al. 2006], and the limits of these approaches may well have been reached. Other work done 
on latency reduction has mainly examined the packet level [Bangun and Dutkiewicz 2001] and used statistical 
means and simulations [Widmer et al. 2002] to predict overall traffic lev­els and delay times. Games 
cannot be played using large amounts of data from clients for security reasons [Cronin et al. 2003], 
so we must avoid looking at giving clients more critical data. Reducing the effects of latency has sometimes 
been a matter of prediction of players future positions, thus relaxing he require­ment for strict synchronicity. 
Systems such as Deva3 [Pettifer and West 1999] and Torque [Garage Games 2008] can realistically reproduce 
server state on client machines using less bandwidth. Client objects can be updated less frequently as 
client-side predic­tion techniques such as dead-reckoning [Singhal and Cheriton 1995] ensure their motion 
is smoothly interpolated. However, updates still need to be sent to every object several times a second, 
causing the amount of bandwidth needed to update a particular cli­ent to increase linearly with respect 
to the number of objects on the server. These techniques alone are, therefore, insufficient for facil­itating 
large crowds. If the positions are predicted incorrectly, the situation jumps into a new state (warps) 
when the server detects the problem, and it may be several hundred milliseconds or more before that occurs. 
The basic strategy is that of dead reckoning and time warp even today. According to [Bernier 2001] For 
instance, if the client is running at 50 frames per second (fps) and has 100 milliseconds of latency 
(round-trip), then the cli­ent will have stored up five user commands ahead of the last one acknowledged 
by the server. These five user commands are simu­lated on the client as a part of client-side prediction. 
Backing up five steps is very disruptive in game play [Mauve 2000]. There are many methods based on limiting 
bandwidth usage by restricting the number of individuals able to simultaneously interact. They do not 
provide environments capable of sustaining large amounts of users; rather, they essentially partition 
large worlds into collections of smaller ones. Spline [Barrus et al. 1996] partitions virtual worlds 
into Locales, and maintains synchroni­zation only between objects in the same Locale. Similarly, NPS­NET 
[Macedonia et al. 1994] and DIVE [Frécon and Stenius 1998] divide the world into hexagonal cells and 
multicast groups called lightweight groups, respectively, to achieve similar results. SCORE [Léty et 
al 2004] seeks to address the problems encoun­tered when too many users occupy a single world partition 
by pro­viding the ability to dynamically subdivide the partitions into sub-regions called cells. Similarly, 
Steed and Angus [Steed and Angus 2005] overcome the limitations of static world subdivision by employing 
frontier sets to dynamically determine which cli­ents may potentially interact, based on the architectural 
layout of the environment. Bendford et. al. [1997] present a technique for the aggregation of crowds 
into single entities called Third Party Objects, allow­ing for more simultaneous users than is possible 
using object-by object updates. However, these Third Party Objects must be explicitly defined by the 
system author through the provision of classifying processes that determine whether a given object is 
inside or outside a crowd. For example, the authors suggest that any client who enters one side of a 
virtual stadium is consid­ered to be a part of the red supporters crowd and otherwise part of the blue 
supporters crowd. Once a client enters one of these statically defined crowd areas, it loses its individually 
unique ava­tar representation and becomes subsumed by an iconographic rep­resentation of the crowd as 
a whole in the author s example: a single giant sized person. It would be preferable if crowds were not 
arbitrarily repre­sented as single abstract entities, but rather as large collections of individuals 
with the high-level aim of reproducing the crowd s appearance. As Blumberg and Gaylean have shown [Blumberg 
and Galyean 1995], objects can indeed be provided with relatively sim­ple behavior models that enable 
them autonomously attain exter­nally specified high level goals with very little direct input. Ken Perlin 
s Improv system [Perlin and Goldberg 1996] employs this approach in a networked environment, allowing 
client agents to asynchronously interpret high-level animation directions issued from the server. In 
the context of an online virtual environment, then, one can consider a client agent s goal to be the 
reproduc­tion of the server s current state. Nearer to the principles of the work to be presented here, 
crowd animation techniques extend this notion further by directing large groups of entities as a whole, 
instead of individually. For example, Craig Reynold s flocking agents can pursue a common target while 
maintaining a herd formation using a very simple reac­tive behavior model [Reynolds 1987]. Recent work 
has continued to improve crowd direction, such as Trueille et al s Continuum Crowds approach [2006]. 
Continuum Crowds are inspired by Hughes method of modeling crowds as a set of continuous differ­ential 
equations [Hughes 2002] (as opposed to individual interact­ing agents,) and are controlled by a two-dimensional 
gradient field that globally optimizes the crowd s path to a goal with respect to factors such as travel 
distance and opposing flow. This approach demonstrates interesting effects such as the formation of traffic 
lanes and vortices, yet requires an expensive re-computation of the gradient field at every time-step 
for every unique goal, and as such is only suitable for situations with relatively few competing objec­tives. 
It is therefore not applicable to networked online environ­ments where every agent s goal (i.e. a server-specified 
location) is unique. 3. M-COVE ArchitectureM-COVE aims to combine elements of the discussed tech­niques 
into a unified architecture that fluidly describes world state in terms of both individual objects and 
large-scale crowd dynam­ics, offering, where appropriate, the simplicity of synchronization of the former 
perspective or the low bandwidth requirements of the latter. The server maintains a description of each 
individual object s behaviour as well as a two dimensional representation of the environment s overall 
flow of crowd traffic, and transmits a subset of this data to each client. The client, then, enacts this 
state through local agents that correspond to the server objects. These agents are equipped with a behaviour 
model that seeks to maintain reliable synchronization when directly in view of the client where synchronization 
is important, while blending into the crowd and following the large-scale traffic flow otherwise. It 
is clear enough that a complex behavior in a multiplayer game can be represented as a recognizable series 
of key presses, but it can also be encoded in other simple ways. For example, in a first person shooter 
simulation if a player is close to hitting you with a bullet, but misses, it should not always be necessary 
to send the exact bullet and time locations to the client so that the near-miss could be calculated precisely 
by the client machine. Nor would they need the keypress sequence the opponent used to nearly miss them. 
The event could be classified as a "near miss" and a "near miss" code (integer ID) would be transmitted 
to the cli­ent which would interpret it, based on it's own local state configu­ration, in a visually 
interesting way. 3.1. Server Updates As it is never possible to predict exactly how the client will 
traverse the virtual environment, the agents must always be ready to gracefully assume a synchronized 
state. This is achieved by ensuring all agents get occasional updates from the server regard­ing their 
server objects actual location. It is then the agents responsibility to stay within a reasonable distance 
from this goal. The updates issued from the server to the autonomous agents on the client can take one 
of two forms. Detailed orders contain 16 bytes of precise location and velocity information and tend 
to be sent at a high rate (around ten times a second). This form of update is used for agents in the 
immediate vicinity of the client, where accurate representation of server state is essential. In this 
case, the behaviour model reduces to dead-reckoning interpolation, achieving synchronicity in a similar 
manner to typical online vir­tual environments. General orders however, are sent to the vast majority 
of agents at a much slower rate (less than once a second), and consist of the object s current server 
position compressed into two bytes. This information represents the overarching goal that a client agent 
is to achieve at its own discretion. Updates are sent as detailed orders when where dnear is a constant 
denoting the range under which agents will be updated every update cycle and dclient is the distance 
of the agent to the client. The factor of 2 ensures agents are pro­vided with some space to smoothly 
transition from a loosely syn­chronized to a tightly synchronized behaviour. Whether or not an update 
will be given to a particular agent on an update cycle is determined by a probabilistic scheduling algorithm, 
which gives priority to agents nearest the client without completely starving distant agents: where 
P[update] is the probability that an update is sent (clamped to _0,1_), and a is an attenuation exponent 
which can be increased dynamically to reduce the total number of orders sent to distant agents This can 
be done, for example, every time a speci­fied bandwidth threshold has been exceeded, theoretically allow­ing 
for any number of evenly distributed agents to be supported while maintaining constant bandwidth usage. 
 3.2. Patch GridThe M-COVE architecture expresses the large-scale dynam­ics of crowd movement by imposing 
a coarse two-dimensional grid over the virtual environment. Each element in the grid is referred to as 
a patch, and contains statistics regarding observed crowd activity. When a server object moves through 
a patch, it marks its entry and exit points. The vector difference is quantized into one of 8 directions 
and stored. The average density of objects on the patch, as well as the average time spent on a patch, 
is also recorded. This information can be collected by the server over time and needs to be sent to each 
client only once, as this information represents long-term usage tendencies that are unlikely to change 
from moment to moment. By taking this information into account, the behaviour model reproduces traffic 
patterns typical of the given environment and therefore exhibits collision avoidance behaviour and simple 
path-planning. Agents, for example, will assume intel­ligent paths through and around environmental obstacles 
simply because they tend to follow the paths of actual users there is no need for expensive path searching 
or cost optimization. 3.3. Behaviour Model The M-COVE architecture makes use of a reactive behavioral 
model that takes into account its current update received from the server, its current position relative 
to the client viewpoint, as well as the properties of the patch it is currently standing on and chooses 
one of four possible behaviors. If an agent currently has a detailed order consisting of precise location 
and velocity infor­mation which is also fresh, (meaning it has not yet arrived at the specified location,) 
it employs classical dead-reckoning behaviour to smoothly interpolate its position to the specified location. 
If an agent with fresh orders is out of view and currently far­ther than WARP_THRESH from its goal location, 
it simply warps to that location. If the desired location is within view of the client, the agent warps 
to the closet off-screen point and proceeds from there. This behaviour ensures agents do not become trapped 
in local minima present in the patch grid when trying to work their way towards their destination. Agents 
that are some distance from the client s perspective are most likely to warp, as it is these agents who 
are most likely to have a great amount of distance to cover between sporadically received orders. Since 
they are generally far away, this behaviour is rarely noticeable. If an agent has no fresh orders the 
agent will stop and wait for a moment with a probability (clamped to [0,1]: where tavg is the average 
time an agent spends on this patch, tcross is the time it would take to cross the patch at normal move­ment 
speeds, and tcur is the time the current agent has spent on the patch. Finally, if none of the previous 
cases hold, the agent picks a direction to move such that its progress towards its goal is maxi­mized. 
This goal is not simply moving towards its destination as quickly as possible, but is rather a system 
of competing goals. For example, an agent must reproduce the crowd dynamics represented by the underlying 
patch, but it also would like to maintain a rela­tively straight path of movement to reduce the amount 
of unnatural and erratic motion. The chosen direction can be represented as the result of the following 
sum of twelve unit vectors: where is the direction towards the agent s server-speci ­fied location and 
 where f =1 if the current order is fresh and 0 otherwise. ci s are adjustable weighting coefficients 
and dgoal is the distance to the agents server-specified location. is the quantized direction pointing 
to the adjacent patch that experiencing the greatest density debt, that is, the greatest difference between 
the number of objects that are usually on the patch and the number of agents currently on the patch. 
Hence, is the current direction of the agent and . This vector encourages agents to maintain smooth 
forward movement. is the direction that is must be taken to move out from the client s viewpoint. This 
direction is useful if the client is approaching an agent that has out-of-date directions and therefore 
likely out-of-sync. It would be undesirable for the client to be able to directly interact with an agent 
that was not really there. Also, by moving off-screen this agent is now able to warp to its destina­tion 
if necessary. The weight is determined by: where age is the age of the latest order received beyond 
a specified threshold, vis = 1 if the agent is in view of the client and 0 otherwise. Finally are the 
eight quantized compass direc ­tions and where ti is the average number of objects on this patch that 
travel in direction . The resulting vector is normalized and the agent checks the patch to ensure that 
a non-zero number of agents have traveled in that direction. If not, this likely signals a nearby obstruction. 
In this case, the agent chooses the nearest direction to the desired direc­tion that does have a non-zero 
usage. It should be evident that each of the elements comprising the behaviour model have a straightforward 
functional purpose and either a yes/no trigger condition or an associated linear weight. It follows that 
any desired behaviour can be similarly given a weight and inserted into the present model. Therefore, 
this framework is suitable for top-down modification, offering a flexibility that allows for the fulfilment 
of a variety of different domain require­ments. 4. ResultsFor testing, a sample environment is populated 
by simulated clients that travel throughout the world in a non-uniform manner via specified waypoints. 
Using traditional client/server synchroni­zation techniques representative of most current online virtual 
environments, the Torque engine is able to reasonably accommo­date 60 of these clients when restricted 
to a 2,000 Bps bandwidth limit. Using the proposed probabilistic update algorithm, the M-COVE architecture 
is able to accommodate approximately 800 simulated clients within the same 2,000 Bps limit before unnatural 
movements become noticeable. Furthermore, the client front-end displays the same traffic flow patterns 
and congestion areas that exist on the server. It is probable that the factor that ultimately limits 
the maxi­mum number of agents supported will be the processing power that is needed to evaluate the behaviour 
model, not the bandwidth used for updates. Though it is not likely to improve the bandwidth effi­ciency, 
it is hoped that further adjustment of the behaviour model will result in more natural individual movement 
and more realistic crowd flow dynamics. More rigorous testing will be conducted in the immediate future. 
 5. ConclusionBy combining classical synchronization techniques with recent work in crowd animation, 
M-COVE is able to express world state in terms of both individual client behaviour and overall crowd 
dynamics. At the core of the architecture is a reactive behaviour model that is computationally inexpensive 
to evaluate and simple to extend. Furthermore, M-COVE has been implemented with an existing commercial 
game engine, suggesting that this architecture could be readily implemented in other typical virtual 
environment systems. M-COVE is therefore a novel, flexible architecture that exploits the lack of synchronicity 
in online virtual environments to support dramatically more simultaneous users than is possible with 
existing methods. The M-COVE behaviour model currently operates under the implicit assumption that the 
only activity that needs modeling is client movement. Clearly, in most real-world virtual environments 
there are several activities in which clients can engage themselves, such as collaboratively building 
new spaces, as in Second Life or battling hostile creatures, as in World of Warcraft [Blizzard Enter­tainment 
2008]. Clearly, the presented model would have to be expanded significantly to account for these unique 
domain require­ments. The current behaviour model also assumes a world where overall traffic flow remains 
relatively stable over time. Volatile crowd characteristics would need to be considered for applications 
where this is not the case. Since M-COVE operates in a way that does not require global synchronization, 
it is likely that this is a technique that would lend itself particularly well to distributed servers. 
It might even be pos­sible to modify this system to operate in a pure P2P environment. 6. ReferencesBANGUN, 
R. A. AND DUTKIEWICZ, E. 2000. Modelling multi-player games traffic. In Proceedings of the International 
Confer­ence on Information Technology: Coding and Computing, Las Vegas, NV, March, 228-233. BARRUS, J. 
W., WATERS, R. C., &#38; ANDERSON, D. B. 1996. Locales: Supporting Large Multi-User Virtual Environments. 
IEEE Computer Graphics and Applications, 16(6), 50-57. BENFORD, S., GREENHALGH, C., AND LLOYD, D. 1997. 
Crowded collaborative virtual environments. In Proceedings of the SIG­CHI Conference on Human Factors 
in Computing Systems(Atlanta, Georgia, United States, March 22 - 27, 1997). S. Pem­berton, Ed. CHI '97. 
ACM, New York, NY, 59-66. BERNIER, Y. W. 2001. Latency compensating methods in client/server in-game 
protocol design and optimization. In Proceedings of the 15th Games Developers Conference, San Jose, CA, 
March 2001. BLIZZARD ENTERTAINMENT INC. 2008. World of Warcraft. http://www.worldofwarcraft.com (February 
20, 2008.) Blumberg, B. M. and Galyean, T. A. 1995. Multi-level direction of autonomous creatures for 
real-time virtual environments. In Pro­ceedings of the 22nd Annual Conference on Computer Graphics and 
interactive Techniques S. G. Mair and R. Cook, Eds. SIG­GRAPH '95. ACM, New York, NY, 47-54. CLAYPOOL, 
M., CLAYPOOL, K. 2006. Latency and Player Actions in Online Games. Communications of the ACM, 49(11), 
40 45 CRONIN, E., FILSTRUP, B. AND JAMIN, S. 2003. Cheat-Proofing Dead Reckoned Multiplayer Games. In 
Proceedings ADCOG2003. DICK, M.,WELLNITZ, O.,WOLF, L. 2005. Analysis of factors affect­ing players performance 
and perception in multiplayer games. In Proceedings of the 4th ACM Network and System Support for Games 
(NetGames), Hawthorne, NY, USA. FRÉCON, E., AND STENIUS, M. 1998. DIVE: A Scalable Network Architecture 
for Distributed Virtual Environments. Distributed Systems Engineering Journal, 5(3), 91-100. FUNKHOUSER, 
T. A. 1995. RING: a client-server system for multi-user virtual environments. In Proceedings of the 1995 
Sympo­sium on interactive 3D Graphics (Monterey, California, United States, April 09 - 12, 1995). SI3D 
'95. ACM, New York, NY, 85-ff. GARAGE GAMES. 2008. Game Development Tools and Software. http://www.garagegames.com/ 
(February 20, 2008.) GAUTIER, L., DIOT, C. AND KUROSE, J. 1999. End-to-end transmis­sion control mechanisms 
for multiparty interactive applications in the internet. In IEEE INFOCOM'99, New York, NY, March HUGHES, 
R. L. 2002. A continuum theory for the flow of pedestri­ans. Transportation Research Part B 36, 6 (July), 
507535. LÉTY, E., TURLETTI, T., AND BACCELLI, F. 2004. SCORE: a scal­able communication protocol for 
large-scale virtual environ­ments. IEEE/ACM Trans. 1etw. 12, 2 (Apr. 2004), 247-260. LINDEN RESEARCH 
INC. 2008. Second Life: Economic Statistics. http://secondlife.com/whatis economy_stats.php (February 
20, 2008.) MACEDONIA, M., ZYDA, M., PRATT, D., BARHAM, P., &#38; ZESWITZ, S. 1994. NPSNET: A Network 
Software Architecture for Large Scale Virtual Environments. Presence, 3(4), 265-287. MAUVE, M. 2000. 
How to keep a dead man from shooting. In 7th International Workshop on Interactive Distributed Multimedia 
Systems and Telecommunication Services (IDMS), pages 199-204. PALAZZI, C.E. FERRETTI, S. CACCIAGUERRA, 
S. ROCCETTI, M. 2006. Interactivity-loss avoidance in event delivery synchroniza­tion for mirrored game 
architectures, IEEE Transactions on Mul­timedia, Volume: 8, Issue: 4, August, page(s): 874- 879. PANTEL, 
L., WOLF, L.C. 2002. On the impact of delay on real-time multiplayer games. In: Proceedings of the Workshop 
on Network and Operating Systems Support for Digital Audio and Video (NOSSDAV), Miami, FL, USA. PERLIN, 
K. AND GOLDBERG, A. 1996. Improv: a system for script­ing interactive actors in virtual worlds. In Proceedings 
of the 23rd Annual Conference on Computer Graphics and interactive Techniques SIGGRAPH '96. ACM, New 
York, NY, 205-216. PETTIFER, S. AND WEST, A. 1999. Subjectivity and the relaxing of synchronization in 
networked virtual environments. In Proceed­ings of the ACM Symposium on Virtual Reality Software and 
Technology (London, United Kingdom, December 20 - 22, 1999). VRST '99. ACM, New York, NY, 170-171. REYNOLDS, 
C. W. 1987. Flocks, herds and schools: A distributed behavioral model. In Proceedings of the 14th Annual 
Conference on Computer Graphics and interactive Techniques M. C. Stone, Ed. SIGGRAPH '87. ACM, New York, 
NY, 25-34. SINGHAL, S. K. AND CHERITON, D. R. 1995. Exploiting Position History for Efficient Remote 
Rendering in Networked Virtual Reality, Presence: Teleoperators and Virtual Environments, vol. 4, no. 
2, pp. 169-193, 1995. STEED, A. AND ANGUS, C. 2005. Supporting Scalable Peer to Peer Virtual Environments 
Using Frontier Sets. In Proceedings of the 2005 IEEE Conference 2005 on Virtual Reality (March 12 - 16, 
2005). VR. IEEE Computer Society, Washington, DC, 27-34. TREUILLE, A., COOPER, S., AND POPOVIÆ, Z. 2006. 
Continuum crowds. ACM Transactions on Graphics, 25, 3, 1160-1168.  WIDMER, J., MAUVE, M. AND DAMM, J. 
P. 2002. Probabilistic con­gestion control for non-adaptable flows. In NOSSDAV, Miami, FL, May.  A 
Novel Network Architecture for Crowded Online EnvironmentsJ.R. ParkerNathan Sorenson Digital Media Laboratory 
Faculty of Fine Arts/Drama   
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
	</article_rec>
	<article_rec>
		<article_id>1401869</article_id>
		<sort_key>260</sort_key>
		<display_label>Pages</display_label>
		<pages>8</pages>
		<article_publication_date>08-09-2008</article_publication_date>
		<seq_no>2</seq_no>
		<title><![CDATA[A tool for adaptive lighting design]]></title>
		<page_from>135</page_from>
		<page_to>142</page_to>
		<doi_number>10.1145/1401843.1401869</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1401869</url>
		<abstract>
			<par><![CDATA[<p>Filmmakers, theater directors, and designers take extreme care in aesthetically composing their scenes. This sense of aesthetics is important to promote presence, immersion, and involvement. Video games have adopted many design theories and techniques from linear media, particularly film. However, interactive environments are dynamic and unpredictable, and thus require the development of theories, techniques, and tools specific to their interactive nature. In this paper, we present a lighting design tool that algorithmically adapts lighting to user interaction within game environments at runtime. Previous work includes our work on the Expressive Lighting Engine (ELE), which uses intelligent algorithms to adapt lighting in real-time accounting for variation in context, narrative, and intended artistic effects defined through numerical constraints. We encoded cinematic lighting techniques within ELE as mathematical formulae that guide the system's choices in terms of lighting to achieve artistic constraints while maintaining visual continuity. The work presented in this paper expands this work in several directions. First, ELE did not take objects' or scenes' materials into consideration. This is important since the appearance of objects under lighting conditions depends on their materials. Second, using numerical constraints as a method by which designers encode their artistic intention for lighting proved to be unintuitive. Thus, we present a prototype that builds on ELE and focuses on exploring solutions to resolve these problems.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[aesthetics]]></kw>
			<kw><![CDATA[interactive environments]]></kw>
			<kw><![CDATA[lighting design]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>H.5</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10003120</concept_id>
				<concept_desc>CCS->Human-centered computing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120</concept_id>
				<concept_desc>CCS->Human-centered computing</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<person_id>P1100749</person_id>
				<author_profile_id><![CDATA[81100351608]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Joseph]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Zupko]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Pennsylvania State University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1100750</person_id>
				<author_profile_id><![CDATA[81100375511]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Magy]]></first_name>
				<middle_name><![CDATA[Seif]]></middle_name>
				<last_name><![CDATA[El-Nasr]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Simon Fraser University]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Alton, J. 1995. <i>Painting with Light</i>. University of California Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Adelson, E. H. (2000). Lightness Perception and Lightness Illusions. The New Cognitive Neurosciences. Cambridge, Massachusetts, MIT Press: 339--351.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2320307</ref_obj_id>
				<ref_obj_pid>2319012</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Barnard, K., V. Cardei, et al. (2002). "A Comparison of Computational Color Constancy Algorithms - Part I: Methodology and Experiments With Synthesized Data." IEEE Transactions on Image Processing 11(9): 972--983.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1076549</ref_obj_id>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Birn, J., Ed. 2000. <i>Digital Lighting &amp; Rendering.</i> New Riders.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Block, B. 2001. <i>The Visual Story: Seeing the Structure of Film, TV, and New Media.</i> Focal Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Brown, B. 1996. <i>Motion Picture and Video Lighting.</i> Focal Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Calahan, S. 1996. <i>Storytelling through lighting: a computer graphics perspective.</i> Siggraph Course Notes.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Campbell, D. 1999. <i>Technical Theatre for Non-technical People.</i> Allworth Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>513076</ref_obj_id>
				<ref_obj_pid>513073</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Comaniciu, D. and Meer, P. 2002. Mean shift: A robust approach toward feature space analysis. <i>IEEE Transactions on Pattern Analysis and Machine Intelligence</i>, 2, 603--619.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>2383844</ref_obj_id>
				<ref_obj_pid>2383815</ref_obj_pid>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Costa, A. C., A. A. Sousa, et al. 1999. Lighting Design: A Goal Based Approach Using Optimisation. <i>EUROGRAPHICS.</i>
]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Crowther, B. 1989. <i>Film Noir: Reflections in a Dark Mirror.</i> Continuum.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1198709</ref_obj_id>
				<ref_obj_pid>1198555</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[P. Debevec. 2005. High-dynamic-range imaging and image-based lighting: Image based lighting. <i>Siggraph Courses.</i>
]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Edge Detection and Image SegmentatiON (EDISON) System. http://www.caip.rutgers.edu/riul/research/code.html.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Evans, J. 2006. Art and Craft of Lighting. <i>Game Developers Conference.</i>
]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Flynn, J. E. 1977. A study of subjective responses to low energy and nonuniform lighting systems. <i>Lighting Design and Application.</i>
]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Folmann, T. 2006. Tomb Raider Legend: Scoring a Next-Generation Soundtrack. In <i>Proceedings of Game Developers Conference 2006.</i>
]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>861425</ref_obj_id>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Freeman, D. 2004. <i>Creating Emotion in Games: The Craft and Art of Emotioneering TM.</i> New Riders.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Gillette, J. M. 1998. <i>Designing with Light.</i> Mayfield.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>602141</ref_obj_id>
				<ref_obj_pid>602099</ref_obj_pid>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Gumhold, S. (2002). "Maximum Entropy Light Source Placement." IEEE Visualization 2002: 275--282.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1081492</ref_obj_id>
				<ref_obj_pid>1081432</ref_obj_pid>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Halle, M. and J. Meng (2003). "LightKit: A lighting system for effective visualization." IEEE Visualization 2003: 363--370.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Henderson, J. M. and A. Hollingworth (2002). Global Transsaccadic Change Blindness During Scene Perception, Michigan State University: 1--7.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>22</ref_seq_no>
				<ref_text><![CDATA[Jobson, D. J. and G. A. Woodell (1995). Properties of a Center/Surround Retinex Part Two: Surround Design, NASA Langley Research Center.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>23</ref_seq_no>
				<ref_text><![CDATA[Kasavin, G. 2004. Doom 3 Review. GameSpot. http://www.gamespot.com/pc/action/doom3/review.html]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>166136</ref_obj_id>
				<ref_obj_pid>166117</ref_obj_pid>
				<ref_seq_no>24</ref_seq_no>
				<ref_text><![CDATA[Kawai, J. K., J. S. Painter, et al. 1993. Radioptimization - Goal Based Rendering. ACM SIGGRAPH 1993.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>25</ref_seq_no>
				<ref_text><![CDATA[Knez, I., Enmarker, I. Effects of office lighting on mood and cognitive performance, and a gender effect in work-related judgment. <i>Environment and Behaviour</i>, 30, 553--567, 1998.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>26</ref_seq_no>
				<ref_text><![CDATA[Kidd, W. 2001. <i>Vermeer: Master of Light Video, J. J. Karkora.</i> National Gallery of Art.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>27</ref_seq_no>
				<ref_text><![CDATA[Knopft, D. C. a. A. 1979. <i>The Book of Movie Photography.</i> Alfred Knopf, Inc.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>28</ref_seq_no>
				<ref_text><![CDATA[Land, E. H. and J. J. McCann (1971). "Lightness and Retinex Theory." Journal of the Optical Society of America 61(1): 1--11.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1110752</ref_obj_id>
				<ref_obj_pid>1110642</ref_obj_pid>
				<ref_seq_no>29</ref_seq_no>
				<ref_text><![CDATA[Lee, C. H., X. Hao, et al. (2006). "Geometry-Dependent Lighting." IEEE Transactions on Visualization and Computer Graphics 12(2): 197--207.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>30</ref_seq_no>
				<ref_text><![CDATA[Lowell, R. 1992. <i>Matters of Light &amp; Depth.</i> Lowel-Light Manufacturing, Inc.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>31</ref_seq_no>
				<ref_text><![CDATA[Millerson, G. 1991. <i>Lighting for Television and Film.</i> Focal Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>32</ref_seq_no>
				<ref_text><![CDATA[Marino, P. 2004. <i>3D Game-Based Filmmaking: The Art of Machinima.</i> Paraglyph Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1536934</ref_obj_id>
				<ref_seq_no>33</ref_seq_no>
				<ref_text><![CDATA[Ngyuyen, H. 2007. <i>GPU Gems 3: Programming Techniques for High Performance Graphics and General-Purpose Computation.</i> Addison-Wesley Education Publishers, Inc.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>792857</ref_obj_id>
				<ref_obj_pid>792756</ref_obj_pid>
				<ref_seq_no>34</ref_seq_no>
				<ref_text><![CDATA[Poulin, P., K. Ratib, et al. (1997). Sketching Shadows and Highlights to Position Lights. Computer Graphics International 1997.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>35</ref_seq_no>
				<ref_text><![CDATA[Patow, G. and X. Pueyo (2003). "A Survey of Inverse Rendering Problems." COMPUTER GRAPHICS forum 22(4): 663--687.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1008238</ref_obj_id>
				<ref_obj_pid>1008213</ref_obj_pid>
				<ref_seq_no>36</ref_seq_no>
				<ref_text><![CDATA[Seif El-Nasr, M. and Horswill, I. 2004. Automating Lighting Design for Interactive Entertainment. <i>ACM Computers and Entertainment</i>, 2(2).]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>37</ref_seq_no>
				<ref_text><![CDATA[Seif El-Nasr, M., Niedenthal, S., Kenz, I., Almeida, P., and Zupko, J. Dynamic Lighting for Tension in Games. <i>Game Studies.</i> 7(1), 2006.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>38</ref_seq_no>
				<ref_text><![CDATA[Shacked, R. (2001). Automatic Lighting Design using a Perceptual Quality Metric. Computer Science and Engineering. Jerusalem, Israel, The Hebrew University of Jerusalem. Master of Science: 68.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>39</ref_seq_no>
				<ref_text><![CDATA[Shesh, A. and B. Chen (2004). Crayon Lighting: Sketch-guided Illumination of Models. Pacific Graphics 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>40</ref_seq_no>
				<ref_text><![CDATA[Shannon, C. E. (1948). A Mathematical Theory of Communication. <i>Bell System Technical Journal.</i> 27(1): 379--423, 623--656.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>41</ref_seq_no>
				<ref_text><![CDATA[V&#225;zquez, P.-P. and M. Sbert (2002). Perception-Based Illumination Information Measurement and Light Source Placement. ICCSA 2003.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>311559</ref_obj_id>
				<ref_obj_pid>311535</ref_obj_pid>
				<ref_seq_no>42</ref_seq_no>
				<ref_text><![CDATA[Y. Yu, P. Debevec, J. Malik, and T. Hawkins. Inverse Global Illumination: Recovering Reflectance Models of Real Scenes from Photographs, <i>Proc. SIGGRAPH '99</i>, pp. 215--224, 1999.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>43</ref_seq_no>
				<ref_text><![CDATA[Zupko, J. and Seif El-Nasr, M. 2006. A Tool for Aesthetic-based Lighting Design in Interactive 3D Environments. <i>Sandbox Siggraph 2006.</i>
]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 A tool for Adaptive Lighting Design Joseph Zupko Magy Seif El-Nasr College of Information Sciences and 
Techonology School of Interactive Arts and Technology Pennsylvania State University Simon Fraser University 
jaz147@psu.edu magy@sfu.ca Abstract Filmmakers, theater directors, and designers take extreme care in 
aesthetically composing their scenes. This sense of aesthetics is important to promote presence, immersion, 
and involvement. Video games have adopted many design theories and techniques from linear media, particularly 
film. However, interactive environments are dynamic and unpredictable, and thus require the development 
of theories, techniques, and tools specific to their interactive nature. In this paper, we present a 
lighting design tool that algorithmically adapts lighting to user interaction within game environments 
at runtime. Previous work includes our work on the Expressive Lighting Engine (ELE), which uses intelligent 
algorithms to adapt lighting in real-time accounting for variation in context, narrative, and intended 
artistic effects defined through numerical constraints. We encoded cinematic lighting techniques within 
ELE as mathematical formulae that guide the system s choices in terms of lighting to achieve artistic 
constraints while maintaining visual continuity. The work presented in this paper expands this work in 
several directions. First, ELE did not take objects or scenes materials into consideration. This is important 
since the appearance of objects under lighting conditions depends on their materials. Second, using numerical 
constraints as a method by which designers encode their artistic intention for lighting proved to be 
unintuitive. Thus, we present a prototype that builds on ELE and focuses on exploring solutions to resolve 
these problems. Categories and Subject Descriptors: H.5. [Information Systems]: Information Interfaces 
and Presentation (e.g., HCI). Keywords: interactive environments, aesthetics, lighting design  Introduction 
Lighting is an important part of creative media, including theater, film, animation, and game productions. 
Our perception of the world is shaped through its lighting. Although lighting is most obvious for its 
influence on visibility, it has many other functions due to its effect on mood, perception of time of 
day, and its influence on visual attention [Block 2000; Millerson 1991; Calahan 1996]. Artists use lighting 
as a powerful tool to control meaning and form. The great works of Rembrandt and Vermeer are explored 
today for their lighting composition. Similarily, lighting in games is important for its influence on 
mood, dramatic tension, visibility, visual attention, and its ability to affect engagement and immersion 
[Seif El-Nasr et al. 2006]. The current methods of game lighting design borrow from traditional linear 
media techniques, which necessitate manual Copyright &#38;#169; 2008 by the Association for Computing 
Machinery, Inc. Permission to make digital or hard copies of part or all of this work for personal or 
classroom use is granted without fee provided that copies are not made or distributed for commercial 
advantage and that copies bear this notice and the full citation on the first page. Copyrights for components 
of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy 
otherwise, to republish, to post on servers, or to redistribute to lists, requires prior specific permission 
and/or a fee. Request permissions from Permissions Dept, ACM Inc., fax +1 (212) 869-0481 or e-mail permissions@acm.org. 
Sandbox Symposium 2008, Los Angeles, California, August 9 10, 2008. &#38;#169; 2008 ACM 978-1-60558-173-6/08/0008 
$5.00 adjustment of many parameters. This manual adjustment is key to creation of desired artistic effects. 
For example, the illusion of light cast by a window into a room when filmed might be created by many 
carefully placed and adjusted lighting instruments. Film lighting designers often add several spot lights 
to a scene to supplement the natural lighting setup. This is done for various artistic reasons, including 
creating depth and ensuring that a character s eyes, for example, are lit at all times. Lighting a game 
environment is more complex due to user interaction which introduces unpredictability. A carefully placed 
and adjusted lighting design can be completely negated by unanticipated user choices at runtime. This 
then requires the development of systems that allow game lighting designers to author adaptable lighting 
compositions to accommodate unpredictable user behaviors. Our research focuses on this problem. Adapting 
the lighting composition at runtime is not an easy problem. An easy solution is to use ambient lighting, 
a technique that evenly lights the entire scene; this technique, however, produces dull and unpleasant 
environments [Birn 2000]. An alternative solution, which many of the current techniques favor, is to 
light the environment according to physically accurate lighting models. While this solution produces 
a realistic design, it does not establish artistic or aesthetic goals. Lighting designers in film, for 
example, often supplement natural scene lighting with additional lights to convey moods, evoke emotions, 
or create visual depth [Evans 2006 and 2008]. Thus, in addressing adaptive lighting design, a system 
will have to address adaptive aesthetic lighting design, which is difficult due to its subjective and 
ill­defined nature. Even though there are many theories on film, theater, and animation lighting design, 
there is very little understanding of what constitutes good or aesthetically pleasing lighting in a given 
situation. In the past, we have developed several systems to tackle this problem. In 2003, we developed 
a dynamic lighting design system called the Expressive Lighting Engine (ELE) [Seif El-Nasr and Horswill 
2004]; ELE encodes artistic goals for lighting and uses artificial intelligence to adapt the lighting 
composition, including setup, direction, and color, within a 3D interactive environment based on theatric 
and cinematic lighting design theories represented mathematically within a constraint optimization system. 
While this system achieved some success, it did not account for different materials used in scene objects, 
and thus did not always perceptually achieve the intended artistic or aesthetic goals. Also, ELE s interface 
allowed artists to encode artistic rules in terms of constraints which was not a very well received method 
by our subject pool. Instead, lighting design by example was suggested as an alternative interface. In 
this paper, we will discuss a work in progress that tackles the two problems discussed above. Mainly, 
we discuss a system that uses images as examples given by designers to the system. The system then uses 
these images to deduce a lighting setup for 3D objects within a 3D scene, given context and scene layout. 
The system also uses a visual perceptual model and cinematic lighting design principles to achieve an 
appearance that is close to the intended aesthetic effect. In other words, it takes into account how 
objects respond to lighting when developing a lighting setup, thus achieving a perceptually motivated 
appearance given the artistic effect intended. 2 Lighting Design Process Traditional Media To frame 
the problem of adaptive interactive lighting design, it is useful to describe lighting design in existing 
media, such as film and theater. The role of a lighting designer is to establish a lighting setup (positions, 
colors, and angles for lights and their changes within the scene) that serves several goals, including 
establishing visibility, portraying motivation for direction, portraying appropriate depth and modeling, 
and evoking mood [Alton 1995; Birn, 2000; Block 2001; Calahan, 1996; Campbell 1999; Crowther 1989; Gillette 
1998; Kidd 2001; Knopf 1979; Lowell 1992]. In creating a lighting design, the designer considers the 
environment, the characters, and the narrative. Specifically, when looking at the environment he considers 
several variables, including the time of day, the period, the style of rendering, and the mood or theme 
[Alton 1995; Birn 2000; Block 2001; Brown 1996; Gilette 1998; Millerson 1991]. To accomplish these goals, 
designers are required to understand how lighting works in the real world and to understand the aesthetic 
style that they want to achieve. They must also establish a sense of lighting direction, fall-off ratio, 
shadow density, brightness, and color composition. Different lighting design methods were created for 
film [Alton 1995; Block 2001; Brown 1996; Millerson 1991], theater [Gillette 1998], and animation [Birn 
2000] to achieve these goals. While a review of lighting design theory is beyond the scope of this paper, 
we will outline a basic lighting technique that is regularly used in theater [Gilette 1998], film [Millerson 
1991], animation [Birn 2000], and games [Evans 2006 and 2008]. The technique is called three-point lighting. 
This technique is mainly used to light characters but can also be used to light the environment [Evans 
2006 and 2008]. Three-point lighting generally consists of three lights or sets of lights: a key light, 
a fill light, and a back light (more than one light is often used for backlighting an object or scene). 
The key light provides dominant direction cues while the fill light controls tonal contrast. The back 
light(s) is used to isolate the silhouette of the object. In addition, lighting designers also use eye 
lights to brighten the eyes or body lights to accent a character s body. They also use lighting patterns 
to evoke specific emotions such as anticipation. Example patterns include: under-lighting a character 
to enhance abnormality, light flickering (e.g. lightning), and backlighting a character to enhance drama. 
 3 Lighting Design Process Games Lighting design in games has not been formalized. Most lighting design 
lectures and literature focuses on adapting film lighting techniques such as three-point lighting [Marino 
2004; Evans 2006 and 2008]. Most lighting design for games is static and environmental in nature. Level 
designers develop a 3D environment using a modeling tool such as Maya. Lighting is then applied to the 
level to create the desired architectural aesthetic effects while maintaining illumination for dynamic 
objects. Some games use limited dynamic lighting designs. The function of dynamic lighting differs from 
game to game. For example, some designers attach dynamic lights to characters to ensure they are lit 
at all times. Player characters can also be coerced into positions where preset lighting will create 
desired effects. In general, game lighting design is labor intensive and rigid. Designers must manually 
place environmental lighting, configure dynamic character lighting, and balance the two to achieve reasonable 
results given all anticipated cases. Even then, designs can produce undesirable results in cases that 
designers did not anticipate, or where an assumption has changed. For example, if a dynamic light attached 
to a character is configured based on the assumption that the average light brightness in an environment 
will be very dim and the light brightness in the environment is later changed, the light may no longer 
have the desired effect.  4 Previous Work Previous work on lighting design systems and tools can be 
classified into two categories. The first is focused on simulating physically accurate lighting (e.g., 
[Debevec 2005]). The second, more relevant to our work, is inverse lighting, where a lighting configuration 
is computed to achieve a lighting goal specified by a user, often by a 2D image and some correlated 3D 
geometry [Patow and Pueyo 2003]. Work in this domain can be divided into architectural inverse lighting, 
perceptual inverse lighting, and interactive inverse lighting. 4.1 Architectural Inverse Lighting Fig. 
1. An automatically illuminated virtual space [Kawai et al.1993]. Work presented in [Kawai et al. 1993] 
was one of the first inverse lighting works (Fig. 1). The domain of Kawai s work was finding light settings 
for real-life environments using architectural visualization tools. The system of this work found angles 
and intensities for lights given: 1) light positions manually specified by a user, and 2) numerically 
defined goals for the lighting design. These goals were subjective in nature and derived from previous 
work by [Flynn 1977]. Flynn explored participants subjective experiences to lighting in spaces, such 
as whether a room felt spacious , using psychophysical techniques. [Costa, Sousa et al. 1999] used a 
similar approach and is the latest and most complete approach to the domain of architectural lighting 
design (Fig. 2). Costa s approach made only three assumptions about an environment: 1) surface reflectance 
can be described with symmetrical Bi-Directional Reflectance Functions (BRDFs), 2) the environment has 
no participating media, and 3) the light model used in the rendering environment obeys the photon nature 
of light. A symmetrical BRDF is a reflectance function for which an inverse can be calculated. Within 
these assumptions, Costa allowed designers to specify almost any illumination goal using scripting. For 
example, a designer might code a rule that constrained intensity on a surface within a specific range. 
The system would then find light sources that fulfilled this and all other rules for a given space. Architectural 
lighting work in-general appears solved . Costa in­particular has produced a general-purpose and flexible 
system for visualization and designing architectural spaces. Unfortunately, the algorithms of this domain 
are too slow for interactive virtual rendering. Both Kawai and Costa, in-particular, require global illumination 
rendering (such as Radiosity or Raytracing). Further, the constraints of architectural visualization 
are very different from those of real-time visualization. Architectural visualization must produce physically 
possible solutions and must consider real-world factors such as energy efficiency and cost effectiveness. 
These considerations are therefore a fundamental part of architectural visualization solutions. These 
considerations are not necessarily true in real-time interactive rendering. Fig. 2. This figure shows 
a virtual scene of an office illuminatedby the system in [Costa, Sousa et al. 1999]. 4.2 Perceptual Inverse 
Lighting Perceptual inverse lighting includes the largest body of literature in inverse lighting [Poulin 
et al. 1997; Shacked 2001; Gumhold 2002; Vázquez and Sbert 2002; Shesh and Chen 2004; Lee, Hao et al. 
2006]. Work in this field operates in the image domain, using metrics derived from an image and possibly 
correlated geometry. In [Shacked 2001; Gumhold 2002; Vázquez and Sbert 2002; Lee, Hao et al. 2006] lighting 
is optimized without user interaction. The goal of lighting is derived from visual perception theories 
to achieve ideal settings to maximize the perception of shape, detail, and depth. Other works allow a 
user to specify a goal by annotating images, by drawing shadows or shading. Fig. 3. The 3D model of 
a ship in this figure is illuminated by thesystem of [Shacked 2001]. The system of [Shacked 2001] found 
light source settings to maximize perceptual features such as shape, detail, and depth perception (Fig. 
3). [Gumhold 2002; Vázquez and Sbert 2002] targeted a similar goal but used a metric based on information 
entropy [Shannon 1948]. All of these works calculated metrics from generated images of an object. Images 
were generated iteratively and evaluated for lighting. Lighting was then changed and the process repeated. 
Eventually, the best solution was found. The work of [Lee, Hao et al. 2006] is the most recent and complete 
work in this area. Lee approached the problem slightly differently from prior work. Objects were classified 
in the geometric domain into areas of local curvature. Illumination was then applied in a discontinuous 
fashion to each area to maximize goals per area. Cast shadow (Fig. 4) was also explicitly considered, 
the only work in this field to do so. This body of literature illustrates that while image analysis is 
useful for specifying lighting goals, straightforward analysis of images is incompatible with real-time 
rendering. Rendering images at runtime is too computationally expensive. No prior work in perceptual 
lighting was applied to the interactive domain. Therefore, the work of this paper offers a unique exploration 
of real-time interactive only considerations to this domain. Fig. 4. This image from [Lee, Hao et al. 
2006] illustrates that system s consideration of cast shadow on an object to help identify depth in a 
figure. The red box highlights a shadow thatthe system explicitly manipulated to help identify the structure 
ofthis 3D figure.  4.3 Interactive Inverse Lighting The only prior work in interactive inverse lighting 
aside from our work with the Expressive Lighting Engine is LightKit [Halle and Meng 2003]. LightKit uses 
film s three-point lighting as a constraining lighting model. In LightKit, the key light is a light that 
provides a dominant sense of direction and it is always located at 45° relative to the orientation of 
the camera. The fill light is fixed at 90° relative to the key and is maintained at an intensity ratio 
of 2:1 to the key. Light kit also uses two back lights that illuminate an object from behind and help 
to isolate it from the background. A user can adjust this lighting configuration by specifying the intensity 
of the key light or the color of the key light using a warmth scale derived by [Halle and Meng 2003]. 
While useful for its domain of medicine, the LightKit has limited application to video games. The LightKit 
simplifies the control of illumination but it still requires a user to actively control illumination 
at runtime. In the domain of this paper, lighting is generally a supporting element and not a first-order 
concern for user interaction.  4.4 Expressive Lighting Engine (ELE) Seif El-Nasr and Horswill [2004] 
proposed ELE. ELE is a dynamic intelligent lighting system developed based on cinematic lighting design 
theory to use artistic constraints to compose a lighting design which it adjusts and manipulates dynamically, 
accommodating interaction while achieving artistic goals. ELE is divided into three subsystems: an allocation 
subsystem used to select the number of lights and their locations, an angle subsystem which selects angles 
for each light, and a color subsystem which selects colors for each light. We will briefly discuss these 
sub­systems in this section. 4.4.1 ELE the System ELE uses stage layout, scene graph information, and 
artistic constraints to create a light layout. ELE divides the scene into n different areas and categorizes 
these areas as focus, non-focus, or background. This information is then used to identify focus, increase 
depth, and increase contrast based on designer goals. ELE also determines where to direct a player s 
attention given characters in the scene. Thus, ELE maximizes a multi-objective function to determine 
the number of lights to use for each area: (1) where p is the light configuration and the weights represented 
by . are the artistic constraints. Specifically, .v is the importance of visibility, .d is the importance 
of depth, .m is the importance of modeling, and .vc is the importance of visual continuity. V(p) is visibility 
given p, D(p) is depth given p, M(p) is modeling given p, and VC(p) is visual continuity given p. In 
determining the angles of light, ELE also takes into account the quality of lights and their influence 
in projecting depth, modeling, and mood. ELE uses non-linear optimization to select an angle for each 
key light that minimizes the following function: (2) where k and s are defined as the key light azimuth 
angle relative to the camera and the subject angle relative to the key light. k-is the key light azimuth 
angle from the previous frame and .s represent artistic constraints. Specifically, .-is the cost of changing 
the key light angle over time (to enforce visual continuity), .m is the cost of deviation from the mood 
azimuth angle, m is the mood azimuth angle suggested by the artist, .l is the cost of azimuth angle deviation 
from a practical source direction, li is the azimuth angle of light emitted by the practical source i, 
and .v is the cost of deviation from an orientation of light that establishes best visibility. The interaction 
of lighting colors in a scene composes the contrast and feeling of the entire image. Similar to the angle 
and layout systems, ELE uses non-linear optimization to search through a nine-dimensional space of RGB 
values. It differentiates among focus colors, non-focus colors, and background areas to select a color 
for each individual light in the scene. The multi-objective cost function evaluates the color against 
the lighting-design goals, including establishing depth, conforming to color style and constraints, paralleling 
dramatic tension, adhering to desired hue, saturation, and lightness, and maintaining visual continuity. 
 4.4.2 Shortcomings of ELE After experimenting and using ELE for several years with various users, we 
deduced that ELE is not easy to use. ELE abstracts low­level lighting design constructs (light colors, 
positions, and angles) into higher level numerical constraints. These constraints include more than twenty-five 
real numbers that are dependent in non-intuitive ways. Lighting designers who have interacted with ELE 
often fail to achieve the desired results, even though their results are theoretically achievable within 
ELE s abstraction. It is also not known whether ELE s abstraction aligns with how game lighting designers 
actually conceptualize lighting design. Abstractions always enforce specific limitations and constraints 
on representation and it is critical that these limitations and constraints are acceptable to game lighting 
designers for ELE to be useful. In addition, ELE did not take into consideration the materials or textures 
of the objects or the environment. This is important as lighting design relies on perceptual quality 
and appearance, which is a function of all visual elements in an environment. Fig. 5. This figure illustrates 
the process of the system.  5 Current Work In this section, we discuss a work in progress which attempts 
to overcome some of the problems faced with ELE discussed above. In particular, this section will address 
early experimentation in integrating image-based analysis approaches, color and lighting perception theories, 
film techniques, and artificial intelligent techniques to achieve intended lighting effects in a 3D environment. 
 In this current system, we decided to constrain the problem. First, instead of deducing lighting setup 
for entire scenes including objects and environment, we focuse on finding lighting parameters for an 
object or a set of objects within a scene. Second, we only deduce lighting direction and brightness contrast. 
It is assumed that lighting is performed using primitives of Rasterization. Specifically, two lights 
are used, a key and a fill light, following film s three-point lighting technique, described previously. 
Thus, the problem is narrowed down to finding the best lighting direction and brightness for key and 
fill lights for objects within a scene. Fig. 5 summarizes the system currently under development. The 
system is composed of two main subsystems. The first subsystem calculates a response surface that encodes 
the response of an object under different lighting conditions and camera angles using metrics extracted 
from final renders of the object. The second subsystem is a result of our earlier exploration of lighting 
a 3D scene using an image as an example [Zupko and Seif El-Nasr 2006]. This subsystem finds light primitives 
to create illumination at runtime that approximates lighting in an example image as closely as possible 
based on information from the response surface calculated by the first subsystem. 5.1 Calculating lighting 
appearance At runtime, the system needs to know the effect of lighting on object appearance. For example, 
increasing the intensity of the fill light will decrease the overall intensity contrast on the object 
by different amounts depending on the object. The system also needs to be able to quickly calculate the 
illumination metrics for an object given camera direction and illumination parameters. To calculate this 
information quickly, the system finds a response surface for the object being lit. This process is done 
off-line. The response surface is a five-dimensional surface of data samples relating independent variables 
to dependent results. The independent variables are: the camera direction, key light direction, and fill 
intensity. The dependent variables are the shading direction and intensity contrast as expressed by a 
render of the object using the independent variables as render settings. The response surface is represented 
as a coarse sampling of points. These points are sampled by rendering the object with random camera direction, 
key light direction, and fill light intensity settings and then processing the image to extract metrics 
representing the shading direction and intensity contrast. Random sampling of camera direction, key light 
direction, and fill light intensity is achieved using jitter sampling. Jitter sampling divides the sampling 
space into an evenly spaced coarse grid of samples and then randomly selects a point within each grid 
cell. This approach is used as it reduces the number of samples necessary to produce an accurate representation 
of the response surface but has been shown to be statistically equivalent to an un-constrained random 
sampling.  5.2 Design by example The system uses an image supplied by a designer as an example of the 
lighting effect that she wishes to create. To mimic this effect, the system performs image analysis on 
the example image. The algorithms for this analysis are based on theories from visual perception. 5.2.1 
Visual Perception Visual perception is a discipline that studies the process of sight. Our ability to 
see is a combination of both the reception of light by our eyes and the interpretation of light stimulus 
by our brains. Understanding the interpretation of light aesthetic requires an understanding of visual 
perception theories. The visual perception theories related to our work come from the sub-field of visual 
perception known as psychophysics. Psychophysics maps low­level stimuli to subjective interpretation. 
A key theory of the psychophysics of illumination perception is color constancy. Color constancy is the 
human visual system s ability to adapt vision to achieve constant color. Constant color is why gray surfaces 
still appear gray under different illumination [Adelson 2000] and a green apple looks green under sunlight 
or fluorescent light. All human interpretation of light occurs through the color constancy effect. Accounting 
for this effect is therefore important for a system to see an image like we do. There is no single mathematical 
model for color constancy but see [Barnard, Cardei et al. 2002] for a survey and comparison. These models 
make several common assumptions. Surfaces are assumed to be diffuse and light is assumed to be sufficiently 
distant such that appearance changes due to illumination are low-frequency. Processing is also assumed 
to be independent across color channels. This means that the red, green, and blue channels of the RGB 
color model are each processed independently from the other channels. A particular mathematical model 
for color constancy which achieves the common assumptions listed here is Retinex [Land and McCann 1971]. 
A simple version of Retinex used in the system presented in this paper is the Single-Scale Retinex (SSR) 
[Jobson and Woodell 1995]. SSR was selected in contrast to other approaches because it is computationally 
cheap to apply. It also requires no tuning parameters which is a desirable feature to keep the system 
robust across changes in context.  5.2.2 Image analysis The system extracts two types of information 
from the image: 1) light direction as indicated by shading, and 2) intensity contrast. Light direction 
roughly corresponds to the direction of a key light but is a combination of the effects of all light 
sources present in an image. Intensity contrast roughly corresponds to the intensity of a fill light 
but it is also a factor of the direction of light sources in the image. 5.2.2.1 Finding Intensity Contrast 
An image is first processed using the Single-Scale Retinex (SSR) algorithm of [Jobson and Woodell 1995] 
to produce an illumination image based on the Retinex model of color constancy [Land and McCann 1971]. 
An illumination image is a filtered version of an image that does not contain high-frequency pixel intensity 
changes. This is based on the assumption that lighting contributes only low-frequency information to 
an image while high-frequency information is due to surface reflectance. The original form of SSR is 
arranged to produce an illumination independent reflectance image: (3)   where i denotes the color 
channel, Li(x, y) is the ith channel of the source image, * is the convolution operator, and F(x ,y) 
is a spherical Gaussian function used to filter the source image. For the purposes of this work the illumination 
image is the goal term, which is:  (4) where Ii(x, y) denotes the ith channel of the illumination image. 
All calculations use the Y value of the XYZ color space conversion from the sRGB color space [Gumhold 
2002], which is:    (5)  where Y is the Y term of the XYZ color space conversion from the sRGB 
color space and R', G', B' are defined by the function:  (6)  with C as either R, G, or B from the 
RGB color space. To find terms correlated with the shading direction, first assume that the surface of 
a given object is Lambertian and convex. The outgoing light intensity from a surface patch covered by 
pixel i in an image is: (7) where n is the normal of the surface patch covered by pixel i, l is the 
direction from the surface patch to an imagined light source, A is the albedo of the surface, and Li 
is the intensity of an imagined light source. A normal is a unit-length vector with two degrees of freedom 
that indicates the direction of the face of a surface patch, where the face is the side of the patch 
that responds to light. The outgoing light intensity Lo is the pixel image data and the goal is to find 
image terms that can be correlated against lighting parameters for a key light and a fill light. The 
filtering of the image to produce an illumination image removes high-frequency pixel intensity changes. 
As a result, it can be assumed that the shading direction in an image is a function of the change in 
pixel intensities across an image due to an unknown but convex change in surface normal n at each pixel 
of the image, the low-frequency effects of albedo, and the unknown but predictably low-frequency changes 
in imagined light direction l at each pixel of the image. Fig. 6. This image illustrates the definition 
of image directionmetrics . and ß.  5.2.3 Finding Lighting Direction To quantify this information as 
an indicator of direction two terms are defined, . and ß, shown in Fig. 6. To find ., a local 3 x 3 window 
of image pixels is examined, starting at the upper-left corner of the image. The center of mass is found 
in the window, where mass is defined as the intensity of a pixel. A two­dimensional vector is formed 
between the center of mass within a window and the center of the window. The window is then slid across 
the image, calculating a vector for each, until every pixel in the image has been the center of a window. 
The average of these vectors is then calculated and converted to an angle to find .. Once . is found, 
the term ß can be calculated. ß is defined as: (8) where i is the ith line out of n adjacent perpendicular 
lines to the axis that ß is defined around, mi is the number of pixels in a line i, and Yi,j is the intensity 
of the jth pixel of the ith line. To find a term correlated with intensity contrast, the entropy metric 
of [Gumhold, 2002] is used. This is defined as: (9)  where m is a number of bins used to segment the 
intensity value of a pixel, and pi is the probability of a pixel falling into the bin i. pi is defined 
as: (10) where ci is the number of pixels falling into a bin i and n is the total number of pixels in 
the image. The i of a pixel is defined as:  (11)   where Y' is the intensity value for a given pixel 
normalized to the range [0,1] and m is a number of bins used to segment the Y value of a pixel. The bins 
are currently set to m = 30 bins.  5.3 Lighting the scene At runtime the system makes decisions by using 
the response surface, the state of the rendering environment, and an example image provided by a designer. 
The system uses two sets of inputs for each object in the scene: one is the illumination features extracted 
from an example image and the other is the illumination features that would be created if the lighting 
motivated by the scene were applied to the object. The first set of features is given by the image analysis 
process of the system while the second set is derived from the response surface. This is because while 
the light source parameters in the scene are given (the system knows explicitly where light sources are 
located in the scene) the results of lighting an object with those parameters are not. Therefore, the 
system derives a set of illumination features by using the response surface. Generating these features 
is a matter of finding the nearest sampled points on the surface to the point of the current camera direction 
and motivated light source parameters (key direction and fill intensity). Once the points are found, 
the illumination features for each point are averaged. The system then uses stochastic gradient descent 
to step from the natural illumination towards the ideal illumination. The best solution is the point 
that produces illumination metrics which are equally distant from the natural and ideal. Essentially, 
the system finds the light settings (independent variables) that produce illumination metrics (dependent 
variables) which are a compromise between the natural and ideal illumination metrics. Fig. 7 shows a 
mock-up of this process. Fig. 7. The left-most image illustrates a figure lit by naturalillumination. 
The center image is the figure lit purely to the idealimage (the lit sphere centered above the images), 
recreating theshading direction and intensity contrast of the ideal image. Theright-most image is a compromise 
between the two. This isachieved by increasing the fill light to lighten the shaded area andadjusting 
the key light to decrease the lightness of the bright area. This process only occurs when the object 
first becomes visible. While the object remains visible, light settings are interpolated. They change 
proportionally with changes to the natural light settings. For example, if the light that motivates the 
key light moves by 15° relative to the object, the key light will also move 15° relative to the object. 
When the object is off-screen for a period of time, the stochastic gradient descent step is run again 
to find new best settings. This approach avoids visual discontinuity from abrupt changes. Conclusions 
and Future Work Games are interactive and unpredictable. Static, preset game lighting can fail to accommodate 
unexpected conditions at runtime. Dynamic adaptive lighting design, however, is a potential solution 
to this problem. There are many challenges to this approach, including computational constraints, understanding 
the aesthetics of lighting design, and defining an algorithm that encodes perceptual knowledge as well 
as cinematic techniques of lighting design. This paper presented an in-progress adaptive dyanmic lighting 
design system that encodes perceptual theories and cinematic lighting techniques. We have discussed this 
system as an ongoing prototype. We expect the system to be a useful tool for several domains. However, 
this will be finally determined when the system is fully implemented and evaluated. An important topic 
for future work is lighting entire scenes. While the system could currently light a scene of objects, 
it would do so by considering each object as a single piece. Lighting multiple pieces as holistic swathes, 
much as a landscape painter might shade a painting, is a different conceptual problem that might be useful 
for both computational and purposeful reasons. Computationally, the system would do less work by deciding 
to use a single light to illuminate a holistic group of twelve objects than by using three lights for 
each object. Purpose could be explored in terms of functional goals (the current system cannot light 
objects that are disproportionably long, deep, or tall) or aesthetic goals (the ability to light a group 
of objects as a group is artistically different from the aesthetics that the system can currently produce 
by lighting each object in the group as an individual). Additional exploration of the relationship between 
multiple objects and the effects of cast and attached shadow are also needed. Lee and Hao [2006] is the 
only automated inverse lighting work to explicitly consider cast shadow, and its algorithms are far too 
expensive for an interactive real-time environment. Considering cast shadow is a difficult problem because 
the response of shadowed area is discontinuous with a change in light parameters. Shadow is a combination 
of the parameters of the occluder, the occludee, and the relationship between the two and any light sources. 
This relationship is challenging to unpack. Finally an interesting question is how lighting design practice 
might expand its set of techniques and theories for the interactive domain with an intelligent system 
as a fundamental piece. Current approaches to interactive lighting design focus on constraining the environment 
to allow easier application of traditional lighting design techniques adopted from film, theater, architecture, 
and other lighting design domains. If designers knew that their tool would automatically adjust in a 
predictable manner to changes in the environment and with regards to their design specification this 
might lead to new approaches for design. This could in turn lead to improvements to the underlying intelligent 
software system. 7 Acknowledgement Special thanks to David Milam, graduate student in EMIIE (Engage Me 
In Interactive Experiences) Lab at School of Interactive Arts and Technology (SIAT), Simon Fraser University 
(SFU), for creating the girl character model used in figures 5, 6, and 7. and the scene used in figure 
5.  8 References Alton, J. 1995. Painting with Light. University of California Press. Adelson, E. H. 
(2000). Lightness Perception and Lightness Illusions. The New Cognitive Neurosciences. Cambridge, Massachusetts, 
MIT Press: 339-351. Barnard, K., V. Cardei, et al. (2002). "A Comparison of Computational Color Constancy 
Algorithms -Part I: Methodology and Experiments With Synthesized Data." IEEE Transactions on Image Processing 
11(9): 972-983. Birn, J., Ed. 2000. Digital Lighting &#38; Rendering. New Riders. Block, B. 2001. The 
Visual Story: Seeing the Structure of Film, TV, and New Media. Focal Press. Brown, B. 1996. Motion Picture 
and Video Lighting. Focal Press. Calahan, S. 1996. Storytelling through lighting: a computer graphics 
perspective. Siggraph Course Notes. Campbell, D. 1999. Technical Theatre for Non-technical People. Allworth 
Press. Comaniciu, D. and Meer, P. 2002. Mean shift: A robust approach toward feature space analysis. 
IEEE Transactions on Pattern Analysis and Machine Intelligence, 2, 603-619. Costa, A. C., A. A. Sousa, 
et al. 1999. Lighting Design: A Goal Based Approach Using Optimisation. EUROGRAPHICS. Crowther, B. 1989. 
Film Noir: Reflections in a Dark Mirror. Continuum. P. Debevec. 2005. High-dynamic-range imaging and 
image­based lighting: Image based lighting. Siggraph Courses. Edge Detection and Image SegmentatiON (EDISON) 
System. http://www.caip.rutgers.edu/riul/research/code.html. Evans, J. 2006. Art and Craft of Lighting. 
Game Developers Conference. Flynn, J. E. 1977. A study of subjective responses to low energy and nonuniform 
lighting systems. Lighting Design and Application. Folmann, T. 2006. Tomb Raider Legend: Scoring a Next-Generation 
Soundtrack. In Proceedings of Game Developers Conference 2006. Freeman, D. 2004. Creating Emotion in 
Games: The Craft and Art of EmotioneeringTM. New Riders. Gillette, J. M. 1998. Designing with Light. 
Mayfield. Gumhold, S. (2002). "Maximum Entropy Light Source Placement." IEEE Visualization 2002: 275-282. 
Halle, M. and J. Meng (2003). "LightKit: A lighting system for effective visualization." IEEE Visualization 
2003: 363-370. Henderson, J. M. and A. Hollingworth (2002). Global Transsaccadic Change Blindness During 
Scene Perception, Michigan State University: 1-7. Jobson, D. J. and G. A. Woodell (1995). Properties 
of a Center/Surround Retinex Part Two: Surround Design, NASA Langley Research Center. Kasavin, G. 2004. 
Doom 3 Review. GameSpot. http://www.gamespot.com/pc/action/doom3/review.html Kawai, J. K., J. S. Painter, 
et al. 1993. Radioptimization -Goal Based Rendering. ACM SIGGRAPH 1993. Knez, I., Enmarker, I. Effects 
of office lighting on mood and cognitive performance, and a gender effect in work-related judgment. Environment 
and Behaviour, 30, 553-567, 1998. Kidd, W. 2001. Vermeer: Master of Light Video, J. J. Karkora. National 
Gallery of Art. Knopft, D. C. a. A. 1979. The Book of Movie Photography. Alfred Knopf, Inc. Land, E. 
H. and J. J. McCann (1971). "Lightness and Retinex Theory." Journal of the Optical Society of America 
61(1): 1­ 11. Lee, C. H., X. Hao, et al. (2006). "Geometry-Dependent Lighting." IEEE Transactions on 
Visualization and Computer Graphics 12(2): 197-207. Lowell, R. 1992. Matters of Light &#38; Depth. Lowel-Light 
Manufacturing, Inc. Millerson, G. 1991. Lighting for Television and Film. Focal Press. Marino, P. 2004. 
3D Game-Based Filmmaking: The Art of Machinima. Paraglyph Press. Ngyuyen, H. 2007. GPU Gems 3: Programming 
Techniques for High Performance Graphics and General-Purpose Computation. Addison-Wesley Education Publishers, 
Inc. Poulin, P., K. Ratib, et al. (1997). Sketching Shadows and Highlights to Position Lights. Computer 
Graphics International 1997. Patow, G. and X. Pueyo (2003). "A Survey of Inverse Rendering Problems." 
COMPUTER GRAPHICS forum 22(4): 663-687. Seif El-Nasr, M. and Horswill, I. 2004. Automating Lighting Design 
for Interactive Entertainment. ACM Computers and Entertainment, 2(2). Seif El-Nasr, M., Niedenthal, S., 
Kenz, I., Almeida, P., and Zupko, J. Dynamic Lighting for Tension in Games. Game Studies. 7(1), 2006. 
Shacked, R. (2001). Automatic Lighting Design using a Perceptual Quality Metric. Computer Science and 
Engineering. Jerusalem, Israel, The Hebrew University of Jerusalem. Master of Science: 68. Shesh, A. 
and B. Chen (2004). Crayon Lighting: Sketch-guided Illumination of Models. Pacific Graphics 2004. Shannon, 
C. E. (1948). A Mathematical Theory of Communication. Bell System Technical Journal. 27(1): 379­423, 
623-656. Vázquez, P.-P. and M. Sbert (2002). Perception-Based Illumination Information Measurement and 
Light Source Placement. ICCSA 2003. Y. Yu, P. Debevec, J. Malik, and T. Hawkins. Inverse Global Illumination: 
Recovering Reflectance Models of Real Scenes from Photographs, Proc. SIGGRAPH '99, pp. 215-224, 1999. 
Zupko, J. and Seif El-Nasr, M. 2006. A Tool for Aesthetic-based Lighting Design in Interactive 3D Environments. 
Sandbox Siggraph 2006.   
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
	</article_rec>
	<article_rec>
		<article_id>1401870</article_id>
		<sort_key>270</sort_key>
		<display_label>Pages</display_label>
		<pages>6</pages>
		<article_publication_date>08-09-2008</article_publication_date>
		<seq_no>3</seq_no>
		<title><![CDATA[Enabling a voice modality in mobile games through VoiceXML]]></title>
		<page_from>143</page_from>
		<page_to>147</page_to>
		<doi_number>10.1145/1401843.1401870</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1401870</url>
		<abstract>
			<par><![CDATA[<p>The use of speech recognition in gaming applications is not entirely new. The growth of voice as a part of gaming has exploded largely due to the popularity of online player matchmaking services such as Xbox Live. Yet, the majority of its use is only limited to communications between players to coordinate game play activities through the use of a headset and a microphone.</p> <p>To further explore the possibilities of using speech recognition to affect game play directly, Motorola has partnered with GamePipe Labs at the University of Southern California. This collaboration aims at leveraging the capabilities of VoiceXML (VXML), and use interactive voice dialogues to directly affect game play on mobile phones. This short paper describes the efforts taken under this initiative, and the results of this collaboration.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[GamePipe labs]]></kw>
			<kw><![CDATA[Motorola labs]]></kw>
			<kw><![CDATA[VoiceXML]]></kw>
			<kw><![CDATA[mobile gaming]]></kw>
			<kw><![CDATA[multi-modal interaction]]></kw>
			<kw><![CDATA[multiplayer multimodal mobile games]]></kw>
			<kw><![CDATA[speech recognition]]></kw>
			<kw><![CDATA[voice recognition]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>H.5.2</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>H.5.3</cat_node>
				<descriptor>Collaborative computing</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>H.5.2</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>J.5</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
			<other_category>
				<cat_node>K.3.2</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10003456.10003457.10003527.10003531.10003533</concept_id>
				<concept_desc>CCS->Social and professional topics->Professional topics->Computing education->Computing education programs->Computer science education</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003456.10003457.10003527.10003531.10003536</concept_id>
				<concept_desc>CCS->Social and professional topics->Professional topics->Computing education->Computing education programs->Information science education</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003121</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010405.10010469</concept_id>
				<concept_desc>CCS->Applied computing->Arts and humanities</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003130</concept_id>
				<concept_desc>CCS->Human-centered computing->Collaborative and social computing</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10003120.10003121</concept_id>
				<concept_desc>CCS->Human-centered computing->Human computer interaction (HCI)</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<person_id>P1100751</person_id>
				<author_profile_id><![CDATA[81100549374]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Michael]]></first_name>
				<middle_name><![CDATA[J.]]></middle_name>
				<last_name><![CDATA[Zyda]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Southern California]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1100752</person_id>
				<author_profile_id><![CDATA[81330499280]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Dhruv]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Thukral]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Southern California]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1100753</person_id>
				<author_profile_id><![CDATA[81365591266]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[James]]></first_name>
				<middle_name><![CDATA[C.]]></middle_name>
				<last_name><![CDATA[Ferrans]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Motorola Labs, Schaumburg, IL]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1100754</person_id>
				<author_profile_id><![CDATA[81330490514]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Jonathan]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Engelsma]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Motorola Labs, Schaumburg, IL]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1100755</person_id>
				<author_profile_id><![CDATA[81365591854]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Mat]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Hans]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Motorola Labs, Schaumburg, IL]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_obj_id>1251628</ref_obj_id>
				<ref_obj_pid>1251554</ref_obj_pid>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Zyda, Thukral et al., "Educating the Next Generation of Mobile Game Developers" for IEEE Computer Graphics and Applications, March 2007]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[J. R. Engelsma et al., "Ubiquitous Mobile Gaming," <i>Proc. System Support for Ubiquitous Computing Workshop (UbiSys)</i>, 2006; http://www.magic.ubc.ca/ubisys/positionsengelsma.pdf.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[D. Pearce et al., "An Architecture for Seamless Access to Distributed Multimodal Services," <i>Proc. 9th European Conf. Speech Communication and Technology</i>, Int'l Speech Communication Assoc., 2005, pp. 2845--2848.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[S. McGlashan et al., "Voice Extensible Markup Language (VoiceXML) Version 2.0," World Wide Web Consortium (W3C)recommendation, Mar. 2004, http://www.w3.org/TRvoicexml20/]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Jim Ferrans and Jonathan Engelsma. "Software architectures for networked mobile speech applications", in Automatic Speech Recognition on Mobile Devices and over Communication Networks, Zeng-Hua Tan, ed., Springer Press, 2008.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
	</article_rec>
	<article_rec>
		<article_id>1401871</article_id>
		<sort_key>280</sort_key>
		<display_label>Pages</display_label>
		<pages>8</pages>
		<article_publication_date>08-09-2008</article_publication_date>
		<seq_no>4</seq_no>
		<title><![CDATA[A new physics engine with automatic process distribution between CPU-GPU]]></title>
		<page_from>149</page_from>
		<page_to>156</page_to>
		<doi_number>10.1145/1401843.1401871</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1401871</url>
		<abstract>
			<par><![CDATA[<p>The Graphics Processing Units or simply GPUs have evolved into extremely powerful and flexible processors. This flexibility and power have allowed new concepts in general purpose computation to emerge. This paper presents a new architecture for physics engines focusing on the simulation of rigid bodies with some of its methods implemented on the GPU. Sending physics computation to the GPU enables the unloading of the required computations from the CPU, allowing it to process other tasks and optimizations. Another important reason for using the GPU is to allow physics engines to process a higher number of bodies in the simulation. It also presents an automatic process distribution scheme between CPU and GPU. The importance of the automatic distribution for physics simulation arises from the fact that, sometimes, the simulated scene characteristics may change during the simulation and by using an automatic distribution scheme the system may obtain the best performance of both processors (CPU and GPU). Also, with an automatic distribution mode, the developer does not have to decide which processor will do the work allowing the system to choose between CPU and GPU. This paper also presents an uncoupled multithread game loop used by the physics engine.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[GPGPU]]></kw>
			<kw><![CDATA[automatic distribution]]></kw>
			<kw><![CDATA[game loops]]></kw>
			<kw><![CDATA[physics simulation]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.1</cat_node>
				<descriptor>Graphics processors</descriptor>
				<type>S</type>
			</primary_category>
			<other_category>
				<cat_node>I.3.5</cat_node>
				<descriptor>Physically based modeling</descriptor>
				<type>S</type>
			</other_category>
			<other_category>
				<cat_node>I.3.7</cat_node>
				<descriptor>Virtual reality</descriptor>
				<type>S</type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010371.10010352.10010379</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation->Physical simulation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387.10010866</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces->Virtual reality</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010396</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Shape modeling</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10002950.10003741.10003742.10003745</concept_id>
				<concept_desc>CCS->Mathematics of computing->Continuous mathematics->Topology->Geometric topology</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010387.10010389</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Graphics systems and interfaces->Graphics processors</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<person_id>P1100756</person_id>
				<author_profile_id><![CDATA[81361607777]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Mark]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Joselli]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Universidade Federal Fluminense]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1100757</person_id>
				<author_profile_id><![CDATA[81339494999]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Esteban]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Clua]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Universidade Federal Fluminense]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1100758</person_id>
				<author_profile_id><![CDATA[81100501812]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Anselmo]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Montenegro]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Universidade Federal Fluminense]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1100759</person_id>
				<author_profile_id><![CDATA[81100387201]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Aura]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Conci]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Universidade Federal Fluminense]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1100760</person_id>
				<author_profile_id><![CDATA[81100504588]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>5</seq_no>
				<first_name><![CDATA[Paulo]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Pagliosa]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Universidade Federal de Mato Grosso do Sul]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Ageia, 2008. Physx. Avalible at: http://www.ageia.com. 20/02/2008.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Anderson, A., III, W. G., and Schr&#246;der, P. 2007. Quantum monte carlo on graphical processing units. <i>Computer Physics Communications 177(3).</i>
]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>940355</ref_obj_id>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Eberly, D. H. 2004. <i>Game Physics.</i> Morgan Kaufmann.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1214185</ref_obj_id>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Eberly, D. 2005. <i>3D Game Engine Architecture - Engineeering Real-Time Aplications with Wild Magic.</i> Morgan Kaufmann.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Ericson, C. 2005. <i>Real-Time Collision Detection.</i> Morgan Kaufmann.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Georgii, J., Echtler, F., and Westermann, R. 2005. Interactive simulation of deformable bodies on gpu. In <i>Proceedings of Simulation and Visualization 2005</i>, 247--258.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>844178</ref_obj_id>
				<ref_obj_pid>844174</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Govindaraju, K. N., Redon, S., Lin, M. C., and Manocha, D. 2003. CULLIDE: interactive collision detection between complex models in large environments using graphics hardware. In <i>Graphics Hardware 2003</i>, 25--32.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Green, S., 2003. NVIDIA cloth sample. Available at: http://download.developer.nvidia.com/developer/SDK/Individual Samples/samples.html#glsl_physics. 03/12/2007.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1281656</ref_obj_id>
				<ref_obj_pid>1281500</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Green, S., 2007. Gpgpu physics. Siggraph07 GPGPU Tutorial.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Harris, M. 2005. Mapping computational concepts to gpus. <i>M. Pharr(Ed.), GPU Gems (2), Addison-Wesley, Boston, USA</i>, 493--508.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1215067</ref_obj_id>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Ierusalimschy, R., de Figueiredo, L. H., and Celes, W. 2006. <i>Lua 5.1 Reference Manual.</i> Lua.org.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1381168</ref_obj_id>
				<ref_obj_pid>1380847</ref_obj_pid>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Joselli, M., Valente, L., Zamith, M., Clua, E., Montenegro, A., Conci, A., Feij&#243;, B., d' Ornellas, M., Pozzer, C., and Leal-Toledo, R. 2008. Automatic dynamic task distribution between cpu and gpu for real-time systems. <i>11th IEEE International Conference on Computational Science and Engineering.</i> To appear.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1058146</ref_obj_id>
				<ref_obj_pid>1058129</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Kipfer, P., Segal, M., and Westermann, R. 2004. Uberflow: a gpu-based particle engine. In <i>Graphics Hardware 2004</i>, 115--122.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1247793</ref_obj_id>
				<ref_obj_pid>1247737</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Muller, C., Strengert, M., and Ertl, T. 2007. Adaptive load balancing for raycasting of non-uniformly bricked volumes. <i>Parallel Computing 33(6)</i>, 406--419.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1407436</ref_obj_id>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Nguyen, H. 2007. <i>GPU Gems 3 - Programming Techniques for High-performance Graphics and General-Purpose Computation.</i> Addison-Wesley.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>16</ref_seq_no>
				<ref_text><![CDATA[Owens, J. D., Leubke, D., Govindaraju, N., Harris, M., Kr&#252;ger, J., Lefohn, A. E., and Purcell, T. J. 2007. A survey of general-purpose computation on graphics hardware. <i>Computer Graphics Forum 26(1)</i>, 80--113.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>17</ref_seq_no>
				<ref_text><![CDATA[Rudom&#253;n, T., Mill&#225;n, E., and Hern&#225;ndez, B. 2005. Fragment shaders for agent animation using finite state machines. <i>Simulation Modelling Practice and Theory 13(8)</i>, 741--751.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>18</ref_seq_no>
				<ref_text><![CDATA[Smith, R., 2008. Open dynamics engine. Available at: http://www.ODE.org/. 20/02/2008.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>19</ref_seq_no>
				<ref_text><![CDATA[Valente, L., Conci, A., and Feij&#243;, B. 2005. Real time game loop models for single-player computer games. In <i>Proceedings of the IV Brazilian Symposium on Computer Games and Digital Entertainment</i>, 89--99.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>20</ref_seq_no>
				<ref_text><![CDATA[Valente, L. 2005. <i>Guff: um framework para desenvolvimento de jogos.</i> Master's thesis, Universidade Federal Fluminense. In Portuguese.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>21</ref_seq_no>
				<ref_text><![CDATA[Zamith, M., Clua, E., Pagliosa, P., Conci, A., Montenegro, A., and Valente, L. 2007. The gpu used as a math co-processor in real time applications. <i>Proceedings of the VI Brazilian Symposium on Computer Games and Digital Entertainment</i>, 37--43.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 A New Physics Engine with Automatic Process Distribution between CPU-GPU Mark Joselli Paulo Pagliosa 
Esteban Clua Departamento de Computac¸ ao e Estat´istica Anselmo Montenegro Universidade Federal de Mato 
Grosso do Sul Aura Conci * Instituto de Computac¸ ao Universidade Federal Fluminense Abstract The Graphics 
Processing Units or simply GPUs have evolved into extremely powerful and .exible processors. This .exibility 
and power have allowed new concepts in general purpose computation to emerge. This paper presents a new 
architecture for physics en­gines focusing on the simulation of rigid bodies with some of its methods 
implemented on the GPU. Sending physics computation to the GPU enables the unloading of the required 
computations fromtheCPU,allowingit toprocessother tasksand optimizations. Another important reason for 
using the GPU is to allow physics engines to process a higher number of bodies in the simulation. It 
also presents an automatic process distribution scheme between CPU and GPU. The importance of the automatic 
distribution for physics simulation arises from the fact that, sometimes, the simu­lated scenecharacteristicsmay 
changeduringthesimulationandby using an automatic distribution scheme the system may obtain the bestperformance 
ofbothprocessors(CPUandGPU).Also, with an automaticdistributionmode,thedeveloperdoesnothave todecide 
whichprocessorwilldo thework allowingthesystem tochoosebe­tween CPU and GPU. This paper also presents 
an uncoupled mul­tithreadgame loop usedby thephysicsengine. CR Categories: I.3.1 [Computer Graphics]: 
Hardware Architecture Graphics processors; I.3.5 [Computer Graphics]: Computational Geometry and Object 
Modeling Physically based modeling;I.3.7[ComputerGraphics]: Three-DimensionalGraph­ics andRealism Virtual 
reality Keywords: physics simulation, automatic distribution, GPGPU, game loops 1 Introduction The increase 
of the level of realism in virtual simulation depends not only on the enhancement of modelling and rendering 
effects, butalsoon the improvement ofdifferent aspectssuch asanimation, arti.cial intelligenceof thecharactersandphysicssimulation. 
The development of programmable GPUs has enabled new possi­bilities for general purpose computation (GPGPU) 
which can be * e-mail: {mjoselli, esteban, anselmo, aura}@ic.uff.br e-mail:pagliosa@dct.ufms.br Copyright 
&#38;#169; 2008 by the Association for Computing Machinery, Inc. Permission to make digital or hard copies 
of part or all of this work for personal or classroom use is granted without fee provided that copies 
are not made or distributed for commercial advantage and that copies bear this notice and the full citation 
on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting 
with credit is permitted. To copy otherwise, to republish, to post on servers, or to redistribute to 
lists, requires prior specific permission and/or a fee. Request permissions from Permissions Dept, ACM 
Inc., fax +1 (212) 869-0481 or e-mail permissions@acm.org. Sandbox Symposium 2008, Los Angeles, California, 
August 9 10, 2008. &#38;#169; 2008 ACM 978-1-60558-173-6/08/0008 $5.00 used to enhance the level of 
realism of virtual simulations. Some examplesof works inGPGPU that address these1 issuesareQuan­tum Monte 
Carlos [Anderson et al. 2007], arti.cial intelligence [Rudom´yn et al.2005] and ray casting[Muller et 
al.2007]. Recently,GPUsare implementingnewarchitectureparadigmssuch as the uni.ed architectures proposed 
by the two major GPU man­ufacturers: Nvidia and AMD/ATI. Each architecture is associated with its own 
programing model and language: Nvidia has devel­opedCUDA(ComputeUni.edDeviceArchitecture) andAMDde­velopedCAL(ComputeAbstractionLayer). 
One main advantage in the use of these models is that they allow the use of the GPU in amore .exibleway(both 
languagesarebased on theC language) without some of the traditional shader languages limitations. Nev­ertheless, 
the disadvantage of these architectures is that they are only available for the vendors of the software, 
i.e., CUDA only works onNvidia andCAL only works onAMD/ATI cards. In order to have GPGPU programs that 
work on both GPUs it is necessary toimplementtheminshaderlanguages likeGLSL(OpenGLShad­ingLanguage),HLSL(HighLevelShaderLanguage) 
andCG(C for Graphics) with all the vertex and pixel shader limitations and idiosyncrasies. This paper 
addresses different issues related to the problem of im­plementing physics methods on the GPU in a multithread 
archi­tecture. The relevance and importance of transferring some of the physicscomputation totheGPUisinthefactthatitmakespossible 
to takeoutpart oftheload oftheCPU,allowingit toprocesssome other tasks like arti.cial intelligence and 
physics simulation opti­mizations. It would, therefore, allow more rigid bodies in a scene oreven theprocessing 
of .exiblebodies. This paper also introduces four automatic distributions methods for the use of the 
physics engine with automatic distribution be­tween CPU and GPU. The importance of these automatic distribu­tioncomesfrom 
threefacts.First,adistributionmethod may enable the system to automatically select the fastest processor 
without re­quiringthedevelopertodetermine it.Second,sometimestheappli­cationcanbesloweddownby otherprocessesofthegame(likeAI) 
if the CPU or GPU is already overloaded with some work. In this case, an automatic process distribution 
method may help to avoid this problem. And third, the simulated scene may change during the application. 
By using an automatic distribution scheme, most ofthephysicsenginescomputationcanbeperformedin thefastest 
processor. Summarizing, thisworkpresents thefollowing mainresults: Implementation of some of the steps 
of the main loop of a physicsengineon theGPU withgood results;  Proposal and implementation of new methods 
for automatic process distribution between CPU and GPU for the physics enginepresented;  Designandimplementationofamultithread 
architecture tobe used with thephysicsengine.  Thepaper isorganizedasfollows:Section2presents theconcept 
of GPGPU.Section3presents some related works. Section4presents the physics engine loop. Section 5 describes 
the implementation and results on the GPU. Section 6 describes the four methods for automaticprocessdistributionbetweenCPU 
andGPUfor comput­ing the tasks involved in the physics loop; some results obtained from the tests are 
also presented. Section 7 presents the game ar­chitecture for the physics simulation and the results 
of the tests. Finally, section8points out some conclusions and remarks.  2 GPGPU GPUs are powerful 
processors dedicated to graphics computation which are much faster than CPU when considered all the paral­lel 
processors. A nVidia 8800 ultra, for instance, can sustain a measured 384 GFLOPS/s against 35.3 GFLOPS/s 
for the 2.6 Ghz dual coreIntelXeon5150.Becauseof theGPUs parallel architec­ture(the nVidiaGeForce9800GX2,for 
example,has256 uni.ed stream processors), they are very good for processing applications that requirehigh 
arithmetic rates anddatabandwidths. The development of programmable GPU opened a new area of re­search,enabling 
theuseof thegraphicsdeviceforprocessing non­graphic data, like physics computation. Nevertheless, because 
of itsSIMD(SingleInstruction,MultipleData) architecture, thede­velopment of GPGPU s applications requires 
a different program­mingparadigmratherthanthe traditionalCPU sequentialprogram­ming model.Besides,onemustbeaware 
that thenatureofgeneric data includes operations that are not optimized in GPU processing [Owensetal.2007](without 
anuni.ed architecture),such as scat­ter memory operations, i.e. indexed write array operations, and others 
that are not even implemented as integer data operands like bit-wise logical operations AND, OR, XOR, 
NOT and bit-shifts. These drawbacks require sometimes ingenious ways to model and implement solutions 
on GPUs if we are not considering the use of uni.ed architectureswhichis thecasewhenplatform independence 
isconsidered,anissuethat willbediscussedfurtherinthe text.  3 Related Work Green[Green2007] presents 
a commercialphysics engine called Havok FX for rigid bodies and particle system that has several methods 
implemented on the GPU, obtaining results eight times fasterwith theuseof nVidiaGeForce8800GTXGPU card 
withan IntelCore2DuoExtreme2.93GHz thanapureCPU version.This justi.es the implementation of some physics 
functionalities on the GPU.Becauseof thehighperformanceof thefragmentprocessors, which allowshighparallelizationoftheproblems 
that canbesolved in this structure, it is possible to have more bodies on the physics simulation application. 
Anothercommercialengine,calledPhysX[Ageia2008],shows the concept ofPPU(PhysicsProcessorsUnit) card. Thishardware 
was developed speci.cally for the processing of physics related prob­lems like: dynamics of rigid bodies, 
collision detection and .uid dynamics. The vendor claims that this technology is capable of processing 
530 million collisions of simple geometric shapes per second. Nevertheless, one of the de.ciencies of 
the PPU is that it requires a new dedicated hardware that would only be used in the simulations of applications 
that require PhysX as the physics en­gine.ButAgeiawasrecentlyboughtbynVidiaand nowsomeofits features 
are being adapted in order to take advantage of the GPUs computationalpower. et al.2005], cloth simulation[Green2003] 
and collisiondetection [Govindarajuetal.2003]. Also, thebookGPUGems3[Nguyen 2007]hasasectiondedicatedforphysicssimulationon 
theGPU. 4 Physics Engine Loop Theproposedphysicsengine isbased onamodi.ed versionof the publicly available 
Open Dynamics Engine (ODE) [Smith 2008], version 0.8. which was originally built focusing on CPU process­ing. 
The loop of theproposedphysicsengine isresponsiblefor: Detecting collisions in two phases: a broad phase 
and a nar­rowphase;  Transforming the inertia tensor matrix of the bodies from lo­cal coordinates to 
world coordinates;  Applying thegravityforceon thebodies;  Setting all joints constraints and contacts 
between bodies as aLCP(LinearComplementaryProblem) and solving it;  Updating the forces acting in the 
bodies according to the an­swerobtainedfrom theLCP;  Forwarding the simulation step for each body by 
computing thenewpositionand velocitiesaccording totheforcesandthe time step, i.e., integrating the equations 
of motion.  All thestepsareshown in .gure1. Figure 1: The physics engine loop  5 Implementation on 
the GPU Besides the Havok FX, there are other works related to the imple-There are two types of programmable 
processors in the current mentationofphysicssimulationprocessesontheGPUlike:parti-GPUs(withoutanuni.ed 
architecture):vertexandfragmentpro­clesystem[Kipferet al.2004],deformablebodiessystem[Georgii cessors.Programsexecutedby 
avertexprocessoraredesignated as vertex shadersandprogramsexecutedby afragmentprocessorare calledfragment 
shaders. In thisworktheprogramswilluse thefragmentprocessor,which is morecommonforGPGPU applicationsfor 
twomainreasons[Har­ris2005]: .rst,inatypicalGPU cardtherearemorefragmentpro­cessors than vertex processors; 
second, the output of the fragment processorgoesdirectly tothememory,whichcanbeusedforfeed­ing the input 
of another shader. In the case of vertex processors, the output must .rst pass by the rasterizer and 
fragment processor before reaching memory. This work has implemented on GPU four steps of the simulation 
loop outlined insection4: Thebroadphaseof thecollisiondetection;  The transformationofinertia tensormatrixofthebodiesfrom 
local coordinates into world coordinates;  Theapplicationof thegravityforceon thebodies;  The simulation 
step.  The broad phase of the collision detection shader is described in subsection 5.1. The next two 
steps are performed by a shader de­scribed in subsection 5.2, while the last step is carried out by a 
shader presented in subsection 5.3. The results of the new physics loop and otheroptimizationsarepresented 
insubsection5.4. All the fragment shaders were written in the OpenGL shading lan­guage anduse an off 
screenbuffer calledframebuffer object(FBO) for rendering the results. 5.1 The Broad Phase of the Collision 
Detection Thebroadphaseof thecollisiondetection isresponsibleforcheck­ing which bodies have a chance 
to collide and for passing them to the narrow phase that will actually do the collision detection be­tween 
thebodies(i.e.,calculate thepoints,normalsanddepthsof contactbetween thebodies)[Ericson2005]. This broad 
phase can be carried out in many ways. In this paper, it uses a bounding sphere around all the bodies 
of the simulation, pre-computed when the body is created. This method receives the position p and the 
radius r as an input for a given body. Then it calculates thedistance d betweenthebodiesand checks if 
thisdis­tance ishigher than thesumof theradiusofbothbounding spheres (d>r1+r2).Ifthishappens, thebodiesdonotcollide,otherwise 
itsendsthe twobodies tothenarrowphase. Thisphasehasbeen implementedon theCPU and alsoon theGPU. In order 
to implement on the GPU it is necessary to approach the problem appropriately using textures and texels. 
This was done by using astructurewhereeachtexture linerepresentsfourbodiesand, for each body, their position 
(x,y,z) and radius r are store in a texel,asshows .gure2. This method is composed of several passes to 
make a better use of the parallel structure of the GPU. A .rst pass applies the sphere bound check on 
the .rstfourbodiesagainst allotherbodies.Then, the shader returns a texture indicating which bodies can 
actually collide and applies the narrow phase to them. Figure 3 shows an example where the .rst body 
is checked against the last four and theresultsareput ina texel. After the .rst pass, the shader performs 
another pass checking the nextfourbodiesagainsttheremaining ofthebodies(i.e. thebodies thathavenotbeencheckedyet)andgenerates 
the texture indicating whichbodiesarecandidates tocollideand sends them to thenarrow phase. The process 
continues until there are no remaining bodies. Body 1 Body 2 Body 3 Body 4  . . . Body n-3 Body n-2 
Body n-1 Body n  Figure 2: Structure of the data in the texture  Figure 3: An example of a collision 
test in the GPU This method is divided in n 4 passes on the GPU, where n is the numberofbodies in thescene.Thismethod 
werealsopresented in [Joselli etal.2008]. 5.2 Transformation of the Inertia Tensor Matrix and Computation 
of the Gravity Force Computingthe inertia tensor matrix in world coordinates is simple. Theshader takesasinputforagivenrigidbody 
a 3× 3matrix with the inertia tensor I0 ofthebodyin local coordinates(pre-computed when the body is created), 
and a quaternion q that represents the orientationofthelocal coordinatesystemofthebodyinrelation to the 
global coordinate system. These data are sent in four textures: threetexturesforeach oneofthethree linesoftheinertiatensor, 
and a texture for the quaternion. The shader, then, transforms the local inertia tensor I0 in the global 
inertia tensor I, where I = RI0 RT and R is the 3 × 3 rotation matrix corresponding to quaternion q [Eberly2005].Afterthis,itreturnstheglobalinertia 
tensorI ofthe bodyinthreetextures,oneforeachlineofthematrix,followingthe same inputformat. The importance 
of the inertia tensor is that it gives an idea of how themassof arigidbodyisdistributedinrelationto itsmasscenter. 
The same shader also receives as input the gravity g, passed as a uniform variable. This value is the 
same for all the bodies. The appliedforces F on thebody arealsosent asa texture, togetherwith the correspondingbody 
mass m. The resultantforces are computed by adding the gravity component Fg , determined according to 
the second law ofNewton(Fg = mg) and the forces applied to the body, which were sent as a texture. The 
shader returns the new appliedforcesonthebody alsoasa texture. 5.3 SimulationStep Another process that 
is implemented on the GPU is the simulation step.Thisone isresponsiblefor integratingtheequationsof motion 
of a rigidbody[Eberly2004]. The shader receives as input ten textures in which are stored the current 
state of the body at the current simulation time t (i.e., its position p,quaternion q, linear velocity 
v, and angular velocity .), the inverted mass m -1 , the global inertia tensor matrix I, the ap­plied 
forces F, and the external torque t. The shader also receives the time step .tpassedas a uniform variable. 
The shader computes thenewstate,i.e.,thenewposition,quaternion, linearvelocityand angularvelocityoftherigidbody 
atthe time t+.t,by applying a numerical integration scheme. In order to avoid sending again data from 
the CPU to the GPU, this shader uses some of the textures from the previous ones, such as the position 
of the body from the broad phase shader, and the quaternion,theinertia tensoringlobalcoordinatesandtheresultant 
force from the transformation of the inertia tensor matrix and the computationof thegravityforceshader. 
 5.4 Results and Optimizations of the New Physics Loop The numerical results from the new physics loop 
implemented in the GPU and CPU can be seen in table 1. All the tests were made in a 3500+ Athlon64 with 
2GB RAM and a nVidia 8400GS GPU card with an PCI-Express 16x socket. The time measurement was taken in 
milliseconds. Table 1: Numerical results, in milliseconds, from the new physics loop implemented on the 
GPU and CPU # Bodies CPU Time GPU time Speedup 16 0.07 0.86 0.08 64 0.25 1.46 0.17 256 2.05 4.03 0.51 
512 7.22 8.08 0.89 1024 26.95 19.92 1.35 2048 106.15 52.67 2.02 4096 430.81 160.12 2.69 8192 2883.84 
534.41 5.30 16380 4382.77 772.24 5.68 The presented results show that the GPU starts to become faster 
than theCPU whenmore than1024bodiesarepresent in thescene. Thisdemonstrates that thefastestprocessorforadetermined 
scene canchangewith thenumberofbodies.Thisfact willbeconsidered forthedesignof someof theautomaticdistributionmethods 
inthe next section. Toshowtheoptimizationoftheentireloopprocess(i.e. withthe narrowphaseof thecollisiondetectionand 
theLCP solver) by the GPU implementation, a test has been made with 2048 bodies with 2104 collisions 
between them. The following results were found: 166.74 ms for the CPU contrasting with 110.34 ms for 
the GPU. This shows a speedup of 1.51 indicates that this new physics loop is optimized onGPUforhigh 
numbers ofbodies. The bottleneck of the GPU implementation is the data transfer be­tween theCPU and theGPU.Toavoid 
that, theengine implements an internal method that, when running on the GPU mode, uploads the texture 
tothegraphiccard onlywhenthedatahasbeenchanged outside the physics loop. Also, if the simulation shows 
a situation where the physics engine loop does not have to process the LCP, such as, no joints and no 
body contacts, it does not have to down­loadtheresultsfromthe transformationoftheinertia tensormatrix 
and thecomputedforceshader.  6 Automatic Distribution between CPU and GPUforthePhysicsEngine Theprocessdistributionbetween 
theCPU andGPUforprocessing the simulation can be carried out manually by the developer or by fourdifferent 
automaticmethods that willbedescribedhere. The decision on how to distribute can be made during the appli­cation 
via a C function or even a script language, such as LUA [Ierusalimschyetal.2006]. Thework[Zamithetal.2007] 
imple­mentsa task schedulingdistributionbetweenCPU-GPU viaascript .le. The implementation of the automatic 
task distribution scheme is based on a virtual base class named Distributor, from which all the heuristics 
are derived. All methods implemented on the CPU and on the GPU have their elapsed times counted by the 
Distribu­tor class. At each frame the Distributor is asked for a decision on how to process the next 
frame. An UML with the main classes for automaticdistributing canbeseen in .gure4. Figure 4: UML of 
the automatic distribution classes The methods for automatic task distribution that are presented in 
thispaperare: starting automaticdistribution, cycle automatic distribution, starting full test automatic 
distribution and adap­tive automatic distribution. The .rst two automatic distribution modesarepresentedin[Josellietal.2008]. 
Thelast twoarenew modesbased onthe.rst twoanddevelopedfor thisphysicsengine inorder todeal with thefact 
that achangeinthenumberofbodies inascenecanchange theprocessorwhichisconsideredthefastest for that speci.c 
scene. 6.1 Starting Distribution The starting strategyforautomaticdistributionbetweenCPU and GPU is very 
simple: it computes 5 frames in the GPU mode and 5 frames in the CPU mode. With these times, it selects 
the fastest processor toprocessalltheframesoftheapplication. The reason why this method computes 5 frames 
in each processor is to avoid making a wrong decision that could happen in the case ofthescheme tocalculateonlyoneframeat 
eachprocessor.Allthe subsequent schemesspend5framesininitial testsforeachproces­sorbecauseof thesameprinciple. 
This method, in normal conditions, always selects the fastest pro­cessor without the necessity for the 
user or developer to select it. This isimportantfor thedeveloperwhodoesnotknow thehardware oftheuseroftheapplicationand 
wants tousethefastestprocessor available. Eventhoughthe starting automaticdistributionselectsthefastest 
processor, itdoesnotavoid theapplicationfrombeing sloweddown byotherprocessesofthesystem if theCPU orGPUisalready 
over­loaded with some work. Also, the simulated scene may change during the application, and with that, 
the fastest processor can no longer be the one selected from the starting automatic distribu­tion.  
6.2 Cycle Distribution The cycle distribution has the following strategy: at every 100 frames, the engine 
calculates 5 frames in the GPU mode and 5 framesmoreintheCPU mode.Withthese times,the cycle auto­maticdistributionchoosesthefastestprocessor 
tosimulatethenext 90 frames. In this case, only 5% of the frames are spent using the slowerscenarioand95% 
with thebest one. Thisscheme is idealforapplicationswhere theperformancediffer­encebetweenbothprocessors 
is low. If thedifferencebetween the processors is high, the 5% of the frames spent in the slowest mode 
canaffect theoverallperformanceof theapplication. 6.3 Starting full test Distribution The startingfulltest 
isbased onthesameprincipleasthe ´´start­ing distribution, i.e, it also does an initial test in the beginning 
of theapplicationbutthedifferenceisthatthismethoddoesafull test. Thisfulltestconsistsinthefollowing strategy: 
itstartswiththecal­culationof minBodies bodiessimulation in5frames in theGPU and 5 frames in the GPU. 
Then it saves those times and increases the number of bodies multiplying by 2, and computes 5 frames 
in each processor, and so on until the maxBodies number of bod­ies is reached. minBodies and maxBodies 
are values that the developermustprovideoruseadefaultvalue(16for minBodies and 8192 for maxBodies ). 
Based on those computed times, the simulationcandeterminewhichprocessor isfasterforadetermined scene. 
This mode always selects the fastest processor for a given scene, but it is very intensive and spends 
considerable time to be spent in thebeginning of theapplication.Thismethod canpreventchanges in thescene(numberofbodies 
in thephysicscalculation) without thenecessityof spending5% of itsframesintheslowest case.  6.4 Adaptive 
Distribution The adaptive distributionisbased onthe cycle mode.Thestrat­egyis toperforman initial test 
inwhich5framesarecomputed on theGPU and another5framesareprocessed on theCPU,and then to compute the 
next 90 frames on the fastest processor. After the execution of these 100 frames, the adaptive distribution 
starts to check every frame if the number of bodies has changed more than apercentage p since the initial 
test.When thishappens, itdoes the initial test again to check which processor is faster for the current 
number of bodies and after the 100 frames it restarts to check the number ofbodies again. Becauseof 
thecharacteristicsoftheprocessors(from table2 can beseen that theCPU isfasterforsmallernumberofbodiesand 
the GPUisfasterforahighernumberofbodies),thismode tries tode­tectwhen thenumberofbodies increases(aboveacertainpercent­age 
p)if it is running on the CPU and when the number of bodies decreases(below thespeci.edpercentage p)if 
it is runningon the GPU.The value of p mustbeprovidedby thedeveloper,otherwise adefaultvalueof20% isused. 
This mode in the best-case scenario behaves like the starting modeandintheworst casebehaves likethe cycle 
.So,thismode is able to select the fastest processor for the physics simulation without the necessity 
of spending 5% of its frames in the slowest scenario(inthebestcase) and withoutspending considerable 
time withanextensive test onprocessors. 6.5 Results Obtained for each Distribution Mode Theresultsobtained 
of all thedistributionmodes: onlyCPU(col­umn 2), only GPU (column 3), starting automatic distribution 
(column4), the cycle automaticdistribution(column5), start­ingfull test automaticdistribution(column6),and 
adaptive au­tomaticdistribution, in100framesof theapplication,forscenes in which the number of bodies 
does not change over time, are shown in table2. From these results it can be seen that the starting distribution 
al­ways behaves like the best case for scenes with a constant number of bodies. If during the simulation 
a number of new bodies are created or old ones are removed from scene being simulated, the method does 
not offer a real-time distribution between the proces­sorsand may notbehave likethebest case. The results 
show that the cycle distribution behaves like almost the best case when the difference of the processing 
time between theCPU andGPU implementations is low(between512 and1024 bodies); in the others cases the 
5% spent in the slower processor affects theoverallperformanceof theapplication. Theseresultsalsoshowthatthe 
´´startingfulltest distributionand the adaptive distribution, for scenes with a constant number of bodies 
over time, behave like the best case. Other tests were made withthese twodistributions(withthedefaultvalues) 
inwhichthe numberofbodiesinthescenechangesover time.Theresultswere as expected, i.e., the starting full 
test and the adaptive modes behave like the best case; with a signi.cant change in the number ofbodiesthe 
adaptive modebehaves likethe cycle distribution. The initial test of the starting full test takes about 
2 minutes to beconcludedinthesame testedhardware.Theuseofthisstrategy, every time a game or simulation 
runs, may be prohibitive if the loading time of the application is also considered. To avoid this drawback 
the proposed physics engine has an option to save these test valuestobeusedinthenext timethegameorsimulationstarts. 
Other testsoftheautomaticdistributionmodesarepresentedinthe next section with the multithread architecture 
for the physics en­gine.  7 A Multithread Architecture for the Physics Engine For real time simulation 
of rigid bodies, the simplest architecture foragame loop[Valenteetal.2005] isasequential executionas 
canbeseen in .gure5. Theexecutionof thephysicsengineonaGPU(withoutusing an uni.ed architecture) requires 
the creation of a window in order to Table 2: A numerical result, in milliseconds, of a cycle of 100 
frames comparing results with 6 methods: only CPU, only GPU, starting automatic distribution, the cycle 
automatic distribution, starting full test automatic distribution and adaptive automatic distribution 
# Bodies CPU GPU Starting Cycle Stating full test Adaptive 16 7 9 7 8 7 7 64 25 146 25 37 25 25 256 
205 403 205 212 205 205 512 722 808 722 729 722 722 1024 2695 1992 1992 1998 1992 1992 2048 10615 5267 
5267 5599 5267 5267 4096 43081 16012 16012 17285 16012 16012 8192 288384 53441 53441 64924 53441 53441 
16380 438277 77224 77224 248660 77224 77224  Figure 5: Single coupled loop process the data. In this 
case, the window that is used for render­ing can also be used for processing data in a traditional GPGPU 
architecture. Themainproblemwith thisapproachis that thephysicsenginewill onlywork withanapplication 
that usesOpenGLAPIfor therender­ingprocess,since thephysicsengineuses theGLSL anditneedsan OpenGL swindow.So 
itwouldnotwork withaDirectXgraphic s application. Anotherproblem is thateven if theapplication isrun­ning 
on OpenGL, the program must save the state of the rendering before moving to the GPGPU computation. After 
.nishing, more data transfer will be necessary, in order to take rendering informa­tion back. To avoid 
these problems, this work uses a multithread architecture. This multithread architecture is composed 
by one thread for read­ing the input loop and executing the rendering computations and anotheronefor 
thephysicsengine loop,ascanbeseen in .gure6. In order to validate the proposed architecture, the physics 
engine was executed in six modes: in the CPU, in the GPU, in the start­ing automatic distribution, in 
the cycle automatic distribution, in the starting full test distribution and in the adaptive distri­bution. 
An academicgameframework[Valente2005] was adopted for the input handling and rendering process. The physics 
engine loop was executed every 25 milliseconds. The main loop thread is updated as fast as possible, 
waiting for the result of the physics loop engine thread after every 25 milliseconds, as can be seen 
on .gure 7. If an input causes changes in the physics behavior, such as theapplicationofforces, impulsesand 
torques,theinputhandle saves thosechangesand sends them in thebeginning of thephysics engine loop.  
Figure 6: Multithread architecture with physics engine loop un­coupled from the main loop The numerical 
results in frame per seconds of this multithread ar­chitecture with physics engine loop uncoupled from 
the main loop canbeseenin table3,consideringthe testswiththeCPU,GPU and the schemesfor automaticdistributionsbetweenCPU 
andGPU. Thepresented resultsshow thatforasmallnumberof rigidbodies the CPU behaves better than the GPU, 
but with no relevant dif­ference since the refresh rate of a monitor is usually 60 Hz. How­ever,withahugeamount 
of rigidbodies, theGPU approachyielded muchbetter results. Itisalsopossible toseein table3thattheframerateoftheapplica­tion 
behaves like the best case in the starting , starting full test and adaptive automatic distributions 
between CPU-GPU. In ad­dition,inthe cycle automaticmodetheframeratebehavesalmost like thebest case. Others 
tests were made with this physics engine with the architec­tureand with theautomaticdistribution indifferenthardwarespec­i.cations 
in order to test the behavior of the automatic distribution methods in different hardware. They were 
tested in the minimum hardware toruntheGPGPUpartofthephysicsengine(annVidia Geeforce6200TC), with a more 
modernGPU card withSLI(Scal­ableLinkInterface) technology(adual nVidiaGeeforce8800GTS) and with dual-core 
andquad-core CPUs, always having similar re­sultsas theonespresented in thiswork. 8 Conclusions The 
importance of taking some of the physics calculation to the GPU is based on two main reasons: .rst, it 
is possible to take out someofthetypicalCPU computation,soitcanprocessother tasks. Second, it is possible 
to optimize the physics engine in order to support morerigidbodies in thesimulation. Table 3: Time measurement 
of the proposed architecture, in FPS, for the tests with the CPU, GPU and the schemes for automatic distributions 
between CPU and GPU # Bodies CPU GPU Starting Cycle Startingfull test Adaptive 16 2600 2450 2600 
2500 2600 2600 64 1990 1870 1990 1950 1990 1990 256 950 850 950 903 905 905 512 480 432 480 455 480 480 
1024 54 60 60 58 60 60 2048 13 38 38 30 38 38 4096 2 16 16 11 16 16 T = 0 ms Figure 7: The synchronism 
of the threads This paper has successfully performed the .rst one by implement­ing a new physics engine 
loop that can distribute some of its pro­cessing between the GPU and CPU, allowing the developer or an 
automatic mode to decide where to process the physics computa­tions. This paper has also ful.lled the 
second step by presenting three methods of physics engine implemented on GPU with good performancefor 
ahigher number ofbodies. Thisphysicsenginehasbeen testedwith twoautomaticschemesfor the distribution 
of processes of the physics engine between CPU and GPU named starting mode and cycle mode. It has pre­sented 
twonewstrategies,based onthe last two,forautomaticdis­tributionbetweenCPU andGPUforthephysicsengine:a 
starting full test and an adaptive mode. The importance of the automatic mode like the starting or start­ing 
full test is that it can select the fastest processor without the necessity of the user or developer 
to determine it. Another advan­tage of using an automatic distribution mode like the starting full test 
, the adaptive and the cycle is that it can also prevent er­roneous process allocation because of changes 
in the number of bodiesinthescene.Also,anautomaticdistribution likethe cycle canavoidslowdowns in thesimulationbecauseof 
other tasksofthe game or the system by taking part of the load from the overloaded processor. Itisimportant 
toemphasizesthateventhoughtthoseautomaticdis­tribution methods were tested with a physics engine that 
uses the pixel processors to process its GPGPU data, they could be used with an uni.ed architecture and 
with others GPGPU applications (that have the implementation in both the CPUand GPU) without any major 
changes. This paper also presents and discusses a multithread architecture where the loop of the physics 
engine is uncoupled from the main loop. References AGEIA, 2008. Physx. Avalible at: http://www.ageia.com. 
20/02/2008. ANDERSON, A., III, W. G., AND SCHR¨ ODER, P. 2007. Quantum monte carlo on graphical processing 
units. Computer Physics Communications 177(3). EBERLY, D. H. 2004. Game Physics. MorganKaufmann. EBERLY, 
D. 2005. 3D Game Engine Architecture -Engineeering Real-Time Aplications with Wild Magic. MorganKaufmann. 
ERICSON, C. 2005. Real-Time Collision Detection. MorganKauf­mann. GEORGII, J., ECHTLER, F., AND WESTERMANN, 
R. 2005. Inter­active simulation of deformable bodies on gpu. In Proceedings of Simulation and Visualization 
2005,247 258. GOVINDARAJU, K. N., REDON, S., LIN, M. C., AND MANOCHA,D.2003.CULLIDE: interactivecollisiondetection 
between complex models in large environments using graphics hardware. In Graphics Hardware 2003,25 32. 
GREEN, S., 2003. NVIDIA cloth sample. Available at: http://download.developer.nvidia.com/ developer/SDK/Individual 
Samples/ samples.html#glsl physics. 03/12/2007.  GREEN, S.,2007. Gpgpuphysics. Siggraph07GPGPUTutorial. 
HARRIS, M. 2005. Mapping computational concepts to gpus. M. Pharr(Ed.), GPU Gems (2), Addison-Wesley, 
Boston, USA,493 508. IERUSALIMSCHY, R., DE FIGUEIREDO, L. H., AND CELES, W. 2006. Lua 5.1 Reference 
Manual. Lua.org. JOSELLI, M., VALENTE, L., ZAMITH, M., CLUA, E., MON-TENEGRO, A., , CONCI, A., FEIJO´, 
B., D ORNELLAS, M., POZZER, C., AND LEAL-TOLEDO, R. 2008. Automatic dy­namic task distribution between 
cpu and gpu for real-time sys­tems. 11th IEEE International Conference on Computational Science and Engineering. 
To appear. KIPFER, P., SEGAL, M., AND WESTERMANN, R. 2004. Uber­.ow: agpu-basedparticleengine. In Graphics 
Hardware 2004, 115 122. MULLER, C., STRENGERT, M., AND ERTL, T. 2007. Adaptive loadbalancingfor raycasting 
of non-uniformlybricked volumes. Parallel Computing 33(6),406 419. NGUYEN, H. 2007. GPU Gems 3 -Programming 
Techniques for High-performance Graphics and General-Purpose Compu­tation. Addison-Wesley. OWENS, J. 
D., LEUBKE, D., GOVINDARAJU, N., HARRIS, M., KR¨ UGER, J., LEFOHN, A. E., AND PURCELL, T. J. 2007. A 
survey of general-purpose computation on graphics hardware. Computer Graphics Forum 26(1),80 113. ´´ 
´ ment shaders for agent animation using .nite state machines. Simulation Modelling Practice and Theory 
13(8),741 751. RUDOMYN, T., MILLAN, E., AND HERNANDEZ, B. 2005. Frag- SMITH, R., 2008. Open dynamics 
engine. Available at: http://www.ODE.org/. 20/02/2008. VALENTE,L.,CONCI,A., AND FEIJO´,B. 2005. Real 
timegame loop models for single-player computer games. In Proceedings of the IV Brazilian Symposium on 
Computer Games and Digital Entertainment,89 99. VALENTE, L. 2005. Guff: um framework para desenvolvimento 
de jogos. Master s thesis, Universidade Federal Fluminense. In Portuguese. ZAMITH, M., CLUA, E., PAGLIOSA, 
P., CONCI, A., MONTENE-GRO, A., AND VALENTE, L. 2007. The gpu used as a math co-processor in real time 
applications. Proceedings of the VI Brazilian Symposium on Computer Games and Digital Enter­tainment,37 
43.  
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
	</article_rec>
	</section>
	<section>
		<section_id>1401872</section_id>
		<sort_key>290</sort_key>
		<section_seq_no>7</section_seq_no>
		<section_type>SESSION</section_type>
		<section_title><![CDATA[3-D and cinematography]]></section_title>
		<section_page_from>157</section_page_from>
	<article_rec>
		<article_id>1401873</article_id>
		<sort_key>300</sort_key>
		<display_label>Pages</display_label>
		<pages>6</pages>
		<article_publication_date>08-09-2008</article_publication_date>
		<seq_no>1</seq_no>
		<title><![CDATA[Effect of dynamic camera control on spatial reasoning in 3D spaces]]></title>
		<page_from>157</page_from>
		<page_to>162</page_to>
		<doi_number>10.1145/1401843.1401873</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1401873</url>
		<abstract>
			<par><![CDATA[<p>Game worlds have to be presented to players via some form of visualization to be accessible. Consequently, there is a direct dependency between the virtual game world and this form of presentation. But how does the camera work affect our understanding of the game space? We implemented a dynamic camera system that procedurally switches camera styles depending on the type of region the player is in. We then tested to what degree this camera behavior affects the players' understanding of the game world and its zoning in comparison with a control group playing the same zoned environment with a default camera. In both cases, recognition of the zones was lower than expected but our results show that after an initial learning phase the recognition was significantly faster when the dynamic camera system was active. Players also appeared to be less "lost" in the game world. The results validate the role of the camera in virtual spaces and suggest a stronger role for visualization strategies in 3D game worlds.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[cinematography]]></kw>
			<kw><![CDATA[interactive camera]]></kw>
			<kw><![CDATA[procedural space]]></kw>
			<kw><![CDATA[video game]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node/>
				<descriptor/>
				<type/>
			</primary_category>
		</categories>
		<authors>
			<au>
				<person_id>P1100761</person_id>
				<author_profile_id><![CDATA[81421602178]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Ogechi]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Nnadi]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Georgia Institute of Technology]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1100762</person_id>
				<author_profile_id><![CDATA[81365593753]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Ute]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Fischer]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Georgia Institute of Technology]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1100763</person_id>
				<author_profile_id><![CDATA[81365590886]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>3</seq_no>
				<first_name><![CDATA[Michael]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Boyce]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Georgia Institute of Technology]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1100764</person_id>
				<author_profile_id><![CDATA[81318491041]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>4</seq_no>
				<first_name><![CDATA[Michael]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Nitsche]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[Georgia Institute of Technology]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Aarseth, Espen. Genre Trouble. In N. Wardrip-Fruin &amp; P. Harrigan (eds.), <i>First person: New media as story, performance and game.</i> MIT Press, Cambridge, MA, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Atkins, Barry What Are We Really Looking At? The Future-Orientation of Video Game Play, <i>Games and Culture</i> 1, no. 2 (2006) 127--40.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Block, Bruce <i>The Visual Story: Seeing the Structure of Film, Tv, and New Media.</i> Focal Press, Boston et al., 2001.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[
<i>Crouching Tiger, Hidden Dragon.</i> Dir. Ang Lee. Asia Union Film &amp; Entertainment Ltd. 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Calderon, C., Worley, N. and Nyman, K. Spatial Cinematic Mediation in Real-Time Architectural Walkthroughs. ITcon, 11 <i>Architectural informatics</i> (special issue). (2006) 343--360.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>199428</ref_obj_id>
				<ref_obj_pid>199404</ref_obj_pid>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Drucker, Steven M. and Zeltzer, D. CamDroid: a System for Implementing Intelligent Camera Control, <i>Proceedings of the 1995 Symposium on Interactive 3D Graphics 1995.</i> ACM, New York. 139--144.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>291101</ref_obj_id>
				<ref_obj_pid>291080</ref_obj_pid>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Bares, William H. and Lester, James C. Intelligent Multi-shot Visualization Interfaces for Dynamic 3D Worlds, <i>Proceedings of the 1999 International Conference on Intelligent User Interfaces</i>, 1999. ACM, New York. 119--126]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>237259</ref_obj_id>
				<ref_obj_pid>237170</ref_obj_pid>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[He, Li-wei, Cohen, Michael F., Salesin, David H. The Virtual Cinematographer, <i>Proceedings of the 23rd annual conference on Computer Graphics and Interactive Techniques</i>, 1996, ACM, New York. 217--224.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Krzywinska, TANYA. "Hands-on Horror." in <i>Screenplay. Cinema/ Videogames/ Interfaces</i>, ed. by Geoff King and Tanja Krzywinska, Wallflower Press, London, 2002. 206--225.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>863217</ref_obj_id>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Meadows, Mark S. <i>Pause &amp; Effect. The Art of Interactive Narrative.</i> New Riders, Indianapolis, 2002.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Nitsche, M. Games, Montage, and the First Person Point of View <i>DiGRA 2005 Conference Proceedings: Changing Views - Worlds of Play.</i> (Vancouver, CAN June 16--20, 2005) DiGRA, Vancouver. 29--36.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Nitsche, M. / Ashmore, C. / Hankinson, W. / Fitzpatrick, R./ Kelly, J. and Margenau, K. 'Designing Procedural Game Spaces: A Case Study' in: <i>Proceedings of FuturePlay</i> 2006 (London, Ontario October 10--12, 2006) (digital proceedings)]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>964453</ref_obj_id>
				<ref_obj_pid>964442</ref_obj_pid>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Steiner, K. E. and Tomkins, J. 2004. Narrative Event Adaptation in Virtual Environments. <i>Proceedings of the 9th international Conference on Intelligent User Interfaces</i> (Funchal, Madeira, Portugal, January 13-16, 2004). IUI '04. ACM, New York. 46--53.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>337513</ref_obj_id>
				<ref_obj_pid>336595</ref_obj_pid>
				<ref_seq_no>14</ref_seq_no>
				<ref_text><![CDATA[Tomlinson, B., Blumberg, B., and Nain, D. Expressive Autonomous Cinematography for Interactive Virtual Environments. <i>Proceedings of the Fourth International Conference on Autonomous Agents</i> (Barcelona, ESP June 2000), ACM, New York. 317--324.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>604108</ref_obj_id>
				<ref_obj_pid>604045</ref_obj_pid>
				<ref_seq_no>15</ref_seq_no>
				<ref_text><![CDATA[Young, R. M. and Riedl, M. 2003. Towards an architecture for intelligent control of narrative in interactive virtual worlds. In Proceedings of the 8th international Conference on intelligent User interfaces (Miami, Florida, USA, January 12--15, 2003). IUI '03. ACM, New York, NY, 310--312.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Effect of Dynamic Camera Control on Spatial Reasoning in 3D Spaces Ogechi Nnadi * CoC Georgia Institute 
of Technology ABSTRACT Game worlds have to be presented to players via some form of visualization to 
be accessible. Consequently, there is a direct dependency between the virtual game world and this form 
of presentation. But how does the camera work affect our understanding of the game space? We implemented 
a dynamic camera system that procedurally switches camera styles depending on the type of region the 
player is in. We then tested to what degree this camera behavior affects the players understanding of 
the game world and its zoning in comparison with a control group playing the same zoned environment with 
a default camera. In both cases, recognition of the zones was lower than expected but our results show 
that after an initial learning phase the recognition was significantly faster when the dynamic camera 
system was active. Players also appeared to be less lost in the game world. The results validate the 
role of the camera in virtual spaces and suggest a stronger role for visualization strategies in 3D game 
worlds.  Keywords cinematography, interactive camera, procedural space, video game 1. BACKGROUND Cameras 
in video games are often used to convey a certain mood or atmosphere. Intuitively, we believe this to 
be true based on our experience with other moving image media where cinematographers use the camera to 
elicit, for example, tension of a situation, intimacy between characters, or a character s personal feelings 
such as vertigo. In video games, this task of the camera as an emotional agent has to be carefully balanced 
with their functional value to present a playable game level. We believe that in interactive 3D games 
the camera provides the game designer with an extra channel for conveying spatial information to a player. 
We argue that a dynamic camera behavior can add an additional layer to the gameplay as it affects the 
perception of the 3D game space and allows to re-position the player in relation to it. The goal of the 
present study was to investigate this influence of a dynamic camera on the player s perception of a 3D 
game * email: ogechi.nnadi@gatech.edu email: ute.fischer@gatech.edu email: mboyce@gatech.edu # email: 
michael.nitsche@lcc.gatech.edu Copyright &#38;#169; 2008 by the Association for Computing Machinery, 
Inc. Permission to make digital or hard copies of part or all of this work for personal or classroom 
use is granted without fee provided that copies are not made or distributed for commercial advantage 
and that copies bear this notice and the full citation on the first page. Copyrights for components of 
this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, 
to republish, to post on servers, or to redistribute to lists, requires prior specific permission and/or 
a fee. Request permissions from Permissions Dept, ACM Inc., fax +1 (212) 869-0481 or e-mail permissions@acm.org. 
Sandbox Symposium 2008, Los Angeles, California, August 9 10, 2008. &#38;#169; 2008 ACM 978-1-60558-173-6/08/0008 
$5.00 Ute Fischer , Michael Boyce , Michael Nitsche # LCC Georgia Institute of Technology world. Current 
research into the use of camera work in video games tends to focus on the camera as an Artificial Intelligence-driven 
system that computes different perspectives based on given parameters that usually copy existing cinematic 
traditions such as shot-reverse-shot patterns and live TV broadcasting styles. Instead of focusing on 
the value (or lack thereof) of cinematic conventions, our hypothesis is more basic. We argue that dynamic 
camera behavior can affect a player's understanding of a virtual space. Our claim is that a dynamic camera 
behavior facilitates the way we understand a given virtual space. More precisely, we argue that dynamic 
visualization can assist players to distinguish definite areas in the game space and thus increases their 
ability to recognize zones within a larger virtual environment. In our experiments, we examined players' 
detection of different spatial zones to track how their spatial comprehension of the 3D environments 
was influenced by the camera's behavior. Since many modern video games take place in elaborate 3D environments 
that require constant re-assessment of the current situation this set up is relevant for numerous game 
titles. Virtual environments demand the gradual assembly of visual components into rather complex cognitive 
maps. If one can prove the importance of the camera in our understanding of game spaces, the results 
would also have implications for research in the area of wayfinding and navigation in virtual environments. 
 2. RELATED WORK A number of projects have been implemented to experiment with dynamic camera behavior. 
Although our approach does not directly suggest a new camera AI method but concentrates more on the role 
of the camera for the player s comprehension, these projects serve as references for our own implementation 
of the test environment. 2.1 Camera Control in Virtual Worlds A first tier of research focuses on AI-driven 
camera behavior and how it might relate to existing cinematic traditions. Drucker implemented a methodology 
of camera encapsulation modules, CamDroid, in order to achieve task level interaction within the virtual 
space. Each module is assembled with four primary components: a local state vector, an initializer, controller, 
and a series of constraints which are drawn from traditional cinematography. The modules are incorporated 
into a camera framework which includes an interpreter allowing low level manipulation and creation of 
virtual prototypes, along with a renderer and object database [Drucker/ Zeltzer 1995]. The result is 
a gradual simulation of existing cinematic techniques into an AI system. Building on Drucker s concepts, 
Tomlinson designed an autonomous cinematography architecture for interactive environments. The architecture 
divides shots into elements, with an emphasis on cinematic characteristic i.e. camera focus or camera 
angle. It uses hierarchical cross-exclusion groupings to prioritize elements. The CameraCreature, an 
autonomous actor drives the visualization in the virtual world. It drives the camera behavior and other 
visual elements based on the environmental emotional state. As an example, the sky color is modified 
based on the mood of the character [Tomlinson/ Blumberg/ Nain 2000]. Bares focuses on constraint control 
within the virtual environment. The ConstraintCam, a visualization interface device for virtual environments, 
manages constraint decision making based on desired visual goal states. Techniques such as picture in 
picture permit simultaneous multi-shot visibility [Bares/ Lester 1999]. He suggests to automatically 
generate camera specifications through a series of finite state machines called Idioms, which correspond 
to a type of scene. Using cinematographic heuristics the system chooses the best shot for the scene. 
The overall framework called Virtual Cinematographer also provides occlusion detection and actor-centered 
camera transitioning [He/ Cohen/ Salesin 1996]. A second tier of research might be characterized as more 
interested in the narrative tasks of a dynamic camera system. For example, Steiner focuses on story coherence 
versus user control. By developing a platform for managing and presenting narratives in virtual environments, 
a sense of balance can be upheld. The platform is divided into sections: world management states, story 
management states, and player management states. Camera positioning serves as one factor in these states 
[Steiner/ Tomkins 2004]. Young s research creates an architecture for building intelligent narrative 
environments. The Mimesis system is a suite of control tools used with Unreal Tournament. Completing 
successful implementation of sentinel threads, it allows for enhanced temporal events such as simultaneously 
occurring events. In addition the system allows for derivations from the traditional storyline, aiming 
to deliver dynamic experiences to the individual user [Young/ Riedl 2003]. Finally, a third research 
tier is interested in the intersection of spatial positioning and representation in dynamic camera systems. 
Nitsche combines play elements and visual representation through interactive montage. Placing specific 
emphasis on spatial reinforcement, he explains how adherence or derivation from traditional cinematic 
techniques can affect the reinforcement of the entire environment. Player-character positioning serves 
as one of the most dominating references in each individual shot [Nitsche 2005]. Calderon et al. investigate 
a dynamic system for camera positioning optimized for architectural representations of virtual spaces. 
Their goal is to designate specific camera work to show certain architectural structures in a form of 
spatially mediated cinematography [Calderon/ Worley/ Nyman 2006]. This presentation, then, should improve 
the perception of the given architectural design. Our own system is less focused on a dramatization or 
narrative impact (as described in the second tier). Instead, as will be outlined below, it combines the 
spatial approach with a reference to existing cinematic traditions.   2.2 Game Cameras There is a notable 
body of work analyzing camera control in video games that is far too rich to be covered here. In contrast 
to the more general principles mentioned above, many approaches in Game Studies present analytical matrixes 
for the predominant camera style used in a specific video game title. However, some researchers have 
suggested wider approaches. As our experiment focuses on spatial recognition in combination with camera 
work we will refer only to a selected few publications that deal with the question of space and camera 
use. [Jensen 2001] and [Meadows 2002], while concerned with virtual environments in general, provide 
some discussion of how games create the illusion of a virtual space through the use of perspective drawing 
of the image. The construction of a spatial effect from a 2D image is traced back to visual expressions 
such as perspective rendering, colors, and shapes. These expressions, furthermore, can provide the basis 
for a kind of visual story [Block 2001] operating on the level of the image. Wolf applies film specific 
methods in his analysis of how game spaces are created in commercial video games [Wolf 2001]. His approach 
is insofar of relevance for our project as he looks at the way in which video games use cinematic elements 
such as on- and off-screen space and moving cameras to generate the experience of a specific virtual 
space. Although 3D navigable space is only one category in his analysis, his approach provides valuable 
insight into the use of virtual cameras for the visual creation of game environments. Numerous publications 
address the use of the virtual camera in specific games and detail how it contributes to a shaping of 
the virtual environment at hand. For example, Krzywinska offers interesting perspectives on a useful 
limitation of spatial access [Krzywinska 2002]. In her work she combines spatial analysis with the visual 
aesthetics of horror movies to show how they jointly provide for a mix of choice and determinism. The 
necessary balance between game functionality and cinematic presentation of the events is still being 
debated. Exactly how much attention should we spend on the cinematic elements versus the functional gameplay 
mechanics? Aarseth has identified a genre trouble in this discussion [Aarseth 2004] that Atkins tried 
to address [Atkins 2006] by pointing toward a future­oriented gaze of players. According to Atkins, players 
understand a video game image in terms of its potential for future interactions. This orientation of 
players towards possible interactions afforded by the depicted space is unlike the way film audiences 
read movie imagery. While such an interaction-based orientation in game design differs from a film approach, 
all means of cinematic imagery can still be applied. Images function as pointers to interactive options 
in the game space ahead. Our prototype did not include spatial changes in the gameplay as identified 
by Krzywinska or alluded by Atkins. While we acknowledge that such a combination would likely enhance 
the perception of structure in a game space, we deliberately excluded most interactive options except 
for navigation to concentrate on players spatial reasoning based on pure visual (camera) behavior. 3. 
APPROACH Our research focuses on the issue of how players read a game space in dependency to the active 
virtual camera work. If a game s camera work affects the way a player perceives and reads the game world, 
then we should be able to trace this effect in the perception of the 3D game space. 3.1 Charbitat To 
explore our research question, our project builds on the technology developed for an earlier experimental 
game project, Charbitat, which dealt with multiple aspects of procedurally generated game worlds [Nitsche 
et al. 2006]. The background story in Charbitat is that the game s hero, a Chinese princess has been 
poisoned and has fallen into a deep sleep. In her dreams, she explores the dream world of Charbitat. 
This dream world is generated as the player moves through it and thus provides a potentially infinite 
procedurally-generated 3D-environment. The underlying design for this game world encapsulates the heroine 
s poisoned condition as it mirrors the turmoil of her elemental balance. Charbitat uses a reference to 
the five Taoist elements of Wood, Fire, Earth, Metal, and Water that are believed to be defining forces 
not only for physical but also for psychological states. All objects, regions, and Non-Player-Characters 
(NPC) are defined by their elemental base values. That means that certain regions will always differ 
in terrain shape and object population from others. The same five elements are used as the necessary 
seed values to drive further space generation. Whenever a player defeats a poisoned elemental NPC, the 
values adjust, the underlying seed values change, and the next world generation will react to that. In 
that way, players drive the world generation through their in-world interactions and thus co-define the 
development of the overall virtual playground. In order to succeed in the game, one has to actively shape 
the game environment to reach specialized areas and cure the poisoned elements. To structure the player 
s progress, Charbitat includes procedurally generated key-and-lock puzzles, which provide further challenges 
to the game. Figure 1: Charbitat world seen from the default camera position 3D game environment, objects 
and NPCs within this world, and conditional quest settings are all generated procedurally. For our investigation 
we decided to use this generative basis and extend it to the use of cameras inside the game world. 3.2 
Charbitat Camera The approach we chose to examine our hypothesis was to design two separate camera environments. 
Both use a version of the Charbitat world but were set up very differently in terms of their visualization 
strategies. One uses a following camera (see fig. 1), which had been used in previous iterations of the 
game prototype and resembles a de facto game camera convention that is not tied to the virtual space 
but to the central character. The other setup included a new form of camera system, wherein the camera 
adjusts to different perspectives dependent on the particular element that dominates the region of the 
game world the player navigates in. What cameras to assign to which elemental value was an almost arbitrary 
decision. Although each camera points back to a specific element, the artistic representation of this 
element can take on many different manifestations. The overall game world has an Asian theme: the heroine 
is a Chinese princess, the only lettering used in-game is Chinese, and most importantly, the basis for 
the world generation derives from the five elements of Taoism. For this reason we turned to Ang Lee's 
film, Crouching Tiger, Hidden Dragon (cinematography by Peter Pau) [Lee 2000] to select the elemental 
camera positions. Lee s film stands in the tradition of the Eastern action movie but it is also accessible 
and well known in the West. Its wide-spread appeal and success made it a useful model to follow in our 
use of cameras. The selection of camera perspective remained subjective but informed by existing cinematic 
references. Our project does not intend to promote a single camera technique; instead, its aim was to 
investigate how players understand the virtual game environment based on camera changes. While the actual 
camera shots themselves were not the focus, they had to provide for sufficient visual differences in 
order to generate sufficient change in the presentation. For example in the Crouching Tiger, Hidden Dragon 
sequences that carried references to Earth, elements appear to use high elevation and far distance with 
the camera angled slightly downward. The earth is seen as a vast landscape, stretching into the distance, 
and open for exploration. We replicated this positioning for our own earth camera. In a similar vein, 
the other cameras had their distinct combinations of distance, angle, and height, corresponding to the 
element that was referenced. In the experimental setup, these cameras were activated whenever a player 
enters a region dominated by the specific elemental value. For instance, if a player moved from a Metal-dominated 
region to a Wood-dominated one, the camera position would change from a metal camera to a wood camera, 
as indicated in fig. 2.  4. TECHNICAL IMPLEMENTATION Our prototype system was implemented as a modification 
to the Unreal Tournament 2004 mod, Charbitat. The 3D world used during the testing was divided up into 
a 5x5 grid of square regions. Each region had a particular element associated with it. As outlined, there 
were 5 elements in the game (Water, Wood, Fire, Earth, Metal) that served as underlying seed values for 
tile generation and affected terrain structuring and object selection in the individual tile. As a result 
the mix of different flora, fauna and terrain differed in each of the tiles depending on the dominating 
element for this zone. The dominating elemental value of each tile defined the overall appearance of 
this zone inside the game world and differentiated it from the neighboring zones. A Fire region, for 
instance, included different objects than a Metal region. In practice, most tiles were mixed environments 
but the dominant element defined most of the visual cues. Our experimental modifications added to this 
design the dynamic camera position seen in fig. 2. Whenever the player stepped into a region, the camera 
gradually transitioned into the perspective for the  Figure 2:Charbitat camera shots and the shots from 
Crouching Tiger, Hidden Dragon that inspired them corresponding element. These transitions took about 
5 seconds to complete. For our experiment, we installed the modification of Charbitat on two computers 
and recruited 27 student volunteers (undergraduate and graduate) to play the game. We had each student 
play Charbitat for about 10 minutes. They were told to explore the Charbitat world and to press a button 
whenever they felt they were in a new region, i.e. a zone with a different element. This instruction 
directed the player to concentrate on the depicted space and to notice differences in the various locations; 
rather than steering his or her attention to reading the camera s visualization which would have distorted 
the results. For this experiment we pre-generated a single world of Charbitat so that the regions north, 
east, west, or south of any region had different elements. This way we included enough variety in the 
tested game world and made sure that all participants experienced the same world structure. Study participants 
were randomly assigned to the experimental or the control group. The experimental group played the game 
with the dynamic camera system at work. The control group played exactly the same game environment but 
instead of the elemental cameras they used a neutral and continuous following camera whose behavior did 
not change during gameplay. Thus, the control group had to distinguish between different regions solely 
based on the different objects and terrain shapes. Both groups of players were informed that there were 
different zones in the virtual game space and asked to identify the different regions inside the game 
environment. They had to press a button on the keyboard whenever they thought they had entered a new 
zone within the overall game space. If, as we hypothesized, the camera affected how players understood 
the game space, then changes of the element-camera, which were triggered whenever players entered a different 
elemental zone, should support their spatial identification. Specifically, players in the experimental 
group were expected to be faster and more accurate in identifying the spatial zones of the game world 
than players in the control group. Our system registered players button presses in addition to tracking 
and time­stamping the movements of their avatars inside the game word. We were thus able to detect when 
and where players crossed into another region, and more importantly, we could determine whether this 
moment coincided with players realization of the new location; i.e., whether this moment was accompanied 
by players pressing the designated change-zone key. After the game each participant filled out a questionnaire 
regarding their play experience.  5. RESULTS There were 13 study participants in the experimental group 
who played the game with cameras focusing on region elements, and 14 participants in the control group 
for whom camera perspective remained neutral throughout the game. An alpha level of .05 was used for 
all statistical tests. Significance testing involved Analysis of Variance with game condition (control 
versus experimental) as independent variable, or when the assumption of normality was violated, the two­sample 
Kolmogorov-Smirnov (K-S) Test. Control and experimental subjects did not differ significantly in terms 
of the distance their avatar traveled in space (MControl = 162,620 units; MExperimental = 137,660 units; 
F(1,25) = 2.13; p = .157.); however, significant differences were observed with respect to the number 
of region crossings by their avatars. Avatars of experimental subjects had on average 36.39 zone crossings, 
10 crossings fewer than avatars of control subjects (MControl = 46.64; F(1,25) = 4.821, p = .038). 5.1 
Ease of Zone Recognition To determine whether a dynamic camera system focusing on zone-specific elements 
faciliates players orientation in a game world, we compared the zone recognition times for control and 
experimental participants. Zone recognition time measured the time difference between a player s avatar 
entering a new game region and the player recognizing that the avatar had crossed into a new zone. If 
elemental cameras support player orientation, then zone recognition times should be shorter for particiapants 
in the experimental group than for those in the control group. Figure 3: Average time participants in 
experimental and  Data screening revealed that all study participants took significantly longer to recognize 
a new game region at the start of the game than later on (K-S Z(27) = 2.112; p = .000, 2-tailed)1. Specifically, 
the first time participants indicated they had crossed into a new zone occurred after a considerably 
longer delay compared to the average time it took them to identify subsequent zone crossings (MRecognition 
Time Initial = 2,228; MRecognition Time Subsequent = 125.71). These finding suggests that participants 
first response times may be conflated, reflecting both familiarization with the game environment and 
recognition of a change in game region. Subsequent responses, in contrast, seem to reflect participants 
 true recognition of a change in region. Moreover as shown in Fig. 3, while control and experimental 
subjects did not differ significantly in their initial recognition times (K-S Z(27) = .599; p = .865, 
2-tailed), experimental subjects were considerably faster than control subjects to recognize subsequent 
zone changes (F(1,25) = 6.937, p = .014).  5.2 Accuracy of Zone Recognition A participant s accuracy 
of zone recognition was conceptualized as the proportion of (actual) zone crossings that he or she correctly 
identified. We hypothesized that experimental subjects whose navigation was accompanied by elemental 
cameras should be more accurate in identifying zone transitions than control subjects for whom camera 
perspective remained neutral. Our findings support this hypothesis, albeit with marginal statistical 
significance (F(1,25) = 3.53, p = .072). Later Zones First Zone  Recognition Time Figure 4: Average 
percentage of zones participants in experimental and control group crossed and correctly recognized Fig. 
4 shows that experimental subjects were almost twice as accurate as control subjects in recognizing a 
zone. Recall, however, that experimental subjects had fewer region crossings than control subjects; i.e., 
they had fewer opportunities to miss a crossing than controls.  6. DISCUSSION Providing players with 
a camera perspective that dynamically adjusts to region-specific elements seems to support their spatial 
understanding. Once they were accustomed to the game environment, players in the experimental (elemental 
camera) 1 A one-sample Kolmogorov-Smirnov Test was conduced with initial recognition time and subsequent 
(average) recognition time as repeated measures. condition were faster, than players in the control (neutral 
camera) condition to recognize that their avatar had moved into a new game region and they tended to 
be more accurate in these judgments. They also seemed less lost in the environment as indicated by their 
smaller number of factual region crossings. Players in the control group, it seems, wandered more (and 
longer) back and forth between different areas. On the other hand, recognition accuracy was fairly poor, 
even for experimental subjects. Most region crossings went unnoticed by experimental and control subjects 
alike. One reason for this finding may be that the different regions were not as distinct as we had thought. 
Different regions shared a number of elements making it difficult for subjects, even for those in the 
experimental condition, to identify region-specific features. If the terrain and fauna in the different 
regions were not very differentiable to begin with, then players may have made the connection between 
the camera changes and the region changes. However, poor recognition accuracy may also indicate that 
spatial perception aided by camera work is an unconscious process. Players might have been influenced 
by changes in camera perspective while they were concentrating on a completely different task (spatial 
identification). In that case, they might not have realized that it functioned as a regional marker but 
still reacted to it. Furthermore, it is possible that players in the experimental group confused the 
transiton from one camera position to the next (which lasted several seconds) with the normal perceptual 
motion of scenery that occurs when an avatar is running. This suggests that the transition between cameras, 
especially their timing, is more important than we anticipated during game design. 7. OUTLOOK While 
our findings suggest that camera changes support a faster, more precise, and more efficient spatial reasoning, 
additional research is needed to address further the impact of region discriminability and camera transition 
time on players spatial orientation. Our experiments have shown that cameras affect players spatial understanding 
but also point toward issues of timing and visual differentiation that seem to have their impact on the 
recognition. Movement speed of re-adjusting cameras, the level of difference of the various visual properties 
between two cameras, and extreme angles might all affect the perception and reasoning of the depicted 
space. Another important issue to consider is whether camera changes impact male and female players alike. 
Our pool of participants was not big enough to allow for a more detailed analysis of this question. However, 
gender differences have been noted in certain orientation and navigation tasks and it would be interesting 
to see whether similar differences occur when camera changes affect field of view and viewing angle. 
 8. REFERENCES AARSETH, ESPEN. Genre Trouble. In N. Wardrip-Fruin &#38; P. Harrigan (eds.), First person: 
New media as story, performance and game. MIT Press, Cambridge, MA, 2004. ATKINS, BARRY What Are We Really 
Looking At? The Future- Orientation of Video Game Play, Games and Culture 1, no. 2 (2006) 127-40. BLOCK, 
BRUCE The Visual Story: Seeing the Structure of Film, Tv, and New Media. Focal Press, Boston et al., 
2001. Crouching Tiger, Hidden Dragon. Dir. Ang Lee. Asia Union Film &#38; Entertainment Ltd. 2000. CALDERON, 
C., WORLEY, N. AND NYMAN, K. Spatial Cinematic Mediation in Real-Time Architectural Walkthroughs. ITcon, 
11 Architectural informatics (special issue). (2006) 343-360. DRUCKER, STEVEN M. AND ZELTZER, D. CamDroid: 
a System for Implementing Intelligent Camera Control, Proceedings of the 1995 Symposium on Interactive 
3D Graphics 1995. ACM, New York. 139-144. BARES, WILLIAM H. AND LESTER, JAMES C. Intelligent Multi-shot 
Visualization Interfaces for Dynamic 3D Worlds, Proceedings of the 1999 International Conference on Intelligent 
User Interfaces, 1999. ACM, New York.119-126 HE, LI-WEI, COHEN, MICHAEL F., SALESIN, DAVID H. The Virtual 
Cinematographer, Proceedings of the 23rd annual conference on Computer Graphics and Interactive Techniques, 
1996, ACM, New York. 217-224. KRZYWINSKA, TANYA."Hands-on Horror." in Screenplay. Cinema/ Videogames/ 
Interfaces, ed. by Geoff King and Tanja Krzywinska, Wallflower Press, London, 2002. 206-225. MEADOWS, 
MARK S. Pause &#38; Effect. The Art of Interactive Narrative. New Riders, Indianapolis, 2002. NITSCHE, 
M. Games, Montage, and the First Person Point of View DiGRA 2005 Conference Proceedings: Changing Views 
-Worlds of Play. (Vancouver, CAN June 16-20, 2005) DiGRA,Vancouver. 29-36. NITSCHE, M. / ASHMORE, C. 
/ HANKINSON, W. / FITZPATRICK, R./ KELLY, J. AND MARGENAU, K. 'Designing Procedural Game Spaces: A Case 
Study' in: Proceedings of FuturePlay 2006 (London, Ontario October 10-12, 2006) (digital proceedings) 
STEINER, K. E. AND TOMKINS, J. 2004. Narrative Event Adaptation in Virtual Environments. Proceedings 
of the 9th international Conference on Intelligent User Interfaces (Funchal, Madeira, Portugal, January 
13 - 16, 2004). IUI '04. ACM, New York. 46-53. TOMLINSON, B., BLUMBERG, B., AND NAIN, D. Expressive Autonomous 
Cinematography for Interactive Virtual Environments. Proceedings of the Fourth International Conference 
on Autonomous Agents (Barcelona, ESP June 2000), ACM, New York. 317-324. YOUNG, R. M. AND RIEDL, M. 2003. 
Towards an architecture for intelligent control of narrative in interactive virtual worlds. In Proceedings 
of the 8th international Conference on intelligent User interfaces (Miami, Florida, USA, January 12 - 
15, 2003). IUI '03. ACM, New York, NY, 310-312.  
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
	</article_rec>
	<article_rec>
		<article_id>1401874</article_id>
		<sort_key>310</sort_key>
		<display_label>Pages</display_label>
		<pages>8</pages>
		<article_publication_date>08-09-2008</article_publication_date>
		<seq_no>2</seq_no>
		<title><![CDATA[Understanding information observation in interactive 3D environments]]></title>
		<page_from>163</page_from>
		<page_to>170</page_to>
		<doi_number>10.1145/1401843.1401874</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1401874</url>
		<abstract>
			<par><![CDATA[<p>Communicating information to the user is a vital part of the interactive experience. In order to better convey the information to the end user, we must know where to place this information and how to present it in a manner that it will be noticed. Subjectively placing this information is not sufficient since every user will interact with the environment in their own unique manner. Information value is a metric that provides us with the knowledge of which surfaces players looked at most in the environment in the form of an ordered list of surfaces. Using an empirical algorithm for discovering the information value of environmental surfaces from recorded player data, we performed a 150 subject information value study and found that placing information in the high value surfaces yields up to 60% improvement in user observation. However, most players did not recall the information that they had seen. We conducted another 150 subject study to investigate what factors improve information retention and found that popular images do improve recall by up to 28%. Finally, we conducted a 30 person study on the effect of changing the player's task (context) from search to exploration on information recall and found that recall increased by 38%.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[data visualization]]></kw>
			<kw><![CDATA[game environments]]></kw>
			<kw><![CDATA[information observation]]></kw>
			<kw><![CDATA[information value]]></kw>
			<kw><![CDATA[interactive data mining]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.6.3</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>I.6.6</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010147.10010341.10010370</concept_id>
				<concept_desc>CCS->Computing methodologies->Modeling and simulation->Simulation evaluation</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010341</concept_id>
				<concept_desc>CCS->Computing methodologies->Modeling and simulation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<person_id>P1100765</person_id>
				<author_profile_id><![CDATA[81335489765]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Priyesh]]></first_name>
				<middle_name><![CDATA[N.]]></middle_name>
				<last_name><![CDATA[Dixit]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The University of North Carolina at Charlotte, Charlotte, NC]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1100766</person_id>
				<author_profile_id><![CDATA[81335499808]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[G.]]></first_name>
				<middle_name><![CDATA[Michael]]></middle_name>
				<last_name><![CDATA[Youngblood]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[The University of North Carolina at Charlotte, Charlotte, NC]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Brashill, J., and Barnett, J., 2007. Portal: In-game commentary. Valve Software, October.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[BusinessWeek, 2007. BusinessWeek Online: Top 100 Global Brands Interactive Table, August. http://bwnt.businessweek.com/interactive_reports/top_brands/index.asp.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Chaney, I. M., Lin, K.-H., and Chaney, J. 2004. The Effect of Billboards within the Gaming Environment. <i>Journal of Interactive Advertising 5</i>, 1.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1176160</ref_obj_id>
				<ref_obj_pid>1175891</ref_obj_pid>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Chittaro, L., Ranon, R., and Ieronutti, L. 2006. VU-Flow: A Visualization Tool for Analyzing Navigation in Virtual Environments. <i>IEEE Transactions on Visualization and Computer Graphics 12</i>, 6 (Nov/Dec), 1475--1485.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1274967</ref_obj_id>
				<ref_obj_pid>1274940</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Dixit, P., and Youngblood, G. M. 2007. Optimal Information Placement in 3D Interactive Environments. In <i>Sandbox Symposium.</i>
]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Dreze, X., and Hussherr, F.-X. 2003. Interacive advertising: Is anybody watching? <i>Journal of Interactive Advertising 17</i>, 4, 8--23.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Green, C. S., and Bavelier, D. 2003. Action Video Game Modifies Visual Selective Attention. <i>Nature 423</i> (May), 534--537.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Most, S. B., Scholl, B. J., and Clifford, E. R. 2005. What You See Is What You Set: Sustained Inattentional Blindness and the Capture of Awareness. In <i>Psychological Review</i>, vol. 112, 217--242.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1238788</ref_obj_id>
				<ref_obj_pid>1238784</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[Ruddle, R. A., and Lessels, S. 2006. Three Levels of Metric for Evaluating Wayfinding. <i>Presence: Teleoperators and Virtual Environments</i>, 15, 637--654.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Simons, D. J. 2000. Attentional Capture and Inattentional Blindness. <i>Trends in Cognitive Science 4</i>, 4 (April), 147--155.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Wright, R. D., Ed. 1998. <i>Visual Attention.</i> Oxford University Press.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Understanding Information Observation in Interactive 3D Environments PriyeshN. Dixit andG. MichaelYoungblood 
The University of North Carolina at Charlotte College of Computing and Informatics, Department of Computer 
Science 9201 University City Blvd, Charlotte, NC 28223-0001 {pndixit, youngbld}@uncc.edu  Figure 1: 
Our process for evaluating information observation in an environment is shown here visually from left 
to right. First, the player interacts with the 3D environment with information placed, then we use our 
HIIVVE tool for evaluating whether the player observed the information, and .nally, we use this knowledge 
to improve information placement for future players. Abstract Communicating information to the user is 
a vital part of the inter­active experience. In order to better conveythe information to the end user, 
we must know where to place this information and how to present it in a manner that it will be noticed. 
Subjectively placing this information is not suf.cient since every user will interact with theenvironmentin 
theirown unique manner. Informationvalueisa metric that provides us with the knowledge of which surfaces 
play­ers looked at most in the environment in the form of an ordered list of surfaces. Using an empiricalalgorithm 
for discovering the infor­mation value of environmental surfaces from recorded player data, we performed 
a 150 subject information value study and found that placing information in the high value surfaces yields 
up to 60% improvement in user observation. However, most players did not recall the information that 
they had seen. We conducted another 150 subject study to investigate whatfactors improve information 
retention and found that popular images do improve recall by up to 28%. Finally, we conducted a 30 person 
study on the effect of changingthe player stask(context)from searchtoexplorationon information recall 
and found that recall increased by 38%. CR Categories: I.6.3 [Simulation and Modeling]: Applications; 
I.6.6 [Simulation and Modeling]: Simulation Output Analysis; Keywords: information observation, informationvalue, 
data visu­alization, interactive data mining,game environments Copyright &#38;#169; 2008 by the Association 
for Computing Machinery, Inc. Permission to make digital or hard copies of part or all of this work for 
personal or classroom use is granted without fee provided that copies are not made or distributed for 
commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights 
for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. 
To copy otherwise, to republish, to post on servers, or to redistribute to lists, requires prior specific 
permission and/or a fee. Request permissions from Permissions Dept, ACM Inc., fax +1 (212) 869-0481 or 
e-mail permissions@acm.org. Sandbox Symposium 2008, Los Angeles, California, August 9 10, 2008. &#38;#169; 
2008 ACM 978-1-60558-173-6/08/0008 $5.00  1 Introduction In an interactive environment, communicating 
vital information to the user is important for providing the desired experience. It can be used to convey 
training information in training scenarios, and itis importantfor communicatinggameplay elementstoa player. 
In-game advertising also relies on the ability to display information for the user to observe. However, 
it has been documented in several cases that people tend not to remember information even if they have 
seen it [Simons 2000; Chaneyet al. 2004; Green and Bavelier 2003; Ruddle and Lessels 2006]. This is known 
as inattentional blindness and is described as failing to notice distinctive objects when focused on 
a task that does not involve those objects [Simons 2000]. Appropriately placing this information so it 
is in the view of the player is one important aspect for improving its observation. Sub­jectively deciding 
where to place such information is not suf.cient since each player will interact with the environment 
in a different way. Using the position and orientation data collected from a set ofplayersinanenvironmentovertime,wecan 
calculatewhichsur­faces in the environment theyobserved and howoften theyobserved them usingametric we 
call information value. Informationvalueis a metric that measures the likelihood that a particular surface 
will be seenbyfuture players based on processing data from previous players in the same environment. 
This allows us to guide infor­mation placement in an interactive environment for future players based 
on data from a corpus of previous players. We implemented this information value algorithm using a tool 
called HIIVVE(Highly InteractiveInformationValueVisualization and Evaluation), which is shown in Figure 
2. The tool allows the user to load world geometry and recorded player data to then cal­culate the information 
value for all surfaces of the geometry based on that player data. In order to calculate the information 
value, we derivea viewfrustum for the player at each time step that their posi­ Figure 2: HIIVVE is 
an interactive tool for calculating information value for the surfaces in an environment. tion and orientation 
was recorded. Aview frustum is a rectangular basedpyramid that representsthe player s .eldof visionata 
time step. We then project a series of rays from the player s position to the base of the frustum and 
calculate intersections with the world geometry.Ifan intersectionis detectedatapointonthesurface,the 
informationvalueof that pointis updated. The informationvalueis distance and radially weighted, which 
means that the further away from theplayer s position and the player s focal point (where they weregazing)thelowerthe 
informationvalue.Anexampleofthis is given in Figure 2. Last year, we conducted a research study to verify 
the effectiveness of our information value metric. In this .rst study, we calculated information values 
for the surfaces in an environment and placed posters based on the surface informationvalues [Dixit andYoung­blood 
2007]. We tracked whether the posters were in a player s .eld of view according to our data (i.e., actual 
views), and whether they remembered seeing the posters (i.e., reported views). Most players did not remember 
seeing anyposters, which indicated that appropriate placement alone is not enough for communicating this 
information to the players when it is not directly related to their target task. In order to investigate 
how to increase our reported views to be closer to the actual views, we conducted a second study. In 
this study, we created .ve new scenarios with posters placed on the highest information value surfaces 
in each scenario. Each scenario changed some aspect of howthe posters were presented to the play­ers 
such as adding a spotlight or sounds to the posters. The goal of this study was to see which method of 
presenting information is more effective for information retention so we can improve how manyposters 
the subjects remember seeing. The context of the scenario being played is important in determin­ingwherethewilllook.Inordertoexploretheeffectof 
contexton recall, we also conducted a small study to determine the impact of context on the results of 
information retention and surface informa­tion values. Instead of instructing the players to .nd and 
defuse an Improvised Explosive Device (IED), they were told to explore the environment for .ve minutes. 
We tracked the actual and reported views for this new scenario and compared it to the high value sce­nario 
from our previous study. We also recalculated the surfaces with the highest information value to examine 
how they changed due to the change in context. 2 Problem Statement Thekeyquestion we are trying to answer 
is: How do we improve recall of information placed in an interactive environment when we know that the 
user has actually seen this information. Using our informationvalue algorithm, we can calculatewhereto 
place infor­mationsothatmost userswillviewit[DixitandYoungblood2007]. However, even though the information 
is viewedit is not remem­bered by most players. Due to the effect of inattentional blindness, we explored 
different ways of presenting this information to make it noticeable for the players such as displaying 
popular images and adding sounds to the posters. Inthis paper,wewill .rst discuss some relatedworkin 
information observation, then provide some background on our .rst information observation study and its 
results. We then detail the results of our new studies. Finally, we outline our observations from the 
results and suggest some future work. 3 Related Work A tool similar to HIIVVE called VU-Flow has been 
developed for tracking user behavior in a virtual environment [Chittaro et al. 2006]. The user s position 
and orientation information is captured, but it is visualized only in two dimensions. The tool was used 
to track areas most visited (and least visited) as well as parts of the environment that were most seen 
(or least seen) by the users. They consider the distance from the user, time ofgaze, and radial focus 
drop-offfor calculating how much a surface was viewed. However, since the calculation is done in 2D space, 
the occlusion calculations are not as accurate as our information value algorithm and this can beamajorfactorin 
calculatingthe amountofexposureofasurface in the environment. Our algorithm for using tracked player 
data to calculate information value surfaces not only takes time, distance and radial focus into account,but 
is in full 3D and includes occlu­sion and an arbitrary focalgaze point for the player (not just the view 
center). This effect of not noticing information that is not part of the primary task is known as inattentional 
blindness [Simons 2000]. Shawn Green and Daphne Bavelier conducted a study to measure the ef­fect of 
playing videogames on visual attention. They measured theeffectofadistracting visual element on thegiven 
task for both videogame players andnon-gamers. Itwas found that those who played videogames tend to have 
more attentional resources even when thereisadistractor element. This means that those who play more 
videogames .nd it easier to ignore peripheral information that is not directly related to their target 
task (i.e., more inattentional blindness). In our information observation study,we did not ask the subjects 
to speci.cally look for the posters while theywere playing, their primary task was to .nd and defuse 
an Improvised Explosive Device. Since the posters were distracting elements, mostgamers found it easy 
to ignore them consistent with the .ndings of Green and Bavelier [Green and Bavelier 2003]. The .eld 
of psychology has conducted many studies of inatten­tional blindness and the related attention capture 
[Wright 1998; Most et al. 2005] and manyof these studies have involved imagery and some level ofinteraction; 
however, studies involving new me­dia and interactivegames are only just now emerging. For addi­tional 
background, we also refer the reader to the .elds of Cognitive Science,Virtual Reality, and Human-Computer 
Interaction, which havealso conducted related studies,butdueto space constraintswe have selected only 
those closely related to our study presented in this paper. Isabella Chaney et al. conducted a study 
with in-game billboards ina .rst-person shootergame thatwas similarto ourown informa­tion observationstudy[Chaneyetal.2004]. 
Playerswereinvitedto a 15 minute session of a .rst-person shooter, and after the session were asked to 
.ll out an online survey. Theyplaced billboards in thegame environment that contained imaginary brand 
names such as Mama s Pizza and Revive Soda . Theseproducts were cho­sen because theywould have some personal 
relevance to the demo­graphic they were targeting for the study and were close tofamil­iar images. The 
surveyasked them which billboards theyrecalled seeing, and most players did not remember any of the billboards. 
Nearly all subjects were experienced players and there were no fe­male participants.Ourstudyhadamuch 
morediversepopulationof participants (based on both experience and gender) and we placed our information 
in a more empirical manner. The results from this study werevery similarto ourown observations,in thatexperienced 
gamersdonot recallanyextraneous informationfromthegameen­vironment. The context of the studies was also 
very different since this studyinvolved the subjects playing against each other compet­itively, while 
our studywas strictly single player witha search task. Ruddle and Lessels conducted a study to explore 
way-.nding in an interactive virtual environment in which they tracked user move­ment and orientation 
[Ruddle and Lessels 2006]. The subjects were asked to .nd targets that were placed within the environment. 
They examined the .eld-of-view of the user over time and found that most of the targets that were not 
found by the user were actually within the user s .eld-of-view, but were simply not noticed. The primary 
task of the subjects in this study was to .nd the targets and yet some users still did not notice the 
targets in their view. According to the in-game commentary in Valve Software s .rst­person puzzlegame 
Portal, Valve also encountered lack of infor­mation observationin theirgames [Brashill and Barnett2007].For 
example, in one area of Portal, the players were passing by vital information without seeing it in this 
case the all-important portal gun. In order to get the player s attention, theyblocked off access tothenext 
roomfora limited amountoftimeandaddedasoundef­fect to the gun, which caused players to look atit through 
the glass window. By blocking access to the next area, the player s target task was changed to exploration 
of the room in which they were currently located. This allowed the players to notice the sound and therefore, 
notice the portal gun. In another area of thegame, the player was required to look up to .nd the exit 
but most players rarelylookedup.Inthis case,theyaddedabroken ladderto prompt the player to investigate 
where it leads and thus look upward. In this case, theyusedafamiliar element that the playerwas looking 
for to guide them to the information they needed to observe. We have also found in our studies thatfamiliar 
images lead to better observation.  4 Information Value Study Toverify our informationvalue algorithm, 
we ran an IRB-approved human study usinga scenario froma Quake3modi.cation called Urban Combat Testbed 
(speci.cally Level 1 Scenario 3). Three posters were selectively placed in the environment, and we studied 
whether the participants observed them while theyplayed.We cre­ated.vescenarioswiththegoalinthesame location,butthe 
posters were placed on surfaces with varying levels of information value. We then studied the number 
of posters that the player actually ob­served and compared it with what theyremembered observing. 4.1 
Setup The information value was calculated for the Urban Combat Testbed Apartments environmental surfaces 
using 32 previously recorded player traces in the same scenario before anyposters were placed in the 
environment. We then created .ve scenarios from the same environment based on the information value category 
that the posterswouldbe placedin. Figure3showsthe posters placed in the UCT environment. The scenarios 
created were high value, high-quartervalue, medianvalue,low-quartervalue,andlowvalue, which was derived 
by segmenting all of the surface information values from the highest to the lowest such that high value 
scenario contained postersinthehigh informationvalue locations,lowinthe lowest,andso forth.The samesetofthree 
posterswasusedineach case. The placement of the posters in each of the .ve scenarios is illustratedin 
Figure4. Each scenariowas playedby30 subjects for a total of 150 subjects. In our study, we assumed the 
focal point of theview frustumstobeinthe centeroftheview.Wemadethisas­sumption becauseina .rst person 
shootergame thereis usually an aiming cursor (reticle) .xed in the center of the screen, which most playerskeep 
theireyes focusedupon. In future studies, we intend to use an eye tracker to more accurately track the 
focal point1.  Figure 3: A screenshot of posters appearing in the UCT Apart­ments environment. 4.2 
Procedure The participants were given a short pre-survey with their consent formto determine theirexperienceingames. 
Oncetheycompleted the surveythey weregivena training scenario tofamiliarize them with the controls and 
then they were taken to the appropriate sce­nario where they had to .nd and defuse the IED within the 
time limit of .ve minutes. The IED was placed in the same location for each of the .ve scenarios. After 
they .nished the task, they an­swered a post-test where they were asked to mark the posters they remembered 
seeing in the environment or circle NONE if theydid not remember anyposters. The context of the task 
was to .nd the IED so they were not speci.cally told to look for anyposters be­forehand. We tracked two 
key results in this study, actual views and reported views. Actual views represent the number of posters 
that were observed according to their recorded play session (i.e., the posters existed in the player 
s view frustum at some point). Re­ported views are what the players marked on the post-test as being 
observed in the environment. The following section will examine each in detail. 1Our HIIVVE tool algorithms 
already calculate foradynamically placed focal point within the view frustum. Figure 4: Location of 
information elements placed within the UCT test environment basedupon the calculated surface information 
val­ues.  4.3 Results The actual views metric was measured by loading the player trace of the subject 
into HIIVVE and determining whether any of the posters were actually observed by the player. This is 
done by look­ing at whether the player s .eld of view ever intersects the areas that contained the posters 
for the scenario that theyplayed. There is clearly a pattern based on the scenario played as seen in 
Figure 5.The participants that played the high informationvalue scenario observed at least two of the 
three posters that were in the envi­ronment. According to our results, 84.4% of the information was seen 
in the high value scenario with a standard deviation of 16.9%. In the high-quarter scenario, 33.3% of 
the information was viewed with a standard deviation of 24.7%. The median scenario also had 34.4% of 
the information viewed and the standard deviation was 23.9%. The low-quarter scenario had the lowest 
amount of infor­mation viewed at 24.4%, with a standard deviation of 19.4%. Fi­nally, the low value scenario 
had 40.0% of the information viewed with a standard deviation of 30.8%. Table 1: One-Way ANOVAfor actual 
and reported views from In­formationValue study. Var Mean Square F Sig. Actual 15.100 29.952 .000 Reported 
.173 .725 .576 A One-Way ANOVA test was conducted on our data to .nd the correlation between the information 
value scenarios played and the number of actual views as seen inTable 1. The results show that the actual 
views had a signi.cance value of 0.00 and an F value of 29.952. This means that the actual views were 
statistically sig­ni.cant across all of the scenarios played. The reported views did not have enough 
variation to show statistical signi.cance; however, it is to be noted that the results were uniformally 
low and did not  Figure 5: Actual viewed information from view frustum examina­tion for the InformationValue 
study.  Figure 6: The average length of the player traces compared by player experience from beginner 
to experienced in eachscenario. Note that the results are stacked, so individual scenarios should be 
read as the area above the curve below it. improve with increases in the sample population. Table2shows 
the statistical difference between eachof the scenar­ios using Scheffe s method. The Scheffe contrast 
is a method of .nding if pairs of means from a sample are signi.cantly different from each other. Statistical 
signi.cance is indicated by a p value of less than 0.05. This analysis shows that the difference between 
the high value scenario and the rest of the scenarios was statisti­cally signi.cant. However, thedifference 
among the other scenar­ios (high-quarter, median, low-quarter, and low) was insigni.cant. This means 
that there is essentially a plateau from high-quarter to low. Intuitively, we would expect a relatively 
smooth curve from high to low. However, in this case we see a peak at the high value and then a plateau 
for the rest caused by a phenomenon we call the Novice Player Exploration Effect (NPEE). As seen in Figure 
6, the less experience players tend to explore the environment sig­ni.cantly more than more experiencedplayers. 
We attribute this phenomenon to a natural tendency for humans to explore in new and unfamiliar environments. 
This causes them to observe posters that are on the low information value surfaces while more experi­encedgamerstakea 
shorterperiodoftimeto.nishthetask.Figure 7showsa novice player trace(a) compared to that of an experience 
player (b). The difference is signi.cant and we believe this is what is causing the high number of posters 
observed in the low value scenario. Figure 7: Anovice player (a) compared with an expert player (b). 
Novice players usually have longer player traces. Table 2: Scheffe Contrasts among pairs of scenarios 
for actual views. Groups Fvalue Sig? Hv.s. HQ 8.36 Yes Hv.s. HQ 8.18 Yes Hv.s. LQ 9.82 Yes Hv.s. L 7.27 
Yes HQ v.s. M 0.18 No HQ v.s. LQ 1.45 No HQ v.s. L 1.09 No Mv.s. LQ 1.64 No Mv.s. L 0.91 No LQ v.s. L 
2.55 No Oncethe participanthadplayedthe scenariotheyweregivenashort post-test that asked them to circle 
the posters theyremembered see­ingintheenvironment.The scoring criteriawasas follows, circling a poster 
that was in the environment added one point, circling a poster that was not in the environment would 
subtract one point, and not circling a poster that was in the environment would do nothing. We then divided 
the number of posters reported with the number actually seen by the player to get the .nal reported views 
metric. This ensures that we do not penalize the players for posters theynever encounteredintheenvironment.Agraphofthe 
reported views metric is seen in Figure 8. It is clear from the graph that most players did not recall 
anyof the posters despite thefact that when we load the player trace of some of these subjects, we can 
clearly see that theyobserved some of the posters. The common response was that they were too focused 
on trying to defuse the IED and did not pay attention to their surroundings. The data for reported views 
is as follows. In the high value scenario, 11.1% of the in­formation was reported as seen with a standard 
deviation of 1.8%. In the high-quarter and low-quarter scenarios, 5.6% of the posters were reported as 
seen with a standard deviation of 1.5% and 1.2% respectively. 10.0% of the information was reported in 
the median scenario with a standard deviation of 1.7%. And .nally, in the low scenario 7.8% of the information 
was reported with a standard de­viation of 1.7%.  5 Information Retention Study The reported views 
from our .rst information value study were lower than expected, which prompted us to do a second study 
to investigate this further. This new study was conducted to measure what it takes to make the reported 
views match or rise towards the actual views. Five new scenarios were created with the posters al­ways 
in the same high value locations as calculated in the previ-  Figure 8: Self-reported information recall 
for the Information Value study. ous study. We presented the information in different ways to study which 
method is best for improving information retention. 5.1 Setup The .ve new scenarios we created were as 
follows. The popular scenario(P)contained posters with popular companylogos accord­ing to BusinessWeek 
sTop 100 brands feature of 2007 [Business-Week 2007]. The sound scenario(S)used the same posters as thepreviousstudybut 
we addeda soundeffecttoevery posterthat was relevant to the content of the poster (i.e., an Army commercial 
for the Army poster). The 3D scenario(T)added 3D elements to the postersfrom the previous study (i.e.,a3D 
cherry model used on the Fruit Break poster). The interactive scenario(I)turned the postersintobuttonsthatcanbepressedtorevealgamerelevant 
hints. Only the posters behind the buttons were being tested for actual observation, so the player would 
have to interact with the outer poster in order to view the actualposter. Finally,The light scenario(L)addeda 
spotlightabovethe posterstomakethemstand out visually. 150volunteer subjectsin totalforall.vescenarios(30 
per scenario) participated in this study. Those who participated in the previous study were not allowed 
to participate in the new study toavoidknowledge contamination. Figure9showsexamplesofthe 3D, interactive, 
and light scenario posters. 5.2 Procedure The proceduresforthisstudy werevery similartoour.rst informa­tion 
observation study. The participants were asked to sign a con­sent form and answer a few pre-test questions 
about their age and experiencelevelingames. In ordertoavoid uneven distributionof experience levels in 
the different scenarios, we explicitly assigned scenarios to subjects based on their experience level. 
This ensured we had an even distribution of experience in each scenario. The .veexperiencelevels werebeginner(never 
played),novice (played a few times), casual (occasionally played), avid (played often), and experienced 
(playedalot). Once theywere assignedascenario they playedthe trainingleveltofamiliarize themselveswiththe 
controls. Thetaskgiventotheplayerswasstill.ndingand defusingtheIED, and it was in the same location as 
the previous study. As in the pre­vious study, the time limit for the task was still .ve minutes. Once 
they.nished the task, theywere asked to .ll out the post-test, which asked them to select the posters 
theyremember seeing in the envi­ronment. Again, we tracked the actual and reported views of the players 
in these new scenarios. Figure 9: Examples of posters used in the second study. (a)In­teractive before 
interaction (b) Interactive after interaction (c) 3D element on the poster (d) Light scenario poster. 
 5.3 Results The actual views metric was measured in the same manner as be­fore (looking at whether 
the posters were ever in the player s view duringtheplay session). Figure10showsthegraphof actualviews 
across the .ve scenarios. The popular scenario had 81.1% informa­tion viewed with a standard deviation 
of 16.8%. The 3D scenario had 75.6% information viewed witha standarddeviationof 21.3%. In the light 
scenario, 75.6% information was viewed with a stan­dard deviation of 23%. In the interactive scenario 
there are two types of actual views tracked. The percentage ofbuttons seen (be­fore interaction) was 
74.4% and the standard deviation was 22.6%, which matchesthepreviousstudy.However,thebuttons were actu­ally 
interacted with only 10% of the time with a standard deviation of 17.8%. The actual views of the interactive 
scenario are shown in Figure 11. Only interacting with thebuttonswould reveal the posters for which we 
were testing in the post-test. And .nally, in the sound scenario the information viewed was 67.8% with 
a stan­dard deviation of 20.5%. We ran a Tukey HSD ( Honestly Sig­ni.cantly Different ) comparison on 
the actual views among the different scenarios. TheTukeyHSD methodis anotherwayto com­pare means to see 
if theyare signi.cantly different from each other. This showed that the actual views for the new scenarios 
were sta­tistically insigni.cantly different (meaning that theyare roughly all the same) from the original 
study except for the sound scenario as seeninTable3.Thedeviationinthe sound scenariomayhavebeen causedbyan 
unintentional changein contextduetothe introduc­tion of the sounds. Players may have stayed away from 
areas that made soundtoavoidwhatseemedtobeadvertising.Astudyonthe effectiveness of internetbanner advertising 
has shown that people actively avoid exposure to advertising [Dreze and Hussherr 2003]. The reported 
views metric is what we are most interested in this time. This is based on the post-test and indicates 
what the user re­membered seeing in the environment. We measured it as a ratio of numberof posters correctly 
reporteddividedby the actual views for the player like our previous study. This ensures we do not count 
posters they never encountered against them since our goal is to measure information retention. Figure 
12 shows the graph for re-  Table 3: TukeyHSD for actual views between the scenarios from both studies. 
Groups Mean diff Signi.cance Is Sig? Hv.s. P 0.33 0.99 No Hv.s. T 0.09 0.68 No Hv.s. L 0.09 0.67 No Hv.s. 
I 0.10 0.54 No Hv.s. S 0.17 0.05 Yes  ported views in our second study. The popular scenario had 39.4% 
information recalled witha standarddeviationof 34%. The3D sce­nario had 15.6% information recalled with 
a standard deviation of 28.3%. In the light scenario, 7.8% information was recalled with a standard deviation 
of 16.2%. In the interactive scenario, the in­formation recalled was 23.3% and the standard deviation 
was 43%. It is important to note that this 23.3% is out of the percentage of posters that were interacted 
with, which was only 10%. Finally, in the sound scenario the information recalled was 20% with a stan­dard 
deviation of 32.9%. The reported views still did not match the actual views; however, there was some 
improvement over our previous study. The amount of reported views for the high value scenariointhepreviousstudywasat 
11.1%.WealsoranaTukey HSD comparison on the reported views data as seen in Table 4. This showed that 
the popular scenario was the only one that was  Table 4: TukeyHSDofreportedviews between scenariosfromboth 
studies. Groups Mean diff Signi.cance Is Sig? Hv.s. P -0.27 0.02 Yes Hv.s. T -0.03 1.00 No Hv.s. L 0.05 
0.99 No Hv.s. I -0.11 0.85 No Hv.s. S -0.72 0.97 No statistically signi.cantly different from the previous 
study. Also, all scenarios except for the light scenario had a higher percentage of information recalled 
than we had in our previous study. How­ever, this increase in unfortunately not statistically signi.cant 
so, the results are essentially .at. The popular scenario had the most improvement witha 28% increaseover 
the previous study with sta­tistical signi.cance. Anecdotally, we also noted that players that played 
the sound scenario did recall hearing the soundsbut did not associate them with the posters.  6 Effect 
of Context We also conducted a short study to examine the effect of changing the context of the player 
stask. Instead of having the player .nd and defuse the IED, in the explore scenario we told them to simply 
explore the environment until the timerexpired (after 300 seconds). Weagain tracked the actual views 
and reported views of the players in the same manner as our information retention study. The actual information 
viewed was 71.1% with a standard deviation of 25.9% as seen in Figure 14. This is statistically insigni.cantly 
different from the actual views in the previous context as seen inTable 5. The information recalled by 
the players in the exploration scenario was 48.9% with a standard deviation of 38.1% as seen in Figure 
15. This is a statistically signi.cant improvement over the previous context as showninTable5. Table 
5: TukeyHSDof Explore scenario and HighValue scenario Variable Groups Mean diff Signi.cance Is Sig? Actual 
Hv.s. E 0.06 0.91 No Reported Hv.s. E -0.35 0.00 Yes Using HIIVVE, we recalculated the information value 
for the sur­faces in the environment from the explore scenario group and  noted that thehighest informationvalue 
surfaces had changed due to the change in context as can be seen in Figure 13. This is also indicated 
by the relatively lower percentage of information viewed compared to the search task of our previous 
scenario. On average, players of the explore scenario only saw 2.1 posters per person compared to 2.5 
posters per person in the information value study. We noted that most players tended to stay near their 
starting posi­tionandwalkonthe roads aroundthelevel missingthe poster loca­tions.Manyplayersalsochoseto 
enterthebuildingsandexplorein­doors, which caused them to see fewer posters. However, the recall was 
signi.cantly higher because the lack of urgencyto .nd the IED allowed for more attentional resources 
for the observation of the posters since the exploration of the environment was now the pri­mary task. 
This analysis shows that scenario context signi.cantly impacts information surface values and information 
retention.  7 Conclusions Throughourexperimentationweused recordedgameplayerdatato gain knowledge about 
where the players are looking in an interac­tive3Denvironmentand calculatethe informationvalueofsurfaces 
in that world. With our information value study we were able to show that placinginformation in the highest 
value locations yields up to 60% better observationby the user. However, when we asked the players which 
posters theyrecalled seeing most of the players did not recall seeing anyposters, which is something 
we explored further with our second study. With the second study we investigated how changing the way 
in which the information is presented would effect information reten­tion.Weobserved that changingthe 
contentofthe posterstofa­miliar images yields up to 28% better recall. It was also noted that only 10% 
of theplayers actually interacted with the posters in the interactive scenario. In addition, we studied 
the effect of changing the context by instructing the players to explore the environment instead of .nding 
the IED. We found that removing the urgency to defuse the IED improved information recall for the players 
by up to 38%. The high value surfaces were also changed based on the explore scenario player traces due 
to the change in context as compared to the previous high value scenario from our .rst study. The results 
indicate that the use of familiar images in game en­vironments does yield better recall, which would 
bene.t in-game advertising. Also if players interact with something to get infor­mation, theytend to 
remember it better. How to take advantage of this interactive element depends on the context of thegame. 
For instance,ifaplayerhasbeen trainedto pressa certaintypeofbut­ton and we place thisbutton so thatit 
revealsa poster, then they are more likely to interact with it and remember the information it reveals. 
Finally, the player s task (or context) plays a key role in information retention as well. The goal of 
.nding and defus­ing an IED results in low information retention because the players are searching for 
the IED and anything else is ignored. However, when given the task of exploring the environment the players 
pay more attention to their surroundings and therefore remember more environmental information.  8 Future 
work Exploring the full impact of different contexts is our next direction, and from there we intend 
to investigate ways in which information artifacts impact player goal satisfaction. We further plan to 
exam­ine attention capture elements and their impact ongameplay. We also hope to explore the use of eye-tracking 
to record the player s focal point on the screen in addition to their look direction in the en­vironment 
fully utilizing the HIIVVE tool we have developed and exploring anydifferences with our previous studies. 
 Acknowledgements The authors wish to thank the Quakecon 2006 staff and partici­pants who provided the 
initial player trace data for this work. We also wish thank the students at UNC Charlotte and the visitors 
of Charlotte-MecklenburgPublic Librarieswho participatedin ourex­periments. References BRASHILL, J., 
AND BARNETT, J., 2007. Portal: In-game com­mentary. Valve Software, October. BUSINESSWEEK, 2007. BusinessWeek 
Online: Top 100 Global Brands Interactive Table, August. http://bwnt.businessweek. com/interactive reports/top 
brands/index.asp. CHANEY, I. M., LIN, K.-H., AND CHANEY, J. 2004. The Ef­fect of Billboards within the 
Gaming Environment. Journal of Interactive Advertising5, 1. CHITTARO,L.,RANON,R., ANDIERONUTTI,L. 2006. 
VU-Flow: AVisualizationTool for Analyzing Navigation inVirtual Envi­ronments. IEEE Transactions on Visualization 
and Computer Graphics 12,6(Nov/Dec), 1475 1485. DIXIT,P., ANDYOUNGBLOOD,G.M. 2007. Optimal Information 
Placement in 3D Interactive Environments. In Sandbox Sympo­sium. DREZE,X., AND HUSSHERR,F.-X. 2003. Interacive 
advertising: Is anybody watching? Journal of Interactive Advertising 17, 4, 8 23. GREEN,C.S., AND BAVELIER,D. 
2003. ActionVideo Game Modi.es Visual Selective Attention. Nature 423 (May), 534 537. MOST,S.B.,SCHOLL,B.J., 
AND CLIFFORD,E.R. 2005. What You SeeIs WhatYou Set: Sustained Inattentional Blindness and the Capture 
ofAwareness. In Psychological Review, vol. 112, 217 242. RUDDLE,R.A., AND LESSELS,S. 2006. ThreeLevelsof 
Metric for EvaluatingWay.nding. Presence:Teleoperators andVirtual Environments, 15, 637 654. SIMONS,D.J. 
2000. Attentional Capture and Inattentional Blind­ness. TrendsinCognitive Science4,4(April), 147 155. 
WRIGHT, R. D., Ed. 1998. Visual Attention. Oxford University Press.  
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
	</article_rec>
	<article_rec>
		<article_id>1401875</article_id>
		<sort_key>320</sort_key>
		<display_label>Pages</display_label>
		<pages>8</pages>
		<article_publication_date>08-09-2008</article_publication_date>
		<seq_no>3</seq_no>
		<title><![CDATA[Virtual cinematography of group scenes using hierarchical lines of actions]]></title>
		<page_from>171</page_from>
		<page_to>178</page_to>
		<doi_number>10.1145/1401843.1401875</doi_number>
		<url>http://dl.acm.org/citation.cfm?id=1401875</url>
		<abstract>
			<par><![CDATA[<p>We present an approach to generate shots for 3D computer graphics cinematic sequences from event-based descriptions of scenes of conversations between groups of actors. Our approach creates camera setups using a combination of geometric constraints and aesthetic parameters, while ensuring that the resulting cinematic sequence obeys the heuristics of good cinematography. More specifically, our main contributions are the a method for defining hierarchical lines of action and the identification and use of relevant first principles of cinematography for using these lines of actions. Our approach is more flexible and powerful than those proposed in previous work, mainly because it naturally generalizes to any number of actors in a scene.</p>]]></par>
		</abstract>
		<keywords>
			<kw><![CDATA[computational cinematics]]></kw>
			<kw><![CDATA[computer animation]]></kw>
			<kw><![CDATA[film editing]]></kw>
			<kw><![CDATA[film grammar]]></kw>
			<kw><![CDATA[virtual characters]]></kw>
			<kw><![CDATA[virtual cinematography]]></kw>
		</keywords>
		<categories>
			<primary_category>
				<cat_node>I.3.7</cat_node>
				<descriptor/>
				<type/>
			</primary_category>
			<other_category>
				<cat_node>J.5</cat_node>
				<descriptor></descriptor>
				<type></type>
			</other_category>
		</categories>
		<ccs2012>
			<concept>
				<concept_id>0.10010405.10010469</concept_id>
				<concept_desc>CCS->Applied computing->Arts and humanities</concept_desc>
				<concept_significance>100</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010371.10010352</concept_id>
				<concept_desc>CCS->Computing methodologies->Computer graphics->Animation</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
			<concept>
				<concept_id>0.10010147.10010178.10010224.10010226.10010239</concept_id>
				<concept_desc>CCS->Computing methodologies->Artificial intelligence->Computer vision->Image and video acquisition->3D imaging</concept_desc>
				<concept_significance>500</concept_significance>
			</concept>
		</ccs2012>
		<authors>
			<au>
				<person_id>P1100767</person_id>
				<author_profile_id><![CDATA[81365594825]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>1</seq_no>
				<first_name><![CDATA[Kaveh]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Kardan]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Hawaii]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
			<au>
				<person_id>P1100768</person_id>
				<author_profile_id><![CDATA[81100150660]]></author_profile_id>
				<orcid_id></orcid_id>
				<seq_no>2</seq_no>
				<first_name><![CDATA[Henri]]></first_name>
				<middle_name><![CDATA[]]></middle_name>
				<last_name><![CDATA[Casanova]]></last_name>
				<suffix><![CDATA[]]></suffix>
				<affiliation><![CDATA[University of Hawaii]]></affiliation>
				<role><![CDATA[Author]]></role>
				<email_address><![CDATA[]]></email_address>
			</au>
		</authors>
		<references>
			<ref>
				<ref_seq_no>1</ref_seq_no>
				<ref_text><![CDATA[Amerson, D. and Kime, S. 2000, Real-time Cinematic Camera Control for Interactive Narratives. In <i>AAAI'00.</i>
]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>2</ref_seq_no>
				<ref_text><![CDATA[Arijon, D. Grammar of the Film Language. Silman-James Press, 1991.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>291101</ref_obj_id>
				<ref_obj_pid>291080</ref_obj_pid>
				<ref_seq_no>3</ref_seq_no>
				<ref_text><![CDATA[Bares, W. H., and Lester, J. C. 1999, Intelligent Multi-Shot Visualization Interfaces for Dynamic 3D Worlds. In <i>Intl. Conf. on Intelligent User Interfaces</i>, pages 119--126.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>4</ref_seq_no>
				<ref_text><![CDATA[Bares, W. H.; Thainimit, S.; and McDermott, S., A Model for Constraint-Based Camera Planning. In <i>Smart Graphics. Papers from the 2000 AAAI Spring Symposium</i>, pages 84--91, 2000.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1892897</ref_obj_id>
				<ref_obj_pid>1892875</ref_obj_pid>
				<ref_seq_no>5</ref_seq_no>
				<ref_text><![CDATA[Christianson, D. B.; Anderson, S. E.; He, L.-W.; Salesin, D. H.; Weld, D. S.; and Cohen, M. F. 1996, Declarative camera control for automatic cinematography. In <i>Proceedings of the Thirteenth National Conference on Artificial Intelligence</i>, 148--155.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>6</ref_seq_no>
				<ref_text><![CDATA[Cozic, L.; Davis, S. B.; and Jones, H., Interaction and Expressivity in Video Games: Harnessing the Rhetoric of Film. In <i>Technologies for Interactive Digital Storytelling and Entertainment</i>, pages 232--239, 2004.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>7</ref_seq_no>
				<ref_text><![CDATA[Friedman, D. A., and Feldman, Y. A., 2004, Knowledge-based cinematography and its applications. In <i>Proceedings of ECAI</i>, pages 256--262.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>8</ref_seq_no>
				<ref_text><![CDATA[Halper, N.; Helbing, R.; and Strothotte, T. 2001, A Camera Engine for Computer Games: Managing the Trade Off Between Constraint Satisfaction and Frame Coherence, In <i>Proc. Eurographics 2001.</i>
]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>237259</ref_obj_id>
				<ref_obj_pid>237170</ref_obj_pid>
				<ref_seq_no>9</ref_seq_no>
				<ref_text><![CDATA[He, L.; Cohen, M.; and Salesin, D., The Virtual Cinematographer: A Paradigm for Automatic Real-time Camera Control and Directing, <i>Proceedings of the 23rd Annual Conference on Computer Graphics and Interactive Techniques</i>, p.217--224, 1996.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>10</ref_seq_no>
				<ref_text><![CDATA[Katz, S., Film Directing: Shot by Shot: Visualizing from Concept to Screen, Michael Wiese Productions, 1991.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_obj_id>1043558</ref_obj_id>
				<ref_obj_pid>1042444</ref_obj_pid>
				<ref_seq_no>11</ref_seq_no>
				<ref_text><![CDATA[Li, T. Y., and Xiao, X. Y., An Interactive Camera Planning System for Automatic Cinematographer. In <i>Conference on Multimedia Modeling</i>, pages 310--315, 2005.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>12</ref_seq_no>
				<ref_text><![CDATA[Oliveros, D. A. M. 2004. Intelligent Cinematic Camera for 3D Games, MSc. Thesis, University of Technology, Sydney Australia.]]></ref_text>
				<ref_id></ref_id>
			</ref>
			<ref>
				<ref_seq_no>13</ref_seq_no>
				<ref_text><![CDATA[Pickering, J. H., 2002, Intelligent Camera Planning for Computer Graphics, PhD. Thesis, University of York, York, UK.]]></ref_text>
				<ref_id></ref_id>
			</ref>
		</references>
		<fulltext>
			<file>
				<seq_no></seq_no>
				<fname></fname>
			</file>
			<ft_body><![CDATA[
 Virtual Cinematography of Group Scenes using Hierarchical Lines of Actions Kaveh Kardan Henri Casanova 
University of Hawaii* Abstract We present an approach to generate shots for 3D computer graphics cinematic 
sequences from event-based descriptions of scenes of conversations between groups of actors. Our approach 
creates camera setups using a combination of geometricconstraints and aesthetic parameters, while ensuring 
that the resulting cinematic sequence obeys the heuristics of goodcinematography. More speci.cally, our 
main contributions are the a method for de.ning hierarchical lines of action and the identi.cation and 
use of relevant .rst principles of cinematography for using these lines of actions. Our approach is more 
.exible and powerful than those proposed in previous work, mainly because it naturally generalizes to 
any number of actors in a scene. CR Categories: I.3.7 [Computer Graphics]: Three-Dimensional Graphics 
and Realism; J.5 [Arts and Humanities] Keywords: computer animation, virtual cinematography, .lm editing, 
.lm grammar, virtual characters, computationalcinematics  Introduction The creation of cinematic sequences 
using 3D computer graphics has many applications. Of particular interest to us is the automated authoring 
of cinematic sequences for computer games. Both scripted sequences (known as non-interactive scenes) 
and the playback movies of players recent actions in the game can bene.t from automated cinematic sequence 
creation. Other applications include computer-assisted storytelling, pre­visualization for .lms, and 
3D chat systems. The effort to create these sequences varies greatly with the visual complexity of the 
.nal result, but in all cases, the task of creation remains a time­consuming one. Even for the simplest 
of sequences, manually setting key frames for camera positions and focal lengths for every setup, and 
then editing together the resulting rendered *e-mail: {kaveh | henric}@hawaii.edu Copyright &#38;#169; 
2008 by the Association for Computing Machinery, Inc. Permission to make digital or hard copies of part 
or all of this work for personal or classroom use is granted without fee provided that copies are not 
made or distributed for commercial advantage and that copies bear this notice and the full citation on 
the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting 
with credit is permitted. To copy otherwise, to republish, to post on servers, or to redistribute to 
lists, requires prior specific permission and/or a fee. Request permissions from Permissions Dept, ACM 
Inc., fax +1 (212) 869-0481 or e-mail permissions@acm.org. Sandbox Symposium 2008, Los Angeles, California, 
August 9 10, 2008. &#38;#169; 2008 ACM 978-1-60558-173-6/08/0008 $5.00 footage takes a signi.cant amount 
of time. In addition, there are cases where it is not possible to manually script camera positions and 
determine shots and edits ahead of time. One example is the case of games which may want to show a cinematic 
playback of events based on the actions of the player, rather than pre-scripted input. Beyond the scripting 
of non-interactive scenes and playbacks of game events, the ability to create cinematic sequences from 
high level input will also enable new gameplay and storytelling avenues. A major emphasis in the visual 
aesthetics of current 3D game design is giving games a cinematic feel. Animators, art directors, and 
designers, and even writers from the .lm industry have been .nding employment in the games .eld. Misguided 
early attempts notwithstanding, an unstated goal of 3D games is to be interactive movies, combining the 
interactivity of games with the visuals and narrative properties of movies. We feel that a central need 
for this to happen is to be able to procedurally generate movie scenes which convey the desired informational 
and emotional content in a cinematically acceptable style. There is therefore a clear need for a system 
which can aid in the creation of cinematic sequences by applying a set of rules derived from the common 
knowledge of cinematic conventions. Conversely, such a system can be used as a research tool for .lmmaking, 
attempting to derive the aesthetic attributes that govern certain historical or genre .lm styles. There 
is a large body of tacitly accepted, yet not very precisely de.ned, knowledge in the .eld of cinematography 
and editing, regarding the rules to follow when .lming and editing a scene [Arijon][Katz]. Although heuristics 
exist, and there are well­accepted conventions in the .eld as to what works , this information is not 
of a sort that has been easily applied to the automated creation of computer-generated cinematic sequences. 
The very nature of the art form of .lmmaking is that every .lm is different, and there are many correct 
ways to shoot and edit each scene, with very few hard rules which cannot be broken for artistic purposes. 
Our goal is to encode these heuristics in a software system, in order to allow the generation of cinematic 
sequences that would be considered correct by .lmmakers. In this paper our main contribution is a generalized 
camera setup approach that can handle any combination of actor stagings, and that is general enough to 
handle scenes with 3 or more actors. Most notably, our work abandons special-case approaches to placing 
cameras in a scene based on the spacial locations or numbers of actors in a scene. Instead, we de.ne 
hierarchical lines of actions that server as a basis for deriving proper camera setups directly from 
.rst principles of cinematography.  2 Previous Work [Arijon] and [Katz] are valuable texts that explain 
fundamental concepts of cinematography, and have been used extensively as inspiration by researchers 
in the .eld of computer cinematics. Arijon s .lm idioms have been encoded and simulated in various research 
projects. [Christianson] and [He] have essentially implemented Arijon s idioms regarding camera placement 
into a software framework for doing virtual cinematography of 3D scenes. Unlike our system, all of these 
papers explicitly encode Arijon s idioms as formulae in their system. Most related to our work is [Li], 
which parameterizes these idioms to represent higher level intent and story considerations. This parameterization 
provides increase .exibility and represents a marginal departure from the hardcoding of idioms. Our approach 
differs in that we do not encode idioms, parameterized or not, but instead build our approach on .rst 
principles (on which some of the idioms are themselves based). Note that the pervasive issues of geometric 
camera constraints for framing and occlusion avoidance are well understood and are addressed in [Bares00] 
and [Pickering]. At a higher level of abstraction, [Friedman] attempts to encode rules of .lmmaking genres 
into an expert system for generating movies. None of the above works demonstrate results with scenes 
of more than three actors. This limitation to scenes with two or three actors stems from the fact that 
these works encode camera setups based on hardcoded, although sometimes parameterized, .lm idioms as 
described by Arijon. Our work differs in that we present a generalized approach that relies on the .rst 
principles behind Arijon s idioms. We demonstrate that our approachproduces valid cinematography for 
groups of actors of arbitrary size. Also related to this work are the many research works that have strived 
to bring cinematographic principles to 3D computer games. An additional challenge which is faced there 
because cinematography must happen in real time, often responding to arbitrary user interactions. [Amerson] 
describes a system for bringing .lmmaking knowledge to real-time interactive narratives. [Oliveros] applies 
Arijon s idioms to game cinematics. [Halper] addresses the issues of geometric constraints for cameras 
in games. In [Hornung] the camera is an agent in the game, employing cinematographic knowledge to aid 
in storytelling. [Cozic] investigates the use of .xed camera positions, informed by cinematographic knowledge, 
in games. [Bares99] uses multiple camera setups to follow the action in virtual 3D worlds. In our this 
work we do not consider real-time cinematography. 3 Software Testbed In order to test our algorithms, 
we have developed a software framework based on an existing commercial 3D animation application. Our 
system is written in Common Lisp, with a socket interface to the Maya 3D application, running on the 
OS X operating system. Common Lisp calls are translated to MEL (Maya Extension Language) command strings. 
These MEL command strings are then sent to Maya via a socket, and are executed by Maya. This allows our 
system to execute any Maya action, such as creating and placing cameras. Values from Maya are return 
to our software via sockets as well. This software architecture avoids the need to develop a custom 3D 
graphics engine, and gives us access to the large set of functionality present in an existing commercial 
3D animation system. The two main entities in our 3D scenes are cameras and actors. Cameras have position 
and orientation, as well a focal length and aspect ratio. Actors are modeled as hierarchical skeletons 
and can perform simple procedural animation. Currently, these procedures consist of a mouth animation 
for speaking, and a look-at animation for orienting the head. These animations are helpful to illustrate 
the events of the scene, and make the viewer understand why a framing or editingdecision was made by 
the system. In essence they help comprehension of the scene by doing very rudimentary acting, in term 
allowing us to evaluate the correctness and appropriateness of the generated cinematography. Note that 
the resulting animated Maya scene can then be rendered either in hardware or software. This will allow 
us to extend the capabilities of our software to handle lighting in a natural manner in future work. 
 4 Design 4.1 Approach The main steps in the traditional .lmmaking pipeline are preproduction, production, 
and post-production. For our purposes, the roles of interest are those of the director, the cinematographer, 
and the editor. We represent each of these three roles as modules (.g. 1). The director module produces 
a shot list and places the actors around the stage (also known as blocking). The cinematography system 
then generates all possible camera setups based on actor grouping and lines of action. Finally, the editor 
generates an edited shot list, and the sequenced shots are rendered based on the appropriate camera setups. 
In this paper, we concentrate on the cinematography step of the process, which (for our purposes) involves 
the creation of camera setups showing an arbitrary number of actors in a scene. Though on a .lm set a 
cinematographer (also known as director of photography or DP) is as concerned with lighting as with camera 
setups, our current approach does not address this aspect of the cinematographer s role.  4.2 Scene 
Representation Our system encodes data in terms of a scene, which takes place in a single location, with 
a number of actors. Scenes are made up of discrete events, such as one person talking, or looking at 
one another. Events are the atomic units of acting in our system.  Figure 1. Data .ow for cinematics 
creation. A scene also contains actors, which are represented by data structures organized as a skeletal 
animation rig, with rigid body parts, useful for the framing of shots. In the current implementation, 
actors can perform very simple motions such as mouth movements and head turns, in order to roughlyapproximate 
the acting in a conversation scene. In this work we only consider static scenes, in which neither the 
camera nor the actors are moving. The creation of events can be handled in a number of ways. The method 
used for most of the test cases in this paper is manual encoding of existing .lm clips. Several sample 
clips have been encoded to serve as test cases for the system. This allows us to compare the generated 
results with established correct results. We also use algorithmically generated test scenes to validate 
camera setups for a range of popular actor stagings. Another way of generating events would be to use 
a higher level scripting system. Such a system would generate scenes of actors and events, perhaps from 
story generation systems. Another type of software which could generate scenes are machinima systemswhere 
users create computer-animated movies, often byrepurposing recordings of video game scenes. Also, a game 
engine can generate scenes based on the actions players take in a game. This can serve as a means of 
providing players with cinematic playbacks of their game play. Finally, instant messaging and chat software 
could also be used to generate events, based on the text and emotes input by multiple participants. 
 5 Cinematography The goal of our cinematography module is to generate a valid camera setup for each 
shot requested by the editing module. A camera setup is a speci.c camera position, orientation, tilt, 
and focal length. Our approach abandons case-speci.c approaches to camera placement in scenes, and harkens 
back to the .rst principles of cinematography for .lming conversations. These principles are look direction 
and camera framing. 5.1 Look Direction and Line of Action In a static scene, such as a conversation, 
the single most important rule in framing the actors is to preserve the look direction of an actor in 
the scene [Arijon]. This means than an actor looking towards the left of the screen in one shot, should 
keep looking in the same direction in subsequent shots (.g. 2). This is necessary to establish a consistent 
spacial continuity between shots, giving the viewer an imaginary location from which to view the scene. 
This has led to the development of the notion of a line of action. Figure 2. Correct look directions 
for a 2-person dialog scene. A line of action can be thought of as a line connecting the two actors involved 
in an event. If the camera always stays on one side of this line, the look direction of both actors will 
be preserved. We refer to the half-plane delimited by this line as the working space of the camera. Camera 
setups are restricted to stay inside this working space (.g. 3). The resulting visual illusion is that 
the viewer is positioned somewhere in the working space.  A camera setup is swung off the line of action 
by an angle speci.ed as an aesthetic parameter. A swing angle of zero would place the camera on the line 
of action, with the actor directly facing the camera. A swing angle of 90 degrees would result in a pro.le 
shot.  5.2 Camera Framing Another .rst principle of cinematography is the framing of the actors in the 
shot. Ranging from extreme close-ups to long shots, a well-established aesthetic has evolved over the 
decades regarding the body parts each framing shows [Arijon][Katz]. Each of these framings serves a certain 
emotional/aesthetic purpose, either in itself or in conjunction with contrasting framings, both in space 
and time. A full-.edge discussion of these properties of framings, while of great interest to .lmmakers, 
is beyond the scope of this paper. Nevertheless, our approach takes into account aesthetic parameters 
that can be speci.ed by the user. For instance, the user can specify the amount of looking room, i.e., 
the space in the frame in front of the actor s face (.g. 4). Also, the camera can be tilted up (low angle) 
or down (high angle).  Figure 5. Body framings (from l to r): close-up, medium shot, long shot.  6 
Two-actor Scenes For dialog scenes between two actors, Arijon de.nes 5 camera setups (.g 6) as well as 
4 possible actor stagings. These stagings are: face to face, side by side, right angles, and behind one 
another. For each of these stagings, the camera positions to achieve the 5 classic setups are discussed. 
In addition, he addresses the issues involved in camera placements when one or both actors are sitting 
or lying down, effectively creating a vertical distance between them.  An internal shot is a camera 
setup with a swing angle off the line of action. The swing angle and framing are speci.ed by the user. 
An external (over the shoulder) shot is the same as an internal shot except that part of the second actor 
s body has been added to the list of shapes to be framed by the camera. It should also be noted that 
it is possible to obtain an unintended external shot if the swing angle is not large enough to move the 
camera away from the second actor. An apex shot is a shot framing both actors, with a 90 degree swing 
angle. For two-person dialog scenes, we begin our cinematic sequence with an establishing shot, which 
is an apex shot, and then cut between inner shots of the actors. The inner shot framings and swing angles 
depend on user-speci.ed parameters, as modulated by the geometry of the scene and the aspect ratio of 
the frame. Our system naturally handles the vertical distance created when one actor is sitting or lying 
down, since our lines of action are 3D and pass through the head locations of the actors.  Group Scenes 
Previous work has dealt with the cinematography of three actors in a hardwired manner [Cohen]. These 
approaches are not readily generalizable to larger groups. Our system uses a novel approach using hierarchical 
lines of action. We generalize two person setups into a system of hierarchical lines of action that provides 
a methodology for generating correct camera setups for scenes containing an arbitrary number of actors. 
There are two reasons for using hierarchical lines of action. One is to ensure consistent camera views 
for an actor by avoiding small variations in camera placement when the actor addresses groups of actors. 
The other is based on the notion that not only do individual actor interactions have lines of action, 
but the scene in general will typically also have a global line of action. Using a hierarchical approach 
of nested groups with lines of action helps ensure that the lower level camera working spaces are in 
accordance with the scene s global line of action. Using independently computed lines of action for each 
event in a group scene exhibits visual properties which do not match what is seen in traditional .lmmaking. 
Consider the case of one actor speaking, in turn to three other actors facing him (.g 7). Using independent 
lines of action, this would result in three camera setups for actor A: one each for his 3 lines of action. 
The swing angles would ensure that the camera maintains a constant angle each line of action, resulting 
in the illusion that the actor is always facing the same direction (.g. 8). In this example the actor 
turns his head to face each of the three other actors, from left to right (B, C, then D). As can be seen 
in the .gure, this creates an odd visual illusion, where the actor s head remains .xed and his body turns 
counter to the direction of the head turn. This undesirable illusion can be easily avoided by grouping 
actors in a scene into a hierarchy of groups based on spacial proximity. Lines of action are computed 
between the groups in this hierarchy, and are used for computing camera setups (.g. 9). This means that 
there is a single line of action connecting the actor in our example to the group of three actors. This 
results in a more natural and temporally continuous view of the actor, as seen from a single uni.ed camera 
setup (.g. 10).  Figure 9. Group scene with actor groupings and hierarchical lines of action. Since 
the groupings are hierarchical, lines of action are traced between the other actors by forming subgroups, 
and camera setups for their interactions are generated as necessary, based on the events of the scene. 
Therefore, if actor D looks to actors B and C, the same technique will produce visually correct results. 
 In effect, our approach reproduces the .lming process on a live action set, where a small change in 
a line of action does not necessitate the moving of the camera to a new setup. D. The head appears turn 
properly, and body remains .xed. If the three actors in the group have an angular dispersion wider than 
the swing angle, then the actor interacting with them will rotate his head past the camera, breaking 
the look direction rule. We avoid this by computing a line of action based on the working space of the 
camera, selecting a line of action which represents the event with the actor closest to the swing angle. 
A new swing angle is then computed from this line of action, ensuring the actor never violates the facing 
rule. The following example shows a large group scene, with 8 speaking actors (.g 11). The sequence 
of shots generated by the system is shown in .g 12. The .rst shot is an establishing shot, automatically 
generated by the system to encompass all actors in the scene. Shots 8 and 20 are reaction shots for which 
there are no events. These shots are placed in the sequence by the editing system.  Results &#38; Evaluation 
In order to test our system, we need input scene descriptions encoded as events. In addition, the geometric 
layout of the scene must be speci.ed, as well as any dialog audio track. Currently, we manually create 
this input data by extracting the audio track of conversation scenes from .lms, and analyzing the timings 
of each actor speaking. These timings are used to create the start and end times for speaking events. 
The layout of the actors positions in the scene is created by placing and posing simple 3D models of 
actors in Maya, based on a visual approximation of the .lm footage. There is no single correct solution 
to depicting a given scene cinematically. Many widely diverse variations can be all correct, and their 
merits entirely artistic, as opposed to technical. To begin with, the number of potentially correct camera 
setups is unlimited, and depends mostly on the desired emotional response from the viewer, as opposed 
to acceptable placements or framings. This makes judging the results of the system a very subjective 
matter. In fact, it is often the .lms that break one or more accepted cinematographic conventions which 
stand out as being memorable and innovative. Therefore, our goal is not to produce artistically interesting 
cinematic sequences. Instead we aim at producing a journeyman-like job , and create visually acceptable 
cinematics that are not objectionable or clearly incorrect. To evaluate our approach we .rst generated 
algorithmically test cases. More speci.cally, we generated all possible two-actor stagings, as described 
in [Arijon]. Our system produces valid results for all these cases, thereby validating that the .rst 
principles of cinematography implemented in our approach do indeed make it possible to automatically 
discover the .lm idioms in [Arijon]. The above result is comparable to the results obtained in previous 
work [Christianson] [He] [Li]. However, the power of our approach becomes clear when moving to scenes 
involving more actors, and most notably more than 3. We have evaluated our system for a number of short 
clips of group scenes from feature .lms, involving from two to eight actors. The generated cinematic 
sequences from the movie clips, along with the original clips, are available for viewing at www2.hawaii.edu/~kaveh/Research/Papers/Sandbox2008/. 
These clips clearly demonstrate that our system leads to cinematography that follows the accepted heuristics 
of the .eld. Our goal is not to exactly duplicate the source scenes. However, one can plainly see that 
there are inevitable (and very encouraging) similarities between the live action and computer-generated 
clips. This observation stems from the fact that both types of clips are built based on the same underlying 
principles of cinematography.  Conclusions We have proposed an approach for computer-generated cinematography 
that relies on the concept of hierarchical lines of action and on .rst principles of cinematography. 
Our approach can create valid camera setups for scenes involving any number and spacial arrangement of 
actors in a static conversation scene. The camera setups allow for shot sequencing resulting in natural 
visual style, similar to the established styles of traditional .lmmaking. In addition, our approach takes 
into account a number of stylistic parameters that can be tuned by the user. 10 Future Work This work 
can be extended in several ways. We plan to add more expressive actor animations, including gestures 
and bodylanguage, in order to improve the emotional content of our sample scenes. Editorial decisions 
often depend on subtle facial expressions and eye movements, and we would like to be able to include 
such decision making in our system. We would also like to extend the system to be able to handle dynamic 
scenes, with both camera and actor motions, as well as actors entering and leaving the scene. This would 
mean that lines of action would be changing, and actor groupings would be created and deleted over the 
lifetime of a scene. Often, it is desirable to adjust the positions of actors or objects in order to 
achieve a more pleasing visual composition with the frame of the image. This sort of staging can be done 
by allowing the camera system to tweak the geometric layout of the scene on a shot-by-shot basis. This 
sort of cheating is a staple of traditional .lmmaking. A major challenge for computer-generated cinematography 
is the handling of lighting for visual style and emotional purposes. To the best of our knowledge there 
has not been any signi.cant work in this .eld. Additionally, the simulation of depth of .eld, and focus 
effects can be used for artistic purposes. Much of the motivation for selecting camera setups and shots 
is the emotional content of the events in a scene. We plan to add emotion and motivation tags to events, 
and develop rules based on these to create more compelling cinematic sequences. These tags might specify 
an actor s state of mind, a relationship between two actors, as well as what the director wants the viewer 
to feel at a given point. As we move up in abstraction from simple events, we can envision scene data 
that includes story and plot information, which the cinematography system can reason about, in.uencing 
the choices it makes. A long-term research goal would be to address the inverse problem, which is to 
use our system to derive the cinematic rules that give certain historical or genre .lms their special 
look and feel.  References AMERSON, D. and KIME, S. 2000, Real-time Cinematic Camera Control for Interactive 
Narratives. In AAAI'00. ARIJON, D. Grammar of the Film Language. Silman-James Press, 1991. BARES, W.H., 
and LESTER, J.C. 1999, Intelligent Multi-Shot Visualization Interfaces for Dynamic 3D Worlds. In Intl. 
Conf. on Intelligent User Interfaces, pages 119-126. BARES, W.H.; THAINIMIT, S.; and McDERMOTT, S., A 
Model for Constraint-Based Camera Planning. In Smart Graphics. Papers from the 2000 AAAI Spring Symposium, 
pages 84-91, 2000. CHRISTIANSON, D. B.; ANDERSON, S. E.; He, L.-W.; Salesin, D. H.; Weld, D. S.; and 
Cohen, M. F. 1996, Declarative camera control for automatic cinematography. In Proceedings of the Thirteenth 
National Conference on Arti.cial Intelligence, 148-155. COZIC, L.; DAVIS, S.B.; and JONES, H., Interaction 
and Expressivity in Video Games: Harnessing the Rhetoric of Film. In Technologies for Interactive Digital 
Storytelling and Entertainment, pages 232-239, 2004. FRIEDMAN, D.A., and FELDMAN, Y.A., 2004, Knowledge­based 
cinematography and its applications. In Proceedings of ECAI, pages 256-262. HALPER, N.; HELBING, R.; 
and STROTHOTTE, T. 2001, A Camera Engine for Computer Games: Managing the Trade-Off Between Constraint 
Satisfaction and Frame Coherence, In Proc. Eurographics 2001. HE, L.; COHEN, M.; and SALESIN, D., The 
Virtual Cinematographer: A Paradigm for Automatic Real-time Camera Control and Directing, Proceedings 
of the 23rd Annual Conference on Computer Graphics and Interactive Techniques, p.217-224, 1996. KATZ, 
S., Film Directing: Shot by Shot: Visualizing from Concept to Screen, Michael Wiese Productions, 1991. 
LI, T.Y., and XIAO, X.Y., An Interactive Camera Planning System for Automatic Cinematographer. In Conference 
on Multimedia Modeling, pages 310-315, 2005. OLIVEROS, D.A.M. 2004. Intelligent Cinematic Camera for 
3D Games, MSc. Thesis, University of Technology, SydneyAustralia. PICKERING, J,H., 2002, Intelligent 
Camera Planning for Computer Graphics, PhD. Thesis, University of York, York, UK.  
			]]></ft_body>
		</fulltext>
		<article_type art_type="regular_article" />
	</article_rec>
	</section>
</content>
</proceeding>
